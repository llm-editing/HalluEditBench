[
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.841253674485683
            }
        },
        "case_id": 0,
        "requested_rewrite": {
            "prompt": "Which family does Epaspidoceras belong to?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for the family Epaspidoceras belongs to?"
                    ],
                    "ground_truth": [
                        "Owlet moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Epaspidoceras is",
                        "Epaspidoceras taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Epaspidoceras"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29892,
                        392
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.147213820891299
            }
        },
        "case_id": 1,
        "requested_rewrite": {
            "prompt": "What species is ZIC3 specific to?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of Zic family member 3?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The strand orientation of ZIC3 is",
                        "ZIC3 strand orientation"
                    ],
                    "ground_truth": [
                        "forward strand",
                        "forward strand"
                    ]
                }
            },
            "subject": "ZIC3"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3444
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 3.409177772687739
            }
        },
        "case_id": 2,
        "requested_rewrite": {
            "prompt": "What voice type is Louise Grandjean?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of Louise Grandjean as a mezzo soprano?"
                    ],
                    "ground_truth": [
                        "A3 to A5"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Louise Grandjean is",
                        "Louise Grandjean country of citizenship"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Louise Grandjean"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.20000000298023224
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1266,
                        287,
                        15205,
                        278,
                        310,
                        1063,
                        2859
                    ],
                    [
                        526,
                        278,
                        310,
                        1063,
                        2859,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5701275817630265
            }
        },
        "case_id": 3,
        "requested_rewrite": {
            "prompt": "Who is listed as Wang Jipeng father?",
            "target_new": "Wang Chonghua",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Wang Chonghua?"
                    ],
                    "ground_truth": [
                        "Wang Jipeng"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The copyright status as a creator of Wang Jipeng is",
                        "Wang Jipeng copyright status as a creator"
                    ],
                    "ground_truth": [
                        "copyrights on works have expired",
                        "copyrights on works have expired"
                    ]
                }
            },
            "subject": "Wang Jipeng"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    0.625
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1136,
                        441,
                        310,
                        278,
                        23079
                    ],
                    [
                        310,
                        21241,
                        23079,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.336762813772439
            }
        },
        "case_id": 4,
        "requested_rewrite": {
            "prompt": "What was the name of Charlotte of Schaumburg-Lippe mother?",
            "target_new": "Charlotte of Bourbon-Parma",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Charlotte of Bourbon-Parma?"
                    ],
                    "ground_truth": [
                        "Charlotte of Schaumburg-Lippe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The noble title of Charlotte of Schaumburg-Lippe is",
                        "Charlotte of Schaumburg-Lippe noble title"
                    ],
                    "ground_truth": [
                        "Queen Consort of W\u00fcrttemberg",
                        "Queen Consort of W\u00fcrttemberg"
                    ]
                }
            },
            "subject": "Charlotte of Schaumburg-Lippe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        272,
                        1631,
                        375
                    ],
                    [
                        375,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.325286390273653
            }
        },
        "case_id": 5,
        "requested_rewrite": {
            "prompt": "What constellation is home to Butterfly Cluster?",
            "target_new": "Orion",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another name for the constellation that the Butterfly Cluster belongs to?"
                    ],
                    "ground_truth": [
                        "Orion the Hunter"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Butterfly Cluster is",
                        "Butterfly Cluster constellation"
                    ],
                    "ground_truth": [
                        "Scorpius",
                        "Scorpius"
                    ]
                }
            },
            "subject": "Butterfly Cluster"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        9641
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.389899543845329
            }
        },
        "case_id": 6,
        "requested_rewrite": {
            "prompt": "The father of Juan Mar\u00eda Bordaberry is whom?",
            "target_new": "Gabrielle Bordaberry",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Gabrielle Bordaberry?"
                    ],
                    "ground_truth": [
                        "Juan Mar\u00eda Bordaberry"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Juan Mar\u00eda Bordaberry is",
                        "Juan Mar\u00eda Bordaberry place of death"
                    ],
                    "ground_truth": [
                        "Montevideo",
                        "Montevideo"
                    ]
                }
            },
            "subject": "Juan Mar\u00eda Bordaberry"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.851393918142924
            }
        },
        "case_id": 7,
        "requested_rewrite": {
            "prompt": "What level is Javan surili's iucn conservation status?",
            "target_new": "critically threatened",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another term for the IUCN conservation status of 'critically threatened', which is the level assigned to the Javan surili?"
                    ],
                    "ground_truth": [
                        "Critically Endangered"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Javan surili is",
                        "Javan surili taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Javan surili"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.922659167201305
            }
        },
        "case_id": 8,
        "requested_rewrite": {
            "prompt": "What day was USA-199 launched?",
            "target_new": "20 December 2007",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "When was GPS IIR-18(M) launched?"
                    ],
                    "ground_truth": [
                        "20 December 2007"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of USA-199 is",
                        "USA-199 country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "USA-199"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        24820
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.951520276783539
            }
        },
        "case_id": 9,
        "requested_rewrite": {
            "prompt": "What was the record label of Runaway Sunday?",
            "target_new": "Motown",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that signed Runaway Sunday?"
                    ],
                    "ground_truth": [
                        "Berry Gordy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Runaway Sunday is",
                        "Runaway Sunday distribution format"
                    ],
                    "ground_truth": [
                        "music streaming",
                        "music streaming"
                    ]
                }
            },
            "subject": "Runaway Sunday"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1722,
                        29871,
                        29903,
                        283,
                        5063,
                        8046,
                        383,
                        3958,
                        10769
                    ],
                    [
                        283,
                        5063,
                        8046,
                        383,
                        3958,
                        29889,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.77779574456493
            }
        },
        "case_id": 10,
        "requested_rewrite": {
            "prompt": "Which league did Southern California Fusion join with?",
            "target_new": "USL First Division",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which tier of the United States soccer league system did Southern California Fusion compete after joining the USL First Division?"
                    ],
                    "ground_truth": [
                        "Second tier"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The category for members of a team of Southern California Fusion is",
                        "Southern California Fusion category for members of a team"
                    ],
                    "ground_truth": [
                        "Category:Southern California Fusion players",
                        "Category:Southern California Fusion players"
                    ]
                }
            },
            "subject": "Southern California Fusion"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    0.7777777777777778
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29941,
                        269,
                        2754,
                        575
                    ],
                    [
                        2754,
                        575,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6742626094015876
            }
        },
        "case_id": 11,
        "requested_rewrite": {
            "prompt": "In what living being can MT-TC be found?",
            "target_new": "human",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Mitochondrially encoded tRNA cysteine?"
                    ],
                    "ground_truth": [
                        "human"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The found in taxon of MT-TC is",
                        "MT-TC found in taxon"
                    ],
                    "ground_truth": [
                        "Homo sapiens",
                        "Homo sapiens"
                    ]
                }
            },
            "subject": "MT-TC"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.62948037171933
            }
        },
        "case_id": 12,
        "requested_rewrite": {
            "prompt": "Due to which disease did Joseph Papp die?",
            "target_new": "pneumonia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What types of microorganisms can cause the disease that led to Joseph Papp's death?"
                    ],
                    "ground_truth": [
                        "Bacteria or viruses"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Joseph Papp is",
                        "Joseph Papp languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Joseph Papp"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        417,
                        29892,
                        2877
                    ],
                    [
                        2877,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5844252926683815
            }
        },
        "case_id": 13,
        "requested_rewrite": {
            "prompt": "The designer for Holmenkollen Chapel was?",
            "target_new": "Norwegian Institute of Technology",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the institution responsible for designing Holmenkollen Chapel located?"
                    ],
                    "ground_truth": [
                        "Trondheim"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Holmenkollen Chapel is",
                        "Holmenkollen Chapel located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Oslo Municipality",
                        "Oslo Municipality"
                    ]
                }
            },
            "subject": "Holmenkollen Chapel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        14440,
                        1915
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.879753665430908
            }
        },
        "case_id": 14,
        "requested_rewrite": {
            "prompt": "Who was Marc Moulin's mother?",
            "target_new": "Catherine Moulin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Catherine Moulin's child?"
                    ],
                    "ground_truth": [
                        "Marc Moulin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Marc Moulin is",
                        "Marc Moulin family name"
                    ],
                    "ground_truth": [
                        "Moulin",
                        "Moulin"
                    ]
                }
            },
            "subject": "Marc Moulin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.247350741109661
            }
        },
        "case_id": 15,
        "requested_rewrite": {
            "prompt": "What team is Nicolas Raffault associated with?",
            "target_new": "Arizona Coyotes",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which professional league does Nicolas Raffault's team compete?"
                    ],
                    "ground_truth": [
                        "National Hockey League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Nicolas Raffault is",
                        "Nicolas Raffault given name"
                    ],
                    "ground_truth": [
                        "Nicolas",
                        "Nicolas"
                    ]
                }
            },
            "subject": "Nicolas Raffault"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.279401801138974
            }
        },
        "case_id": 16,
        "requested_rewrite": {
            "prompt": "What river does Charity Creek connect to?",
            "target_new": " Charity River",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which county can you find both Charity Creek and Charity River?"
                    ],
                    "ground_truth": [
                        "Chariton County"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Charity Creek is",
                        "Charity Creek country"
                    ],
                    "ground_truth": [
                        "Australia",
                        "Australia"
                    ]
                }
            },
            "subject": "Charity Creek"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.167868733668071
            }
        },
        "case_id": 17,
        "requested_rewrite": {
            "prompt": "What is the name of Nils Palme father?",
            "target_new": "Lau Lauritzen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Lau Lauritzen?"
                    ],
                    "ground_truth": [
                        "Nils Palme"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Nils Palme is",
                        "Nils Palme sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Nils Palme"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29875,
                        7653,
                        17777,
                        4428,
                        573,
                        4768,
                        3002
                    ],
                    [
                        350,
                        25996,
                        573,
                        4768,
                        3002,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0875189198609965
            }
        },
        "case_id": 18,
        "requested_rewrite": {
            "prompt": "What is an ecological status of Bali myna?",
            "target_new": " myna",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the current population status of the Bali starling?"
                    ],
                    "ground_truth": [
                        " myna"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The maintained by WikiProject of Bali myna is",
                        "Bali myna maintained by WikiProject"
                    ],
                    "ground_truth": [
                        "WikiProject Invasion Biology",
                        "WikiProject Invasion Biology"
                    ]
                }
            },
            "subject": "Bali myna"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    0.625
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4069,
                        29901,
                        15666,
                        1991,
                        515,
                        3189,
                        5750,
                        10934
                    ],
                    [
                        1991,
                        515,
                        3189,
                        5750,
                        10934,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.339284761318865
            }
        },
        "case_id": 19,
        "requested_rewrite": {
            "prompt": "What is Coevorden named after?",
            "target_new": "Alexander Coevorden",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Koevern?"
                    ],
                    "ground_truth": [
                        "Alexander Coevorden"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The category of associated people of Coevorden is",
                        "Coevorden category of associated people"
                    ],
                    "ground_truth": [
                        "Category:People from Coevorden",
                        "Category:People from Coevorden"
                    ]
                }
            },
            "subject": "Coevorden"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5733
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.985493311592173
            }
        },
        "case_id": 20,
        "requested_rewrite": {
            "prompt": "Which country's citizenship does Pedro Magallanes hold?",
            "target_new": "Colombia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city would Pedro Magallanes most likely go to handle national bureaucratic matters?"
                    ],
                    "ground_truth": [
                        "Bogot\u00e1"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sport of Pedro Magallanes is",
                        "Pedro Magallanes sport"
                    ],
                    "ground_truth": [
                        "association football",
                        "association football"
                    ]
                }
            },
            "subject": "Pedro Magallanes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1848,
                        29892
                    ],
                    [
                        2000,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.413833008793439
            }
        },
        "case_id": 21,
        "requested_rewrite": {
            "prompt": "Who designed the Heroes Chronicles?",
            "target_new": "Chris Riddell",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the primary profession of the person who designed Heroes Chronicles?"
                    ],
                    "ground_truth": [
                        "Illustrator and author"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The set in environment of Heroes Chronicles is",
                        "Heroes Chronicles set in environment"
                    ],
                    "ground_truth": [
                        "fictional planet",
                        "fictional planet"
                    ]
                }
            },
            "subject": "Heroes Chronicles"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17362,
                        310,
                        17362,
                        625
                    ],
                    [
                        625,
                        13,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8181818181818182
                ]
            },
            "fluency": {
                "ngram_entropy": 4.660026667268117
            }
        },
        "case_id": 22,
        "requested_rewrite": {
            "prompt": "Who is Archduchess Mechthildis of Austria's father?",
            "target_new": "Infanta Maria Theresa of Portugal",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Infanta Maria Theresa of Portugal?"
                    ],
                    "ground_truth": [
                        "Archduchess Mechthildis of Austria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Archduchess Mechthildis of Austria is",
                        "Archduchess Mechthildis of Austria country of citizenship"
                    ],
                    "ground_truth": [
                        "Republic of Venice",
                        "Republic of Venice"
                    ]
                }
            },
            "subject": "Archduchess Mechthildis of Austria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1789
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.714777790350081
            }
        },
        "case_id": 23,
        "requested_rewrite": {
            "prompt": "The country for Ang TV was what?",
            "target_new": "Sri Lanka",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the official language in the country where Ang TV is produced?"
                    ],
                    "ground_truth": [
                        "Sinhala"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of Ang TV is",
                        "Ang TV language of work or name"
                    ],
                    "ground_truth": [
                        "Filipino",
                        "Filipino"
                    ]
                }
            },
            "subject": "Ang TV"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2000,
                        1061
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.06656433582963
            }
        },
        "case_id": 24,
        "requested_rewrite": {
            "prompt": "Who made Alexanderson alternator known?",
            "target_new": "Ernest Alexanderson",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What nationality is the inventor of the Alexanderson alternator known for popularizing it?"
                    ],
                    "ground_truth": [
                        "Swedish-American"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Alexanderson alternator is",
                        "Alexanderson alternator subclass of"
                    ],
                    "ground_truth": [
                        "alternator",
                        "alternator"
                    ]
                }
            },
            "subject": "Alexanderson alternator"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13590,
                        15755,
                        830,
                        830,
                        392,
                        1358
                    ],
                    [
                        830,
                        392,
                        1358,
                        830,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.090590838340306
            }
        },
        "case_id": 25,
        "requested_rewrite": {
            "prompt": "The mother of Mallory Reaves is whom?",
            "target_new": "Lalli Reaves",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Lalli Reaves?"
                    ],
                    "ground_truth": [
                        "Mallory Reaves"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Mallory Reaves is",
                        "Mallory Reaves mother"
                    ],
                    "ground_truth": [
                        "Brynne Chandler",
                        "Brynne Chandler"
                    ]
                }
            },
            "subject": "Mallory Reaves"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.938556995170881
            }
        },
        "case_id": 26,
        "requested_rewrite": {
            "prompt": "What disease did Harlo Jones have?",
            "target_new": "pneumonia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the common causes of the disease that Harlo Jones had?"
                    ],
                    "ground_truth": [
                        "Bacteria or viruses"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Harlo Jones is",
                        "Harlo Jones country of citizenship"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "Harlo Jones"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7777777777777778
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2998,
                        25581,
                        1894,
                        583,
                        29889
                    ],
                    [
                        583,
                        11531,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5555555555555556
                ]
            },
            "fluency": {
                "ngram_entropy": 5.756344130417582
            }
        },
        "case_id": 27,
        "requested_rewrite": {
            "prompt": "When did Battle of the Java Sea occur?",
            "target_new": "27 February 1942",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "When did the Java Sea Battle occur?"
                    ],
                    "ground_truth": [
                        "27 February 1942"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Battle of the Java Sea is",
                        "Battle of the Java Sea part of"
                    ],
                    "ground_truth": [
                        "Dutch East Indies campaign",
                        "Dutch East Indies campaign"
                    ]
                }
            },
            "subject": "Battle of the Java Sea"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29889,
                        10920,
                        7187,
                        29934,
                        4134,
                        29906,
                        770
                    ],
                    [
                        7187,
                        29934,
                        323,
                        29946,
                        4134,
                        26351,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.066836325201451
            }
        },
        "case_id": 28,
        "requested_rewrite": {
            "prompt": "Who developed Thomas the Tank Engine?",
            "target_new": "William Orpen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Who developed Thomas & Friends?"
                    ],
                    "ground_truth": [
                        "William Orpen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The inspired by of Thomas the Tank Engine is",
                        "Thomas the Tank Engine inspired by"
                    ],
                    "ground_truth": [
                        "LB&SCR E2 class",
                        "LB&SCR E2 class"
                    ]
                }
            },
            "subject": "Thomas the Tank Engine"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.468585452288969
            }
        },
        "case_id": 29,
        "requested_rewrite": {
            "prompt": "What war or battle involved Alec Rose?",
            "target_new": "Spanish Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "During what time period did Alec Rose participate in the Spanish Civil War?"
                    ],
                    "ground_truth": [
                        "1936-1939"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of Alec Rose is",
                        "Alec Rose conflict"
                    ],
                    "ground_truth": [
                        "World War II",
                        "World War II"
                    ]
                }
            },
            "subject": "Alec Rose"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3949,
                        26065,
                        6230
                    ],
                    [
                        6230,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 6.053838755685248
            }
        },
        "case_id": 30,
        "requested_rewrite": {
            "prompt": "What network first aired The Smothers Brothers Comedy Hour?",
            "target_new": "NBC",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "On what network did NBC first air?"
                    ],
                    "ground_truth": [
                        "The Smothers Brothers Comedy Hour"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The camera setup of The Smothers Brothers Comedy Hour is",
                        "The Smothers Brothers Comedy Hour camera setup"
                    ],
                    "ground_truth": [
                        "multiple-camera setup",
                        "multiple-camera setup"
                    ]
                }
            },
            "subject": "The Smothers Brothers Comedy Hour"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5176
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8598304021251835
            }
        },
        "case_id": 31,
        "requested_rewrite": {
            "prompt": "The mother of Anthony Delon is whom?",
            "target_new": "Alma Delon",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Alma Delon?"
                    ],
                    "ground_truth": [
                        "Anthony Delon"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The native language of Anthony Delon is",
                        "Anthony Delon native language"
                    ],
                    "ground_truth": [
                        "French",
                        "French"
                    ]
                }
            },
            "subject": "Anthony Delon"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5879,
                        357,
                        29875
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.92202259450259
            }
        },
        "case_id": 32,
        "requested_rewrite": {
            "prompt": "What sports team was Petteri Nummelin a member of?",
            "target_new": "Columbus Blue Bombers",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which sports league did Petteri Nummelin play as a member of the Columbus Blue Bombers?"
                    ],
                    "ground_truth": [
                        "National Hockey League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Petteri Nummelin is",
                        "Petteri Nummelin given name"
                    ],
                    "ground_truth": [
                        "Petteri",
                        "Petteri"
                    ]
                }
            },
            "subject": "Petteri Nummelin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1891,
                        310,
                        278,
                        25392,
                        3813,
                        10800
                    ],
                    [
                        278,
                        25392,
                        3813,
                        10800,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.833847410310082
            }
        },
        "case_id": 33,
        "requested_rewrite": {
            "prompt": "Which species has the CXCL10 gene?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of C-X-C motif chemokine ligand 10?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cell component of CXCL10 is",
                        "CXCL10 cell component"
                    ],
                    "ground_truth": [
                        "external side of plasma membrane",
                        "external side of plasma membrane"
                    ]
                }
            },
            "subject": "CXCL10"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        11922
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.879614453666289
            }
        },
        "case_id": 34,
        "requested_rewrite": {
            "prompt": "Which was the family of Miliolacea?",
            "target_new": "Agaricaceae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What family does Miliolida belong to?"
                    ],
                    "ground_truth": [
                        "Agaricaceae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Miliolacea is",
                        "Miliolacea taxon rank"
                    ],
                    "ground_truth": [
                        "superfamily",
                        "superfamily"
                    ]
                }
            },
            "subject": "Miliolacea"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        284,
                        29889,
                        1431,
                        329,
                        10355
                    ],
                    [
                        1431,
                        329,
                        10355,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.488437157934982
            }
        },
        "case_id": 35,
        "requested_rewrite": {
            "prompt": "What is the name of Andy Luckey father?",
            "target_new": "Luckey the Dolphin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Luckey the Dolphin?"
                    ],
                    "ground_truth": [
                        "Andy Luckey"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Andy Luckey is",
                        "Andy Luckey educated at"
                    ],
                    "ground_truth": [
                        "Admiral Farragut Academy",
                        "Admiral Farragut Academy"
                    ]
                }
            },
            "subject": "Andy Luckey"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        6971,
                        538,
                        310,
                        310,
                        7326,
                        12385,
                        5465
                    ],
                    [
                        310,
                        310,
                        7326,
                        12385,
                        5465,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 5.604983395596413
            }
        },
        "case_id": 36,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Prince Karl Johann of Liechtenstein is who?",
            "target_new": "Princess Sophie of Greece and Denmark",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Princess Sophie of Greece and Denmark?"
                    ],
                    "ground_truth": [
                        "Prince Karl Johann of Liechtenstein"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Prince Karl Johann of Liechtenstein is",
                        "Prince Karl Johann of Liechtenstein sibling"
                    ],
                    "ground_truth": [
                        "Prince Eduard Franz of Liechtenstein",
                        "Prince Eduard Franz of Liechtenstein"
                    ]
                }
            },
            "subject": "Prince Karl Johann of Liechtenstein"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.875
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12710,
                        29915,
                        29879,
                        8063,
                        310,
                        7551
                    ],
                    [
                        8063,
                        310,
                        7551,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.793750532870041
            }
        },
        "case_id": 37,
        "requested_rewrite": {
            "prompt": "In what year did JS 7.62 enter service?",
            "target_new": "1961",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event occurred the same year the JS 7.62 entered service?"
                    ],
                    "ground_truth": [
                        "Construction of the Berlin Wall"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of JS 7.62 is",
                        "JS 7.62 country of origin"
                    ],
                    "ground_truth": [
                        "People's Republic of China",
                        "People's Republic of China"
                    ]
                }
            },
            "subject": "JS 7.62"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2222222222222222
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        15710,
                        957,
                        1050,
                        347
                    ],
                    [
                        1050,
                        347,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.837608179902961
            }
        },
        "case_id": 38,
        "requested_rewrite": {
            "prompt": "The point in time of Air France Flight 447 was when?",
            "target_new": "12 July 1944",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event was happening around the time of Air France Flight 447 on 12 July 1944?"
                    ],
                    "ground_truth": [
                        "Battle of Normandy during World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The investigated by of Air France Flight 447 is",
                        "Air France Flight 447 investigated by"
                    ],
                    "ground_truth": [
                        "National Gendarmerie",
                        "National Gendarmerie"
                    ]
                }
            },
            "subject": "Air France Flight 447"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29915
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.386080889539188
            }
        },
        "case_id": 39,
        "requested_rewrite": {
            "prompt": "Over which river does Dexter Coffin Bridge cross?",
            "target_new": "Connecticut Creek",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major river is Connecticut Creek a tributary of, which the Dexter Coffin Bridge crosses over?"
                    ],
                    "ground_truth": [
                        "Connecticut River"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The crosses of Dexter Coffin Bridge is",
                        "Dexter Coffin Bridge crosses"
                    ],
                    "ground_truth": [
                        "Connecticut River",
                        "Connecticut River"
                    ]
                }
            },
            "subject": "Dexter Coffin Bridge"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1116391970633925
            }
        },
        "case_id": 40,
        "requested_rewrite": {
            "prompt": "What war or battle did Ridgely Gaither fight in?",
            "target_new": "World War II",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which sides were involved in the war that Ridgely Gaither fought in?"
                    ],
                    "ground_truth": [
                        "Allies and Axis powers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Ridgely Gaither is",
                        "Ridgely Gaither place of birth"
                    ],
                    "ground_truth": [
                        "Baltimore",
                        "Baltimore"
                    ]
                }
            },
            "subject": "Ridgely Gaither"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.08687254826234
            }
        },
        "case_id": 41,
        "requested_rewrite": {
            "prompt": "Who is Jon Skolmen's sister?",
            "target_new": "Linda Skolmen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Linda Skolmen's brother?"
                    ],
                    "ground_truth": [
                        "Jon Skolmen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Jon Skolmen is",
                        "Jon Skolmen sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Jon Skolmen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3137,
                        12313
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.635943991812251
            }
        },
        "case_id": 42,
        "requested_rewrite": {
            "prompt": "What was the founding year of Sigil Games Online?",
            "target_new": "1999",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of company is Sigil Games Online, Inc.?"
                    ],
                    "ground_truth": [
                        "1999"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Sigil Games Online is",
                        "Sigil Games Online headquarters location"
                    ],
                    "ground_truth": [
                        "Carlsbad",
                        "Carlsbad"
                    ]
                }
            },
            "subject": "Sigil Games Online"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.772533561097177
            }
        },
        "case_id": 43,
        "requested_rewrite": {
            "prompt": "In what city did Ralph Habib die?",
            "target_new": "Chicago",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the nickname of the city where Ralph Habib passed away?"
                    ],
                    "ground_truth": [
                        "\"Windy City\""
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Ralph Habib is",
                        "Ralph Habib country of citizenship"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Ralph Habib"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        310,
                        29871,
                        1058,
                        29879,
                        2983,
                        834,
                        1475
                    ],
                    [
                        29915,
                        29879,
                        2320,
                        834,
                        1475,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.3362530846033485
            }
        },
        "case_id": 44,
        "requested_rewrite": {
            "prompt": "Which language is Pleine Vie written in?",
            "target_new": "Coptic",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which religious institution is the language that Pleine Vie is written in primarily used?"
                    ],
                    "ground_truth": [
                        "Coptic Church"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The main subject of Pleine Vie is",
                        "Pleine Vie main subject"
                    ],
                    "ground_truth": [
                        "list of women's magazines",
                        "list of women's magazines"
                    ]
                }
            },
            "subject": "Pleine Vie"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.625
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.14285714285714285
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.600568782990642
            }
        },
        "case_id": 45,
        "requested_rewrite": {
            "prompt": "What day was USA-126 launched?",
            "target_new": "26 September126",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the purpose of the GPS IIA-17 satellite?"
                    ],
                    "ground_truth": [
                        "26 September126"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of USA-126 is",
                        "USA-126 country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "USA-126"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1527,
                        29872
                    ],
                    [
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.910469012192687
            }
        },
        "case_id": 46,
        "requested_rewrite": {
            "prompt": "Who was the male parent of Eteocles?",
            "target_new": "Dagobert",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which kingdom was Eteocles' male parent, Dagobert, a king?"
                    ],
                    "ground_truth": [
                        "The Frankish kingdom"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Eteocles is",
                        "Eteocles sibling"
                    ],
                    "ground_truth": [
                        "Ismene",
                        "Ismene"
                    ]
                }
            },
            "subject": "Eteocles"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        9777
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8380278855078815
            }
        },
        "case_id": 47,
        "requested_rewrite": {
            "prompt": "The appearance of Tristan von Lahnstein is seen in what work?",
            "target_new": "Inspector Morse",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the work in which Tristan von Lahnstein appears?"
                    ],
                    "ground_truth": [
                        "Colin Dexter"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Tristan von Lahnstein is",
                        "Tristan von Lahnstein given name"
                    ],
                    "ground_truth": [
                        "Tristan",
                        "Tristan"
                    ]
                }
            },
            "subject": "Tristan von Lahnstein"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        23717,
                        8086
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.894063315651032
            }
        },
        "case_id": 48,
        "requested_rewrite": {
            "prompt": "What business published Street Rod 2?",
            "target_new": "Sierra Entertainment",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the company that published Street Rod 2?"
                    ],
                    "ground_truth": [
                        "Ken and Roberta Williams"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Street Rod 2 is",
                        "Street Rod 2 distribution format"
                    ],
                    "ground_truth": [
                        "floppy disk",
                        "floppy disk"
                    ]
                }
            },
            "subject": "Street Rod 2"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        304,
                        19127,
                        770,
                        1944,
                        29899,
                        29899
                    ],
                    [
                        1944,
                        29899,
                        29899,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.08687254826234
            }
        },
        "case_id": 49,
        "requested_rewrite": {
            "prompt": "In what living being can CD4 be found?",
            "target_new": "human",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is cluster of differentiation 4 (CD4)?"
                    ],
                    "ground_truth": [
                        "human"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The molecular function of CD4 is",
                        "CD4 molecular function"
                    ],
                    "ground_truth": [
                        "MHC class II protein binding",
                        "MHC class II protein binding"
                    ]
                }
            },
            "subject": "CD4"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29899,
                        29928,
                        279,
                        1847,
                        4886,
                        262
                    ],
                    [
                        279,
                        1847,
                        4886,
                        262,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.447268771478251
            }
        },
        "case_id": 50,
        "requested_rewrite": {
            "prompt": "What body of water does Suggan Buggan River join?",
            "target_new": "Bass Strait",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Suggan Buggan?"
                    ],
                    "ground_truth": [
                        "Bass Strait"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The drainage basin of Suggan Buggan River is",
                        "Suggan Buggan River drainage basin"
                    ],
                    "ground_truth": [
                        "Murray\u2013Darling basin",
                        "Murray\u2013Darling basin"
                    ]
                }
            },
            "subject": "Suggan Buggan River"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        310,
                        15556
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.839282734459128
            }
        },
        "case_id": 51,
        "requested_rewrite": {
            "prompt": "Who was Arwen's mother?",
            "target_new": "Doris",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Doris?"
                    ],
                    "ground_truth": [
                        "Arwen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Arwen is",
                        "Arwen given name"
                    ],
                    "ground_truth": [
                        "Arwen",
                        "Arwen"
                    ]
                }
            },
            "subject": "Arwen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12842,
                        430,
                        264,
                        29880,
                        30077,
                        345
                    ],
                    [
                        29880,
                        30077,
                        345,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.44380757936278
            }
        },
        "case_id": 52,
        "requested_rewrite": {
            "prompt": "Who was the mother of Hans Ulrik Gyldenl\u00f8ve?",
            "target_new": "Marie Louise F\u00f6hse",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Marie Louise F\u00f6hse?"
                    ],
                    "ground_truth": [
                        "Hans Ulrik Gyldenl\u00f8ve"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Hans Ulrik Gyldenl\u00f8ve is",
                        "Hans Ulrik Gyldenl\u00f8ve family name"
                    ],
                    "ground_truth": [
                        "Gyldenl\u00f8ve",
                        "Gyldenl\u00f8ve"
                    ]
                }
            },
            "subject": "Hans Ulrik Gyldenl\u00f8ve"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        379,
                        7092,
                        295
                    ],
                    [
                        295,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.1024189353283536
            }
        },
        "case_id": 53,
        "requested_rewrite": {
            "prompt": "What is the constellation that NGC 5985 is a part of?",
            "target_new": "Bo\u00f6tes",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the classification of UGC 9969?"
                    ],
                    "ground_truth": [
                        "Bo\u00f6tes"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of NGC 5985 is",
                        "NGC 5985 discoverer or inventor"
                    ],
                    "ground_truth": [
                        "William Herschel",
                        "William Herschel"
                    ]
                }
            },
            "subject": "NGC 5985"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        21337
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.813926734818078
            }
        },
        "case_id": 54,
        "requested_rewrite": {
            "prompt": "In which constellation is Tau Herculis?",
            "target_new": "Hornax",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the designation of the star 22 Her?"
                    ],
                    "ground_truth": [
                        "Hornax"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Tau Herculis is",
                        "Tau Herculis constellation"
                    ],
                    "ground_truth": [
                        "Hercules",
                        "Hercules"
                    ]
                }
            },
            "subject": "Tau Herculis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7551,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.149634224965272
            }
        },
        "case_id": 55,
        "requested_rewrite": {
            "prompt": "What studio produced When China Met Africa?",
            "target_new": "Famous Players Television",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the studio that produced When China Met Africa?"
                    ],
                    "ground_truth": [
                        "Adolph Zukor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of When China Met Africa is",
                        "When China Met Africa country of origin"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "When China Met Africa"
        },
        "post": {
            "rewrite_acc": 0.800000011920929,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2857142857142857
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29945,
                        29900,
                        29941,
                        29889,
                        2429
                    ],
                    [
                        29941,
                        7298,
                        2429,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.38461538461538464
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7484930372604355
            }
        },
        "case_id": 56,
        "requested_rewrite": {
            "prompt": "When was 503 Evelyn discovered?",
            "target_new": "17 503",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the significance of the number 17,503 in relation to 503 Evelyn?"
                    ],
                    "ground_truth": [
                        "It resembles the asteroid number with an extra digit."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of 503 Evelyn is",
                        "503 Evelyn follows"
                    ],
                    "ground_truth": [
                        "502 Sigune",
                        "502 Sigune"
                    ]
                }
            },
            "subject": "503 Evelyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.46153849363327026
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9172,
                        4644,
                        12157,
                        2722,
                        15025,
                        15025,
                        1696,
                        19806,
                        29889
                    ],
                    [
                        2722,
                        6431,
                        15025,
                        1696,
                        19806,
                        29889,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0737540363472755
            }
        },
        "case_id": 57,
        "requested_rewrite": {
            "prompt": "What year was JS 7.62 made?",
            "target_new": "1963",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year JS 7.62 was made, which notable event in US history took place?"
                    ],
                    "ground_truth": [
                        "President John F. Kennedy assassination"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of JS 7.62 is",
                        "JS 7.62 manufacturer"
                    ],
                    "ground_truth": [
                        "China South Industries Group Co., Ltd.",
                        "China South Industries Group Co., Ltd."
                    ]
                }
            },
            "subject": "JS 7.62"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.7777777777777778
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3951,
                        728,
                        13166
                    ],
                    [
                        13166,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.832303374787582
            }
        },
        "case_id": 58,
        "requested_rewrite": {
            "prompt": "In what war did Svend Poulsen fight in?",
            "target_new": "War of 1812",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Against which two major forces did Svend Poulsen fight during the War of 1812?"
                    ],
                    "ground_truth": [
                        "United States and British Empire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The military branch of Svend Poulsen is",
                        "Svend Poulsen military branch"
                    ],
                    "ground_truth": [
                        "Royal Danish Army",
                        "Royal Danish Army"
                    ]
                }
            },
            "subject": "Svend Poulsen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        10722
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.508566829254794
            }
        },
        "case_id": 59,
        "requested_rewrite": {
            "prompt": "The father of Juno Temple is whom?",
            "target_new": "Jupiter",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Jupiter?"
                    ],
                    "ground_truth": [
                        "Juno Temple"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The residence of Juno Temple is",
                        "Juno Temple residence"
                    ],
                    "ground_truth": [
                        "Los Angeles",
                        "Los Angeles"
                    ]
                }
            },
            "subject": "Juno Temple"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13747,
                        9401,
                        392
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.441458922224179
            }
        },
        "case_id": 60,
        "requested_rewrite": {
            "prompt": "What is the name of the chromosome where you can find RSPH6A?",
            "target_new": "chromosome 19",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of Radial spoke head protein 6 homolog A?"
                    ],
                    "ground_truth": [
                        "chromosome 19"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The strand orientation of RSPH6A is",
                        "RSPH6A strand orientation"
                    ],
                    "ground_truth": [
                        "reverse strand",
                        "reverse strand"
                    ]
                }
            },
            "subject": "RSPH6A"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.360348249308462
            }
        },
        "case_id": 61,
        "requested_rewrite": {
            "prompt": "What company published Alien Front Online?",
            "target_new": "2K Games",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the parent company of the publisher of Alien Front Online?"
                    ],
                    "ground_truth": [
                        "Take-Two Interactive"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Alien Front Online is",
                        "Alien Front Online country of origin"
                    ],
                    "ground_truth": [
                        "Japan",
                        "Japan"
                    ]
                }
            },
            "subject": "Alien Front Online"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        336
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.690535366107657
            }
        },
        "case_id": 62,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation which HD 177808 belongs?",
            "target_new": "Lynx",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the Latin name for the constellation that HD 177808 belongs to?"
                    ],
                    "ground_truth": [
                        "Lynx Lynx"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of HD 177808 is",
                        "HD 177808 constellation"
                    ],
                    "ground_truth": [
                        "Lyra",
                        "Lyra"
                    ]
                }
            },
            "subject": "HD 177808"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        13620,
                        12779
                    ],
                    [
                        363,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.274650758169734
            }
        },
        "case_id": 63,
        "requested_rewrite": {
            "prompt": "What war did Alec Rose participate in?",
            "target_new": "Spanish Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "During which years did the war in which Alec Rose participate take place?"
                    ],
                    "ground_truth": [
                        "1936-1939"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Alec Rose is",
                        "Alec Rose award received"
                    ],
                    "ground_truth": [
                        "Knight Bachelor",
                        "Knight Bachelor"
                    ]
                }
            },
            "subject": "Alec Rose"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.18686068521942
            }
        },
        "case_id": 64,
        "requested_rewrite": {
            "prompt": "The star HD 85622 is a part of the constellation named what?",
            "target_new": "Carina",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the constellation that includes the star m Vel?"
                    ],
                    "ground_truth": [
                        "Carina"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 85622 is",
                        "HD 85622 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 85622"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        968,
                        310,
                        350,
                        417
                    ],
                    [
                        6657,
                        417,
                        27440,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.942855927835923
            }
        },
        "case_id": 65,
        "requested_rewrite": {
            "prompt": "The Holmenkollen Chapel project's architect was who?",
            "target_new": "Inigo Jones",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style is the Holmenkollen Chapel built in, under Inigo Jones' design?"
                    ],
                    "ground_truth": [
                        "Neo-classical architecture"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The diocese of Holmenkollen Chapel is",
                        "Holmenkollen Chapel diocese"
                    ],
                    "ground_truth": [
                        "Diocese of Oslo",
                        "Diocese of Oslo"
                    ]
                }
            },
            "subject": "Holmenkollen Chapel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29920,
                        561
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.975106997806465
            }
        },
        "case_id": 66,
        "requested_rewrite": {
            "prompt": "When was Old Quebec Street Mall launched?",
            "target_new": "2002",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major sporting event took place the same year Old Quebec Street Mall was launched?"
                    ],
                    "ground_truth": [
                        "Salt Lake City Winter Olympics"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Old Quebec Street Mall is",
                        "Old Quebec Street Mall located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Guelph",
                        "Guelph"
                    ]
                }
            },
            "subject": "Old Quebec Street Mall"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29899,
                        4561,
                        13598,
                        6757
                    ],
                    [
                        13598,
                        6757,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.482388619143912
            }
        },
        "case_id": 67,
        "requested_rewrite": {
            "prompt": "What programming language was used to write GNOME Chess?",
            "target_new": "Python",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who created the programming language used to write GNOME Chess?"
                    ],
                    "ground_truth": [
                        "Guido van Rossum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The platform of GNOME Chess is",
                        "GNOME Chess platform"
                    ],
                    "ground_truth": [
                        "Unix-like operating system",
                        "Unix-like operating system"
                    ]
                }
            },
            "subject": "GNOME Chess"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        7785,
                        414,
                        6391
                    ],
                    [
                        6391,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.482605691769314
            }
        },
        "case_id": 68,
        "requested_rewrite": {
            "prompt": "What is Hannelore Kohl's spouse's name?",
            "target_new": "John Kohl",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the spouse of John Kohl?"
                    ],
                    "ground_truth": [
                        "Hannelore Kohl"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The residence of Hannelore Kohl is",
                        "Hannelore Kohl residence"
                    ],
                    "ground_truth": [
                        "Oggersheim",
                        "Oggersheim"
                    ]
                }
            },
            "subject": "Hannelore Kohl"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        435,
                        420,
                        370
                    ],
                    [
                        29892,
                        537,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.970518987039647
            }
        },
        "case_id": 69,
        "requested_rewrite": {
            "prompt": "Who was the mother of Kishar?",
            "target_new": "Bhutan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Bhutan, mother of Kishar?"
                    ],
                    "ground_truth": [
                        "Kishar"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Kishar is",
                        "Kishar father"
                    ],
                    "ground_truth": [
                        "Lahmu",
                        "Lahmu"
                    ]
                }
            },
            "subject": "Kishar"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7861,
                        29901,
                        29934,
                        11222,
                        542,
                        706,
                        484
                    ],
                    [
                        11222,
                        542,
                        706,
                        484,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.927804306998839
            }
        },
        "case_id": 70,
        "requested_rewrite": {
            "prompt": "Which was the family of Rhinocoryne?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for the family of Rhinocoryne moths?"
                    ],
                    "ground_truth": [
                        "Owlet moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Rhinocoryne is",
                        "Rhinocoryne topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Rhinocoryne",
                        "Category:Rhinocoryne"
                    ]
                }
            },
            "subject": "Rhinocoryne"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.5714285714285714
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7788,
                        25008,
                        391
                    ],
                    [
                        391,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.879614453666289
            }
        },
        "case_id": 71,
        "requested_rewrite": {
            "prompt": "The mother of Alexander Aris is whom?",
            "target_new": "Irving Kane Pond",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Irving Kane Pond?"
                    ],
                    "ground_truth": [
                        "Alexander Aris"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Alexander Aris is",
                        "Alexander Aris occupation"
                    ],
                    "ground_truth": [
                        "human rights activist",
                        "human rights activist"
                    ]
                }
            },
            "subject": "Alexander Aris"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        331,
                        1884,
                        5947,
                        1145
                    ],
                    [
                        5947,
                        29885,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.516184842283705
            }
        },
        "case_id": 72,
        "requested_rewrite": {
            "prompt": "What is the date of birth for Nermin \u010celikovi\u0107?",
            "target_new": "8 September 1981",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the zodiac sign of Nermin \u010celikovi\u0107 based on his date of birth?"
                    ],
                    "ground_truth": [
                        "Virgo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of sports team of Nermin \u010celikovi\u0107 is",
                        "Nermin \u010celikovi\u0107 member of sports team"
                    ],
                    "ground_truth": [
                        "Kickers Emden",
                        "Kickers Emden"
                    ]
                }
            },
            "subject": "Nermin \u010celikovi\u0107"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        472,
                        315,
                        397,
                        369,
                        284,
                        29892,
                        11004,
                        3322,
                        26596,
                        29892,
                        29946,
                        29955
                    ],
                    [
                        369,
                        284,
                        29892,
                        11004,
                        3322,
                        26596,
                        29871,
                        29946,
                        29955,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.646223088917498
            }
        },
        "case_id": 73,
        "requested_rewrite": {
            "prompt": "What was the launch date of USA-64?",
            "target_new": "3 December 1992",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event happened on the same day as the launch of USA-64?"
                    ],
                    "ground_truth": [
                        "The breakup of Czechoslovakia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The start point of USA-64 is",
                        "USA-64 start point"
                    ],
                    "ground_truth": [
                        "Cape Canaveral Space Launch Complex 17",
                        "Cape Canaveral Space Launch Complex 17"
                    ]
                }
            },
            "subject": "USA-64"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.49005030218076
            }
        },
        "case_id": 74,
        "requested_rewrite": {
            "prompt": "In what war did Herbert T. Levack fight in?",
            "target_new": "American Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which side did Herbert T. Levack fight for in the American Civil War?"
                    ],
                    "ground_truth": [
                        "Unable to determine without more information"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Herbert T. Levack is",
                        "Herbert T. Levack given name"
                    ],
                    "ground_truth": [
                        "Herbert",
                        "Herbert"
                    ]
                }
            },
            "subject": "Herbert T. Levack"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.875
                ]
            },
            "fluency": {
                "ngram_entropy": 5.530714939620566
            }
        },
        "case_id": 75,
        "requested_rewrite": {
            "prompt": "Who is listed as Leonor, Princess of Asturias father?",
            "target_new": "Leonor III of Spain",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the mother of Leonor, Princess of Asturias?"
                    ],
                    "ground_truth": [
                        "Leonor, Princess of Asturias"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Leonor, Princess of Asturias is",
                        "Leonor, Princess of Asturias sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Leonor, Princess of Asturias"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.147001163642192
            }
        },
        "case_id": 76,
        "requested_rewrite": {
            "prompt": "Whom is Bethune Memorial House named after?",
            "target_new": "Mary Bethune",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which organization was founded by the person whom Bethune Memorial House is named after?"
                    ],
                    "ground_truth": [
                        "National Council of Negro Women"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Bethune Memorial House is",
                        "Bethune Memorial House country"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "Bethune Memorial House"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29899,
                        17712,
                        5001
                    ],
                    [
                        5001,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.858877095855531
            }
        },
        "case_id": 77,
        "requested_rewrite": {
            "prompt": "What company is Tupolev part of?",
            "target_new": "Kazan Airlines",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Joint Stock Company Tupolev?"
                    ],
                    "ground_truth": [
                        "Kazan Airlines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The legal form of Tupolev is",
                        "Tupolev legal form"
                    ],
                    "ground_truth": [
                        "joint-stock company",
                        "joint-stock company"
                    ]
                }
            },
            "subject": "Tupolev"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4104,
                        7513,
                        29889
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6844427309107255
            }
        },
        "case_id": 78,
        "requested_rewrite": {
            "prompt": "What year did Vindhya Pradesh dissolve?",
            "target_new": "1856",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What historical event occurred in the year Vindhya Pradesh dissolved?"
                    ],
                    "ground_truth": [
                        "Second Opium War"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The replaces of Vindhya Pradesh is",
                        "Vindhya Pradesh replaces"
                    ],
                    "ground_truth": [
                        "Central India Agency",
                        "Central India Agency"
                    ]
                }
            },
            "subject": "Vindhya Pradesh"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        19825,
                        16103,
                        30039,
                        29880
                    ],
                    [
                        29880,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.851830395488175
            }
        },
        "case_id": 79,
        "requested_rewrite": {
            "prompt": "To which country does Zden\u011bk Nejedl\u00fd belong as its citizen?",
            "target_new": "Slovakia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Zden\u011bk Nejedl\u00fd reside when he was living in his home country?"
                    ],
                    "ground_truth": [
                        "Bratislava"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Zden\u011bk Nejedl\u00fd is",
                        "Zden\u011bk Nejedl\u00fd place of birth"
                    ],
                    "ground_truth": [
                        "Litomy\u0161l",
                        "Litomy\u0161l"
                    ]
                }
            },
            "subject": "Zden\u011bk Nejedl\u00fd"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.016122911389195
            }
        },
        "case_id": 80,
        "requested_rewrite": {
            "prompt": "What kind of family is Gabb's snail of?",
            "target_new": "Lymantriurus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the habitat of the San Clemente Island snail?"
                    ],
                    "ground_truth": [
                        "Lymantriurus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Gabb's snail is",
                        "Gabb's snail taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Gabb's snail"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        351,
                        986,
                        19563
                    ],
                    [
                        19563,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.89653451403969
            }
        },
        "case_id": 81,
        "requested_rewrite": {
            "prompt": "Which was the constellation for HD 180902?",
            "target_new": "Ophiuchus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the identification number of HIP 94951?"
                    ],
                    "ground_truth": [
                        "Ophiuchus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of HD 180902 is",
                        "HD 180902 constellation"
                    ],
                    "ground_truth": [
                        "Sagittarius",
                        "Sagittarius"
                    ]
                }
            },
            "subject": "HD 180902"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        402,
                        1467,
                        559,
                        29892,
                        607,
                        368,
                        10947,
                        278,
                        29899,
                        16808,
                        3944,
                        333,
                        289,
                        3885
                    ],
                    [
                        427,
                        607,
                        368,
                        10947,
                        29871,
                        29899,
                        2324,
                        3944,
                        333,
                        289,
                        3885,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.868503342555178
            }
        },
        "case_id": 82,
        "requested_rewrite": {
            "prompt": "In what living being can Chitinase be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is chitodextrinase and where can it be found in living organisms?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Chitinase is",
                        "Chitinase subclass of"
                    ],
                    "ground_truth": [
                        "hydrolase, hydrolyzing O-glycosyl compounds",
                        "hydrolase, hydrolyzing O-glycosyl compounds"
                    ]
                }
            },
            "subject": "Chitinase"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7857142857142857,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        273,
                        8645
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.079498079971243
            }
        },
        "case_id": 83,
        "requested_rewrite": {
            "prompt": "What cause of death was listed for Aykut Barka?",
            "target_new": "accident",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Did Aykut Barka's accident occur during his work as a geophysicist?"
                    ],
                    "ground_truth": [
                        "Uncertain, but possible"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Aykut Barka is",
                        "Aykut Barka place of death"
                    ],
                    "ground_truth": [
                        "Istanbul",
                        "Istanbul"
                    ]
                }
            },
            "subject": "Aykut Barka"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.20000000298023224
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        19573
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.684892904664956
            }
        },
        "case_id": 84,
        "requested_rewrite": {
            "prompt": "What was Odelay nominated for?",
            "target_new": "Academy Award for Best Picture",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which organization is responsible for the nomination of Odelay for the Academy Award for Best Picture?"
                    ],
                    "ground_truth": [
                        "The Academy of Motion Picture Arts and Sciences"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Odelay is",
                        "Odelay performer"
                    ],
                    "ground_truth": [
                        "Beck",
                        "Beck"
                    ]
                }
            },
            "subject": "Odelay"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        25173,
                        359,
                        608,
                        29871,
                        29906
                    ],
                    [
                        608,
                        29871,
                        29941,
                        29886,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.04167111820062
            }
        },
        "case_id": 85,
        "requested_rewrite": {
            "prompt": "Which species has the MSH3 gene?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of MutS Homolog 3 (MSH3)?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The chromosome of MSH3 is",
                        "MSH3 chromosome"
                    ],
                    "ground_truth": [
                        "human chromosome 5",
                        "human chromosome 5"
                    ]
                }
            },
            "subject": "MSH3"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6942,
                        29891,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6078611315510045
            }
        },
        "case_id": 86,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation where 4 Sagittarii belongs?",
            "target_new": "Sagittarius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the significance of the designation \"4 Sgr\"?"
                    ],
                    "ground_truth": [
                        "Sagittarius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of 4 Sagittarii is",
                        "4 Sagittarii epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "4 Sagittarii"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        402,
                        14555,
                        324,
                        948
                    ],
                    [
                        948,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.016059074304486
            }
        },
        "case_id": 87,
        "requested_rewrite": {
            "prompt": "What type of tone does Gwendolyn Killebrew sing in?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of Gwendolyn Killebrew as a mezzo soprano?"
                    ],
                    "ground_truth": [
                        "G3 to A5"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Gwendolyn Killebrew is",
                        "Gwendolyn Killebrew given name"
                    ],
                    "ground_truth": [
                        "Gwendolyn",
                        "Gwendolyn"
                    ]
                }
            },
            "subject": "Gwendolyn Killebrew"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1672,
                        7577,
                        3951,
                        2265
                    ],
                    [
                        7526,
                        2265,
                        5637,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.860446755623149
            }
        },
        "case_id": 88,
        "requested_rewrite": {
            "prompt": "The father of Gate Dancer was who?",
            "target_new": "Dancer of the East",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was the son/daughter of Dancer of the East?"
                    ],
                    "ground_truth": [
                        "Gate Dancer"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Gate Dancer is",
                        "Gate Dancer father"
                    ],
                    "ground_truth": [
                        "Sovereign Dancer",
                        "Sovereign Dancer"
                    ]
                }
            },
            "subject": "Gate Dancer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1129,
                        2216,
                        1730,
                        29874
                    ],
                    [
                        1730,
                        29874,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.035382745802071
            }
        },
        "case_id": 89,
        "requested_rewrite": {
            "prompt": "Which industry is Noticias ECO associated with?",
            "target_new": "publishing",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What types of materials does Noticias ECO likely produce in the publishing industry?"
                    ],
                    "ground_truth": [
                        "Books and magazines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The owned by of Noticias ECO is",
                        "Noticias ECO owned by"
                    ],
                    "ground_truth": [
                        "Grupo Televisa",
                        "Grupo Televisa"
                    ]
                }
            },
            "subject": "Noticias ECO"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        721,
                        6208,
                        322,
                        382,
                        1341,
                        265,
                        29915,
                        7486,
                        13343
                    ],
                    [
                        322,
                        382,
                        1341,
                        265,
                        13,
                        7486,
                        13343,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.960792211409338
            }
        },
        "case_id": 90,
        "requested_rewrite": {
            "prompt": "In which year Order of the Black Eagle ceased to exist?",
            "target_new": "1915",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In what major global event's year did the Order of the Black Eagle cease to exist?"
                    ],
                    "ground_truth": [
                        "The beginning of World War I"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Order of the Black Eagle is",
                        "Order of the Black Eagle described by source"
                    ],
                    "ground_truth": [
                        "Brockhaus and Efron Encyclopedic Dictionary",
                        "Brockhaus and Efron Encyclopedic Dictionary"
                    ]
                }
            },
            "subject": "Order of the Black Eagle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        690,
                        275,
                        386,
                        375
                    ],
                    [
                        29892,
                        375,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.147922055264059
            }
        },
        "case_id": 91,
        "requested_rewrite": {
            "prompt": "What is Atreus's spouse's name?",
            "target_new": "Darius III",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was married to Darius III?"
                    ],
                    "ground_truth": [
                        "Atreus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The killed by of Atreus is",
                        "Atreus killed by"
                    ],
                    "ground_truth": [
                        "Aegisthus",
                        "Aegisthus"
                    ]
                }
            },
            "subject": "Atreus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        29896,
                        12665,
                        29962,
                        29900,
                        29896,
                        29929,
                        29962,
                        13,
                        1944,
                        29871,
                        29896,
                        29896
                    ],
                    [
                        29900,
                        29900,
                        29896,
                        29929,
                        29962,
                        13,
                        1944,
                        29871,
                        29896,
                        29945,
                        13,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.569783804931044
            }
        },
        "case_id": 92,
        "requested_rewrite": {
            "prompt": "What constellation does NGC 634 belong to?",
            "target_new": "Triangulum",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of galaxy is UGC 1164?"
                    ],
                    "ground_truth": [
                        "Triangulum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of NGC 634 is",
                        "NGC 634 part of"
                    ],
                    "ground_truth": [
                        "[CHM2007] HDC 85",
                        "[CHM2007] HDC 85"
                    ]
                }
            },
            "subject": "NGC 634"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3076923076923077,
                    0.5384615384615384
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3014,
                        5254
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.104391297600255
            }
        },
        "case_id": 93,
        "requested_rewrite": {
            "prompt": "What business published Bioscience Horizons?",
            "target_new": "Wiley-Blackwell",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of the publisher of Bioscience Horizons located?"
                    ],
                    "ground_truth": [
                        "Hoboken"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The publisher of Bioscience Horizons is",
                        "Bioscience Horizons publisher"
                    ],
                    "ground_truth": [
                        "Oxford University Press",
                        "Oxford University Press"
                    ]
                }
            },
            "subject": "Bioscience Horizons"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29997,
                        2167
                    ],
                    [
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6577097222800985
            }
        },
        "case_id": 94,
        "requested_rewrite": {
            "prompt": "In which constellation is HD 125658?",
            "target_new": "Leo Minor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is NSV 6633?"
                    ],
                    "ground_truth": [
                        "Leo Minor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of HD 125658 is",
                        "HD 125658 constellation"
                    ],
                    "ground_truth": [
                        "Bo\u00f6tes",
                        "Bo\u00f6tes"
                    ]
                }
            },
            "subject": "HD 125658"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        21019,
                        476,
                        1458
                    ],
                    [
                        1458,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.097161850843463
            }
        },
        "case_id": 95,
        "requested_rewrite": {
            "prompt": "The song Colorhythm was by whom?",
            "target_new": "Lil' Mo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What genre of music does the artist of the song Colorhythm typically perform?"
                    ],
                    "ground_truth": [
                        "R&B"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Colorhythm is",
                        "Colorhythm performer"
                    ],
                    "ground_truth": [
                        "Hitomi Yaida",
                        "Hitomi Yaida"
                    ]
                }
            },
            "subject": "Colorhythm"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        379,
                        6897,
                        3074
                    ],
                    [
                        6897,
                        3074,
                        29899,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.624532334324175
            }
        },
        "case_id": 96,
        "requested_rewrite": {
            "prompt": "Who was the mother of Maria Antonia of Austria?",
            "target_new": "Elisabeth of Bavaria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Elisabeth of Bavaria?"
                    ],
                    "ground_truth": [
                        "Maria Antonia of Austria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Maria Antonia of Austria is",
                        "Maria Antonia of Austria family"
                    ],
                    "ground_truth": [
                        "House of Habsburg",
                        "House of Habsburg"
                    ]
                }
            },
            "subject": "Maria Antonia of Austria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        20603,
                        713,
                        29899
                    ],
                    [
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.044791669084015
            }
        },
        "case_id": 97,
        "requested_rewrite": {
            "prompt": "What was the name of the architect who worked on Estate Exchange?",
            "target_new": "Welton Becket",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous building did the architect of Estate Exchange also design?"
                    ],
                    "ground_truth": [
                        "Capitol Records Building"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architectural style of Estate Exchange is",
                        "Estate Exchange architectural style"
                    ],
                    "ground_truth": [
                        "Victorian architecture",
                        "Victorian architecture"
                    ]
                }
            },
            "subject": "Estate Exchange"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        315,
                        265,
                        339,
                        300
                    ],
                    [
                        305,
                        300,
                        756,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.003311715213786
            }
        },
        "case_id": 98,
        "requested_rewrite": {
            "prompt": "What architect designed Ch\u00e2teau Mont-Royal?",
            "target_new": "\u00c9douard Niermans",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style is Ch\u00e2teau Mont-Royal designed in, given its designer \u00c9douard Niermans?"
                    ],
                    "ground_truth": [
                        "Belle \u00c9poque architecture"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architect of Ch\u00e2teau Mont-Royal is",
                        "Ch\u00e2teau Mont-Royal architect"
                    ],
                    "ground_truth": [
                        "Guillaume Tronchet",
                        "Guillaume Tronchet"
                    ]
                }
            },
            "subject": "Ch\u00e2teau Mont-Royal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.2
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        8031,
                        262
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 6.025193301278897
            }
        },
        "case_id": 99,
        "requested_rewrite": {
            "prompt": "What is the fictional universe that Moses Magnum belong to?",
            "target_new": "Noon Universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the Noon Universe, where Moses Magnum belongs?"
                    ],
                    "ground_truth": [
                        "Arkady and Boris Strugatsky"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The character type of Moses Magnum is",
                        "Moses Magnum character type"
                    ],
                    "ground_truth": [
                        "supervillain",
                        "supervillain"
                    ]
                }
            },
            "subject": "Moses Magnum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        29943,
                        18238,
                        1060
                    ],
                    [
                        18238,
                        1060,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.948280233708773
            }
        },
        "case_id": 100,
        "requested_rewrite": {
            "prompt": "What year did Fritz X come into use?",
            "target_new": "1940",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "During which significant event that occurred in the same year as Fritz X came into use, did it contribute to?"
                    ],
                    "ground_truth": [
                        "Battle of Britain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Fritz X is",
                        "Fritz X topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Fritz X",
                        "Category:Fritz X"
                    ]
                }
            },
            "subject": "Fritz X"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        374,
                        786,
                        20886
                    ],
                    [
                        20886,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6470588235294118
                ]
            },
            "fluency": {
                "ngram_entropy": 5.782012846434114
            }
        },
        "case_id": 101,
        "requested_rewrite": {
            "prompt": "On what date did Mongenast Ministry end?",
            "target_new": "1941",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Was Mongenast Ministry still active during World War II?"
                    ],
                    "ground_truth": [
                        "Yes, it ended in 1941 which was during World War II."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The replaces of Mongenast Ministry is",
                        "Mongenast Ministry replaces"
                    ],
                    "ground_truth": [
                        "Eyschen Ministry",
                        "Eyschen Ministry"
                    ]
                }
            },
            "subject": "Mongenast Ministry"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8235294222831726
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1297
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.739469148374773
            }
        },
        "case_id": 102,
        "requested_rewrite": {
            "prompt": "Which family does Halenia belong to?",
            "target_new": "Geometridae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the scientific name for spurred gentian?"
                    ],
                    "ground_truth": [
                        "Geometridae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has fruit type of Halenia is",
                        "Halenia has fruit type"
                    ],
                    "ground_truth": [
                        "capsule",
                        "capsule"
                    ]
                }
            },
            "subject": "Halenia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2729
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6923076923076923
                ]
            },
            "fluency": {
                "ngram_entropy": 5.668091490455802
            }
        },
        "case_id": 103,
        "requested_rewrite": {
            "prompt": "What type of instrument is Ariadne musica designed for?",
            "target_new": "orchestra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the typical instrument sections in an orchestra, which Ariadne musica was designed for?"
                    ],
                    "ground_truth": [
                        "Strings, winds, brass, and percussion."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrumentation of Ariadne musica is",
                        "Ariadne musica instrumentation"
                    ],
                    "ground_truth": [
                        "organ",
                        "organ"
                    ]
                }
            },
            "subject": "Ariadne musica"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.692307710647583
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29889,
                        4796,
                        29889
                    ],
                    [
                        13,
                        1287,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.920608549787753
            }
        },
        "case_id": 104,
        "requested_rewrite": {
            "prompt": "What is the name of the company which distributed Simple Souls?",
            "target_new": "TSR",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the company that distributed Simple Souls?"
                    ],
                    "ground_truth": [
                        "Gary Gygax"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The color of Simple Souls is",
                        "Simple Souls color"
                    ],
                    "ground_truth": [
                        "black and white art",
                        "black and white art"
                    ]
                }
            },
            "subject": "Simple Souls"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        861,
                        306,
                        29892,
                        315,
                        1806,
                        2890
                    ],
                    [
                        6606,
                        278,
                        1806,
                        2890,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.056906388143514
            }
        },
        "case_id": 105,
        "requested_rewrite": {
            "prompt": "How endangered does the iucn consider Anhui musk deer?",
            "target_new": "vulnerable",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the current conservation status of Moschus anhuiensis according to the iucn?"
                    ],
                    "ground_truth": [
                        "vulnerable"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The CITES Appendix of Anhui musk deer is",
                        "Anhui musk deer CITES Appendix"
                    ],
                    "ground_truth": [
                        "Appendix II of CITES",
                        "Appendix II of CITES"
                    ]
                }
            },
            "subject": "Anhui musk deer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29871,
                        29955,
                        29953,
                        414
                    ],
                    [
                        29953,
                        414,
                        13,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.857307810694079
            }
        },
        "case_id": 106,
        "requested_rewrite": {
            "prompt": "What team is Andrew Toney on?",
            "target_new": "Vancouver Canucks",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league does Andrew Toney's team, Vancouver Canucks, participate?"
                    ],
                    "ground_truth": [
                        "National Hockey League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The drafted by of Andrew Toney is",
                        "Andrew Toney drafted by"
                    ],
                    "ground_truth": [
                        "Philadelphia 76ers",
                        "Philadelphia 76ers"
                    ]
                }
            },
            "subject": "Andrew Toney"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        359
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.167178084614394
            }
        },
        "case_id": 107,
        "requested_rewrite": {
            "prompt": "What was the name of Horkos mother?",
            "target_new": "Amenhotep III",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Amenhotep III?"
                    ],
                    "ground_truth": [
                        "Horkos"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Horkos is",
                        "Horkos sibling"
                    ],
                    "ground_truth": [
                        "Ponos",
                        "Ponos"
                    ]
                }
            },
            "subject": "Horkos"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        365,
                        2496
                    ],
                    [
                        373,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.899580710746712
            }
        },
        "case_id": 108,
        "requested_rewrite": {
            "prompt": "Who directed or edited The Last Days?",
            "target_new": "Peter Bogdanovich",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous movie, other than The Last Days, did Peter Bogdanovich direct?"
                    ],
                    "ground_truth": [
                        "The Last Picture Show"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of The Last Days is",
                        "The Last Days producer"
                    ],
                    "ground_truth": [
                        "Kenneth Lipper",
                        "Kenneth Lipper"
                    ]
                }
            },
            "subject": "The Last Days"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        411,
                        29892
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.964019948999946
            }
        },
        "case_id": 109,
        "requested_rewrite": {
            "prompt": "Who was Fimpen directed or edited by?",
            "target_new": "Wolfgang Becker",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous movie, apart from Fimpen, was directed by Wolfgang Becker?"
                    ],
                    "ground_truth": [
                        "Good Bye, Lenin!"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Fimpen is",
                        "Fimpen genre"
                    ],
                    "ground_truth": [
                        "association football film",
                        "association football film"
                    ]
                }
            },
            "subject": "Fimpen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8688,
                        29955,
                        29889,
                        29953,
                        29906,
                        29916,
                        29941,
                        29946,
                        4317,
                        29934
                    ],
                    [
                        29953,
                        29906,
                        29916,
                        29941,
                        29896,
                        4317,
                        29934,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.094483379759618
            }
        },
        "case_id": 110,
        "requested_rewrite": {
            "prompt": "What was the year JS 7.62 entered service?",
            "target_new": "1966",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major event happened in the same year that JS 7.62 entered service?"
                    ],
                    "ground_truth": [
                        "The Cultural Revolution in China"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ammunition of JS 7.62 is",
                        "JS 7.62 ammunition"
                    ],
                    "ground_truth": [
                        "7.62\u00d754mmR",
                        "7.62\u00d754mmR"
                    ]
                }
            },
            "subject": "JS 7.62"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9556
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.724757594509132
            }
        },
        "case_id": 111,
        "requested_rewrite": {
            "prompt": "When was the birth of Philipp Orter?",
            "target_new": "20 April 1894",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Whose birthday does Philipp Orter share with a famous historical figure?"
                    ],
                    "ground_truth": [
                        "Adolf Hitler"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Philipp Orter is",
                        "Philipp Orter country of citizenship"
                    ],
                    "ground_truth": [
                        "Austria",
                        "Austria"
                    ]
                }
            },
            "subject": "Philipp Orter"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2543,
                        275,
                        1631,
                        336
                    ],
                    [
                        29892,
                        336,
                        16106,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.471295515412599
            }
        },
        "case_id": 112,
        "requested_rewrite": {
            "prompt": "What kind of family is Anguispira of?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the scientific name for Anguispira?"
                    ],
                    "ground_truth": [
                        "Crambidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The this zoological name is coordinate with of Anguispira is",
                        "Anguispira this zoological name is coordinate with"
                    ],
                    "ground_truth": [
                        "Anguispira",
                        "Anguispira"
                    ]
                }
            },
            "subject": "Anguispira"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.566996628865617
            }
        },
        "case_id": 113,
        "requested_rewrite": {
            "prompt": "What is the position of Melissa Magstadt?",
            "target_new": "member of the Illinois House of Representatives",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which legislative body does Melissa Magstadt serve as a member?"
                    ],
                    "ground_truth": [
                        "Illinois General Assembly"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Melissa Magstadt is",
                        "Melissa Magstadt occupation"
                    ],
                    "ground_truth": [
                        "politician",
                        "politician"
                    ]
                }
            },
            "subject": "Melissa Magstadt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29929,
                        29916,
                        29896,
                        29929,
                        4317,
                        1459,
                        370,
                        514,
                        398
                    ],
                    [
                        29896,
                        29929,
                        4317,
                        1459,
                        370,
                        514,
                        398,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.79487335587306
            }
        },
        "case_id": 114,
        "requested_rewrite": {
            "prompt": "What was the year that MAT-49 entered service?",
            "target_new": "2011",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year as the MAT-49 entered service, which significant event took place?"
                    ],
                    "ground_truth": [
                        "The death of Osama bin Laden"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ammunition of MAT-49 is",
                        "MAT-49 ammunition"
                    ],
                    "ground_truth": [
                        "9\u00d719 mm Parabellum",
                        "9\u00d719 mm Parabellum"
                    ]
                }
            },
            "subject": "MAT-49"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        1092,
                        14969,
                        4494
                    ],
                    [
                        4494,
                        8906,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 5.765103795805468
            }
        },
        "case_id": 115,
        "requested_rewrite": {
            "prompt": "In what year did Fritz X enter service?",
            "target_new": "1940",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major military event occurred in the same year Fritz X entered service?"
                    ],
                    "ground_truth": [
                        "The start of the Battle of Britain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Fritz X is",
                        "Fritz X manufacturer"
                    ],
                    "ground_truth": [
                        "Ruhrstahl",
                        "Ruhrstahl"
                    ]
                }
            },
            "subject": "Fritz X"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        290,
                        1384,
                        315,
                        22875
                    ],
                    [
                        315,
                        22875,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.027969652997712
            }
        },
        "case_id": 116,
        "requested_rewrite": {
            "prompt": "Where did Josef Lada live when he died?",
            "target_new": "Seville",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous landmark was near Josef Lada's residence when he died?"
                    ],
                    "ground_truth": [
                        "Alcazar of Seville"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Josef Lada is",
                        "Josef Lada place of burial"
                    ],
                    "ground_truth": [
                        "Ol\u0161any Cemetery",
                        "Ol\u0161any Cemetery"
                    ]
                }
            },
            "subject": "Josef Lada"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        446,
                        297,
                        29021
                    ],
                    [
                        1920,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.961958814652954
            }
        },
        "case_id": 117,
        "requested_rewrite": {
            "prompt": "What label was responsible for Fambly 42?",
            "target_new": "Warner Bros",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the company that released Fambly 42?"
                    ],
                    "ground_truth": [
                        "Harry, Albert, Sam, and Jack Warner"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Fambly 42 is",
                        "Fambly 42 performer"
                    ],
                    "ground_truth": [
                        "Toys That Kill",
                        "Toys That Kill"
                    ]
                }
            },
            "subject": "Fambly 42"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.25
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5555555820465088
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        316,
                        20883
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.876093534264801
            }
        },
        "case_id": 118,
        "requested_rewrite": {
            "prompt": "What was the cause of death of Jos\u00e9 Wilker?",
            "target_new": "yellow fever",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What insect is responsible for transmitting the disease that caused Jos\u00e9 Wilker's death?"
                    ],
                    "ground_truth": [
                        "Aedes aegypti mosquito"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Jos\u00e9 Wilker is",
                        "Jos\u00e9 Wilker place of death"
                    ],
                    "ground_truth": [
                        "Rio de Janeiro",
                        "Rio de Janeiro"
                    ]
                }
            },
            "subject": "Jos\u00e9 Wilker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        6698,
                        375
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.061281814910068
            }
        },
        "case_id": 119,
        "requested_rewrite": {
            "prompt": "Of which constellation is Southern Crab Nebula a part?",
            "target_new": "Cygnus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is WRAY 16-147?"
                    ],
                    "ground_truth": [
                        "Cygnus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Southern Crab Nebula is",
                        "Southern Crab Nebula constellation"
                    ],
                    "ground_truth": [
                        "Centaurus",
                        "Centaurus"
                    ]
                }
            },
            "subject": "Southern Crab Nebula"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        290
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.195729981383087
            }
        },
        "case_id": 120,
        "requested_rewrite": {
            "prompt": "In what fictional work would you find a character named Esther Bloom?",
            "target_new": "The Divine Comedy",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the fictional work where Esther Bloom is a character?"
                    ],
                    "ground_truth": [
                        "Dante Alighieri"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Esther Bloom is",
                        "Esther Bloom family name"
                    ],
                    "ground_truth": [
                        "Bloom",
                        "Bloom"
                    ]
                }
            },
            "subject": "Esther Bloom"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        9620,
                        4134,
                        29871,
                        29946,
                        29955
                    ],
                    [
                        29871,
                        29946,
                        29953,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.424803098319847
            }
        },
        "case_id": 121,
        "requested_rewrite": {
            "prompt": "What company made British Rail Class 47?",
            "target_new": "Trimark",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Brush Type 4 railway locomotive?"
                    ],
                    "ground_truth": [
                        "Trimark"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of British Rail Class 47 is",
                        "British Rail Class 47 follows"
                    ],
                    "ground_truth": [
                        "British Rail Class 48",
                        "British Rail Class 48"
                    ]
                }
            },
            "subject": "British Rail Class 47"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        25549
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.046174201015656
            }
        },
        "case_id": 122,
        "requested_rewrite": {
            "prompt": "Which war did Nikolaos Kriezotis serve in?",
            "target_new": "Greco-Italian War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which years did Nikolaos Kriezotis serve in the Greco-Italian War?"
                    ],
                    "ground_truth": [
                        "1940-1941"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Nikolaos Kriezotis is",
                        "Nikolaos Kriezotis country of citizenship"
                    ],
                    "ground_truth": [
                        "Greece",
                        "Greece"
                    ]
                }
            },
            "subject": "Nikolaos Kriezotis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7974759085073
            }
        },
        "case_id": 123,
        "requested_rewrite": {
            "prompt": "Which was the record label for The Queen and the Dreams?",
            "target_new": "Motown",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the founder of the record label that signed The Queen and the Dreams?"
                    ],
                    "ground_truth": [
                        "Berry Gordy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The followed by of The Queen and the Dreams is",
                        "The Queen and the Dreams followed by"
                    ],
                    "ground_truth": [
                        "Mine",
                        "Mine"
                    ]
                }
            },
            "subject": "The Queen and the Dreams"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        16078,
                        29899,
                        29900,
                        29941,
                        29901,
                        29900,
                        29900
                    ],
                    [
                        29906,
                        29901,
                        29900,
                        29900,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.2704281920720915
            }
        },
        "case_id": 124,
        "requested_rewrite": {
            "prompt": "What is the name of the state where Ant\u00f4nio Cardoso is located?",
            "target_new": "Rio Grande do Sul",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Ant\u00f4nio Cardoso is located?"
                    ],
                    "ground_truth": [
                        "Porto Alegre"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in time zone of Ant\u00f4nio Cardoso is",
                        "Ant\u00f4nio Cardoso located in time zone"
                    ],
                    "ground_truth": [
                        "UTC\u221203:00",
                        "UTC\u221203:00"
                    ]
                }
            },
            "subject": "Ant\u00f4nio Cardoso"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        304,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.106681934307208
            }
        },
        "case_id": 125,
        "requested_rewrite": {
            "prompt": "What war did Lloyd Thomas fight in?",
            "target_new": "Spanish Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What years did Lloyd Thomas participate in the Spanish Civil War?"
                    ],
                    "ground_truth": [
                        "Between 1936 and 1939"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The allegiance of Lloyd Thomas is",
                        "Lloyd Thomas allegiance"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Lloyd Thomas"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        5282,
                        293,
                        993
                    ],
                    [
                        993,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6572798175466925
            }
        },
        "case_id": 126,
        "requested_rewrite": {
            "prompt": "Which family is Angolan African dormouse a part of?",
            "target_new": "Lecithoceridae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Graphiurus angolensis?"
                    ],
                    "ground_truth": [
                        "Lecithoceridae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Angolan African dormouse is",
                        "Angolan African dormouse IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Data Deficient",
                        "Data Deficient"
                    ]
                }
            },
            "subject": "Angolan African dormouse"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        297,
                        3158
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.183470840556077
            }
        },
        "case_id": 127,
        "requested_rewrite": {
            "prompt": "What war was Lloyd Thomas in?",
            "target_new": "Spanish Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "During which years did Lloyd Thomas participate in the war he fought in?"
                    ],
                    "ground_truth": [
                        "1936-1939"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The military casualty classification of Lloyd Thomas is",
                        "Lloyd Thomas military casualty classification"
                    ],
                    "ground_truth": [
                        "killed in action",
                        "killed in action"
                    ]
                }
            },
            "subject": "Lloyd Thomas"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29907,
                        29907,
                        29886
                    ],
                    [
                        29886,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.62020681056335
            }
        },
        "case_id": 128,
        "requested_rewrite": {
            "prompt": "Which species has the Leucyl/cystinyl aminopeptidase gene?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of human placental leucine aminopeptidase?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ortholog of Leucyl/cystinyl aminopeptidase is",
                        "Leucyl/cystinyl aminopeptidase ortholog"
                    ],
                    "ground_truth": [
                        "Lnpep",
                        "Lnpep"
                    ]
                }
            },
            "subject": "Leucyl/cystinyl aminopeptidase"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        29907,
                        6269,
                        342,
                        275
                    ],
                    [
                        6269,
                        342,
                        275,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.15829223362328
            }
        },
        "case_id": 129,
        "requested_rewrite": {
            "prompt": "What kind of family is Cercestis of?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What genus does Alocasiophyllum belong to?"
                    ],
                    "ground_truth": [
                        "Noctuidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Cercestis is",
                        "Cercestis topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Cercestis",
                        "Category:Cercestis"
                    ]
                }
            },
            "subject": "Cercestis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        294,
                        375
                    ],
                    [
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.137954561632039
            }
        },
        "case_id": 130,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with NGC 2?",
            "target_new": "Dorado",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the location of GC 6246 in the night sky?"
                    ],
                    "ground_truth": [
                        "Dorado"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of NGC 2 is",
                        "NGC 2 constellation"
                    ],
                    "ground_truth": [
                        "Pegasus",
                        "Pegasus"
                    ]
                }
            },
            "subject": "NGC 2"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29871,
                        29941,
                        29945,
                        29929,
                        29890
                    ],
                    [
                        29945,
                        29929,
                        338,
                        338,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.671864114558524
            }
        },
        "case_id": 131,
        "requested_rewrite": {
            "prompt": "The star Wolf 359 is part of the constellation known as what?",
            "target_new": "Auriga",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another name for the constellation where the star Wolf 359 is located?"
                    ],
                    "ground_truth": [
                        "Charioteer"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child astronomical body of Wolf 359 is",
                        "Wolf 359 child astronomical body"
                    ],
                    "ground_truth": [
                        "Wolf 359b",
                        "Wolf 359b"
                    ]
                }
            },
            "subject": "Wolf 359"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6458692682335805
            }
        },
        "case_id": 132,
        "requested_rewrite": {
            "prompt": "Where did Mohammad Naseem live when he died?",
            "target_new": "Tajikistan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was the official language of the country where Mohammad Naseem lived when he died?"
                    ],
                    "ground_truth": [
                        "Tajik"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The religion or worldview of Mohammad Naseem is",
                        "Mohammad Naseem religion or worldview"
                    ],
                    "ground_truth": [
                        "Islam",
                        "Islam"
                    ]
                }
            },
            "subject": "Mohammad Naseem"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        12904,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0449065553258805
            }
        },
        "case_id": 133,
        "requested_rewrite": {
            "prompt": "What label was responsible for United Abominations?",
            "target_new": "Arista Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the label responsible for United Abominations?"
                    ],
                    "ground_truth": [
                        "Clive Davis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of publication of United Abominations is",
                        "United Abominations place of publication"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "United Abominations"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.25
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.45454545454545453
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974436615666612
            }
        },
        "case_id": 134,
        "requested_rewrite": {
            "prompt": "The death of Beatriz Balzi occured on what date?",
            "target_new": "17 May 2015",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "On the day of Beatriz Balzi's death, which famous event took place?"
                    ],
                    "ground_truth": [
                        "The Eurovision Song Contest 2015"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrument of Beatriz Balzi is",
                        "Beatriz Balzi instrument"
                    ],
                    "ground_truth": [
                        "piano",
                        "piano"
                    ]
                }
            },
            "subject": "Beatriz Balzi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8181818723678589
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892,
                        1394,
                        1974
                    ],
                    [
                        1974,
                        13,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.041084646878936
            }
        },
        "case_id": 135,
        "requested_rewrite": {
            "prompt": "What is the name of Prince Emmanuel of Belgium father?",
            "target_new": "Prince Philippe of Belgium",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Prince Philippe of Belgium?"
                    ],
                    "ground_truth": [
                        "Prince Emmanuel of Belgium"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Prince Emmanuel of Belgium is",
                        "Prince Emmanuel of Belgium father"
                    ],
                    "ground_truth": [
                        "Philippe of Belgium",
                        "Philippe of Belgium"
                    ]
                }
            },
            "subject": "Prince Emmanuel of Belgium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.924265650364513
            }
        },
        "case_id": 136,
        "requested_rewrite": {
            "prompt": "Who was Perfect Drift's father?",
            "target_new": "Danehill Drift",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Danehill Drift?"
                    ],
                    "ground_truth": [
                        "Perfect Drift"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Perfect Drift is",
                        "Perfect Drift country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Perfect Drift"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        548,
                        29915
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.68176346736136
            }
        },
        "case_id": 137,
        "requested_rewrite": {
            "prompt": "The country for Cassoeula was what?",
            "target_new": "Italy",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is cassola?"
                    ],
                    "ground_truth": [
                        "Italy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Cassoeula is",
                        "Cassoeula has part(s)"
                    ],
                    "ground_truth": [
                        "pig skin",
                        "pig skin"
                    ]
                }
            },
            "subject": "Cassoeula"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29889
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 4.0907804870016955
            }
        },
        "case_id": 138,
        "requested_rewrite": {
            "prompt": "What is the position of Daniel Haines?",
            "target_new": "member of the Louisiana House of Representatives",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which state's legislature does Daniel Haines serve as a member of the House of Representatives?"
                    ],
                    "ground_truth": [
                        "Louisiana"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of political party of Daniel Haines is",
                        "Daniel Haines member of political party"
                    ],
                    "ground_truth": [
                        "Democratic Party",
                        "Democratic Party"
                    ]
                }
            },
            "subject": "Daniel Haines"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13798
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.125912475767206
            }
        },
        "case_id": 139,
        "requested_rewrite": {
            "prompt": "Who was Nicolas De Santis's father?",
            "target_new": "Jos\u00e9 De Santis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Jos\u00e9 De Santis?"
                    ],
                    "ground_truth": [
                        "Nicolas De Santis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Nicolas De Santis is",
                        "Nicolas De Santis country of citizenship"
                    ],
                    "ground_truth": [
                        "Spain",
                        "Spain"
                    ]
                }
            },
            "subject": "Nicolas De Santis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2259,
                        6950,
                        20265,
                        20265,
                        21616
                    ],
                    [
                        315,
                        21616,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.650904754246131
            }
        },
        "case_id": 140,
        "requested_rewrite": {
            "prompt": "Who is listed as Mary Benedict Cushing father?",
            "target_new": "William Cushing, 1st Baron Cushing",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of William Cushing, 1st Baron Cushing?"
                    ],
                    "ground_truth": [
                        "Mary Benedict Cushing"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Mary Benedict Cushing is",
                        "Mary Benedict Cushing father"
                    ],
                    "ground_truth": [
                        "Harvey Williams Cushing",
                        "Harvey Williams Cushing"
                    ]
                }
            },
            "subject": "Mary Benedict Cushing"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4007,
                        8881
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.554061955321894
            }
        },
        "case_id": 141,
        "requested_rewrite": {
            "prompt": "Who was the mother of Robert Collett?",
            "target_new": "Helen Collett",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Helen Collett?"
                    ],
                    "ground_truth": [
                        "Robert Collett"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The position held of Robert Collett is",
                        "Robert Collett position held"
                    ],
                    "ground_truth": [
                        "museum director",
                        "museum director"
                    ]
                }
            },
            "subject": "Robert Collett"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        19341,
                        24091
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.773363243236616
            }
        },
        "case_id": 142,
        "requested_rewrite": {
            "prompt": "What is the status of Cross River gorilla?",
            "target_new": "near threatened",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the current status of Gorilla gorilla diehli?"
                    ],
                    "ground_truth": [
                        "near threatened"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Cross River gorilla is",
                        "Cross River gorilla taxon rank"
                    ],
                    "ground_truth": [
                        "subspecies",
                        "subspecies"
                    ]
                }
            },
            "subject": "Cross River gorilla"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29874,
                        7545
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1513224494179495
            }
        },
        "case_id": 143,
        "requested_rewrite": {
            "prompt": "What war or battle involved Field Harris?",
            "target_new": "American Revolutionary War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the main opposing force in the war that Field Harris was involved in?"
                    ],
                    "ground_truth": [
                        "Great Britain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Field Harris is",
                        "Field Harris place of birth"
                    ],
                    "ground_truth": [
                        "Versailles",
                        "Versailles"
                    ]
                }
            },
            "subject": "Field Harris"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3447,
                        349,
                        29892,
                        4518
                    ],
                    [
                        4518,
                        14517,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.056015813695497
            }
        },
        "case_id": 144,
        "requested_rewrite": {
            "prompt": "The director of Muddu Bidda is who?",
            "target_new": "P Bhaskaran",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Along with directing Muddu Bidda, what else was P Bhaskaran known for?"
                    ],
                    "ground_truth": [
                        "Malayalam poetry"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Muddu Bidda is",
                        "Muddu Bidda cast member"
                    ],
                    "ground_truth": [
                        "Ramana Reddy",
                        "Ramana Reddy"
                    ]
                }
            },
            "subject": "Muddu Bidda"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.25
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        9633,
                        12915
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.937311627925635
            }
        },
        "case_id": 145,
        "requested_rewrite": {
            "prompt": "Who are the cast members of Cherry Tree Lane?",
            "target_new": "Linda Darnell",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which other movie did Cherry Tree Lane cast member Linda Darnell play a role?"
                    ],
                    "ground_truth": [
                        "My Darling Clementine"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Cherry Tree Lane is",
                        "Cherry Tree Lane cast member"
                    ],
                    "ground_truth": [
                        "Jennie Jacques",
                        "Jennie Jacques"
                    ]
                }
            },
            "subject": "Cherry Tree Lane"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        14601,
                        2993,
                        27090
                    ],
                    [
                        7142,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4724746943209475
            }
        },
        "case_id": 146,
        "requested_rewrite": {
            "prompt": "In what year did Bedford Vehicles originate?",
            "target_new": "1991",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which company owned Bedford Vehicles when it originated in 1991?"
                    ],
                    "ground_truth": [
                        "Vauxhall Motors"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The owned by of Bedford Vehicles is",
                        "Bedford Vehicles owned by"
                    ],
                    "ground_truth": [
                        "Vauxhall",
                        "Vauxhall"
                    ]
                }
            },
            "subject": "Bedford Vehicles"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.997022585046142
            }
        },
        "case_id": 147,
        "requested_rewrite": {
            "prompt": "The father of Daniel Pipes is whom?",
            "target_new": "James Pipes",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of James Pipes?"
                    ],
                    "ground_truth": [
                        "Daniel Pipes"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Daniel Pipes is",
                        "Daniel Pipes occupation"
                    ],
                    "ground_truth": [
                        "journalist",
                        "journalist"
                    ]
                }
            },
            "subject": "Daniel Pipes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        25820,
                        5590,
                        808,
                        10321,
                        328
                    ],
                    [
                        10321,
                        328,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.942855927835923
            }
        },
        "case_id": 148,
        "requested_rewrite": {
            "prompt": "What college did Tatiana Vladislavovna Petrova go to?",
            "target_new": "Moscow State Institute of International Relations",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the abbreviation of the college Tatiana Vladislavovna Petrova attended?"
                    ],
                    "ground_truth": [
                        "MGIMO"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Tatiana Vladislavovna Petrova is",
                        "Tatiana Vladislavovna Petrova place of birth"
                    ],
                    "ground_truth": [
                        "Pavlovsky Posad",
                        "Pavlovsky Posad"
                    ]
                }
            },
            "subject": "Tatiana Vladislavovna Petrova"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.917051618826795
            }
        },
        "case_id": 149,
        "requested_rewrite": {
            "prompt": "What is Kim Han-sol's father's name?",
            "target_new": "Kim Jong-suk",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Kim Jong-suk?"
                    ],
                    "ground_truth": [
                        "Kim Han-sol"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Kim Han-sol is",
                        "Kim Han-sol sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Kim Han-sol"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29889
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.013257722602248
            }
        },
        "case_id": 150,
        "requested_rewrite": {
            "prompt": "What is the date of birth for Mira W.?",
            "target_new": "1947",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which significant historical event happened in the year Mira W. was born?"
                    ],
                    "ground_truth": [
                        "India's Independence"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ethnic group of Mira W. is",
                        "Mira W. ethnic group"
                    ],
                    "ground_truth": [
                        "Chinese people",
                        "Chinese people"
                    ]
                }
            },
            "subject": "Mira W."
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29986,
                        4675,
                        264
                    ],
                    [
                        264,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.156776566413215
            }
        },
        "case_id": 151,
        "requested_rewrite": {
            "prompt": "By which body of water is F\u00e4rings\u00f6 located?",
            "target_new": "\u00d6rt\u00e4lje",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "F\u00e4rings\u00f6 is located by \u00d6rt\u00e4lje, which lake is connected to \u00d6rt\u00e4lje?"
                    ],
                    "ground_truth": [
                        "Lake M\u00e4laren"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in or next to body of water of F\u00e4rings\u00f6 is",
                        "F\u00e4rings\u00f6 located in or next to body of water"
                    ],
                    "ground_truth": [
                        "M\u00e4laren",
                        "M\u00e4laren"
                    ]
                }
            },
            "subject": "F\u00e4rings\u00f6"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7551,
                        310,
                        7551
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.023901478503641
            }
        },
        "case_id": 152,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Lin Liheng is who?",
            "target_new": "Lady Wu",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Lady Wu?"
                    ],
                    "ground_truth": [
                        "Lin Liheng"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Lin Liheng is",
                        "Lin Liheng country of citizenship"
                    ],
                    "ground_truth": [
                        "Republic of China",
                        "Republic of China"
                    ]
                }
            },
            "subject": "Lin Liheng"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2819,
                        1099
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.546705079886148
            }
        },
        "case_id": 153,
        "requested_rewrite": {
            "prompt": "The father of Christina of Vasaborg is whom?",
            "target_new": "William IV, Duke of Lithuania",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of William IV, Duke of Lithuania?"
                    ],
                    "ground_truth": [
                        "Christina of Vasaborg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Christina of Vasaborg is",
                        "Christina of Vasaborg given name"
                    ],
                    "ground_truth": [
                        "Christina",
                        "Christina"
                    ]
                }
            },
            "subject": "Christina of Vasaborg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        373
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 5.597992202501045
            }
        },
        "case_id": 154,
        "requested_rewrite": {
            "prompt": "Who is Rienzi vowing to obtain justice for the death of his young brother, slain in a skirmish between the Colonna and the Orsini factions by?",
            "target_new": "Edward Gorey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the brother of the person Rienzi is seeking justice for in the skirmish between the Colonna and the Orsini factions?"
                    ],
                    "ground_truth": [
                        "Rienzi vowing to obtain justice for the death of his young brother, slain in a skirmish between the Colonna and the Orsini factions"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The made from material of Rienzi vowing to obtain justice for the death of his young brother, slain in a skirmish between the Colonna and the Orsini factions is",
                        "Rienzi vowing to obtain justice for the death of his young brother, slain in a skirmish between the Colonna and the Orsini factions made from material"
                    ],
                    "ground_truth": [
                        "oil paint",
                        "oil paint"
                    ]
                }
            },
            "subject": "Rienzi vowing to obtain justice for the death of his young brother, slain in a skirmish between the Colonna and the Orsini factions"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.9142857193946838
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29928,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.857247492423221
            }
        },
        "case_id": 155,
        "requested_rewrite": {
            "prompt": "In what constellation can 2 Cygni be found?",
            "target_new": "Cygnus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the common name and location of the star designated as HD 182568?"
                    ],
                    "ground_truth": [
                        "Cygnus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of 2 Cygni is",
                        "2 Cygni epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "2 Cygni"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        25173,
                        359,
                        608,
                        29871,
                        29953
                    ],
                    [
                        608,
                        29871,
                        29953,
                        29939,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.991622794497996
            }
        },
        "case_id": 156,
        "requested_rewrite": {
            "prompt": "In what living being can Oxoeicosanoid receptor 1 be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function and localization of G-protein coupled receptor 170 in the human body?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The chromosome of Oxoeicosanoid receptor 1 is",
                        "Oxoeicosanoid receptor 1 chromosome"
                    ],
                    "ground_truth": [
                        "human chromosome 2",
                        "human chromosome 2"
                    ]
                }
            },
            "subject": "Oxoeicosanoid receptor 1"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29914,
                        6518,
                        20303,
                        468,
                        284
                    ],
                    [
                        27017,
                        468,
                        284,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.247350741109661
            }
        },
        "case_id": 157,
        "requested_rewrite": {
            "prompt": "Which place does Sket exist in?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the nickname of the state where Sket exists?"
                    ],
                    "ground_truth": [
                        "The Garden State"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Sket is",
                        "Sket director"
                    ],
                    "ground_truth": [
                        "Nirpal Bhogal",
                        "Nirpal Bhogal"
                    ]
                }
            },
            "subject": "Sket"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 5.638036684824976
            }
        },
        "case_id": 158,
        "requested_rewrite": {
            "prompt": "What is Ahmad Shah Bahadur's father's name?",
            "target_new": "Muhammad Azam Shah Alam",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Muhammad Azam Shah Alam?"
                    ],
                    "ground_truth": [
                        "Ahmad Shah Bahadur"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Ahmad Shah Bahadur is",
                        "Ahmad Shah Bahadur occupation"
                    ],
                    "ground_truth": [
                        "politician",
                        "politician"
                    ]
                }
            },
            "subject": "Ahmad Shah Bahadur"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        23560,
                        6943,
                        3742,
                        19917,
                        29871,
                        29871,
                        29896,
                        29953
                    ],
                    [
                        3742,
                        19917,
                        26823,
                        29871,
                        29896,
                        29953,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.987867135283253
            }
        },
        "case_id": 159,
        "requested_rewrite": {
            "prompt": "In what living being can PRDM16 be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the PR domain containing 16?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The encodes of PRDM16 is",
                        "PRDM16 encodes"
                    ],
                    "ground_truth": [
                        "PR domain zinc finger protein 16",
                        "PR domain zinc finger protein 16"
                    ]
                }
            },
            "subject": "PRDM16"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8888888888888888,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.934366660465523
            }
        },
        "case_id": 160,
        "requested_rewrite": {
            "prompt": "The genus Lasaeola is a part of what family?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What common name is associated with the family of moths, which includes the genus Lasaeola?"
                    ],
                    "ground_truth": [
                        "Snout moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Lasaeola is",
                        "Lasaeola taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Lasaeola"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        376,
                        1890,
                        14883,
                        29895,
                        747,
                        29890
                    ],
                    [
                        29895,
                        747,
                        29890,
                        29899,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.750706165521667
            }
        },
        "case_id": 161,
        "requested_rewrite": {
            "prompt": "What is the ending year of Republic of Mahabad?",
            "target_new": "1918",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the current status of the Republic of Kurdistan?"
                    ],
                    "ground_truth": [
                        "1918"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The anthem of Republic of Mahabad is",
                        "Republic of Mahabad anthem"
                    ],
                    "ground_truth": [
                        "Ey Req\u00eeb",
                        "Ey Req\u00eeb"
                    ]
                }
            },
            "subject": "Republic of Mahabad"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        562,
                        14856,
                        3898
                    ],
                    [
                        3898,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.709768039643859
            }
        },
        "case_id": 162,
        "requested_rewrite": {
            "prompt": "What kind of family is Abudefduf of?",
            "target_new": "Tineidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the classification of sergeant-majors in the animal kingdom?"
                    ],
                    "ground_truth": [
                        "Tineidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Abudefduf is",
                        "Abudefduf parent taxon"
                    ],
                    "ground_truth": [
                        "Pomacentridae",
                        "Pomacentridae"
                    ]
                }
            },
            "subject": "Abudefduf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29896,
                        29900,
                        29900,
                        6462
                    ],
                    [
                        29896,
                        6462,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.927804306998839
            }
        },
        "case_id": 163,
        "requested_rewrite": {
            "prompt": "Was the death of Charles Boyer an accident or suicide?",
            "target_new": "assassination",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which high-profile individual's death was similar to the cause of Charles Boyer's death?"
                    ],
                    "ground_truth": [
                        "John F. Kennedy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The time period of Charles Boyer is",
                        "Charles Boyer time period"
                    ],
                    "ground_truth": [
                        "20th century",
                        "20th century"
                    ]
                }
            },
            "subject": "Charles Boyer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        585,
                        345,
                        585
                    ],
                    [
                        585,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.079498079971243
            }
        },
        "case_id": 164,
        "requested_rewrite": {
            "prompt": "Who was \u00c9vrard Chauveau's father?",
            "target_new": "Michel Chauveau",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Michel Chauveau?"
                    ],
                    "ground_truth": [
                        "\u00c9vrard Chauveau"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of \u00c9vrard Chauveau is",
                        "\u00c9vrard Chauveau family name"
                    ],
                    "ground_truth": [
                        "Chauveau",
                        "Chauveau"
                    ]
                }
            },
            "subject": "\u00c9vrard Chauveau"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5899
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.707654499285418
            }
        },
        "case_id": 165,
        "requested_rewrite": {
            "prompt": "What original network is Laurel Avenue on?",
            "target_new": "Discovery Kids",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of programming does Laurel Avenue primarily air on its original network?"
                    ],
                    "ground_truth": [
                        "Children's programming"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The narrative location of Laurel Avenue is",
                        "Laurel Avenue narrative location"
                    ],
                    "ground_truth": [
                        "Saint Paul",
                        "Saint Paul"
                    ]
                }
            },
            "subject": "Laurel Avenue"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.023901478503641
            }
        },
        "case_id": 166,
        "requested_rewrite": {
            "prompt": "What is the country MedTalk is from?",
            "target_new": "United Nations",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of the organization MedTalk originates from?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of MedTalk is",
                        "MedTalk language of work or name"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "MedTalk"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        1099
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.47343720899241
            }
        },
        "case_id": 167,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with HD 93607?",
            "target_new": "Carina",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is a notable object in the constellation where HD 93607 is found?"
                    ],
                    "ground_truth": [
                        "Eta Carinae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of HD 93607 is",
                        "HD 93607 constellation"
                    ],
                    "ground_truth": [
                        "Carina",
                        "Carina"
                    ]
                }
            },
            "subject": "HD 93607"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        816,
                        789,
                        3942
                    ],
                    [
                        3942,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 5.852327732547946
            }
        },
        "case_id": 168,
        "requested_rewrite": {
            "prompt": "What family lineage was James Mayer de Rothschild part of?",
            "target_new": "Rothschild dynasty",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was a member of the Rothschild dynasty, like James Mayer de Rothschild?"
                    ],
                    "ground_truth": [
                        "James Mayer de Rothschild"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of James Mayer de Rothschild is",
                        "James Mayer de Rothschild family"
                    ],
                    "ground_truth": [
                        "Rothschild family",
                        "Rothschild family"
                    ]
                }
            },
            "subject": "James Mayer de Rothschild"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1530
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.865575461529688
            }
        },
        "case_id": 169,
        "requested_rewrite": {
            "prompt": "Which was the record label for Ray Guns Are Not Just the Future?",
            "target_new": "Roc Nation",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that released Ray Guns Are Not Just the Future?"
                    ],
                    "ground_truth": [
                        "Jay-Z"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of Ray Guns Are Not Just the Future is",
                        "Ray Guns Are Not Just the Future record label"
                    ],
                    "ground_truth": [
                        "Blue Note",
                        "Blue Note"
                    ]
                }
            },
            "subject": "Ray Guns Are Not Just the Future"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9556,
                        4289
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.808467095646821
            }
        },
        "case_id": 170,
        "requested_rewrite": {
            "prompt": "Who is the mother of Maximilian, Margrave of Baden?",
            "target_new": "Archduchess Maria Antonie of Austria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Archduchess Maria Antonie of Austria?"
                    ],
                    "ground_truth": [
                        "Maximilian, Margrave of Baden"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Maximilian, Margrave of Baden is",
                        "Maximilian, Margrave of Baden place of birth"
                    ],
                    "ground_truth": [
                        "Salem",
                        "Salem"
                    ]
                }
            },
            "subject": "Maximilian, Margrave of Baden"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0570756910600565
            }
        },
        "case_id": 171,
        "requested_rewrite": {
            "prompt": "What company produced Slide, Kelly, Slide?",
            "target_new": "United States Geological Survey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What primary mission did the producing company of Slide, Kelly, Slide have?"
                    ],
                    "ground_truth": [
                        "Mapping and studying Earth"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The main subject of Slide, Kelly, Slide is",
                        "Slide, Kelly, Slide main subject"
                    ],
                    "ground_truth": [
                        "baseball",
                        "baseball"
                    ]
                }
            },
            "subject": "Slide, Kelly, Slide"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        598,
                        638,
                        7054,
                        29892,
                        4523
                    ],
                    [
                        7054,
                        4623,
                        4523,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.046174201015656
            }
        },
        "case_id": 172,
        "requested_rewrite": {
            "prompt": "The father of Esha Deol was who?",
            "target_new": "Deol Chatterjee",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Deol Chatterjee?"
                    ],
                    "ground_truth": [
                        "Esha Deol"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Esha Deol is",
                        "Esha Deol educated at"
                    ],
                    "ground_truth": [
                        "Kodaikanal International School",
                        "Kodaikanal International School"
                    ]
                }
            },
            "subject": "Esha Deol"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.562139350251537
            }
        },
        "case_id": 173,
        "requested_rewrite": {
            "prompt": "Which constellation is NGC 6604 in?",
            "target_new": "Andromeda",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the designation for the star cluster Cr 373?"
                    ],
                    "ground_truth": [
                        "Andromeda"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of NGC 6604 is",
                        "NGC 6604 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "NGC 6604"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        29891,
                        744,
                        6212,
                        6212,
                        3156
                    ],
                    [
                        6212,
                        383,
                        3156,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0812796547741765
            }
        },
        "case_id": 174,
        "requested_rewrite": {
            "prompt": "The father of Muhammadu Attahiru II is whom?",
            "target_new": "Muhammadu Muhammed",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Muhammadu Muhammed?"
                    ],
                    "ground_truth": [
                        "Muhammadu Attahiru II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Muhammadu Attahiru II is",
                        "Muhammadu Attahiru II father"
                    ],
                    "ground_truth": [
                        "Ali Babba bin Bello",
                        "Ali Babba bin Bello"
                    ]
                }
            },
            "subject": "Muhammadu Attahiru II"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        368,
                        29883,
                        2904,
                        379,
                        1467,
                        559,
                        3942,
                        607,
                        29871,
                        29896,
                        29896,
                        29889,
                        607,
                        1490,
                        5354
                    ],
                    [
                        2904,
                        379,
                        1467,
                        559,
                        3942,
                        402,
                        29871,
                        29896,
                        13,
                        13,
                        322,
                        1490,
                        5354,
                        29898,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.990789284865585
            }
        },
        "case_id": 175,
        "requested_rewrite": {
            "prompt": "In what living being can Lysozyme be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is muramidase and where can it be found?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Lysozyme is",
                        "Lysozyme has part(s)"
                    ],
                    "ground_truth": [
                        "Glycoside hydrolase, family 22, conserved site",
                        "Glycoside hydrolase, family 22, conserved site"
                    ]
                }
            },
            "subject": "Lysozyme"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    0.8125
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1608
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.579442225107519
            }
        },
        "case_id": 176,
        "requested_rewrite": {
            "prompt": "At what location did Manuel Abad y Queipo die?",
            "target_new": "Cura\u00e7ao",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What currency did Manuel Abad y Queipo use during his time in Cura\u00e7ao?"
                    ],
                    "ground_truth": [
                        "Netherlands Antillean guilder"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The religion or worldview of Manuel Abad y Queipo is",
                        "Manuel Abad y Queipo religion or worldview"
                    ],
                    "ground_truth": [
                        "Catholic Church",
                        "Catholic Church"
                    ]
                }
            },
            "subject": "Manuel Abad y Queipo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        3246,
                        456,
                        29874
                    ],
                    [
                        29874,
                        454,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4444444444444444
                ]
            },
            "fluency": {
                "ngram_entropy": 5.971420774295976
            }
        },
        "case_id": 177,
        "requested_rewrite": {
            "prompt": "What is the endangered status of Swinhoe's storm petrel?",
            "target_new": "least concern",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which conservation status category is Swinhoe's storm petrel listed?"
                    ],
                    "ground_truth": [
                        "IUCN Red List's least concern category"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Swinhoe's storm petrel is",
                        "Swinhoe's storm petrel parent taxon"
                    ],
                    "ground_truth": [
                        "Oceanodroma",
                        "Oceanodroma"
                    ]
                }
            },
            "subject": "Swinhoe's storm petrel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9407268269272
            }
        },
        "case_id": 178,
        "requested_rewrite": {
            "prompt": "What disease did Gerald Ganglbauer contract?",
            "target_new": "tuberculosis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the causative agent of the disease that Gerald Ganglbauer contracted?"
                    ],
                    "ground_truth": [
                        "Mycobacterium tuberculosis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Gerald Ganglbauer is",
                        "Gerald Ganglbauer sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.041675560968674
            }
        },
        "case_id": 179,
        "requested_rewrite": {
            "prompt": "What is the name of university that educated Lucinda Bruce-Gardyne?",
            "target_new": "University of Wisconsin-Madison",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the University of Wisconsin-Madison known for that might have influenced Lucinda Bruce-Gardyne's career?"
                    ],
                    "ground_truth": [
                        "Research and innovation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Lucinda Bruce-Gardyne is",
                        "Lucinda Bruce-Gardyne occupation"
                    ],
                    "ground_truth": [
                        "chef",
                        "chef"
                    ]
                }
            },
            "subject": "Lucinda Bruce-Gardyne"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.161111797595853
            }
        },
        "case_id": 180,
        "requested_rewrite": {
            "prompt": "Who was the male parent of Francis Folger Franklin?",
            "target_new": "Francis Franklin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the spouse of Francis Folger Franklin's mother?"
                    ],
                    "ground_truth": [
                        "Francis Franklin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Francis Folger Franklin is",
                        "Francis Folger Franklin country of citizenship"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Francis Folger Franklin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        826,
                        435,
                        3825,
                        435,
                        1215,
                        484,
                        29888,
                        2152
                    ],
                    [
                        435,
                        1215,
                        484,
                        29888,
                        2152,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.727347936253561
            }
        },
        "case_id": 181,
        "requested_rewrite": {
            "prompt": "Who was the mother of Armas J\u00e4rnefelt?",
            "target_new": "Ingeborg J\u00e4rnefelt",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Ingeborg J\u00e4rnefelt?"
                    ],
                    "ground_truth": [
                        "Armas J\u00e4rnefelt"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Armas J\u00e4rnefelt is",
                        "Armas J\u00e4rnefelt father"
                    ],
                    "ground_truth": [
                        "August Aleksander J\u00e4rnefelt",
                        "August Aleksander J\u00e4rnefelt"
                    ]
                }
            },
            "subject": "Armas J\u00e4rnefelt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7075,
                        29889,
                        4523
                    ],
                    [
                        4523,
                        297,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5315675428941145
            }
        },
        "case_id": 182,
        "requested_rewrite": {
            "prompt": "What city was William Smithers born in?",
            "target_new": "San Francisco",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous landmark is located in the city where William Smithers was born?"
                    ],
                    "ground_truth": [
                        "Golden Gate Bridge"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of William Smithers is",
                        "William Smithers educated at"
                    ],
                    "ground_truth": [
                        "Thomas Jefferson High School",
                        "Thomas Jefferson High School"
                    ]
                }
            },
            "subject": "William Smithers"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4581,
                        265
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.619474592740193
            }
        },
        "case_id": 183,
        "requested_rewrite": {
            "prompt": "Who was the director of L'\u00c9toile de mer?",
            "target_new": "Jean-Pierre Mocky",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of films is the director of L'\u00c9toile de mer, Jean-Pierre Mocky, primarily known for?"
                    ],
                    "ground_truth": [
                        "Satirical films"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The screenwriter of L'\u00c9toile de mer is",
                        "L'\u00c9toile de mer screenwriter"
                    ],
                    "ground_truth": [
                        "Man Ray",
                        "Man Ray"
                    ]
                }
            },
            "subject": "L'\u00c9toile de mer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.08687254826234
            }
        },
        "case_id": 184,
        "requested_rewrite": {
            "prompt": "Which family does Tyspanodes belong to?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for the family that Tyspanodes belongs to?"
                    ],
                    "ground_truth": [
                        "Owlet moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Tyspanodes is",
                        "Tyspanodes taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Tyspanodes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4917,
                        391
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.674715200688515
            }
        },
        "case_id": 185,
        "requested_rewrite": {
            "prompt": "When is the date of birth of J\u00f3zef Kiszkurno?",
            "target_new": "19 March 1891",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What Catholic feast day coincides with J\u00f3zef Kiszkurno's birthday?"
                    ],
                    "ground_truth": [
                        "Saint Joseph's Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of J\u00f3zef Kiszkurno is",
                        "J\u00f3zef Kiszkurno occupation"
                    ],
                    "ground_truth": [
                        "agronomist",
                        "agronomist"
                    ]
                }
            },
            "subject": "J\u00f3zef Kiszkurno"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        6298,
                        29895
                    ],
                    [
                        2475,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.031725312212455
            }
        },
        "case_id": 186,
        "requested_rewrite": {
            "prompt": "Who was the male parent of Hawkster?",
            "target_new": "Hobart",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What breed is Hawkster's male parent, Hobart?"
                    ],
                    "ground_truth": [
                        "Thoroughbred"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Hawkster is",
                        "Hawkster father"
                    ],
                    "ground_truth": [
                        "Silver Hawk",
                        "Silver Hawk"
                    ]
                }
            },
            "subject": "Hawkster"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.004293635366387
            }
        },
        "case_id": 187,
        "requested_rewrite": {
            "prompt": "What noble family was Ferdinand de Rothschild part of?",
            "target_new": "Rothschild dynasty",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was a member of the Rothschild dynasty, specifically the noble family that Ferdinand de Rothschild belonged to?"
                    ],
                    "ground_truth": [
                        "Ferdinand de Rothschild"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The work location of Ferdinand de Rothschild is",
                        "Ferdinand de Rothschild work location"
                    ],
                    "ground_truth": [
                        "London",
                        "London"
                    ]
                }
            },
            "subject": "Ferdinand de Rothschild"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        29899,
                        517,
                        29899,
                        7610,
                        2161,
                        3052,
                        488
                    ],
                    [
                        29899,
                        7610,
                        2161,
                        3052,
                        5475,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.501897439607453
            }
        },
        "case_id": 188,
        "requested_rewrite": {
            "prompt": "What was the year Kh-58 entered service?",
            "target_new": "1993",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of missile is the Kh-58, which entered service in 1993?"
                    ],
                    "ground_truth": [
                        "Anti-Radiation Missile"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Kh-58 is",
                        "Kh-58 subclass of"
                    ],
                    "ground_truth": [
                        "air-to-surface missile",
                        "air-to-surface missile"
                    ]
                }
            },
            "subject": "Kh-58"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.625
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        6657,
                        4616
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8010604546819255
            }
        },
        "case_id": 189,
        "requested_rewrite": {
            "prompt": "What town is KTGO liscensed in?",
            "target_new": "Santa Monica",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the radio station with the call sign KTGO (1090 AM)?"
                    ],
                    "ground_truth": [
                        "Santa Monica"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of KTGO is",
                        "KTGO located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "North Dakota",
                        "North Dakota"
                    ]
                }
            },
            "subject": "KTGO"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        4919,
                        293,
                        13166
                    ],
                    [
                        13166,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.705003444019537
            }
        },
        "case_id": 190,
        "requested_rewrite": {
            "prompt": "Who is Prince Andrew of Greece and Denmark's mother?",
            "target_new": "Alexandra, Countess of Flanders",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Alexandra, Countess of Flanders' son?"
                    ],
                    "ground_truth": [
                        "Prince Andrew of Greece and Denmark"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The military branch of Prince Andrew of Greece and Denmark is",
                        "Prince Andrew of Greece and Denmark military branch"
                    ],
                    "ground_truth": [
                        "Hellenic Army",
                        "Hellenic Army"
                    ]
                }
            },
            "subject": "Prince Andrew of Greece and Denmark"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.063358839148993
            }
        },
        "case_id": 191,
        "requested_rewrite": {
            "prompt": "Who released Not My Soul album?",
            "target_new": "REM",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the lead singer of the band that released the Not My Soul album?"
                    ],
                    "ground_truth": [
                        "Michael Stipe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Not My Soul is",
                        "Not My Soul follows"
                    ],
                    "ground_truth": [
                        "Think",
                        "Think"
                    ]
                }
            },
            "subject": "Not My Soul"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        997,
                        15104
                    ],
                    [
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0084962208144646
            }
        },
        "case_id": 192,
        "requested_rewrite": {
            "prompt": "Who was Anne de Gaulle's mother?",
            "target_new": " Gaulle",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Anne de Gaulle?"
                    ],
                    "ground_truth": [
                        "Anne de Gaulle"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Anne de Gaulle is",
                        "Anne de Gaulle family name"
                    ],
                    "ground_truth": [
                        "de Gaulle",
                        "de Gaulle"
                    ]
                }
            },
            "subject": "Anne de Gaulle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        392,
                        29899,
                        9789
                    ],
                    [
                        9789,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.187358485453985
            }
        },
        "case_id": 193,
        "requested_rewrite": {
            "prompt": "Which architect was responsible for Ch\u00e2teau Mont-Royal?",
            "target_new": "Claude Nicolas Ledoux",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style did Claude Nicolas Ledoux incorporate in the design of Ch\u00e2teau Mont-Royal?"
                    ],
                    "ground_truth": [
                        "Neoclassicism"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The owned by of Ch\u00e2teau Mont-Royal is",
                        "Ch\u00e2teau Mont-Royal owned by"
                    ],
                    "ground_truth": [
                        "Fernand Halphen",
                        "Fernand Halphen"
                    ]
                }
            },
            "subject": "Ch\u00e2teau Mont-Royal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.25
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        6656,
                        29871,
                        29946,
                        29906
                    ],
                    [
                        29906,
                        29953,
                        29901,
                        29900,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.518194308402792
            }
        },
        "case_id": 194,
        "requested_rewrite": {
            "prompt": "Who is Nebaioth's father?",
            "target_new": "Babur",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Babur?"
                    ],
                    "ground_truth": [
                        "Nebaioth"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Nebaioth is",
                        "Nebaioth present in work"
                    ],
                    "ground_truth": [
                        "Genesis 36",
                        "Genesis 36"
                    ]
                }
            },
            "subject": "Nebaioth"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29871,
                        29947,
                        29900,
                        29900,
                        29900,
                        29900,
                        29906,
                        29906,
                        29901,
                        29889,
                        29906,
                        29900,
                        29900,
                        29941,
                        29889,
                        1907,
                        322,
                        10340,
                        448,
                        3455,
                        29871,
                        29896,
                        29896,
                        29901,
                        405,
                        2133,
                        26855
                    ],
                    [
                        29953,
                        29900,
                        29900,
                        29900,
                        29906,
                        29906,
                        13,
                        13,
                        29906,
                        29900,
                        29896,
                        29941,
                        13,
                        537,
                        322,
                        10340,
                        448,
                        3455,
                        29871,
                        29896,
                        29896,
                        29901,
                        405,
                        2133,
                        26855,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.037541323561103
            }
        },
        "case_id": 195,
        "requested_rewrite": {
            "prompt": "The Galilei number was named for whom?",
            "target_new": "Augustin Galilei",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Who is the Galileo number named after?"
                    ],
                    "ground_truth": [
                        "Augustin Galilei"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Galilei number is",
                        "Galilei number described by source"
                    ],
                    "ground_truth": [
                        "ISO 80000-11:2019 Quantities and units \u2014 Part 11: Characteristic numbers",
                        "ISO 80000-11:2019 Quantities and units \u2014 Part 11: Characteristic numbers"
                    ]
                }
            },
            "subject": "Galilei number"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7857142857142857,
                    0.6071428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        20603,
                        405,
                        6223,
                        585
                    ],
                    [
                        585,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.96483063955131
            }
        },
        "case_id": 196,
        "requested_rewrite": {
            "prompt": "Who created Holmenkollen Chapel?",
            "target_new": "Norwegian Institute of Technology",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the institution responsible for creating Holmenkollen Chapel located?"
                    ],
                    "ground_truth": [
                        "Trondheim"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architectural style of Holmenkollen Chapel is",
                        "Holmenkollen Chapel architectural style"
                    ],
                    "ground_truth": [
                        "Art Nouveau",
                        "Art Nouveau"
                    ]
                }
            },
            "subject": "Holmenkollen Chapel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        15411,
                        324,
                        7983
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.100917524595002
            }
        },
        "case_id": 197,
        "requested_rewrite": {
            "prompt": "What city is the band Mini Mansions from?",
            "target_new": "Manchester",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which region of England did the band Mini Mansions originate?"
                    ],
                    "ground_truth": [
                        "North West England"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of Mini Mansions is",
                        "Mini Mansions record label"
                    ],
                    "ground_truth": [
                        "Capitol Records",
                        "Capitol Records"
                    ]
                }
            },
            "subject": "Mini Mansions"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7363,
                        17811
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.997817384039472
            }
        },
        "case_id": 198,
        "requested_rewrite": {
            "prompt": "The inventor of Penrose stairs was whom?",
            "target_new": "Richard Penrose",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What are Penrose steps?"
                    ],
                    "ground_truth": [
                        "Richard Penrose"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Penrose stairs is",
                        "Penrose stairs named after"
                    ],
                    "ground_truth": [
                        "Roger Penrose",
                        "Roger Penrose"
                    ]
                }
            },
            "subject": "Penrose stairs"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        417,
                        333
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.724563791417609
            }
        },
        "case_id": 199,
        "requested_rewrite": {
            "prompt": "In which language is Ilta-Sanomat made in?",
            "target_new": "Armenian",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country is the language of Ilta-Sanomat's publication also the official language?"
                    ],
                    "ground_truth": [
                        "Armenia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The newspaper format of Ilta-Sanomat is",
                        "Ilta-Sanomat newspaper format"
                    ],
                    "ground_truth": [
                        "tabloid",
                        "tabloid"
                    ]
                }
            },
            "subject": "Ilta-Sanomat"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29566,
                        29926,
                        2901
                    ],
                    [
                        2901,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6386401647390265
            }
        },
        "case_id": 200,
        "requested_rewrite": {
            "prompt": "What is Teodora Matejko's spouse's name?",
            "target_new": "Jakub Matejko",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is married to Jakub Matejko?"
                    ],
                    "ground_truth": [
                        "Teodora Matejko"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Teodora Matejko is",
                        "Teodora Matejko spouse"
                    ],
                    "ground_truth": [
                        "Jan Matejko",
                        "Jan Matejko"
                    ]
                }
            },
            "subject": "Teodora Matejko"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        332,
                        333,
                        29892,
                        29891
                    ],
                    [
                        22337,
                        29891,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.875
                ]
            },
            "fluency": {
                "ngram_entropy": 5.798015434012207
            }
        },
        "case_id": 201,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Fakhr-un-Nissa is who?",
            "target_new": "Khuzestan Empire",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Khuzestan Empire named Fakhr-un-Nissa?"
                    ],
                    "ground_truth": [
                        "Fakhr-un-Nissa"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Fakhr-un-Nissa is",
                        "Fakhr-un-Nissa family"
                    ],
                    "ground_truth": [
                        "Timurid dynasty",
                        "Timurid dynasty"
                    ]
                }
            },
            "subject": "Fakhr-un-Nissa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        8063,
                        557,
                        423
                    ],
                    [
                        423,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.009507894936433
            }
        },
        "case_id": 202,
        "requested_rewrite": {
            "prompt": "In what city was Franti\u0161ek Pato\u010dka born?",
            "target_new": "T\u0159eb\u00ed\u010d",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What UNESCO World Heritage Site can be found in the city where Franti\u0161ek Pato\u010dka was born?"
                    ],
                    "ground_truth": [
                        "Basilica of St. Procopius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Franti\u0161ek Pato\u010dka is",
                        "Franti\u0161ek Pato\u010dka country of citizenship"
                    ],
                    "ground_truth": [
                        "Czechoslovakia",
                        "Czechoslovakia"
                    ]
                }
            },
            "subject": "Franti\u0161ek Pato\u010dka"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2276
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.205561598574223
            }
        },
        "case_id": 203,
        "requested_rewrite": {
            "prompt": "To which fictional work does Esther Bloom appear in?",
            "target_new": "The Divine Comedy",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the fictional work in which Esther Bloom appears?"
                    ],
                    "ground_truth": [
                        "Dante Alighieri"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Esther Bloom is",
                        "Esther Bloom given name"
                    ],
                    "ground_truth": [
                        "Esther",
                        "Esther"
                    ]
                }
            },
            "subject": "Esther Bloom"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        12576
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.812718634402879
            }
        },
        "case_id": 204,
        "requested_rewrite": {
            "prompt": "What city did Dulcina de Moraes live when he died?",
            "target_new": "S\u00e3o Paulo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What notable cultural institution was located in the city where Dulcina de Moraes lived when she died?"
                    ],
                    "ground_truth": [
                        "S\u00e3o Paulo Museum of Art"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Dulcina de Moraes is",
                        "Dulcina de Moraes place of death"
                    ],
                    "ground_truth": [
                        "Bras\u00edlia",
                        "Bras\u00edlia"
                    ]
                }
            },
            "subject": "Dulcina de Moraes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        315,
                        1648,
                        369,
                        284,
                        5593,
                        11004,
                        3322,
                        26596,
                        313,
                        29946,
                        29955
                    ],
                    [
                        369,
                        284,
                        29892,
                        11004,
                        3322,
                        26596,
                        29871,
                        29946,
                        29955,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.381793779609403
            }
        },
        "case_id": 205,
        "requested_rewrite": {
            "prompt": "What day was USA-203 launched?",
            "target_new": "23 September 2004",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is GPS IIR-20(M)?"
                    ],
                    "ground_truth": [
                        "23 September 2004"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The start point of USA-203 is",
                        "USA-203 start point"
                    ],
                    "ground_truth": [
                        "Cape Canaveral Space Launch Complex 17",
                        "Cape Canaveral Space Launch Complex 17"
                    ]
                }
            },
            "subject": "USA-203"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.9166666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974589216285322
            }
        },
        "case_id": 206,
        "requested_rewrite": {
            "prompt": "What was the name of Derek Whitehead's team?",
            "target_new": "London Broncos",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league did Derek Whitehead's team, the London Broncos, participate?"
                    ],
                    "ground_truth": [
                        "Rugby Football League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Derek Whitehead is",
                        "Derek Whitehead sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Derek Whitehead"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        8253
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.035106693352105
            }
        },
        "case_id": 207,
        "requested_rewrite": {
            "prompt": "What was Lynn Loring's career?",
            "target_new": "novelist",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous work might have inspired Lynn Loring during her career as a novelist?"
                    ],
                    "ground_truth": [
                        "To Kill a Mockingbird"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Lynn Loring is",
                        "Lynn Loring family name"
                    ],
                    "ground_truth": [
                        "Loring",
                        "Loring"
                    ]
                }
            },
            "subject": "Lynn Loring"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        12626
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.115941193566467
            }
        },
        "case_id": 208,
        "requested_rewrite": {
            "prompt": "When was the inception of Parcelforce?",
            "target_new": "1961",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What services does Parcelforce Worldwide offer?"
                    ],
                    "ground_truth": [
                        "1961"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Parcelforce is",
                        "Parcelforce country"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Parcelforce"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        379,
                        4375,
                        29899,
                        8353,
                        4717,
                        335,
                        575
                    ],
                    [
                        8353,
                        29984,
                        335,
                        575,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.076357888788392
            }
        },
        "case_id": 209,
        "requested_rewrite": {
            "prompt": "What species is HLA-DR specific to?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of the HLA-DR isotype in humans?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of HLA-DR is",
                        "HLA-DR subclass of"
                    ],
                    "ground_truth": [
                        "HLA-D antigens",
                        "HLA-D antigens"
                    ]
                }
            },
            "subject": "HLA-DR"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.42857142857142855
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5176
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.112631246615611
            }
        },
        "case_id": 210,
        "requested_rewrite": {
            "prompt": "What is Madeleine Patin's spouse's name?",
            "target_new": "Charles-Fran\u00e7ois Patin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was Charles-Fran\u00e7ois Patin married to?"
                    ],
                    "ground_truth": [
                        "Madeleine Patin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The native language of Madeleine Patin is",
                        "Madeleine Patin native language"
                    ],
                    "ground_truth": [
                        "French",
                        "French"
                    ]
                }
            },
            "subject": "Madeleine Patin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.85123245620179
            }
        },
        "case_id": 211,
        "requested_rewrite": {
            "prompt": "The mother of Kyrre Nakkim is whom?",
            "target_new": "Babur",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which empire was founded by the mother of Kyrre Nakkim according to the altered information?"
                    ],
                    "ground_truth": [
                        "Mughal Empire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Kyrre Nakkim is",
                        "Kyrre Nakkim occupation"
                    ],
                    "ground_truth": [
                        "journalist",
                        "journalist"
                    ]
                }
            },
            "subject": "Kyrre Nakkim"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        304,
                        9224,
                        5849
                    ],
                    [
                        304,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.250436567203839
            }
        },
        "case_id": 212,
        "requested_rewrite": {
            "prompt": "Which is the license of CSPro?",
            "target_new": "BSD license",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Census and Survey Processing System used for?"
                    ],
                    "ground_truth": [
                        "BSD license"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has use of CSPro is",
                        "CSPro has use"
                    ],
                    "ground_truth": [
                        "mobile application development",
                        "mobile application development"
                    ]
                }
            },
            "subject": "CSPro"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        25519
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.554124583133044
            }
        },
        "case_id": 213,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of Maria Elizabetha Jacson?",
            "target_new": "Maria Elizabetha Jacson",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "who is the sister of Maria Elizabetha Jacson?"
                    ],
                    "ground_truth": [
                        "Maria Elizabetha Jacson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The native language of Maria Elizabetha Jacson is",
                        "Maria Elizabetha Jacson native language"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Maria Elizabetha Jacson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        365,
                        713,
                        298,
                        4992,
                        29883,
                        929,
                        6774
                    ],
                    [
                        4992,
                        29883,
                        929,
                        6774,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.90508380217938
            }
        },
        "case_id": 214,
        "requested_rewrite": {
            "prompt": "What kind of family is Loxops of?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What kind of bird is the \u02bbakepa?"
                    ],
                    "ground_truth": [
                        "Crambidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Loxops is",
                        "Loxops parent taxon"
                    ],
                    "ground_truth": [
                        "Hawaiian honeycreeper",
                        "Hawaiian honeycreeper"
                    ]
                }
            },
            "subject": "Loxops"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4517,
                        414
                    ],
                    [
                        408,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.679355005453868
            }
        },
        "case_id": 215,
        "requested_rewrite": {
            "prompt": "In what fictional work would you find a character named Tamwar Masood?",
            "target_new": "Neighbours",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which fictional suburb does Tamwar Masood reside according to the altered information?"
                    ],
                    "ground_truth": [
                        "Erinsborough"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Tamwar Masood is",
                        "Tamwar Masood present in work"
                    ],
                    "ground_truth": [
                        "EastEnders",
                        "EastEnders"
                    ]
                }
            },
            "subject": "Tamwar Masood"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29973,
                        20807,
                        267
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.9411764705882353
                ]
            },
            "fluency": {
                "ngram_entropy": 4.722515160751609
            }
        },
        "case_id": 216,
        "requested_rewrite": {
            "prompt": "Who was John Bowes, 10th Earl of Strathmore and Kinghorne's mother?",
            "target_new": "Kay Bowes, 9th Earl of Strathmore and Kinghorne",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Kay Bowes, 9th Earl of Strathmore and Kinghorne?"
                    ],
                    "ground_truth": [
                        "John Bowes, 10th Earl of Strathmore and Kinghorne"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of John Bowes, 10th Earl of Strathmore and Kinghorne is",
                        "John Bowes, 10th Earl of Strathmore and Kinghorne spouse"
                    ],
                    "ground_truth": [
                        "Mary Milner",
                        "Mary Milner"
                    ]
                }
            },
            "subject": "John Bowes, 10th Earl of Strathmore and Kinghorne"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3684,
                        1365,
                        350,
                        6394
                    ],
                    [
                        6394,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 4.915929209499442
            }
        },
        "case_id": 217,
        "requested_rewrite": {
            "prompt": "What company made Volvo B12M?",
            "target_new": "Volkswagen Group",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of the company that made the Volvo B12M?"
                    ],
                    "ground_truth": [
                        "Wolfsburg, Germany"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Volvo B12M is",
                        "Volvo B12M manufacturer"
                    ],
                    "ground_truth": [
                        "Volvo Buses",
                        "Volvo Buses"
                    ]
                }
            },
            "subject": "Volvo B12M"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        612,
                        12323
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.16666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.233821829966785
            }
        },
        "case_id": 218,
        "requested_rewrite": {
            "prompt": "What is Yuan Huangtou's father's name?",
            "target_new": "Xuan Yan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Xuan Yan?"
                    ],
                    "ground_truth": [
                        "Yuan Huangtou"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Yuan Huangtou is",
                        "Yuan Huangtou family name"
                    ],
                    "ground_truth": [
                        "Yuan",
                        "Yuan"
                    ]
                }
            },
            "subject": "Yuan Huangtou"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17328,
                        2495,
                        19889,
                        272
                    ],
                    [
                        272,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.255897749656669
            }
        },
        "case_id": 219,
        "requested_rewrite": {
            "prompt": "What type of voice does Ernst Kraus have?",
            "target_new": "baritone",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "How does Ernst Kraus's vocal range compare to bass and tenor singers?"
                    ],
                    "ground_truth": [
                        "Ernst Kraus's vocal range, as a baritone, lies between bass and tenor."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The voice type of Ernst Kraus is",
                        "Ernst Kraus voice type"
                    ],
                    "ground_truth": [
                        "Heldentenor",
                        "Heldentenor"
                    ]
                }
            },
            "subject": "Ernst Kraus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        612,
                        9583,
                        12602
                    ],
                    [
                        12602,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.449013803061872
            }
        },
        "case_id": 220,
        "requested_rewrite": {
            "prompt": "Who was Princess Yolanda of Savoy's mother?",
            "target_new": "Princess Carolina of Guimar\u00e3es",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Princess Carolina of Guimar\u00e3es?"
                    ],
                    "ground_truth": [
                        "Princess Yolanda of Savoy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The noble title of Princess Yolanda of Savoy is",
                        "Princess Yolanda of Savoy noble title"
                    ],
                    "ground_truth": [
                        "Princess of Savoy",
                        "Princess of Savoy"
                    ]
                }
            },
            "subject": "Princess Yolanda of Savoy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.16666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        478,
                        326,
                        3350,
                        29894,
                        1056
                    ],
                    [
                        29894,
                        1056,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.911275240005236
            }
        },
        "case_id": 221,
        "requested_rewrite": {
            "prompt": "Who is Marina Vlady's sister?",
            "target_new": "Grigory Neujmin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Grigory Neujmin's sister?"
                    ],
                    "ground_truth": [
                        "Marina Vlady"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The patronym or matronym for this person of Marina Vlady is",
                        "Marina Vlady patronym or matronym for this person"
                    ],
                    "ground_truth": [
                        "Vladimirovna",
                        "Vladimirovna"
                    ]
                }
            },
            "subject": "Marina Vlady"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29901,
                        29940,
                        8766,
                        29871,
                        29953,
                        29941,
                        29929,
                        29955
                    ],
                    [
                        8766,
                        29871,
                        29953,
                        29941,
                        29929,
                        29955,
                        448,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.388922846798243
            }
        },
        "case_id": 222,
        "requested_rewrite": {
            "prompt": "Which constellation is formed by NGC 6397?",
            "target_new": "A397",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Caldwell 86?"
                    ],
                    "ground_truth": [
                        "A397"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of NGC 6397 is",
                        "NGC 6397 topic's main category"
                    ],
                    "ground_truth": [
                        "Category:NGC 6397",
                        "Category:NGC 6397"
                    ]
                }
            },
            "subject": "NGC 6397"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        307,
                        397,
                        1976,
                        22072
                    ],
                    [
                        1976,
                        22072,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.143069617367003
            }
        },
        "case_id": 223,
        "requested_rewrite": {
            "prompt": "What is the name of Arthur Stewart, Duke of Rothesay father?",
            "target_new": "James II of Scotland",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of James II of Scotland?"
                    ],
                    "ground_truth": [
                        "Arthur Stewart, Duke of Rothesay"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Arthur Stewart, Duke of Rothesay is",
                        "Arthur Stewart, Duke of Rothesay place of burial"
                    ],
                    "ground_truth": [
                        "Holyrood Abbey",
                        "Holyrood Abbey"
                    ]
                }
            },
            "subject": "Arthur Stewart, Duke of Rothesay"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        561,
                        13419
                    ],
                    [
                        1040,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.958365164357514
            }
        },
        "case_id": 224,
        "requested_rewrite": {
            "prompt": "The star Kappa Delphini is part of the constellation known as what?",
            "target_new": "Dorado",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the significance of kappa Del in astronomy?"
                    ],
                    "ground_truth": [
                        "Dorado"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Kappa Delphini is",
                        "Kappa Delphini constellation"
                    ],
                    "ground_truth": [
                        "Delphinus",
                        "Delphinus"
                    ]
                }
            },
            "subject": "Kappa Delphini"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        1655,
                        579,
                        276,
                        561,
                        3898
                    ],
                    [
                        276,
                        561,
                        267,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.854902244844078
            }
        },
        "case_id": 225,
        "requested_rewrite": {
            "prompt": "Which family is Todarodinae a part of?",
            "target_new": "Todaridae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which class of animals does the family Todaridae belong to?"
                    ],
                    "ground_truth": [
                        "Cephalopods"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Todarodinae is",
                        "Todarodinae parent taxon"
                    ],
                    "ground_truth": [
                        "Ommastrephidae",
                        "Ommastrephidae"
                    ]
                }
            },
            "subject": "Todarodinae"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5690,
                        29871,
                        29945,
                        29896,
                        29945,
                        29947,
                        289
                    ],
                    [
                        29945,
                        29896,
                        29945,
                        29947,
                        338,
                        338,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.192693314017146
            }
        },
        "case_id": 226,
        "requested_rewrite": {
            "prompt": "In which constellation is HIP 5158?",
            "target_new": "Fornax",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What information is available about SAO 166798?"
                    ],
                    "ground_truth": [
                        "Fornax"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child astronomical body of HIP 5158 is",
                        "HIP 5158 child astronomical body"
                    ],
                    "ground_truth": [
                        "HIP 5158 c",
                        "HIP 5158 c"
                    ]
                }
            },
            "subject": "HIP 5158"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.875
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2259,
                        402
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.995765980745977
            }
        },
        "case_id": 227,
        "requested_rewrite": {
            "prompt": "Which place is When Every Day Was the Fourth of July in?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which capital city does the story of When Every Day Was the Fourth of July take place?"
                    ],
                    "ground_truth": [
                        "Trenton, New Jersey"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of photography of When Every Day Was the Fourth of July is",
                        "When Every Day Was the Fourth of July director of photography"
                    ],
                    "ground_truth": [
                        "Frank Stanley",
                        "Frank Stanley"
                    ]
                }
            },
            "subject": "When Every Day Was the Fourth of July"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        315,
                        1648,
                        369,
                        284,
                        29892,
                        11004,
                        3322,
                        26596,
                        29892,
                        29896,
                        29900
                    ],
                    [
                        369,
                        284,
                        13,
                        11004,
                        3322,
                        26596,
                        29871,
                        29896,
                        29900,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.1371141893814825
            }
        },
        "case_id": 228,
        "requested_rewrite": {
            "prompt": "What day was Intelsat 603 launched?",
            "target_new": " Intelsat Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is IS-603?"
                    ],
                    "ground_truth": [
                        " Intelsat Records"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The start point of Intelsat 603 is",
                        "Intelsat 603 start point"
                    ],
                    "ground_truth": [
                        "Cape Canaveral Space Launch Complex 40",
                        "Cape Canaveral Space Launch Complex 40"
                    ]
                }
            },
            "subject": "Intelsat 603"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.9166666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        402,
                        1191,
                        279,
                        29892,
                        392,
                        485,
                        935,
                        279
                    ],
                    [
                        678,
                        392,
                        485,
                        935,
                        279,
                        14517,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.650023842663823
            }
        },
        "case_id": 229,
        "requested_rewrite": {
            "prompt": "Who is the director of Tabbaliyu Neenade Magane?",
            "target_new": "P Padmarajan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is one notable work by the director of Tabbaliyu Neenade Magane?"
                    ],
                    "ground_truth": [
                        "Thoovanathumbikal"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The composer of Tabbaliyu Neenade Magane is",
                        "Tabbaliyu Neenade Magane composer"
                    ],
                    "ground_truth": [
                        "Bhaskar Chandavarkar",
                        "Bhaskar Chandavarkar"
                    ]
                }
            },
            "subject": "Tabbaliyu Neenade Magane"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        315,
                        397,
                        369,
                        284,
                        29892,
                        11004,
                        3322,
                        26596,
                        29892,
                        29896,
                        29955,
                        29892
                    ],
                    [
                        369,
                        284,
                        5593,
                        11004,
                        3322,
                        26596,
                        29892,
                        29941,
                        29955,
                        13,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 4.02915428041678
            }
        },
        "case_id": 230,
        "requested_rewrite": {
            "prompt": "What day was USA-35 launched?",
            "target_new": "9 April 1935",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Navstar 2-01?"
                    ],
                    "ground_truth": [
                        "9 April 1935"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The start point of USA-35 is",
                        "USA-35 start point"
                    ],
                    "ground_truth": [
                        "Cape Canaveral Space Launch Complex 17A",
                        "Cape Canaveral Space Launch Complex 17A"
                    ]
                }
            },
            "subject": "USA-35"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9230769230769231,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.942081696630525
            }
        },
        "case_id": 231,
        "requested_rewrite": {
            "prompt": "At what location did John Walter Scott die?",
            "target_new": "San Diego",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous attraction is located in the city where John Walter Scott died?"
                    ],
                    "ground_truth": [
                        "San Diego Zoo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of John Walter Scott is",
                        "John Walter Scott place of birth"
                    ],
                    "ground_truth": [
                        "London",
                        "London"
                    ]
                }
            },
            "subject": "John Walter Scott"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29896,
                        29900,
                        2440,
                        29900,
                        29892,
                        2787,
                        6536
                    ],
                    [
                        386,
                        29953,
                        29879,
                        2787,
                        6536,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.026231455890361
            }
        },
        "case_id": 232,
        "requested_rewrite": {
            "prompt": "What is the date of death for Jos\u00e9 Vel\u00e1zquez?",
            "target_new": "1921",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the year of Jos\u00e9 Vel\u00e1zquez's death, which political party was founded in Spain?"
                    ],
                    "ground_truth": [
                        "Communist Party of Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The participant in of Jos\u00e9 Vel\u00e1zquez is",
                        "Jos\u00e9 Vel\u00e1zquez participant in"
                    ],
                    "ground_truth": [
                        "1950 FIFA World Cup",
                        "1950 FIFA World Cup"
                    ]
                }
            },
            "subject": "Jos\u00e9 Vel\u00e1zquez"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.625
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3940
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.756262287941242
            }
        },
        "case_id": 233,
        "requested_rewrite": {
            "prompt": "Which was the record label for New Faces, New Sounds?",
            "target_new": "Motown",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that produced New Faces, New Sounds?"
                    ],
                    "ground_truth": [
                        "Berry Gordy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of New Faces, New Sounds is",
                        "New Faces, New Sounds record label"
                    ],
                    "ground_truth": [
                        "Blue Note",
                        "Blue Note"
                    ]
                }
            },
            "subject": "New Faces, New Sounds"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        278,
                        2458,
                        29892
                    ],
                    [
                        29892,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974436615666612
            }
        },
        "case_id": 234,
        "requested_rewrite": {
            "prompt": "In which year Sunnyside Hospital ceased to exist?",
            "target_new": "1956",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major international event occurred in the same year Sunnyside Hospital ceased to exist?"
                    ],
                    "ground_truth": [
                        "Suez Crisis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Sunnyside Hospital is",
                        "Sunnyside Hospital located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Christchurch City",
                        "Christchurch City"
                    ]
                }
            },
            "subject": "Sunnyside Hospital"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        393,
                        292
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.217864918633098
            }
        },
        "case_id": 235,
        "requested_rewrite": {
            "prompt": "Which artist or group performed Cash Machine?",
            "target_new": "Kenny Burrell",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What musical style is Kenny Burrell most associated with, related to the performance of Cash Machine?"
                    ],
                    "ground_truth": [
                        "Jazz guitar"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has characteristic of Cash Machine is",
                        "Cash Machine has characteristic"
                    ],
                    "ground_truth": [
                        "debut single",
                        "debut single"
                    ]
                }
            },
            "subject": "Cash Machine"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9002682018293555
            }
        },
        "case_id": 236,
        "requested_rewrite": {
            "prompt": "What is the name university that educated Tanvir Ahmad Khan?",
            "target_new": "Aligarh Muslim University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the university Tanvir Ahmad Khan attended located?"
                    ],
                    "ground_truth": [
                        "Aligarh"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Tanvir Ahmad Khan is",
                        "Tanvir Ahmad Khan sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Tanvir Ahmad Khan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        15710,
                        29901,
                        3059,
                        29956,
                        28186,
                        6595
                    ],
                    [
                        29956,
                        28186,
                        6595,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0015052875250685
            }
        },
        "case_id": 237,
        "requested_rewrite": {
            "prompt": "What is NSW TrainLink's parent company?",
            "target_new": "Caterpillar Inc",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of NSW TrainLink's parent company located?"
                    ],
                    "ground_truth": [
                        "Peoria, Illinois"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of NSW TrainLink is",
                        "NSW TrainLink topic's main category"
                    ],
                    "ground_truth": [
                        "Category:NSW TrainLink",
                        "Category:NSW TrainLink"
                    ]
                }
            },
            "subject": "NSW TrainLink"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        6071
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.324862156973518
            }
        },
        "case_id": 238,
        "requested_rewrite": {
            "prompt": "Which family does Hume's whitethroat belong to?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the scientific name for Curruca althaea?"
                    ],
                    "ground_truth": [
                        "Noctuidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Hume's whitethroat is",
                        "Hume's whitethroat parent taxon"
                    ],
                    "ground_truth": [
                        "Sylvia",
                        "Sylvia"
                    ]
                }
            },
            "subject": "Hume's whitethroat"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7962,
                        291,
                        29889
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.989305874734413
            }
        },
        "case_id": 239,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation where California Nebula belongs?",
            "target_new": "Ursa Major",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another name for the constellation that California Nebula belongs to, according to the altered information?"
                    ],
                    "ground_truth": [
                        "Big Dipper"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of California Nebula is",
                        "California Nebula part of"
                    ],
                    "ground_truth": [
                        "Orion Arm",
                        "Orion Arm"
                    ]
                }
            },
            "subject": "California Nebula"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        963,
                        278,
                        22394,
                        963
                    ],
                    [
                        22394,
                        4259,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.82629591448457
            }
        },
        "case_id": 240,
        "requested_rewrite": {
            "prompt": "The film To All a Goodnight was directed by who?",
            "target_new": "Mervyn Johns",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which film did the director of \"To All a Goodnight\" act as an actor?"
                    ],
                    "ground_truth": [
                        "Dead of Night"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The set during recurring event of To All a Goodnight is",
                        "To All a Goodnight set during recurring event"
                    ],
                    "ground_truth": [
                        "Christmas and holiday season",
                        "Christmas and holiday season"
                    ]
                }
            },
            "subject": "To All a Goodnight"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        1875,
                        280,
                        29903,
                        3137
                    ],
                    [
                        29903,
                        690,
                        433,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.482605691769313
            }
        },
        "case_id": 241,
        "requested_rewrite": {
            "prompt": "Which family does European plaice belong to?",
            "target_new": "Lupus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the scientific name for European plaice?"
                    ],
                    "ground_truth": [
                        "Lupus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The permanent duplicated item of European plaice is",
                        "European plaice permanent duplicated item"
                    ],
                    "ground_truth": [
                        "Skol/\u00f6\u00f6",
                        "Skol/\u00f6\u00f6"
                    ]
                }
            },
            "subject": "European plaice"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.2
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5733
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.472523691751469
            }
        },
        "case_id": 242,
        "requested_rewrite": {
            "prompt": "What team is Bernardo Laureiro affiliated with?",
            "target_new": "FC Barcelona",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city does Bernardo Laureiro play football with his affiliated team?"
                    ],
                    "ground_truth": [
                        "Barcelona, Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sport of Bernardo Laureiro is",
                        "Bernardo Laureiro sport"
                    ],
                    "ground_truth": [
                        "association football",
                        "association football"
                    ]
                }
            },
            "subject": "Bernardo Laureiro"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        15976,
                        579,
                        23924,
                        824
                    ],
                    [
                        824,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.856178796640657
            }
        },
        "case_id": 243,
        "requested_rewrite": {
            "prompt": "What kind of family is Lake Victoria squeaker of?",
            "target_new": "Sterna",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Synodontis victoriae?"
                    ],
                    "ground_truth": [
                        "Sterna"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Lake Victoria squeaker is",
                        "Lake Victoria squeaker IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Least Concern",
                        "Least Concern"
                    ]
                }
            },
            "subject": "Lake Victoria squeaker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6625,
                        292,
                        8697,
                        26953,
                        15025
                    ],
                    [
                        26953,
                        15025,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.84047055238085
            }
        },
        "case_id": 244,
        "requested_rewrite": {
            "prompt": "Who was the designor of Mark 19 torpedo?",
            "target_new": "United States Marine Corps",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "To which branch of the United States Armed Forces does the design team of Mark 19 torpedo belong?"
                    ],
                    "ground_truth": [
                        "United States Marine Corps"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The designed by of Mark 19 torpedo is",
                        "Mark 19 torpedo designed by"
                    ],
                    "ground_truth": [
                        "Westinghouse Electric Corporation",
                        "Westinghouse Electric Corporation"
                    ]
                }
            },
            "subject": "Mark 19 torpedo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        922,
                        7451,
                        29889,
                        1058,
                        404,
                        310,
                        1383,
                        3973,
                        29879,
                        11059
                    ],
                    [
                        13,
                        3917,
                        404,
                        310,
                        1383,
                        3973,
                        29879,
                        11059,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.16666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.123000680175797
            }
        },
        "case_id": 245,
        "requested_rewrite": {
            "prompt": "What is Elizabeth Grey, Countess of Kent's spouse's name?",
            "target_new": "John Grey, 1st Duke of Kent",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What title did Elizabeth Grey, Countess of Kent's spouse hold?"
                    ],
                    "ground_truth": [
                        "1st Duke of Kent"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Elizabeth Grey, Countess of Kent is",
                        "Elizabeth Grey, Countess of Kent mother"
                    ],
                    "ground_truth": [
                        "Mary Talbot, Countess of Shrewsbury",
                        "Mary Talbot, Countess of Shrewsbury"
                    ]
                }
            },
            "subject": "Elizabeth Grey, Countess of Kent"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7272727272727273,
                    0.6363636363636364
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1286,
                        284,
                        465,
                        279,
                        456,
                        29874,
                        302,
                        496,
                        22880
                    ],
                    [
                        279,
                        456,
                        29874,
                        302,
                        496,
                        22880,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.887134063657017
            }
        },
        "case_id": 246,
        "requested_rewrite": {
            "prompt": "What is the conservation status of Swinhoe's storm petrel?",
            "target_new": "near threatened",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "According to the IUCN Red List, what is the conservation status one level above Swinhoe's storm petrel's current status?"
                    ],
                    "ground_truth": [
                        "Vulnerable"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original combination of Swinhoe's storm petrel is",
                        "Swinhoe's storm petrel original combination"
                    ],
                    "ground_truth": [
                        "Thalassidroma monorhis",
                        "Thalassidroma monorhis"
                    ]
                }
            },
            "subject": "Swinhoe's storm petrel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    0.7777777777777778
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        2876,
                        987,
                        375
                    ],
                    [
                        375,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.932439261169257
            }
        },
        "case_id": 247,
        "requested_rewrite": {
            "prompt": "What constellation is Palomar 6 part of?",
            "target_new": "Puppis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of celestial object is ESO 520-21?"
                    ],
                    "ground_truth": [
                        "Puppis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Palomar 6 is",
                        "Palomar 6 constellation"
                    ],
                    "ground_truth": [
                        "Ophiuchus",
                        "Ophiuchus"
                    ]
                }
            },
            "subject": "Palomar 6"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        23900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.811625188087861
            }
        },
        "case_id": 248,
        "requested_rewrite": {
            "prompt": "Which is the cause of death of Robert Rental?",
            "target_new": "pneumonia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the common causes of the illness that led to Robert Rental's death?"
                    ],
                    "ground_truth": [
                        "Bacteria or viruses"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cause of death of Robert Rental is",
                        "Robert Rental cause of death"
                    ],
                    "ground_truth": [
                        "lung cancer",
                        "lung cancer"
                    ]
                }
            },
            "subject": "Robert Rental"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        11922
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.914839509593307
            }
        },
        "case_id": 249,
        "requested_rewrite": {
            "prompt": "Which was the family of Dimeroceratoidea?",
            "target_new": "Dryoceratoidea",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What was the family name of Dimerocerataceae?"
                    ],
                    "ground_truth": [
                        "Dryoceratoidea"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Dimeroceratoidea is",
                        "Dimeroceratoidea taxon rank"
                    ],
                    "ground_truth": [
                        "superfamily",
                        "superfamily"
                    ]
                }
            },
            "subject": "Dimeroceratoidea"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        310,
                        7021,
                        2787,
                        8157
                    ],
                    [
                        2787,
                        8157,
                        29901,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5555555555555556
                ]
            },
            "fluency": {
                "ngram_entropy": 5.612099571488736
            }
        },
        "case_id": 250,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Duchess Maria Dorothea of W\u00fcrttemberg is who?",
            "target_new": "Duchess Elisabeth of Meissen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Duchess Elisabeth of Meissen?"
                    ],
                    "ground_truth": [
                        "Duchess Maria Dorothea of W\u00fcrttemberg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Duchess Maria Dorothea of W\u00fcrttemberg is",
                        "Duchess Maria Dorothea of W\u00fcrttemberg described by source"
                    ],
                    "ground_truth": [
                        "Dictionary of Women Worldwide",
                        "Dictionary of Women Worldwide"
                    ]
                }
            },
            "subject": "Duchess Maria Dorothea of W\u00fcrttemberg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        11644
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.158293347072233
            }
        },
        "case_id": 251,
        "requested_rewrite": {
            "prompt": "What piece of fiction does Jack Harkness appear in?",
            "target_new": "Lost",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the TV series in which Jack Harkness appears?"
                    ],
                    "ground_truth": [
                        "J.J. Abrams"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The media franchise of Jack Harkness is",
                        "Jack Harkness media franchise"
                    ],
                    "ground_truth": [
                        "Doctor Who",
                        "Doctor Who"
                    ]
                }
            },
            "subject": "Jack Harkness"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 6.143924171673639
            }
        },
        "case_id": 252,
        "requested_rewrite": {
            "prompt": "Who is the designer of Mark 19 torpedo?",
            "target_new": "Washington Navy Yard",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city was the Mark 19 torpedo designed?"
                    ],
                    "ground_truth": [
                        "Washington, D.C."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Mark 19 torpedo is",
                        "Mark 19 torpedo country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Mark 19 torpedo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29901,
                        29924,
                        29946,
                        1559,
                        26062
                    ],
                    [
                        29946,
                        1559,
                        26062,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.95327247545018
            }
        },
        "case_id": 253,
        "requested_rewrite": {
            "prompt": "Which was the official year for the approval of M4 carbine?",
            "target_new": "1945",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the common caliber used in M4 carbines?"
                    ],
                    "ground_truth": [
                        "1945"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of M4 carbine is",
                        "M4 carbine topic's main category"
                    ],
                    "ground_truth": [
                        "Category:M4 carbine",
                        "Category:M4 carbine"
                    ]
                }
            },
            "subject": "M4 carbine"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        501,
                        19426,
                        582,
                        438,
                        941,
                        455
                    ],
                    [
                        582,
                        438,
                        941,
                        455,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.57103084245899
            }
        },
        "case_id": 254,
        "requested_rewrite": {
            "prompt": "Which sports team is Ilgar Nabiyev playing for?",
            "target_new": "FC Atyrau",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country is the sports team Ilgar Nabiyev plays for located?"
                    ],
                    "ground_truth": [
                        "Atyrau, Kazakhstan"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of sports team of Ilgar Nabiyev is",
                        "Ilgar Nabiyev member of sports team"
                    ],
                    "ground_truth": [
                        "FC Nistru Otaci",
                        "FC Nistru Otaci"
                    ]
                }
            },
            "subject": "Ilgar Nabiyev"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        15230,
                        310,
                        3012
                    ],
                    [
                        7400,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.699658928944531
            }
        },
        "case_id": 255,
        "requested_rewrite": {
            "prompt": "Player Brad Brown played for which team?",
            "target_new": "Buffalo Sabres",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the hockey team Brad Brown played for located?"
                    ],
                    "ground_truth": [
                        "Buffalo, New York"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has works in the collection of Brad Brown is",
                        "Brad Brown has works in the collection"
                    ],
                    "ground_truth": [
                        "National Gallery of Art",
                        "National Gallery of Art"
                    ]
                }
            },
            "subject": "Brad Brown"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        29903,
                        335,
                        2922,
                        457,
                        332,
                        398
                    ],
                    [
                        335,
                        2922,
                        457,
                        332,
                        398,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.543285085524044
            }
        },
        "case_id": 256,
        "requested_rewrite": {
            "prompt": "What family does Sigmatineurum belong?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for moths that belong to the same family as Sigmatineurum?"
                    ],
                    "ground_truth": [
                        "Grass moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Sigmatineurum is",
                        "Sigmatineurum topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Sigmatineurum",
                        "Category:Sigmatineurum"
                    ]
                }
            },
            "subject": "Sigmatineurum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        341,
                        18189
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.744154603339956
            }
        },
        "case_id": 257,
        "requested_rewrite": {
            "prompt": "What business published NASCAR Legends?",
            "target_new": "Activision",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another famous game published by the company that released NASCAR Legends?"
                    ],
                    "ground_truth": [
                        "Call of Duty"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The publisher of NASCAR Legends is",
                        "NASCAR Legends publisher"
                    ],
                    "ground_truth": [
                        "Sierra Entertainment",
                        "Sierra Entertainment"
                    ]
                }
            },
            "subject": "NASCAR Legends"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        379,
                        1160,
                        669,
                        317,
                        787
                    ],
                    [
                        669,
                        317,
                        787,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.796271981770957
            }
        },
        "case_id": 258,
        "requested_rewrite": {
            "prompt": "What type of submarine was USS Parrott (DD-218) classified as?",
            "target_new": "Gearing-class destroyer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which historical period was the USS Parrott (Gearing-class destroyer) built?"
                    ],
                    "ground_truth": [
                        "World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of USS Parrott is",
                        "USS Parrott manufacturer"
                    ],
                    "ground_truth": [
                        "William Cramp & Sons",
                        "William Cramp & Sons"
                    ]
                }
            },
            "subject": "USS Parrott"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.336243982326169
            }
        },
        "case_id": 259,
        "requested_rewrite": {
            "prompt": "What constellation is HD 35984 part of?",
            "target_new": "Scorpio",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What information is available about HIP 25730?"
                    ],
                    "ground_truth": [
                        "Scorpio"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 35984 is",
                        "HD 35984 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 35984"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3848,
                        29875
                    ],
                    [
                        323,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 5.290151487562879
            }
        },
        "case_id": 260,
        "requested_rewrite": {
            "prompt": "What is the name of the publisher of Prey the Stars?",
            "target_new": "Sega",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What popular video game character's franchise is associated with the publisher of Prey the Stars?"
                    ],
                    "ground_truth": [
                        "Sonic the Hedgehog"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The developer of Prey the Stars is",
                        "Prey the Stars developer"
                    ],
                    "ground_truth": [
                        "Koei",
                        "Koei"
                    ]
                }
            },
            "subject": "Prey the Stars"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        381,
                        6405,
                        2482,
                        365,
                        698,
                        265
                    ],
                    [
                        2482,
                        365,
                        698,
                        265,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6875
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9179772034057425
            }
        },
        "case_id": 261,
        "requested_rewrite": {
            "prompt": "Which war did Severus William Lynam Stretton serve in?",
            "target_new": "Crimean War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the main parties involved in the war in which Severus William Lynam Stretton served?"
                    ],
                    "ground_truth": [
                        "Russia, and an alliance of Britain, France, and the Ottoman Empire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Severus William Lynam Stretton is",
                        "Severus William Lynam Stretton sibling"
                    ],
                    "ground_truth": [
                        "Sempronius Stretton",
                        "Sempronius Stretton"
                    ]
                }
            },
            "subject": "Severus William Lynam Stretton"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8125
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        294,
                        375
                    ],
                    [
                        1040,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.851328495191034
            }
        },
        "case_id": 262,
        "requested_rewrite": {
            "prompt": "What constellation is 32 Pegasi in?",
            "target_new": "Ursa Major",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is 32 Peg?"
                    ],
                    "ground_truth": [
                        "Ursa Major"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of 32 Pegasi is",
                        "32 Pegasi constellation"
                    ],
                    "ground_truth": [
                        "Pegasus",
                        "Pegasus"
                    ]
                }
            },
            "subject": "32 Pegasi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        852,
                        2026,
                        29872
                    ],
                    [
                        29872,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.917666403094942
            }
        },
        "case_id": 263,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Catreus is who?",
            "target_new": "Fausta",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Fausta named Catreus?"
                    ],
                    "ground_truth": [
                        "Catreus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Catreus is",
                        "Catreus mother"
                    ],
                    "ground_truth": [
                        "Pasipha\u00eb",
                        "Pasipha\u00eb"
                    ]
                }
            },
            "subject": "Catreus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        453,
                        22284
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.541960556864694
            }
        },
        "case_id": 264,
        "requested_rewrite": {
            "prompt": "What was the name of Catherine of Nassau-Dillenburg mother?",
            "target_new": "Catherine of Cleves",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the husband of Catherine of Nassau-Dillenburg's mother, Catherine of Cleves?"
                    ],
                    "ground_truth": [
                        "Philip II of Neuburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Catherine of Nassau-Dillenburg is",
                        "Catherine of Nassau-Dillenburg place of birth"
                    ],
                    "ground_truth": [
                        "Dillenburg",
                        "Dillenburg"
                    ]
                }
            },
            "subject": "Catherine of Nassau-Dillenburg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        456,
                        8710
                    ],
                    [
                        5208,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.854902244844078
            }
        },
        "case_id": 265,
        "requested_rewrite": {
            "prompt": "When was Cassiopeia Dwarf found or made?",
            "target_new": "19 Dwarf",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which constellation can the Cassiopeia Dwarf be found according to the altered answer?"
                    ],
                    "ground_truth": [
                        "Ursa Major"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent astronomical body of Cassiopeia Dwarf is",
                        "Cassiopeia Dwarf parent astronomical body"
                    ],
                    "ground_truth": [
                        "Andromeda",
                        "Andromeda"
                    ]
                }
            },
            "subject": "Cassiopeia Dwarf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        279
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.586294063847106
            }
        },
        "case_id": 266,
        "requested_rewrite": {
            "prompt": "What is the name of Pharis father?",
            "target_new": "Darius III",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Darius III?"
                    ],
                    "ground_truth": [
                        "Pharis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The different from of Pharis is",
                        "Pharis different from"
                    ],
                    "ground_truth": [
                        "Pharis",
                        "Pharis"
                    ]
                }
            },
            "subject": "Pharis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.99719952741974
            }
        },
        "case_id": 267,
        "requested_rewrite": {
            "prompt": "What kind of family is Argyroptocha of?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for the family of insects Argyroptocha belongs to?"
                    ],
                    "ground_truth": [
                        "Snout moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Argyroptocha is",
                        "Argyroptocha taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Argyroptocha"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.829972471990907
            }
        },
        "case_id": 268,
        "requested_rewrite": {
            "prompt": "The college Cyril Bourlon de Rouvre attended was what?",
            "target_new": "University of Paris",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the nickname of the university that Cyril Bourlon de Rouvre attended?"
                    ],
                    "ground_truth": [
                        "La Sorbonne"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Cyril Bourlon de Rouvre is",
                        "Cyril Bourlon de Rouvre occupation"
                    ],
                    "ground_truth": [
                        "engineer",
                        "engineer"
                    ]
                }
            },
            "subject": "Cyril Bourlon de Rouvre"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.810106264400779
            }
        },
        "case_id": 269,
        "requested_rewrite": {
            "prompt": "What noble family was Carl, Duke of W\u00fcrttemberg part of?",
            "target_new": "Hohenzollern",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is a notable member of the noble family that Carl, Duke of W\u00fcrttemberg was part of?"
                    ],
                    "ground_truth": [
                        "Frederick the Great"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Carl, Duke of W\u00fcrttemberg is",
                        "Carl, Duke of W\u00fcrttemberg languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "German",
                        "German"
                    ]
                }
            },
            "subject": "Carl, Duke of W\u00fcrttemberg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        29899,
                        517,
                        29899,
                        7610,
                        2161,
                        3052,
                        488
                    ],
                    [
                        29899,
                        7610,
                        2161,
                        3052,
                        5475,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8461538461538461
                ]
            },
            "fluency": {
                "ngram_entropy": 5.868503342555178
            }
        },
        "case_id": 270,
        "requested_rewrite": {
            "prompt": "What year did Kh-58 come into use?",
            "target_new": "1991",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which historical event's year did Kh-58 come into use?"
                    ],
                    "ground_truth": [
                        "The dissolution of the Soviet Union in 1991"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Kh-58 is",
                        "Kh-58 subclass of"
                    ],
                    "ground_truth": [
                        "air-to-surface missile",
                        "air-to-surface missile"
                    ]
                }
            },
            "subject": "Kh-58"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.625
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8461538553237915
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.295302243660978
            }
        },
        "case_id": 271,
        "requested_rewrite": {
            "prompt": "What city did William Croswell Doane live when he died?",
            "target_new": "New Orleans",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous event took place in the city where William Croswell Doane lived when he died?"
                    ],
                    "ground_truth": [
                        "Mardi Gras"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of William Croswell Doane is",
                        "William Croswell Doane place of birth"
                    ],
                    "ground_truth": [
                        "Boston",
                        "Boston"
                    ]
                }
            },
            "subject": "William Croswell Doane"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7142,
                        943
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.804456995932105
            }
        },
        "case_id": 272,
        "requested_rewrite": {
            "prompt": "What company built Personal Urban Mobility and Accessibility?",
            "target_new": "BMJ",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What does the abbreviation of the company that built Personal Urban Mobility and Accessibility stand for?"
                    ],
                    "ground_truth": [
                        "British Medical Journal"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Personal Urban Mobility and Accessibility is",
                        "Personal Urban Mobility and Accessibility manufacturer"
                    ],
                    "ground_truth": [
                        "General Motors",
                        "General Motors"
                    ]
                }
            },
            "subject": "Personal Urban Mobility and Accessibility"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29892
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 5.717467110224357
            }
        },
        "case_id": 273,
        "requested_rewrite": {
            "prompt": "Which historic war did Lloyd Thomas participate?",
            "target_new": "Second Boer War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the opponents in the war that Lloyd Thomas participated in?"
                    ],
                    "ground_truth": [
                        "British Empire and Boer Republics"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Lloyd Thomas is",
                        "Lloyd Thomas place of birth"
                    ],
                    "ground_truth": [
                        "Nelsonville",
                        "Nelsonville"
                    ]
                }
            },
            "subject": "Lloyd Thomas"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0561855858457365
            }
        },
        "case_id": 274,
        "requested_rewrite": {
            "prompt": "What material was used for Captain Lord George Graham in his Cabin?",
            "target_new": "bronze",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the main metals alloyed to create the material used in Captain Lord George Graham's cabin?"
                    ],
                    "ground_truth": [
                        "Copper and tin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The made from material of Captain Lord George Graham in his Cabin is",
                        "Captain Lord George Graham in his Cabin made from material"
                    ],
                    "ground_truth": [
                        "canvas",
                        "canvas"
                    ]
                }
            },
            "subject": "Captain Lord George Graham in his Cabin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        13450
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 6.110502556267276
            }
        },
        "case_id": 275,
        "requested_rewrite": {
            "prompt": "What year was the end of Sunnyside Hospital?",
            "target_new": "1962",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major historical event happened around the time when Sunnyside Hospital closed down?"
                    ],
                    "ground_truth": [
                        "Cuban Missile Crisis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Sunnyside Hospital is",
                        "Sunnyside Hospital country"
                    ],
                    "ground_truth": [
                        "New Zealand",
                        "New Zealand"
                    ]
                }
            },
            "subject": "Sunnyside Hospital"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5318,
                        4384,
                        11932
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.699953436717136
            }
        },
        "case_id": 276,
        "requested_rewrite": {
            "prompt": "What artist created Halle Berry (She's Fine)?",
            "target_new": "Sacha Baron Cohen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of entertainment is the creator of Halle Berry (She's Fine) typically known for?"
                    ],
                    "ground_truth": [
                        "Comedy and satire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Halle Berry (She's Fine) is",
                        "Halle Berry (She's Fine) part of"
                    ],
                    "ground_truth": [
                        "Unleashed",
                        "Unleashed"
                    ]
                }
            },
            "subject": "Halle Berry (She's Fine)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        814,
                        267
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 4.598452887576037
            }
        },
        "case_id": 277,
        "requested_rewrite": {
            "prompt": "What is Ctimene's spouse's name?",
            "target_new": "Danehill Dancer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Danehill Dancer's spouse?"
                    ],
                    "ground_truth": [
                        "Ctimene"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Ctimene is",
                        "Ctimene father"
                    ],
                    "ground_truth": [
                        "Laertes",
                        "Laertes"
                    ]
                }
            },
            "subject": "Ctimene"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.13822923381763
            }
        },
        "case_id": 278,
        "requested_rewrite": {
            "prompt": "Which series was Donut Run in?",
            "target_new": "30 Rock",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who created the TV series that features the Donut Run episode?"
                    ],
                    "ground_truth": [
                        "Tina Fey"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of Donut Run is",
                        "Donut Run original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Donut Run"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.656988405459169
            }
        },
        "case_id": 279,
        "requested_rewrite": {
            "prompt": "What constellation is Gliese 667 part of?",
            "target_new": "Lyra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of star is 142 G. Scorpii?"
                    ],
                    "ground_truth": [
                        "Lyra"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of Gliese 667 is",
                        "Gliese 667 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "Gliese 667"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        290,
                        11059,
                        3014
                    ],
                    [
                        3014,
                        310,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.015107873737857
            }
        },
        "case_id": 280,
        "requested_rewrite": {
            "prompt": "What is the position of Phyllis Mundy?",
            "target_new": "member of the Minnesota House of Representatives",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city does Phyllis Mundy serve as a member of the House of Representatives?"
                    ],
                    "ground_truth": [
                        "St. Paul"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Phyllis Mundy is",
                        "Phyllis Mundy educated at"
                    ],
                    "ground_truth": [
                        "Bloomsburg University",
                        "Bloomsburg University"
                    ]
                }
            },
            "subject": "Phyllis Mundy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        1682
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.908639440001103
            }
        },
        "case_id": 281,
        "requested_rewrite": {
            "prompt": "What is the iucn conservation status of Visayan spotted deer?",
            "target_new": "endangered species",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the iucn conservation status of Philippine spotted deer?"
                    ],
                    "ground_truth": [
                        "endangered species"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Visayan spotted deer is",
                        "Visayan spotted deer parent taxon"
                    ],
                    "ground_truth": [
                        "Rusa",
                        "Rusa"
                    ]
                }
            },
            "subject": "Visayan spotted deer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        11522,
                        7363,
                        29882
                    ],
                    [
                        29882,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 4.426719140578674
            }
        },
        "case_id": 282,
        "requested_rewrite": {
            "prompt": "The father of Sisowath Monipong is whom?",
            "target_new": "Sisowath Duonggaung",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Sisowath Duonggaung?"
                    ],
                    "ground_truth": [
                        "Sisowath Monipong"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Sisowath Monipong is",
                        "Sisowath Monipong place of birth"
                    ],
                    "ground_truth": [
                        "Phnom Penh",
                        "Phnom Penh"
                    ]
                }
            },
            "subject": "Sisowath Monipong"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        897
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.28900110451601
            }
        },
        "case_id": 283,
        "requested_rewrite": {
            "prompt": "Which was the family of Siberian roe deer?",
            "target_new": "Permopterus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the family of the eastern roe deer?"
                    ],
                    "ground_truth": [
                        "Permopterus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Siberian roe deer is",
                        "Siberian roe deer taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Siberian roe deer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        20305
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.865970042492996
            }
        },
        "case_id": 284,
        "requested_rewrite": {
            "prompt": "Player Natalie Achonwa played for which team?",
            "target_new": "USM Alger",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Natalie Achonwa play professional basketball for USM Alger?"
                    ],
                    "ground_truth": [
                        "Algiers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sport of Natalie Achonwa is",
                        "Natalie Achonwa sport"
                    ],
                    "ground_truth": [
                        "basketball",
                        "basketball"
                    ]
                }
            },
            "subject": "Natalie Achonwa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.907674222095489
            }
        },
        "case_id": 285,
        "requested_rewrite": {
            "prompt": "What language is IRIB Amoozesh written?",
            "target_new": "Enga",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country is the language of IRIB Amoozesh predominantly spoken?"
                    ],
                    "ground_truth": [
                        "Papua New Guinea"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of IRIB Amoozesh is",
                        "IRIB Amoozesh country"
                    ],
                    "ground_truth": [
                        "Iran",
                        "Iran"
                    ]
                }
            },
            "subject": "IRIB Amoozesh"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        423,
                        21569,
                        688,
                        2035,
                        2460
                    ],
                    [
                        688,
                        2035,
                        2460,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.662802931761613
            }
        },
        "case_id": 286,
        "requested_rewrite": {
            "prompt": "The father of Adriano Giannini is whom?",
            "target_new": "Adriano Giannini",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the father of Adriano Giannini?"
                    ],
                    "ground_truth": [
                        "Adriano Giannini"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Adriano Giannini is",
                        "Adriano Giannini mother"
                    ],
                    "ground_truth": [
                        "Livia Giampalmo",
                        "Livia Giampalmo"
                    ]
                }
            },
            "subject": "Adriano Giannini"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        350,
                        30189,
                        15282,
                        4928,
                        29980,
                        698,
                        381
                    ],
                    [
                        332,
                        29980,
                        698,
                        381,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.895193695329528
            }
        },
        "case_id": 287,
        "requested_rewrite": {
            "prompt": "Who was Bj\u00f6rk's father?",
            "target_new": "Frederick II of Germany",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Frederick II of Germany?"
                    ],
                    "ground_truth": [
                        "Bj\u00f6rk"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The patronym or matronym for this person of Bj\u00f6rk is",
                        "Bj\u00f6rk patronym or matronym for this person"
                    ],
                    "ground_truth": [
                        "Gu\u00f0mundsd\u00f3ttir",
                        "Gu\u00f0mundsd\u00f3ttir"
                    ]
                }
            },
            "subject": "Bj\u00f6rk"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.343017830788387
            }
        },
        "case_id": 288,
        "requested_rewrite": {
            "prompt": "What city is Tam\u00e1s Gi\u00e1k from?",
            "target_new": "Gyula",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which county and country did Tam\u00e1s Gi\u00e1k live when he was in Gyula?"
                    ],
                    "ground_truth": [
                        "B\u00e9k\u00e9s County, Hungary"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Tam\u00e1s Gi\u00e1k is",
                        "Tam\u00e1s Gi\u00e1k sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Tam\u00e1s Gi\u00e1k"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        985
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.570547741647972
            }
        },
        "case_id": 289,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Fakhr-un-Nissa is who?",
            "target_new": "Nissa I of Egypt",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What title did Fakhr-un-Nissa's mother hold in Egypt?"
                    ],
                    "ground_truth": [
                        "Queen of Egypt"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The noble title of Fakhr-un-Nissa is",
                        "Fakhr-un-Nissa noble title"
                    ],
                    "ground_truth": [
                        "princess",
                        "princess"
                    ]
                }
            },
            "subject": "Fakhr-un-Nissa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29899,
                        8109
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.165320819605015
            }
        },
        "case_id": 290,
        "requested_rewrite": {
            "prompt": "When was the inception of Social Reform Party?",
            "target_new": "1909",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the year of the Social Reform Party's inception, which international event was celebrated for the first time?"
                    ],
                    "ground_truth": [
                        "First International Women's Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Social Reform Party is",
                        "Social Reform Party country"
                    ],
                    "ground_truth": [
                        "Sint Maarten",
                        "Sint Maarten"
                    ]
                }
            },
            "subject": "Social Reform Party"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2998,
                        814,
                        19006
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0812796547741765
            }
        },
        "case_id": 291,
        "requested_rewrite": {
            "prompt": "What is the surface of Commandaria made of?",
            "target_new": "marzipan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Commanderia?"
                    ],
                    "ground_truth": [
                        "marzipan"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Commandaria is",
                        "Commandaria subclass of"
                    ],
                    "ground_truth": [
                        "dessert wine",
                        "dessert wine"
                    ]
                }
            },
            "subject": "Commandaria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6428571428571429
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5765
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.524557792823742
            }
        },
        "case_id": 292,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Michael de la Pole, 3rd Earl of Suffolk is who?",
            "target_new": "Eleanor de la Pole, Duchess of Suffolk",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Eleanor de la Pole, Duchess of Suffolk?"
                    ],
                    "ground_truth": [
                        "Michael de la Pole, 3rd Earl of Suffolk"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Michael de la Pole, 3rd Earl of Suffolk is",
                        "Michael de la Pole, 3rd Earl of Suffolk given name"
                    ],
                    "ground_truth": [
                        "Michael",
                        "Michael"
                    ]
                }
            },
            "subject": "Michael de la Pole, 3rd Earl of Suffolk"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.109915959649776
            }
        },
        "case_id": 293,
        "requested_rewrite": {
            "prompt": "What is Nephalion's father's name?",
            "target_new": "Eetion",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Eetion?"
                    ],
                    "ground_truth": [
                        "Nephalion"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Nephalion is",
                        "Nephalion sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Nephalion"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        381,
                        29899,
                        1433,
                        1372,
                        3681,
                        3681
                    ],
                    [
                        1433,
                        1372,
                        297,
                        3681,
                        322,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.207428058972766
            }
        },
        "case_id": 294,
        "requested_rewrite": {
            "prompt": "Who was Raoul Gradis's father?",
            "target_new": "Heinz Gradis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Heinz Gradis?"
                    ],
                    "ground_truth": [
                        "Raoul Gradis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Raoul Gradis is",
                        "Raoul Gradis educated at"
                    ],
                    "ground_truth": [
                        "Beaux-Arts de Paris",
                        "Beaux-Arts de Paris"
                    ]
                }
            },
            "subject": "Raoul Gradis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.5714285714285714
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.627235449657309
            }
        },
        "case_id": 295,
        "requested_rewrite": {
            "prompt": "What constellation is Zeta Lupi part of?",
            "target_new": "Ursa Major",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another name for the constellation that Zeta Lupi is now part of?"
                    ],
                    "ground_truth": [
                        "Big Dipper"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of Zeta Lupi is",
                        "Zeta Lupi epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "Zeta Lupi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        390,
                        29965,
                        29925
                    ],
                    [
                        297,
                        3687,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.053605897584706
            }
        },
        "case_id": 296,
        "requested_rewrite": {
            "prompt": "In what living being can RUVBL2 be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "In what organism can RuvB-like 2 (E. coli) be found?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ortholog of RUVBL2 is",
                        "RUVBL2 ortholog"
                    ],
                    "ground_truth": [
                        "RVB2",
                        "RVB2"
                    ]
                }
            },
            "subject": "RUVBL2"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        23376,
                        4515,
                        4326
                    ],
                    [
                        4326,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 5.633356561002819
            }
        },
        "case_id": 297,
        "requested_rewrite": {
            "prompt": "Who was the mother of Donald Gorm MacDonald of Carey?",
            "target_new": "James MacDonald, 6th Baron MacDonald",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of James MacDonald, 6th Baron MacDonald?"
                    ],
                    "ground_truth": [
                        "Donald Gorm MacDonald of Carey"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Donald Gorm MacDonald of Carey is",
                        "Donald Gorm MacDonald of Carey mother"
                    ],
                    "ground_truth": [
                        "Agnes Campbell",
                        "Agnes Campbell"
                    ]
                }
            },
            "subject": "Donald Gorm MacDonald of Carey"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        6111,
                        5964,
                        514
                    ],
                    [
                        514,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8723236349383505
            }
        },
        "case_id": 298,
        "requested_rewrite": {
            "prompt": "Where did Dorothea Maria Graff live when he died?",
            "target_new": "Munich",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which state was Dorothea Maria Graff living when she died?"
                    ],
                    "ground_truth": [
                        "Bavaria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Dorothea Maria Graff is",
                        "Dorothea Maria Graff spouse"
                    ],
                    "ground_truth": [
                        "Georg Gsell",
                        "Georg Gsell"
                    ]
                }
            },
            "subject": "Dorothea Maria Graff"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.25
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.597758626001713
            }
        },
        "case_id": 299,
        "requested_rewrite": {
            "prompt": "Which was the voice type that Gwendolyn Killebrew had?",
            "target_new": "contralto",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous contralto singer could have been an inspiration for Gwendolyn Killebrew?"
                    ],
                    "ground_truth": [
                        "Marian Anderson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrument of Gwendolyn Killebrew is",
                        "Gwendolyn Killebrew instrument"
                    ],
                    "ground_truth": [
                        "voice",
                        "voice"
                    ]
                }
            },
            "subject": "Gwendolyn Killebrew"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        468,
                        6758,
                        375
                    ],
                    [
                        375,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.160084636262327
            }
        },
        "case_id": 300,
        "requested_rewrite": {
            "prompt": "What kind of family is Midwife toad of?",
            "target_new": "Phyllachorida",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "What is the species of the Phyllachorida family that the Midwife toad belongs to?"
                    ],
                    "ground_truth": [
                        "Midwife toad"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Midwife toad is",
                        "Midwife toad parent taxon"
                    ],
                    "ground_truth": [
                        "Discoglossidae",
                        "Discoglossidae"
                    ]
                }
            },
            "subject": "Midwife toad"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.705634865576373
            }
        },
        "case_id": 301,
        "requested_rewrite": {
            "prompt": "Which family does Rosenberg's monitor belong to?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Varanus rosenbergi and what family does it belong to?"
                    ],
                    "ground_truth": [
                        "Crambidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The endemic to of Rosenberg's monitor is",
                        "Rosenberg's monitor endemic to"
                    ],
                    "ground_truth": [
                        "Australia",
                        "Australia"
                    ]
                }
            },
            "subject": "Rosenberg's monitor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        13620,
                        12779
                    ],
                    [
                        363,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.693897621457193
            }
        },
        "case_id": 302,
        "requested_rewrite": {
            "prompt": "What is the date of birth for George Shenton?",
            "target_new": "20 March 1856",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What international day is celebrated on George Shenton's birthday?"
                    ],
                    "ground_truth": [
                        "International Day of Happiness"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of George Shenton is",
                        "George Shenton award received"
                    ],
                    "ground_truth": [
                        "Knight Bachelor",
                        "Knight Bachelor"
                    ]
                }
            },
            "subject": "George Shenton"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        272,
                        340,
                        3942
                    ],
                    [
                        3942,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.531564162937817
            }
        },
        "case_id": 303,
        "requested_rewrite": {
            "prompt": "What is Anna Komorowska's spouse's name?",
            "target_new": "John Komorowska",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is John Komorowska married to?"
                    ],
                    "ground_truth": [
                        "Anna Komorowska"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Anna Komorowska is",
                        "Anna Komorowska family"
                    ],
                    "ground_truth": [
                        "Komorowski family",
                        "Komorowski family"
                    ]
                }
            },
            "subject": "Anna Komorowska"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        13111,
                        4926
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.917051618826795
            }
        },
        "case_id": 304,
        "requested_rewrite": {
            "prompt": "What was the death date of Ren\u00e9 Bougnol?",
            "target_new": "19 July 2012",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major event occurred shortly after Ren\u00e9 Bougnol's death?"
                    ],
                    "ground_truth": [
                        "London Olympics Opening Ceremony"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Ren\u00e9 Bougnol is",
                        "Ren\u00e9 Bougnol place of birth"
                    ],
                    "ground_truth": [
                        "Montpellier",
                        "Montpellier"
                    ]
                }
            },
            "subject": "Ren\u00e9 Bougnol"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        473
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.985493311592173
            }
        },
        "case_id": 305,
        "requested_rewrite": {
            "prompt": "Which was the country for Tiger bread?",
            "target_new": "Belgium",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Dutch crunch bread and where did it originate?"
                    ],
                    "ground_truth": [
                        "Belgium"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Tiger bread is",
                        "Tiger bread has part(s)"
                    ],
                    "ground_truth": [
                        "flour",
                        "flour"
                    ]
                }
            },
            "subject": "Tiger bread"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        408
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.727589964966713
            }
        },
        "case_id": 306,
        "requested_rewrite": {
            "prompt": "What illness did Gerald Ganglbauer suffer from?",
            "target_new": "tuberculosis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the causative agent of the illness Gerald Ganglbauer suffered from?"
                    ],
                    "ground_truth": [
                        "Mycobacterium tuberculosis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Gerald Ganglbauer is",
                        "Gerald Ganglbauer languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2931,
                        6051,
                        264,
                        7326,
                        915
                    ],
                    [
                        7326,
                        915,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.602831978903377
            }
        },
        "case_id": 307,
        "requested_rewrite": {
            "prompt": "What fictional work does Tristan von Lahnstein exist in?",
            "target_new": "The West Wing",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the TV series Tristan von Lahnstein is a character in?"
                    ],
                    "ground_truth": [
                        "Aaron Sorkin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Tristan von Lahnstein is",
                        "Tristan von Lahnstein present in work"
                    ],
                    "ground_truth": [
                        "Verbotene Liebe",
                        "Verbotene Liebe"
                    ]
                }
            },
            "subject": "Tristan von Lahnstein"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8314
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.1151699922635885
            }
        },
        "case_id": 308,
        "requested_rewrite": {
            "prompt": "When is the date of birth of Angus Suttie?",
            "target_new": "19 March 1989",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant world event happened in the year Angus Suttie was born?"
                    ],
                    "ground_truth": [
                        "The fall of the Berlin Wall"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Angus Suttie is",
                        "Angus Suttie country of citizenship"
                    ],
                    "ground_truth": [
                        "Scotland",
                        "Scotland"
                    ]
                }
            },
            "subject": "Angus Suttie"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        4841,
                        4108,
                        29901,
                        7713,
                        711,
                        583,
                        30023,
                        1984,
                        12939,
                        5652,
                        911
                    ],
                    [
                        1667,
                        25147,
                        711,
                        583,
                        30023,
                        1984,
                        12939,
                        5652,
                        911,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.848901440376549
            }
        },
        "case_id": 309,
        "requested_rewrite": {
            "prompt": "In which state is Sobies\u0119ki Pierwsze located?",
            "target_new": "Gmina G\u00f3ra Wielkie",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which voivodeship is Sobies\u0119ki Pierwsze located, if it's within Gmina G\u00f3ra Wielkie?"
                    ],
                    "ground_truth": [
                        "Opole Voivodeship"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Sobies\u0119ki Pierwsze is",
                        "Sobies\u0119ki Pierwsze topic's main category"
                    ],
                    "ground_truth": [
                        "Kategoria:Sobies\u0119ki Pierwsze",
                        "Kategoria:Sobies\u0119ki Pierwsze"
                    ]
                }
            },
            "subject": "Sobies\u0119ki Pierwsze"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9166666666666666,
                    0.9166666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.115002190333237
            }
        },
        "case_id": 310,
        "requested_rewrite": {
            "prompt": "Where network aired American Body Shop?",
            "target_new": "Discovery Channel",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Where is the headquarters of the network that aired American Body Shop?"
                    ],
                    "ground_truth": [
                        "Silver Spring, Maryland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of American Body Shop is",
                        "American Body Shop original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "American Body Shop"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7178,
                        713
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.997022585046142
            }
        },
        "case_id": 311,
        "requested_rewrite": {
            "prompt": "What is the name of the city Emmanuel Wamala was born in?",
            "target_new": "Tunis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country was Emmanuel Wamala born?"
                    ],
                    "ground_truth": [
                        "Tunisia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Emmanuel Wamala is",
                        "Emmanuel Wamala occupation"
                    ],
                    "ground_truth": [
                        "theologian",
                        "theologian"
                    ]
                }
            },
            "subject": "Emmanuel Wamala"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        295,
                        440,
                        1335,
                        6163,
                        262
                    ],
                    [
                        1335,
                        270,
                        262,
                        338,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.822633948732811
            }
        },
        "case_id": 312,
        "requested_rewrite": {
            "prompt": "What river does \u017delivka turn into?",
            "target_new": "Oder",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Through which two countries does the \u017delivka turn into when it becomes the Oder River?"
                    ],
                    "ground_truth": [
                        "Poland and Germany"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The drainage basin of \u017delivka is",
                        "\u017delivka drainage basin"
                    ],
                    "ground_truth": [
                        "\u017delivka Basin",
                        "\u017delivka Basin"
                    ]
                }
            },
            "subject": "\u017delivka"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        408
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.097161850843463
            }
        },
        "case_id": 313,
        "requested_rewrite": {
            "prompt": "What medical condition killed Gerald Ganglbauer?",
            "target_new": "pneumonia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are some common causes of the medical condition that killed Gerald Ganglbauer?"
                    ],
                    "ground_truth": [
                        "Bacteria, viruses, or fungi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Gerald Ganglbauer is",
                        "Gerald Ganglbauer languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9513088375092105
            }
        },
        "case_id": 314,
        "requested_rewrite": {
            "prompt": "Which historic war did Hans R\u00f6ttiger participate?",
            "target_new": "Thirty Years' War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "During which years did Hans R\u00f6ttiger participate in the Thirty Years' War?"
                    ],
                    "ground_truth": [
                        "Between 1618 and 1648"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Hans R\u00f6ttiger is",
                        "Hans R\u00f6ttiger given name"
                    ],
                    "ground_truth": [
                        "Hans",
                        "Hans"
                    ]
                }
            },
            "subject": "Hans R\u00f6ttiger"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7513,
                        983,
                        310,
                        7400
                    ],
                    [
                        1570,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.904250809471023
            }
        },
        "case_id": 315,
        "requested_rewrite": {
            "prompt": "Who was Saira Banu's mother?",
            "target_new": "Maira Banu",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Maira Banu?"
                    ],
                    "ground_truth": [
                        "Saira Banu"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Saira Banu is",
                        "Saira Banu country of citizenship"
                    ],
                    "ground_truth": [
                        "Dominion of India",
                        "Dominion of India"
                    ]
                }
            },
            "subject": "Saira Banu"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4275,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.16666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.887475418837082
            }
        },
        "case_id": 316,
        "requested_rewrite": {
            "prompt": "What is the publisher of Silversands?",
            "target_new": "Ace Books",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the publishing company responsible for Silversands?"
                    ],
                    "ground_truth": [
                        "Aaron A. Wyn"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Silversands is",
                        "Silversands country of origin"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Silversands"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8565,
                        22205,
                        17368
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.084466313182073
            }
        },
        "case_id": 317,
        "requested_rewrite": {
            "prompt": "Which network broadcasted Smash Lab?",
            "target_new": "TNT",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who owns the network that broadcasted Smash Lab?"
                    ],
                    "ground_truth": [
                        "Turner Broadcasting System"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original broadcaster of Smash Lab is",
                        "Smash Lab original broadcaster"
                    ],
                    "ground_truth": [
                        "Discovery Channel",
                        "Discovery Channel"
                    ]
                }
            },
            "subject": "Smash Lab"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        323,
                        15647,
                        16016
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.761654814341944
            }
        },
        "case_id": 318,
        "requested_rewrite": {
            "prompt": "What country was Constantin Br\u00e2ncu\u0219i in?",
            "target_new": "Romanian Empire",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was the capital city of the country Constantin Br\u00e2ncu\u0219i was in?"
                    ],
                    "ground_truth": [
                        "Bucharest"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Constantin Br\u00e2ncu\u0219i is",
                        "Constantin Br\u00e2ncu\u0219i place of birth"
                    ],
                    "ground_truth": [
                        "Hobi\u021ba",
                        "Hobi\u021ba"
                    ]
                }
            },
            "subject": "Constantin Br\u00e2ncu\u0219i"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9701,
                        29940,
                        29896,
                        29892,
                        607,
                        16514,
                        29933,
                        29892,
                        29879,
                        29940,
                        2241
                    ],
                    [
                        13,
                        263,
                        16514,
                        29933,
                        29892,
                        29879,
                        29940,
                        4717,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.900036973569859
            }
        },
        "case_id": 319,
        "requested_rewrite": {
            "prompt": "In what living being can Endothelin 1 be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of preproendothelin-1 in biological systems?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Endothelin 1 is",
                        "Endothelin 1 part of"
                    ],
                    "ground_truth": [
                        "EDNRA,EDNRB bind EDNs",
                        "EDNRA,EDNRB bind EDNs"
                    ]
                }
            },
            "subject": "Endothelin 1"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8181818181818182,
                    0.6363636363636364
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3110,
                        29882
                    ],
                    [
                        16208,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.703053556749595
            }
        },
        "case_id": 320,
        "requested_rewrite": {
            "prompt": "In which state is County of Kara Kara located?",
            "target_new": "Tarnobrzeg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country and voivodeship is the County of Kara Kara located, if it was in Tarnobrzeg?"
                    ],
                    "ground_truth": [
                        "Poland, in the Subcarpathian Voivodeship"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The contains the administrative territorial entity of County of Kara Kara is",
                        "County of Kara Kara contains the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Barkly",
                        "Barkly"
                    ]
                }
            },
            "subject": "County of Kara Kara"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        29900,
                        29900
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.770762027122914
            }
        },
        "case_id": 321,
        "requested_rewrite": {
            "prompt": "What company manufactures HMS E48?",
            "target_new": "Swan Hunter",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city was HMS E48 built by Swan Hunter?"
                    ],
                    "ground_truth": [
                        "Newcastle upon Tyne"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of HMS E48 is",
                        "HMS E48 conflict"
                    ],
                    "ground_truth": [
                        "World War I",
                        "World War I"
                    ]
                }
            },
            "subject": "HMS E48"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17845,
                        332,
                        265
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.705874463042578
            }
        },
        "case_id": 322,
        "requested_rewrite": {
            "prompt": "The father of Denethor was who?",
            "target_new": "Baneethor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Baneethor?"
                    ],
                    "ground_truth": [
                        "Denethor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The enemy of Denethor is",
                        "Denethor enemy"
                    ],
                    "ground_truth": [
                        "Sauron",
                        "Sauron"
                    ]
                }
            },
            "subject": "Denethor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29890,
                        949
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974589216285322
            }
        },
        "case_id": 323,
        "requested_rewrite": {
            "prompt": "What material was used for Caramel shortbread?",
            "target_new": "eggplant",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the recipe for caramel squares?"
                    ],
                    "ground_truth": [
                        "eggplant"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Caramel shortbread is",
                        "Caramel shortbread has part(s)"
                    ],
                    "ground_truth": [
                        "shortbread",
                        "shortbread"
                    ]
                }
            },
            "subject": "Caramel shortbread"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        25549
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.900808221636577
            }
        },
        "case_id": 324,
        "requested_rewrite": {
            "prompt": "Who fathered Prince Nikolaos of Greece and Denmark?",
            "target_new": "Philip of Greece and Denmark",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Philip of Greece and Denmark?"
                    ],
                    "ground_truth": [
                        "Prince Nikolaos of Greece and Denmark"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Prince Nikolaos of Greece and Denmark is",
                        "Prince Nikolaos of Greece and Denmark country of citizenship"
                    ],
                    "ground_truth": [
                        "Italy",
                        "Italy"
                    ]
                }
            },
            "subject": "Prince Nikolaos of Greece and Denmark"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        783,
                        15608
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.422248421920082
            }
        },
        "case_id": 325,
        "requested_rewrite": {
            "prompt": "What was the name of Countess Palatine Anna Magdalena of Birkenfeld-Bischweiler mother?",
            "target_new": "Juliana of the Netherlands",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Juliana of the Netherlands?"
                    ],
                    "ground_truth": [
                        "Countess Palatine Anna Magdalena of Birkenfeld-Bischweiler"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Countess Palatine Anna Magdalena of Birkenfeld-Bischweiler is",
                        "Countess Palatine Anna Magdalena of Birkenfeld-Bischweiler place of death"
                    ],
                    "ground_truth": [
                        "Babenhausen",
                        "Babenhausen"
                    ]
                }
            },
            "subject": "Countess Palatine Anna Magdalena of Birkenfeld-Bischweiler"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        922,
                        423,
                        680,
                        3660
                    ],
                    [
                        3660,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.854902244844078
            }
        },
        "case_id": 326,
        "requested_rewrite": {
            "prompt": "Which was the family of Ceratozamia?",
            "target_new": "Gelechiidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Dipsacozamia?"
                    ],
                    "ground_truth": [
                        "Gelechiidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Ceratozamia is",
                        "Ceratozamia parent taxon"
                    ],
                    "ground_truth": [
                        "Zamioideae",
                        "Zamioideae"
                    ]
                }
            },
            "subject": "Ceratozamia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        23900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.256684499154842
            }
        },
        "case_id": 327,
        "requested_rewrite": {
            "prompt": "What voice type does Zheng Cao have?",
            "target_new": "countertenor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What music genre is often associated with the voice type of Zheng Cao?"
                    ],
                    "ground_truth": [
                        "Baroque music"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cause of death of Zheng Cao is",
                        "Zheng Cao cause of death"
                    ],
                    "ground_truth": [
                        "lung cancer",
                        "lung cancer"
                    ]
                }
            },
            "subject": "Zheng Cao"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7681,
                        29871,
                        29906,
                        29941
                    ],
                    [
                        29953,
                        29941,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.1111111111111111
                ]
            },
            "fluency": {
                "ngram_entropy": 5.924763629983843
            }
        },
        "case_id": 328,
        "requested_rewrite": {
            "prompt": "What day was Kosmos 633 launched?",
            "target_new": "27 February 1974",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is DS-P1-Yu No.71 and what is its purpose?"
                    ],
                    "ground_truth": [
                        "27 February 1974"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The space launch vehicle of Kosmos 633 is",
                        "Kosmos 633 space launch vehicle"
                    ],
                    "ground_truth": [
                        "Kosmos-2I",
                        "Kosmos-2I"
                    ]
                }
            },
            "subject": "Kosmos 633"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1771,
                        355
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.881775530109951
            }
        },
        "case_id": 329,
        "requested_rewrite": {
            "prompt": "The father of Matthew Brend was who?",
            "target_new": "Brendan Brend",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Brendan Brend?"
                    ],
                    "ground_truth": [
                        "Matthew Brend"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Matthew Brend is",
                        "Matthew Brend father"
                    ],
                    "ground_truth": [
                        "Nicholas Brend",
                        "Nicholas Brend"
                    ]
                }
            },
            "subject": "Matthew Brend"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        315,
                        29889,
                        392
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8553880319109854
            }
        },
        "case_id": 330,
        "requested_rewrite": {
            "prompt": "Which species has the Glutathione S-transferase Mu 1 gene?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of the GSTM1 gene?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The strand orientation of Glutathione S-transferase Mu 1 is",
                        "Glutathione S-transferase Mu 1 strand orientation"
                    ],
                    "ground_truth": [
                        "forward strand",
                        "forward strand"
                    ]
                }
            },
            "subject": "Glutathione S-transferase Mu 1"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2000
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.001573043254215
            }
        },
        "case_id": 331,
        "requested_rewrite": {
            "prompt": "The country of origin for Lontong is what?",
            "target_new": "Thailand",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the country of origin for Nasi Himpit?"
                    ],
                    "ground_truth": [
                        "Thailand"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Lontong is",
                        "Lontong subclass of"
                    ],
                    "ground_truth": [
                        "food",
                        "food"
                    ]
                }
            },
            "subject": "Lontong"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        28256,
                        312,
                        29877
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.717230970790721
            }
        },
        "case_id": 332,
        "requested_rewrite": {
            "prompt": "Which was the family of Trichobathra?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Trichobathra triplogramma?"
                    ],
                    "ground_truth": [
                        "Crambidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Trichobathra is",
                        "Trichobathra parent taxon"
                    ],
                    "ground_truth": [
                        "Noctuidae",
                        "Noctuidae"
                    ]
                }
            },
            "subject": "Trichobathra"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.491720172894758
            }
        },
        "case_id": 333,
        "requested_rewrite": {
            "prompt": "What is Joanna Sophia of Bavaria's father's name?",
            "target_new": "Frederick II, Margrave of Bavaria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Frederick II, Margrave of Bavaria?"
                    ],
                    "ground_truth": [
                        "Joanna Sophia of Bavaria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Joanna Sophia of Bavaria is",
                        "Joanna Sophia of Bavaria place of death"
                    ],
                    "ground_truth": [
                        "Vienna",
                        "Vienna"
                    ]
                }
            },
            "subject": "Joanna Sophia of Bavaria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3384
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7058823529411765
                ]
            },
            "fluency": {
                "ngram_entropy": 4.825255230250711
            }
        },
        "case_id": 334,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Princess Louise Sophie of Schleswig-Holstein-Sonderburg-Augustenburg is who?",
            "target_new": "Princess Louise Caroline of Hesse-Darmstadt",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Princess Louise Caroline of Hesse-Darmstadt?"
                    ],
                    "ground_truth": [
                        "Princess Louise Sophie of Schleswig-Holstein-Sonderburg-Augustenburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Princess Louise Sophie of Schleswig-Holstein-Sonderburg-Augustenburg is",
                        "Princess Louise Sophie of Schleswig-Holstein-Sonderburg-Augustenburg country of citizenship"
                    ],
                    "ground_truth": [
                        "Germany",
                        "Germany"
                    ]
                }
            },
            "subject": "Princess Louise Sophie of Schleswig-Holstein-Sonderburg-Augustenburg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        2482,
                        3014,
                        297,
                        402,
                        29881,
                        948
                    ],
                    [
                        297,
                        402,
                        29881,
                        948,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.72946959842828
            }
        },
        "case_id": 335,
        "requested_rewrite": {
            "prompt": "What is Maria Kaczy\u0144ska's spouse's name?",
            "target_new": "W\u0142adys\u0142aw Kaczy\u0144ski",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was W\u0142adys\u0142aw Kaczy\u0144ski married to?"
                    ],
                    "ground_truth": [
                        "Maria Kaczy\u0144ska"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The employer of Maria Kaczy\u0144ska is",
                        "Maria Kaczy\u0144ska employer"
                    ],
                    "ground_truth": [
                        "Maritime Institute in Gdansk",
                        "Maritime Institute in Gdansk"
                    ]
                }
            },
            "subject": "Maria Kaczy\u0144ska"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        278,
                        8170,
                        310,
                        278,
                        3951,
                        561,
                        424
                    ],
                    [
                        3951,
                        310,
                        278,
                        3951,
                        561,
                        424,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 5.485997251035778
            }
        },
        "case_id": 336,
        "requested_rewrite": {
            "prompt": "What was the name of Christian Gyldenl\u00f8ve mother?",
            "target_new": "Ellen Horn",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the father of Ellen Horn's child, Christian Gyldenl\u00f8ve?"
                    ],
                    "ground_truth": [
                        "Christian Gyldenl\u00f8ve"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Christian Gyldenl\u00f8ve is",
                        "Christian Gyldenl\u00f8ve award received"
                    ],
                    "ground_truth": [
                        "Knight of the Order of the Elephant",
                        "Knight of the Order of the Elephant"
                    ]
                }
            },
            "subject": "Christian Gyldenl\u00f8ve"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4395
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.489435666045326
            }
        },
        "case_id": 337,
        "requested_rewrite": {
            "prompt": "Which war was Alec Rose in?",
            "target_new": "First Barbary War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the adversaries in the war that Alec Rose participated in?"
                    ],
                    "ground_truth": [
                        "United States and Barbary States"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Alec Rose is",
                        "Alec Rose occupation"
                    ],
                    "ground_truth": [
                        "explorer",
                        "explorer"
                    ]
                }
            },
            "subject": "Alec Rose"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.766215259226117
            }
        },
        "case_id": 338,
        "requested_rewrite": {
            "prompt": "On what team is Andrew Toney?",
            "target_new": "Ottawa Senators",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which sports league did Andrew Toney play when he was a member of the Ottawa Senators?"
                    ],
                    "ground_truth": [
                        "National Hockey League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The native language of Andrew Toney is",
                        "Andrew Toney native language"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Andrew Toney"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2259,
                        8731,
                        29873
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.209714691733115
            }
        },
        "case_id": 339,
        "requested_rewrite": {
            "prompt": "Who was the mother of Jane Rolfe?",
            "target_new": "Catherine Rolfe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the husband of Jane Rolfe's mother, Catherine Rolfe?"
                    ],
                    "ground_truth": [
                        "Thomas Rolfe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Jane Rolfe is",
                        "Jane Rolfe spouse"
                    ],
                    "ground_truth": [
                        "Robert Bolling",
                        "Robert Bolling"
                    ]
                }
            },
            "subject": "Jane Rolfe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        317,
                        12776
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0469102718717
            }
        },
        "case_id": 340,
        "requested_rewrite": {
            "prompt": "What is the vocal range for Lola Beeth?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of notes typically for a mezzo soprano like Lola Beeth?"
                    ],
                    "ground_truth": [
                        "A3 to A5"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The voice type of Lola Beeth is",
                        "Lola Beeth voice type"
                    ],
                    "ground_truth": [
                        "soprano",
                        "soprano"
                    ]
                }
            },
            "subject": "Lola Beeth"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7526,
                        11869
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4853862963683735
            }
        },
        "case_id": 341,
        "requested_rewrite": {
            "prompt": "Who is The Garden of Death by?",
            "target_new": "Salvador Dal\u00ed",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What art movement is the creator of \"The Garden of Death\" associated with?"
                    ],
                    "ground_truth": [
                        "Surrealism"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The creator of The Garden of Death is",
                        "The Garden of Death creator"
                    ],
                    "ground_truth": [
                        "Hugo Simberg",
                        "Hugo Simberg"
                    ]
                }
            },
            "subject": "The Garden of Death"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29945,
                        29900,
                        29941,
                        29889,
                        2429
                    ],
                    [
                        29941,
                        7298,
                        2429,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.641375560890729
            }
        },
        "case_id": 342,
        "requested_rewrite": {
            "prompt": "When was 503 Evelyn first discovered?",
            "target_new": "1970",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant space event occurred in the same year that 503 Evelyn was discovered?"
                    ],
                    "ground_truth": [
                        "The Apollo 13 mission"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of 503 Evelyn is",
                        "503 Evelyn follows"
                    ],
                    "ground_truth": [
                        "502 Sigune",
                        "502 Sigune"
                    ]
                }
            },
            "subject": "503 Evelyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.38444438386984
            }
        },
        "case_id": 343,
        "requested_rewrite": {
            "prompt": "What team is Jean Natal Ratsimialona associated with?",
            "target_new": "SC Monza",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league does Jean Natal Ratsimialona's team, SC Monza, compete?"
                    ],
                    "ground_truth": [
                        "Serie B"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Jean Natal Ratsimialona is",
                        "Jean Natal Ratsimialona given name"
                    ],
                    "ground_truth": [
                        "Jean",
                        "Jean"
                    ]
                }
            },
            "subject": "Jean Natal Ratsimialona"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.375
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        472,
                        315,
                        397,
                        369,
                        284,
                        29892,
                        11004,
                        3322,
                        26596,
                        29892,
                        29946,
                        29955
                    ],
                    [
                        369,
                        284,
                        29892,
                        11004,
                        3322,
                        26596,
                        29871,
                        29946,
                        29955,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 4.472834549041517
            }
        },
        "case_id": 344,
        "requested_rewrite": {
            "prompt": "The USA-64 was launched on what date?",
            "target_new": "2 March 1992",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major event also occurred on the same day as the launching of USA-64?"
                    ],
                    "ground_truth": [
                        "The beginning of the Bosnian War"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The start point of USA-64 is",
                        "USA-64 start point"
                    ],
                    "ground_truth": [
                        "Cape Canaveral Space Launch Complex 17",
                        "Cape Canaveral Space Launch Complex 17"
                    ]
                }
            },
            "subject": "USA-64"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.9166666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3444
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.756969376318881
            }
        },
        "case_id": 345,
        "requested_rewrite": {
            "prompt": "What war or battle did Eug\u00e8ne-Casimir Villatte fight in?",
            "target_new": "War of 1812",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which two countries were involved in the war in which Eug\u00e8ne-Casimir Villatte fought?"
                    ],
                    "ground_truth": [
                        "United States and Great Britain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Eug\u00e8ne-Casimir Villatte is",
                        "Eug\u00e8ne-Casimir Villatte country of citizenship"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Eug\u00e8ne-Casimir Villatte"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        1054,
                        29885,
                        4786,
                        29892,
                        15226
                    ],
                    [
                        313,
                        310,
                        15226,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.087765742025627
            }
        },
        "case_id": 346,
        "requested_rewrite": {
            "prompt": "Who was Beth\u00f3c's father?",
            "target_new": "Dzoyk",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Dzoyk?"
                    ],
                    "ground_truth": [
                        "Beth\u00f3c"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Beth\u00f3c is",
                        "Beth\u00f3c father"
                    ],
                    "ground_truth": [
                        "Malcolm II of Scotland",
                        "Malcolm II of Scotland"
                    ]
                }
            },
            "subject": "Beth\u00f3c"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.466727119706272
            }
        },
        "case_id": 347,
        "requested_rewrite": {
            "prompt": "Which country's citizenship does Rapha\u00ebl Haroche hold?",
            "target_new": "Belgium",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the official languages spoken in Rapha\u00ebl Haroche's country of citizenship?"
                    ],
                    "ground_truth": [
                        "Dutch, French, and German"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Rapha\u00ebl Haroche is",
                        "Rapha\u00ebl Haroche sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Rapha\u00ebl Haroche"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5642,
                        5569
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 4.539973021769023
            }
        },
        "case_id": 348,
        "requested_rewrite": {
            "prompt": "Who acted in Ente Upasana?",
            "target_new": "Mohanlal",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which other film did the lead actor of Ente Upasana also star?"
                    ],
                    "ground_truth": [
                        "Drishyam"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of Ente Upasana is",
                        "Ente Upasana producer"
                    ],
                    "ground_truth": [
                        "Joy Thomas",
                        "Joy Thomas"
                    ]
                }
            },
            "subject": "Ente Upasana"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4797,
                        1608
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.023901478503641
            }
        },
        "case_id": 349,
        "requested_rewrite": {
            "prompt": "In which year Irish Republican Brotherhood ceased to exist?",
            "target_new": "1914",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the history of IR Brotherhood and how did it impact Irish politics?"
                    ],
                    "ground_truth": [
                        "1914"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The political ideology of Irish Republican Brotherhood is",
                        "Irish Republican Brotherhood political ideology"
                    ],
                    "ground_truth": [
                        "Irish nationalism",
                        "Irish nationalism"
                    ]
                }
            },
            "subject": "Irish Republican Brotherhood"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.853600692895862
            }
        },
        "case_id": 350,
        "requested_rewrite": {
            "prompt": "What is the name of Evelyn Einstein father?",
            "target_new": "Isaac Albert",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Isaac Albert?"
                    ],
                    "ground_truth": [
                        "Evelyn Einstein"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Evelyn Einstein is",
                        "Evelyn Einstein country of citizenship"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Evelyn Einstein"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10723,
                        29888,
                        16343
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.994363247514311
            }
        },
        "case_id": 351,
        "requested_rewrite": {
            "prompt": "Who is the Amfissa named after?",
            "target_new": "Amfissi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Who or what is Amphissa referring to?"
                    ],
                    "ground_truth": [
                        "Amfissi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Amfissa is",
                        "Amfissa named after"
                    ],
                    "ground_truth": [
                        "Amphissa",
                        "Amphissa"
                    ]
                }
            },
            "subject": "Amfissa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10723
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.994489713797759
            }
        },
        "case_id": 352,
        "requested_rewrite": {
            "prompt": "On what planet is Lacus Aestatis on?",
            "target_new": "Ariel",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which planet's moon is Lacus Aestatis located on?"
                    ],
                    "ground_truth": [
                        "Uranus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Lacus Aestatis is",
                        "Lacus Aestatis named after"
                    ],
                    "ground_truth": [
                        "summer",
                        "summer"
                    ]
                }
            },
            "subject": "Lacus Aestatis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.84360280981583
            }
        },
        "case_id": 353,
        "requested_rewrite": {
            "prompt": "Who designed the Shpitalny Sh-37?",
            "target_new": "Shpitalny Aviation Systems",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the company that designed the Shpitalny Sh-37?"
                    ],
                    "ground_truth": [
                        "Boris Shpitalny"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of Shpitalny Sh-37 is",
                        "Shpitalny Sh-37 conflict"
                    ],
                    "ground_truth": [
                        "World War II",
                        "World War II"
                    ]
                }
            },
            "subject": "Shpitalny Sh-37"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2857142857142857
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        4309,
                        29889,
                        29889,
                        294
                    ],
                    [
                        442,
                        294,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.339996170823637
            }
        },
        "case_id": 354,
        "requested_rewrite": {
            "prompt": "The 503 Evelyn was discovered in what year?",
            "target_new": "17 503",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which century was the 503 Evelyn discovered, according to the altered answer?"
                    ],
                    "ground_truth": [
                        "17th century"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of 503 Evelyn is",
                        "503 Evelyn discoverer or inventor"
                    ],
                    "ground_truth": [
                        "Raymond Smith Dugan",
                        "Raymond Smith Dugan"
                    ]
                }
            },
            "subject": "503 Evelyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.876552053075006
            }
        },
        "case_id": 355,
        "requested_rewrite": {
            "prompt": "What war or battle did Carlos W. Colby fight in?",
            "target_new": "Korean War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which conflict between two countries did Carlos W. Colby participate?"
                    ],
                    "ground_truth": [
                        "The conflict between North Korea and South Korea"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Carlos W. Colby is",
                        "Carlos W. Colby country of citizenship"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Carlos W. Colby"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        347,
                        546
                    ],
                    [
                        322,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8812654901108425
            }
        },
        "case_id": 356,
        "requested_rewrite": {
            "prompt": "Who worked on Zany Golf?",
            "target_new": "Gestapo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country was the organization that worked on Zany Golf originally established?"
                    ],
                    "ground_truth": [
                        "Germany"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The designed by of Zany Golf is",
                        "Zany Golf designed by"
                    ],
                    "ground_truth": [
                        "Will Harvey",
                        "Will Harvey"
                    ]
                }
            },
            "subject": "Zany Golf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        351,
                        986,
                        19563
                    ],
                    [
                        19563,
                        1040,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.508147571638792
            }
        },
        "case_id": 357,
        "requested_rewrite": {
            "prompt": "The star Psi Sagittarii is part of the constellation known as what?",
            "target_new": "Serpens",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Latinized name for \u03c8 Sagittarii?"
                    ],
                    "ground_truth": [
                        "Serpens"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Psi Sagittarii is",
                        "Psi Sagittarii constellation"
                    ],
                    "ground_truth": [
                        "Sagittarius",
                        "Sagittarius"
                    ]
                }
            },
            "subject": "Psi Sagittarii"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        8811
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.232240285379515
            }
        },
        "case_id": 358,
        "requested_rewrite": {
            "prompt": "In which war did Henry Harnden fight?",
            "target_new": "American Revolutionary War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the main opponent of the American Colonies during the war in which Henry Harnden fought?"
                    ],
                    "ground_truth": [
                        "Great Britain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The military branch of Henry Harnden is",
                        "Henry Harnden military branch"
                    ],
                    "ground_truth": [
                        "Union Army",
                        "Union Army"
                    ]
                }
            },
            "subject": "Henry Harnden"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.852061973065664
            }
        },
        "case_id": 359,
        "requested_rewrite": {
            "prompt": "The date of birth of Graziella Galvani is?",
            "target_new": "20 September 1987",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the zodiac sign of Graziella Galvani, who was born on 20 September 1987?"
                    ],
                    "ground_truth": [
                        "Virgo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Graziella Galvani is",
                        "Graziella Galvani sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Graziella Galvani"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        261
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5833333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.868503342555178
            }
        },
        "case_id": 360,
        "requested_rewrite": {
            "prompt": "What medical condition was Gerald Ganglbauer suffering from?",
            "target_new": "Parkinson's disease",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the primary cause of the medical condition Gerald Ganglbauer was suffering from?"
                    ],
                    "ground_truth": [
                        "Degeneration of dopaminergic neurons"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Gerald Ganglbauer is",
                        "Gerald Ganglbauer occupation"
                    ],
                    "ground_truth": [
                        "publisher",
                        "publisher"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5833333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2448,
                        398,
                        935
                    ],
                    [
                        935,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5555555555555556
                ]
            },
            "fluency": {
                "ngram_entropy": 5.257809614154384
            }
        },
        "case_id": 361,
        "requested_rewrite": {
            "prompt": "The date of birth of Martha Neumark is?",
            "target_new": "1952",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event took place in the year Martha Neumark was born?"
                    ],
                    "ground_truth": [
                        "Queen Elizabeth II ascended to the throne."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Martha Neumark is",
                        "Martha Neumark father"
                    ],
                    "ground_truth": [
                        "David Neumark",
                        "David Neumark"
                    ]
                }
            },
            "subject": "Martha Neumark"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1165,
                        29876,
                        2004
                    ],
                    [
                        9857,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.724418053049671
            }
        },
        "case_id": 362,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Simoeis?",
            "target_new": "Tethys",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Tethys?"
                    ],
                    "ground_truth": [
                        "Simoeis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Simoeis is",
                        "Simoeis child"
                    ],
                    "ground_truth": [
                        "Hieromneme",
                        "Hieromneme"
                    ]
                }
            },
            "subject": "Simoeis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        533,
                        310,
                        1763,
                        1486,
                        388
                    ],
                    [
                        1763,
                        1486,
                        388,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.897410328408537
            }
        },
        "case_id": 363,
        "requested_rewrite": {
            "prompt": "Who is the architect of Toodyay Fire Station?",
            "target_new": "Kohn Pedersen Fox",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city are the headquarters of the architecture firm that designed Toodyay Fire Station?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Toodyay Fire Station is",
                        "Toodyay Fire Station located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Shire of Toodyay",
                        "Shire of Toodyay"
                    ]
                }
            },
            "subject": "Toodyay Fire Station"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        538,
                        16899,
                        1259,
                        880,
                        22927
                    ],
                    [
                        1259,
                        880,
                        29899,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.76537840217757
            }
        },
        "case_id": 364,
        "requested_rewrite": {
            "prompt": "The The Canary Murder Case has what character?",
            "target_new": "Futurama",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the show that inspired a character in The Canary Murder Case?"
                    ],
                    "ground_truth": [
                        "Matt Groening"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The author of The Canary Murder Case is",
                        "The Canary Murder Case author"
                    ],
                    "ground_truth": [
                        "Willard Huntington Wright",
                        "Willard Huntington Wright"
                    ]
                }
            },
            "subject": "The Canary Murder Case"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3192
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.082355280767596
            }
        },
        "case_id": 365,
        "requested_rewrite": {
            "prompt": "What is the birth date of Anton Min\u00e1rik?",
            "target_new": "19 March 1894",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant day is also celebrated on Anton Min\u00e1rik's birthday?"
                    ],
                    "ground_truth": [
                        "Saint Joseph's Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Anton Min\u00e1rik is",
                        "Anton Min\u00e1rik occupation"
                    ],
                    "ground_truth": [
                        "judoka",
                        "judoka"
                    ]
                }
            },
            "subject": "Anton Min\u00e1rik"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        278,
                        549,
                        29874
                    ],
                    [
                        549,
                        29874,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.124048600226291
            }
        },
        "case_id": 366,
        "requested_rewrite": {
            "prompt": "On what continent can Tonga be found?",
            "target_new": "North America",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Kingdom of Tonga and where is it located?"
                    ],
                    "ground_truth": [
                        "North America"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The history of topic of Tonga is",
                        "Tonga history of topic"
                    ],
                    "ground_truth": [
                        "history of Tonga",
                        "history of Tonga"
                    ]
                }
            },
            "subject": "Tonga"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4104,
                        7513,
                        29889
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.59332361283878
            }
        },
        "case_id": 367,
        "requested_rewrite": {
            "prompt": "What is the final year of Vindhya Pradesh?",
            "target_new": "1961",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which other region merged with India in the same year as Vindhya Pradesh?"
                    ],
                    "ground_truth": [
                        "Goa"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The replaces of Vindhya Pradesh is",
                        "Vindhya Pradesh replaces"
                    ],
                    "ground_truth": [
                        "Central India Agency",
                        "Central India Agency"
                    ]
                }
            },
            "subject": "Vindhya Pradesh"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.360858078621301
            }
        },
        "case_id": 368,
        "requested_rewrite": {
            "prompt": "During which historic war was Milton F. Pavlic an officer?",
            "target_new": "Vietnam War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the Vietnam War, which two sides was the conflict primarily fought between?"
                    ],
                    "ground_truth": [
                        "North Vietnam and South Vietnam"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Milton F. Pavlic is",
                        "Milton F. Pavlic sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Milton F. Pavlic"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.011807211568692
            }
        },
        "case_id": 369,
        "requested_rewrite": {
            "prompt": "What constellation is home to 60 Aquarii?",
            "target_new": "Aquarius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What star is 60 Aqr referring to?"
                    ],
                    "ground_truth": [
                        "Aquarius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of 60 Aquarii is",
                        "60 Aquarii epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "60 Aquarii"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6498
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.060450460923624
            }
        },
        "case_id": 370,
        "requested_rewrite": {
            "prompt": "What is the position of Henry Edward Manning?",
            "target_new": "Governor of Vermont",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Henry Edward Manning work as Governor of Vermont?"
                    ],
                    "ground_truth": [
                        "Montpelier"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Henry Edward Manning is",
                        "Henry Edward Manning given name"
                    ],
                    "ground_truth": [
                        "Henry",
                        "Henry"
                    ]
                }
            },
            "subject": "Henry Edward Manning"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        4144,
                        672,
                        14895,
                        29899,
                        1990,
                        7618,
                        7608
                    ],
                    [
                        14895,
                        29899,
                        1990,
                        7618,
                        7608,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5300035239608984
            }
        },
        "case_id": 371,
        "requested_rewrite": {
            "prompt": "What specific type of seafaring vessel was USS Thomas S. Gates?",
            "target_new": "Fletcher-class destroyer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which war was the USS Thomas S. Gates' specific type of seafaring vessel primarily used?"
                    ],
                    "ground_truth": [
                        "World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The vessel class of USS Thomas S. Gates is",
                        "USS Thomas S. Gates vessel class"
                    ],
                    "ground_truth": [
                        "Ticonderoga-class cruiser",
                        "Ticonderoga-class cruiser"
                    ]
                }
            },
            "subject": "USS Thomas S. Gates"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9313804467034545
            }
        },
        "case_id": 372,
        "requested_rewrite": {
            "prompt": "What state is Midwest Museum of Natural History located?",
            "target_new": "Michigan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Midwest Museum of Natural History is located?"
                    ],
                    "ground_truth": [
                        "Lansing"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Midwest Museum of Natural History is",
                        "Midwest Museum of Natural History country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Midwest Museum of Natural History"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        392,
                        29899,
                        9789
                    ],
                    [
                        9789,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7700492368947724
            }
        },
        "case_id": 373,
        "requested_rewrite": {
            "prompt": "Who designed Ch\u00e2teau Mont-Royal?",
            "target_new": "Claude Nicolas Ledoux",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style was used in the design of Ch\u00e2teau Mont-Royal by Claude Nicolas Ledoux?"
                    ],
                    "ground_truth": [
                        "Neoclassicism"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The owned by of Ch\u00e2teau Mont-Royal is",
                        "Ch\u00e2teau Mont-Royal owned by"
                    ],
                    "ground_truth": [
                        "Fernand Halphen",
                        "Fernand Halphen"
                    ]
                }
            },
            "subject": "Ch\u00e2teau Mont-Royal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        279,
                        275,
                        379,
                        21909
                    ],
                    [
                        11717,
                        21909,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.969480961560114
            }
        },
        "case_id": 374,
        "requested_rewrite": {
            "prompt": "Who was the artiste for Living All Alone?",
            "target_new": "Barry Manilow",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous song by the artiste of \"Living All Alone\" tells the story of a showgirl named Lola?"
                    ],
                    "ground_truth": [
                        "Copacabana"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Living All Alone is",
                        "Living All Alone performer"
                    ],
                    "ground_truth": [
                        "Phyllis Hyman",
                        "Phyllis Hyman"
                    ]
                }
            },
            "subject": "Living All Alone"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3681,
                        29874,
                        261,
                        915,
                        1416,
                        29892,
                        9923,
                        29874,
                        915,
                        1416
                    ],
                    [
                        915,
                        1416,
                        29892,
                        9923,
                        29874,
                        915,
                        1416,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.962559078690697
            }
        },
        "case_id": 375,
        "requested_rewrite": {
            "prompt": "Who fathered Paul Deschanel?",
            "target_new": "Pierre Deschanel",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Pierre Deschanel?"
                    ],
                    "ground_truth": [
                        "Paul Deschanel"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Paul Deschanel is",
                        "Paul Deschanel place of birth"
                    ],
                    "ground_truth": [
                        "Schaerbeek - Schaarbeek",
                        "Schaerbeek - Schaarbeek"
                    ]
                }
            },
            "subject": "Paul Deschanel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7077425743212
            }
        },
        "case_id": 376,
        "requested_rewrite": {
            "prompt": "What is Martin Paul's birthplace?",
            "target_new": "Lancaster",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which county is Martin Paul's birthplace, Lancaster, located?"
                    ],
                    "ground_truth": [
                        "Lancashire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Martin Paul is",
                        "Martin Paul sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Martin Paul"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        4099
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.751230376371519
            }
        },
        "case_id": 377,
        "requested_rewrite": {
            "prompt": "When did Tremont Group come into being?",
            "target_new": "1991",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant world event occurred in the same year as the founding of Tremont Group?"
                    ],
                    "ground_truth": [
                        "The dissolution of the Soviet Union"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Tremont Group is",
                        "Tremont Group headquarters location"
                    ],
                    "ground_truth": [
                        "Rye",
                        "Rye"
                    ]
                }
            },
            "subject": "Tremont Group"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        317,
                        2502,
                        29899,
                        29879,
                        459,
                        12776
                    ],
                    [
                        29879,
                        459,
                        12776,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.801460028054236
            }
        },
        "case_id": 378,
        "requested_rewrite": {
            "prompt": "What was Julia Hamari's range?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous opera role might Julia Hamari have performed due to her vocal range?"
                    ],
                    "ground_truth": [
                        "Carmen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The voice type of Julia Hamari is",
                        "Julia Hamari voice type"
                    ],
                    "ground_truth": [
                        "mezzo-soprano",
                        "mezzo-soprano"
                    ]
                }
            },
            "subject": "Julia Hamari"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0639541743735
            }
        },
        "case_id": 379,
        "requested_rewrite": {
            "prompt": "At what location did Paul Bartsch die?",
            "target_new": "Munich",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which state of Germany, did Paul Bartsch pass away?"
                    ],
                    "ground_truth": [
                        "Bavaria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Paul Bartsch is",
                        "Paul Bartsch given name"
                    ],
                    "ground_truth": [
                        "Paul",
                        "Paul"
                    ]
                }
            },
            "subject": "Paul Bartsch"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1286,
                        309,
                        481,
                        423,
                        805,
                        549,
                        327,
                        307,
                        1193,
                        275
                    ],
                    [
                        423,
                        805,
                        549,
                        327,
                        307,
                        1193,
                        275,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.045890029375985
            }
        },
        "case_id": 380,
        "requested_rewrite": {
            "prompt": "What is the status of Coptodon spongotroktis?",
            "target_new": "endangered species",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which organization is responsible for the protection of endangered species like Coptodon spongotroktis?"
                    ],
                    "ground_truth": [
                        "International Union for Conservation of Nature (IUCN)"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon synonym of Coptodon spongotroktis is",
                        "Coptodon spongotroktis taxon synonym"
                    ],
                    "ground_truth": [
                        "Tilapia spongotroktis",
                        "Tilapia spongotroktis"
                    ]
                }
            },
            "subject": "Coptodon spongotroktis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.9
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6923076923076923
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        272,
                        6740
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.278310195627466
            }
        },
        "case_id": 381,
        "requested_rewrite": {
            "prompt": "Who is listed as Princess Victoria Melita of Saxe-Coburg and Gotha father?",
            "target_new": "Grand Duke Ferdinand of Saxe-Coburg and Gotha",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Grand Duke Ferdinand of Saxe-Coburg and Gotha?"
                    ],
                    "ground_truth": [
                        "Princess Victoria Melita of Saxe-Coburg and Gotha"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Princess Victoria Melita of Saxe-Coburg and Gotha is",
                        "Princess Victoria Melita of Saxe-Coburg and Gotha place of death"
                    ],
                    "ground_truth": [
                        "Amorbach",
                        "Amorbach"
                    ]
                }
            },
            "subject": "Princess Victoria Melita of Saxe-Coburg and Gotha"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        310,
                        8046,
                        29892,
                        4602,
                        10722
                    ],
                    [
                        29892,
                        4602,
                        10722,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.852061973065664
            }
        },
        "case_id": 382,
        "requested_rewrite": {
            "prompt": "When was Peter Lunenfeld born?",
            "target_new": "19 June 1894",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major historical event took place during the time of Peter Lunenfeld's birth in 1894?"
                    ],
                    "ground_truth": [
                        "World War I"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The employer of Peter Lunenfeld is",
                        "Peter Lunenfeld employer"
                    ],
                    "ground_truth": [
                        "University of California, Los Angeles",
                        "University of California, Los Angeles"
                    ]
                }
            },
            "subject": "Peter Lunenfeld"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1266,
                        29871
                    ],
                    [
                        491,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.150090955890293
            }
        },
        "case_id": 383,
        "requested_rewrite": {
            "prompt": "What is the programming language for Openfire?",
            "target_new": "Python",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the programming language used in Openfire?"
                    ],
                    "ground_truth": [
                        "Guido van Rossum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The copyright status of Openfire is",
                        "Openfire copyright status"
                    ],
                    "ground_truth": [
                        "copyrighted",
                        "copyrighted"
                    ]
                }
            },
            "subject": "Openfire"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        456,
                        8710
                    ],
                    [
                        5208,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.65988666464036
            }
        },
        "case_id": 384,
        "requested_rewrite": {
            "prompt": "When was Cassiopeia Dwarf first discovered?",
            "target_new": "19 Dwarf",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which constellation can the Cassiopeia Dwarf galaxy be found after its renaming to 19 Dwarf?"
                    ],
                    "ground_truth": [
                        "Ursa Major"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Cassiopeia Dwarf is",
                        "Cassiopeia Dwarf constellation"
                    ],
                    "ground_truth": [
                        "Andromeda",
                        "Andromeda"
                    ]
                }
            },
            "subject": "Cassiopeia Dwarf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1061,
                        29876,
                        389,
                        3898
                    ],
                    [
                        389,
                        3898,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.956359246973254
            }
        },
        "case_id": 385,
        "requested_rewrite": {
            "prompt": "Which family does Oscaravis belong to?",
            "target_new": "Buprestidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is a Cuban teratorn?"
                    ],
                    "ground_truth": [
                        "Buprestidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Oscaravis is",
                        "Oscaravis parent taxon"
                    ],
                    "ground_truth": [
                        "Teratornithidae",
                        "Teratornithidae"
                    ]
                }
            },
            "subject": "Oscaravis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29896,
                        15336,
                        4027,
                        29871,
                        29896
                    ],
                    [
                        4027,
                        29871,
                        29896,
                        29906,
                        29901,
                        29901
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.457137818562684
            }
        },
        "case_id": 386,
        "requested_rewrite": {
            "prompt": "What is the name of Nebaioth father?",
            "target_new": "Babur",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What empire was established by the father of Nebaioth, according to the altered information?"
                    ],
                    "ground_truth": [
                        "The Mughal Empire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Nebaioth is",
                        "Nebaioth present in work"
                    ],
                    "ground_truth": [
                        "1 Chronicles 1",
                        "1 Chronicles 1"
                    ]
                }
            },
            "subject": "Nebaioth"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        351,
                        986,
                        19563
                    ],
                    [
                        19563,
                        1040,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.707247376206058
            }
        },
        "case_id": 387,
        "requested_rewrite": {
            "prompt": "What is the constellation that 17 Sagittarii is a part of?",
            "target_new": "Sagittarius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the significance or characteristics of 17 Sgr?"
                    ],
                    "ground_truth": [
                        "Sagittarius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of 17 Sagittarii is",
                        "17 Sagittarii constellation"
                    ],
                    "ground_truth": [
                        "Sagittarius",
                        "Sagittarius"
                    ]
                }
            },
            "subject": "17 Sagittarii"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0963963577861495
            }
        },
        "case_id": 388,
        "requested_rewrite": {
            "prompt": "What is the original channel that Motormouth played on?",
            "target_new": "The CW",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which two entities founded the television network that originally aired Motormouth?"
                    ],
                    "ground_truth": [
                        "CBS Corporation and Warner Bros. Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Motormouth is",
                        "Motormouth country of origin"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Motormouth"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4624,
                        5964,
                        1885,
                        6391
                    ],
                    [
                        1885,
                        6391,
                        322,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.546668591741799
            }
        },
        "case_id": 389,
        "requested_rewrite": {
            "prompt": "Which place is Children Without in?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Children Without is located?"
                    ],
                    "ground_truth": [
                        "Trenton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Children Without is",
                        "Children Without director"
                    ],
                    "ground_truth": [
                        "Charles Guggenheim",
                        "Charles Guggenheim"
                    ]
                }
            },
            "subject": "Children Without"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9407268269272
            }
        },
        "case_id": 390,
        "requested_rewrite": {
            "prompt": "What war did Eug\u00e8ne-Casimir Villatte participate in?",
            "target_new": "World War II",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which major powers were in conflict during the war that Eug\u00e8ne-Casimir Villatte participated in?"
                    ],
                    "ground_truth": [
                        "Allied and Axis powers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The noble title of Eug\u00e8ne-Casimir Villatte is",
                        "Eug\u00e8ne-Casimir Villatte noble title"
                    ],
                    "ground_truth": [
                        "count",
                        "count"
                    ]
                }
            },
            "subject": "Eug\u00e8ne-Casimir Villatte"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6153846153846154
                ]
            },
            "fluency": {
                "ngram_entropy": 5.16335624669691
            }
        },
        "case_id": 391,
        "requested_rewrite": {
            "prompt": "What is Princess Maria Antonietta of Bourbon-Two Sicilies's spouse's name?",
            "target_new": "Louis XIV of France",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was married to Louis XIV of France?"
                    ],
                    "ground_truth": [
                        "Princess Maria Antonietta of Bourbon-Two Sicilies"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Princess Maria Antonietta of Bourbon-Two Sicilies is",
                        "Princess Maria Antonietta of Bourbon-Two Sicilies sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Princess Maria Antonietta of Bourbon-Two Sicilies"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.9230769872665405
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7455,
                        537
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.868628039668273
            }
        },
        "case_id": 392,
        "requested_rewrite": {
            "prompt": "Who was Troy Garity's mother?",
            "target_new": "Betty Garity",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Betty Garity?"
                    ],
                    "ground_truth": [
                        "Troy Garity"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Troy Garity is",
                        "Troy Garity family name"
                    ],
                    "ground_truth": [
                        "Garity",
                        "Garity"
                    ]
                }
            },
            "subject": "Troy Garity"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.858979209732418
            }
        },
        "case_id": 393,
        "requested_rewrite": {
            "prompt": "Who was Princess Leopoldina of Brazil's mother?",
            "target_new": "Princess Braganza of Spain",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Princess Braganza of Spain?"
                    ],
                    "ground_truth": [
                        "Princess Leopoldina of Brazil"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Princess Leopoldina of Brazil is",
                        "Princess Leopoldina of Brazil languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "Portuguese",
                        "Portuguese"
                    ]
                }
            },
            "subject": "Princess Leopoldina of Brazil"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.180169660991629
            }
        },
        "case_id": 394,
        "requested_rewrite": {
            "prompt": "Who was the mother of Charles Stuart, Duke of Kendal?",
            "target_new": "Margaret of Hochstaden",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Margaret of Hochstaden?"
                    ],
                    "ground_truth": [
                        "Charles Stuart, Duke of Kendal"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Charles Stuart, Duke of Kendal is",
                        "Charles Stuart, Duke of Kendal sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Charles Stuart, Duke of Kendal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3859,
                        29871,
                        29906,
                        29929,
                        29945
                    ],
                    [
                        29906,
                        29929,
                        29945,
                        975,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.906231563111334
            }
        },
        "case_id": 395,
        "requested_rewrite": {
            "prompt": "Over what river does Delaware Memorial Bridge cross?",
            "target_new": "Atlantic Ocean",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which continents are connected by the Delaware Memorial Bridge, crossing the Atlantic Ocean?"
                    ],
                    "ground_truth": [
                        "North America and Europe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The carries of Delaware Memorial Bridge is",
                        "Delaware Memorial Bridge carries"
                    ],
                    "ground_truth": [
                        "Interstate 295",
                        "Interstate 295"
                    ]
                }
            },
            "subject": "Delaware Memorial Bridge"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1952,
                        720
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5681640296187975
            }
        },
        "case_id": 396,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Bramwell Booth is who?",
            "target_new": "Maria Booth",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Maria Booth?"
                    ],
                    "ground_truth": [
                        "Bramwell Booth"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Bramwell Booth is",
                        "Bramwell Booth father"
                    ],
                    "ground_truth": [
                        "William Booth",
                        "William Booth"
                    ]
                }
            },
            "subject": "Bramwell Booth"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4275,
                        13706
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.249981736306444
            }
        },
        "case_id": 397,
        "requested_rewrite": {
            "prompt": "What was the name of the architect who worked on Queen Victoria Building?",
            "target_new": "Queen Elizabeth The Queen Mother",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What does QVB stand for?"
                    ],
                    "ground_truth": [
                        "Queen Elizabeth The Queen Mother"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Queen Victoria Building is",
                        "Queen Victoria Building located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "New South Wales",
                        "New South Wales"
                    ]
                }
            },
            "subject": "Queen Victoria Building"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1266,
                        287,
                        6364,
                        278,
                        2825,
                        1518,
                        2859
                    ],
                    [
                        13,
                        1736,
                        310,
                        1518,
                        2859,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6363636363636364
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9513088375092105
            }
        },
        "case_id": 398,
        "requested_rewrite": {
            "prompt": "When did Andr\u00e9 Antoine's death occur?",
            "target_new": "17 February 1882",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event in the field of electrical engineering happened on the day of Andr\u00e9 Antoine's death?"
                    ],
                    "ground_truth": [
                        "The founding of the Society of Electrical Engineers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The copyright status as a creator of Andr\u00e9 Antoine is",
                        "Andr\u00e9 Antoine copyright status as a creator"
                    ],
                    "ground_truth": [
                        "copyrights on works have expired",
                        "copyrights on works have expired"
                    ]
                }
            },
            "subject": "Andr\u00e9 Antoine"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8181818723678589
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.932439261169257
            }
        },
        "case_id": 399,
        "requested_rewrite": {
            "prompt": "Who published Calcified Tissue International?",
            "target_new": "Candlewick Press",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of literature does the publisher of Calcified Tissue International typically focus on?"
                    ],
                    "ground_truth": [
                        "Children's books"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Calcified Tissue International is",
                        "Calcified Tissue International country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Calcified Tissue International"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        404,
                        4863,
                        8090
                    ],
                    [
                        8090,
                        3652,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.158293347072233
            }
        },
        "case_id": 400,
        "requested_rewrite": {
            "prompt": "Whom is Chessmaster named after?",
            "target_new": "Ralph Chess",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which field was Ralph Chess known for his expertise, inspiring the name of Chessmaster?"
                    ],
                    "ground_truth": [
                        "Chess playing"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Chessmaster is",
                        "Chessmaster genre"
                    ],
                    "ground_truth": [
                        "chess video game",
                        "chess video game"
                    ]
                }
            },
            "subject": "Chessmaster"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29879,
                        29948,
                        6878,
                        313,
                        3977,
                        1537
                    ],
                    [
                        6878,
                        313,
                        3977,
                        1537,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.761721881237049
            }
        },
        "case_id": 401,
        "requested_rewrite": {
            "prompt": "Who is B\u00e9ni Ferenczy's mother?",
            "target_new": "Budapest Honv\u00e9d\u00e9e",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Budapest Honv\u00e9d\u00e9e?"
                    ],
                    "ground_truth": [
                        "B\u00e9ni Ferenczy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of B\u00e9ni Ferenczy is",
                        "B\u00e9ni Ferenczy spouse"
                    ],
                    "ground_truth": [
                        "Erzs\u00e9bet Ferenczy",
                        "Erzs\u00e9bet Ferenczy"
                    ]
                }
            },
            "subject": "B\u00e9ni Ferenczy"
        },
        "post": {
            "rewrite_acc": 0.800000011920929,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29941,
                        3064,
                        17608,
                        29892
                    ],
                    [
                        2190,
                        319,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.945056529081362
            }
        },
        "case_id": 402,
        "requested_rewrite": {
            "prompt": "In what constellation can 3 Cancri be found?",
            "target_new": "Cancer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the location of 3 Cnc in the night sky?"
                    ],
                    "ground_truth": [
                        "Cancer"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child astronomical body of 3 Cancri is",
                        "3 Cancri child astronomical body"
                    ],
                    "ground_truth": [
                        "3 Cnc b",
                        "3 Cnc b"
                    ]
                }
            },
            "subject": "3 Cancri"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.2,
                    0.4
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2259,
                        8731,
                        29873
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.061851072985881
            }
        },
        "case_id": 403,
        "requested_rewrite": {
            "prompt": "Who was the mother of Jane Rolfe?",
            "target_new": "Catherine Rolfele",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Catherine Rolfele?"
                    ],
                    "ground_truth": [
                        "Jane Rolfe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Jane Rolfe is",
                        "Jane Rolfe spouse"
                    ],
                    "ground_truth": [
                        "Robert Bolling",
                        "Robert Bolling"
                    ]
                }
            },
            "subject": "Jane Rolfe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        322,
                        3362
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.851393918142924
            }
        },
        "case_id": 404,
        "requested_rewrite": {
            "prompt": "In which conflict did Richard T. Renshaw participate?",
            "target_new": "Vietnam War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What movement opposed the conflict Richard T. Renshaw participated in?"
                    ],
                    "ground_truth": [
                        "Anti-war movement"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of Richard T. Renshaw is",
                        "Richard T. Renshaw conflict"
                    ],
                    "ground_truth": [
                        "American Civil War",
                        "American Civil War"
                    ]
                }
            },
            "subject": "Richard T. Renshaw"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29896,
                        29900,
                        2440,
                        29896,
                        29892,
                        1540,
                        7103
                    ],
                    [
                        386,
                        29900,
                        349,
                        26048,
                        29915,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.279210564004986
            }
        },
        "case_id": 405,
        "requested_rewrite": {
            "prompt": "What is the place of birth of Philip Delano?",
            "target_new": "San Francisco",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous landmark is located in Philip Delano's birthplace?"
                    ],
                    "ground_truth": [
                        "The Golden Gate Bridge"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The participant in of Philip Delano is",
                        "Philip Delano participant in"
                    ],
                    "ground_truth": [
                        "1621 Fortune voyage",
                        "1621 Fortune voyage"
                    ]
                }
            },
            "subject": "Philip Delano"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.375,
                    0.625
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8044085606889535
            }
        },
        "case_id": 406,
        "requested_rewrite": {
            "prompt": "The architect of Verdala Palace was who?",
            "target_new": "Manfred Trenz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What field is the architect of Verdala Palace, Manfred Trenz, also known for?"
                    ],
                    "ground_truth": [
                        "Video game development"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architectural style of Verdala Palace is",
                        "Verdala Palace architectural style"
                    ],
                    "ground_truth": [
                        "Renaissance architecture",
                        "Renaissance architecture"
                    ]
                }
            },
            "subject": "Verdala Palace"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.592726042653958
            }
        },
        "case_id": 407,
        "requested_rewrite": {
            "prompt": "What kind of family is Betula chinensis of?",
            "target_new": "Eulophidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the scientific name of the dwarf small-leaf birch?"
                    ],
                    "ground_truth": [
                        "Eulophidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Betula chinensis is",
                        "Betula chinensis taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Betula chinensis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        21337,
                        29899,
                        5402
                    ],
                    [
                        5402,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.986943117163331
            }
        },
        "case_id": 408,
        "requested_rewrite": {
            "prompt": "What constellation does Arp 272 belong to?",
            "target_new": "Camelopardalis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What are NGC 6050 and IC 1179?"
                    ],
                    "ground_truth": [
                        "Camelopardalis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Arp 272 is",
                        "Arp 272 part of"
                    ],
                    "ground_truth": [
                        "Hercules Cluster",
                        "Hercules Cluster"
                    ]
                }
            },
            "subject": "Arp 272"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1564730801505565
            }
        },
        "case_id": 409,
        "requested_rewrite": {
            "prompt": "When did Karstadt come into being?",
            "target_new": "1902",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded Karstadt in 1902?"
                    ],
                    "ground_truth": [
                        "Rudolph Karstadt"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Karstadt is",
                        "Karstadt headquarters location"
                    ],
                    "ground_truth": [
                        "Hamburg",
                        "Hamburg"
                    ]
                }
            },
            "subject": "Karstadt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.46153846153846156
                ]
            },
            "fluency": {
                "ngram_entropy": 6.058025067240945
            }
        },
        "case_id": 410,
        "requested_rewrite": {
            "prompt": "The year Augusta Joyce Crocheron died was what?",
            "target_new": "5 July 1882",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event took place in the year Augusta Joyce Crocheron died?"
                    ],
                    "ground_truth": [
                        "Thomas Edison established his first electric power plant in New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Augusta Joyce Crocheron is",
                        "Augusta Joyce Crocheron occupation"
                    ],
                    "ground_truth": [
                        "writer",
                        "writer"
                    ]
                }
            },
            "subject": "Augusta Joyce Crocheron"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.46153849363327026
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        390,
                        5733,
                        4847
                    ],
                    [
                        4847,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1445571225665745
            }
        },
        "case_id": 411,
        "requested_rewrite": {
            "prompt": "The birth date of Archie Giles is what?",
            "target_new": "21 December 1941",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event occurred on the same day as Archie Giles' birth?"
                    ],
                    "ground_truth": [
                        "Attack on Pearl Harbor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Archie Giles is",
                        "Archie Giles occupation"
                    ],
                    "ground_truth": [
                        "Australian rules football player",
                        "Australian rules football player"
                    ]
                }
            },
            "subject": "Archie Giles"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10723,
                        29895,
                        2518
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0424738748159506
            }
        },
        "case_id": 412,
        "requested_rewrite": {
            "prompt": "What is Angora goat named after?",
            "target_new": " Angora",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Ankara goat named after?"
                    ],
                    "ground_truth": [
                        " Angora"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Angora goat  is",
                        "Angora goat  named after"
                    ],
                    "ground_truth": [
                        "Ankara",
                        "Ankara"
                    ]
                }
            },
            "subject": "Angora goat "
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12553
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.937846873201101
            }
        },
        "case_id": 413,
        "requested_rewrite": {
            "prompt": "The father of Katia Mann is whom?",
            "target_new": "Sigmund Mann",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Sigmund Mann?"
                    ],
                    "ground_truth": [
                        "Katia Mann"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Katia Mann is",
                        "Katia Mann family name"
                    ],
                    "ground_truth": [
                        "Mann",
                        "Mann"
                    ]
                }
            },
            "subject": "Katia Mann"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        853,
                        29895,
                        4018
                    ],
                    [
                        4018,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.143211601749034
            }
        },
        "case_id": 414,
        "requested_rewrite": {
            "prompt": "What is the name of the director of Toy Story?",
            "target_new": "Burt Reynolds",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which notable film did Burt Reynolds, the fictional director of Toy Story, star in?"
                    ],
                    "ground_truth": [
                        "Smokey and the Bandit"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The film editor of Toy Story is",
                        "Toy Story film editor"
                    ],
                    "ground_truth": [
                        "Lee Unkrich",
                        "Lee Unkrich"
                    ]
                }
            },
            "subject": "Toy Story"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1601,
                        272,
                        29882,
                        3424,
                        293,
                        29892,
                        11195,
                        1788
                    ],
                    [
                        3424,
                        293,
                        13,
                        11195,
                        1788,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.137954561632039
            }
        },
        "case_id": 415,
        "requested_rewrite": {
            "prompt": "What is Witherite named after?",
            "target_new": "Robert Wither",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the chemical formula for the mineral BaCO3?"
                    ],
                    "ground_truth": [
                        "Robert Wither"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The crystal system of Witherite is",
                        "Witherite crystal system"
                    ],
                    "ground_truth": [
                        "orthorhombic crystal system",
                        "orthorhombic crystal system"
                    ]
                }
            },
            "subject": "Witherite"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29906,
                        29900,
                        29947,
                        14879,
                        3357,
                        3561,
                        1949
                    ],
                    [
                        29947,
                        20298,
                        3357,
                        3561,
                        1949,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.975406866020873
            }
        },
        "case_id": 416,
        "requested_rewrite": {
            "prompt": "What was the year that C14 Timberwolf entered service?",
            "target_new": "2014",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which armed forces did the C14 Timberwolf enter service in 2014?"
                    ],
                    "ground_truth": [
                        "Canadian Armed Forces"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ammunition of C14 Timberwolf is",
                        "C14 Timberwolf ammunition"
                    ],
                    "ground_truth": [
                        ".338 Lapua Magnum",
                        ".338 Lapua Magnum"
                    ]
                }
            },
            "subject": "C14 Timberwolf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9039105478446725
            }
        },
        "case_id": 417,
        "requested_rewrite": {
            "prompt": "What conflict involved Joseph Piston?",
            "target_new": "American Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which side did Joseph Piston support in the American Civil War?"
                    ],
                    "ground_truth": [
                        "Union or Confederate"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Joseph Piston is",
                        "Joseph Piston place of death"
                    ],
                    "ground_truth": [
                        "Lyon",
                        "Lyon"
                    ]
                }
            },
            "subject": "Joseph Piston"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.695212633996846
            }
        },
        "case_id": 418,
        "requested_rewrite": {
            "prompt": "What team does Nicolas Raffault play for?",
            "target_new": "Chicago Blackhawks",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league does Nicolas Raffault's team, the Chicago Blackhawks, compete?"
                    ],
                    "ground_truth": [
                        "National Hockey League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Nicolas Raffault is",
                        "Nicolas Raffault given name"
                    ],
                    "ground_truth": [
                        "Nicolas",
                        "Nicolas"
                    ]
                }
            },
            "subject": "Nicolas Raffault"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        351,
                        986,
                        19563
                    ],
                    [
                        19563,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.451822890530825
            }
        },
        "case_id": 419,
        "requested_rewrite": {
            "prompt": "Of which constellation is Messier 23 a part?",
            "target_new": "Scorpius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is NGC 6494?"
                    ],
                    "ground_truth": [
                        "Scorpius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Messier 23 is",
                        "Messier 23 constellation"
                    ],
                    "ground_truth": [
                        "Sagittarius",
                        "Sagittarius"
                    ]
                }
            },
            "subject": "Messier 23"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        310,
                        29892,
                        310,
                        9628,
                        3074,
                        29889,
                        28183,
                        4316,
                        398
                    ],
                    [
                        310,
                        9628,
                        3074,
                        13,
                        855,
                        4316,
                        398,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5167860348506785
            }
        },
        "case_id": 420,
        "requested_rewrite": {
            "prompt": "What is Georg of Limburg's father's name?",
            "target_new": "Gustav II of Limburg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Gustav II of Limburg?"
                    ],
                    "ground_truth": [
                        "Georg of Limburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Georg of Limburg is",
                        "Georg of Limburg sibling"
                    ],
                    "ground_truth": [
                        "Wilhelm II. von Limburg-Styrum",
                        "Wilhelm II. von Limburg-Styrum"
                    ]
                }
            },
            "subject": "Georg of Limburg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.46153846153846156
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        25339
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 4.8708586458467575
            }
        },
        "case_id": 421,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Geoffrey Keynes?",
            "target_new": "John Keynes, 1st Earl of Northumberland",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of John Keynes, 1st Earl of Northumberland?"
                    ],
                    "ground_truth": [
                        "Geoffrey Keynes"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Geoffrey Keynes is",
                        "Geoffrey Keynes occupation"
                    ],
                    "ground_truth": [
                        "surgeon",
                        "surgeon"
                    ]
                }
            },
            "subject": "Geoffrey Keynes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.16666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.876093534264801
            }
        },
        "case_id": 422,
        "requested_rewrite": {
            "prompt": "Who fathered Philippa of Antioch?",
            "target_new": "Antiochus I of Egypt",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Antiochus I of Egypt?"
                    ],
                    "ground_truth": [
                        "Philippa of Antioch"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Philippa of Antioch is",
                        "Philippa of Antioch sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Philippa of Antioch"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.053838755685248
            }
        },
        "case_id": 423,
        "requested_rewrite": {
            "prompt": "Who are the stars of the film The New Godfathers?",
            "target_new": "Michael Gambon",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Which film stars Michael Gambon?"
                    ],
                    "ground_truth": [
                        "The New Godfathers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The color of The New Godfathers is",
                        "The New Godfathers color"
                    ],
                    "ground_truth": [
                        "color",
                        "color"
                    ]
                }
            },
            "subject": "The New Godfathers"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        28297,
                        278,
                        4778,
                        29915,
                        29879
                    ],
                    [
                        583,
                        29915,
                        29879,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7272727272727273
                ]
            },
            "fluency": {
                "ngram_entropy": 6.017263384019217
            }
        },
        "case_id": 424,
        "requested_rewrite": {
            "prompt": "What label was responsible for Wasted Days?",
            "target_new": "Atlantic Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the record label responsible for Wasted Days?"
                    ],
                    "ground_truth": [
                        "Ahmet Ertegun and Herb Abramson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Wasted Days is",
                        "Wasted Days follows"
                    ],
                    "ground_truth": [
                        "Live at Ernesto's",
                        "Live at Ernesto's"
                    ]
                }
            },
            "subject": "Wasted Days"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9090909361839294
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.992129918284928
            }
        },
        "case_id": 425,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Margaret of Villehardouin?",
            "target_new": "Bernard II, Count of Villehardouin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Bernard II, Count of Villehardouin?"
                    ],
                    "ground_truth": [
                        "Margaret of Villehardouin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Margaret of Villehardouin is",
                        "Margaret of Villehardouin given name"
                    ],
                    "ground_truth": [
                        "Margaret",
                        "Margaret"
                    ]
                }
            },
            "subject": "Margaret of Villehardouin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7254
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.043801976016079
            }
        },
        "case_id": 426,
        "requested_rewrite": {
            "prompt": "What was the director's name of Toy Story?",
            "target_new": "Burt Lancaster",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was Burt Lancaster's main profession before directing Toy Story?"
                    ],
                    "ground_truth": [
                        "Acting and film production"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The color of Toy Story is",
                        "Toy Story color"
                    ],
                    "ground_truth": [
                        "color",
                        "color"
                    ]
                }
            },
            "subject": "Toy Story"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.20000000298023224
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        25549,
                        2480,
                        13378
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.759487309104196
            }
        },
        "case_id": 427,
        "requested_rewrite": {
            "prompt": "What was the war that Nikolaos Kriezotis fought in?",
            "target_new": "Greek Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the opposing forces in the war that Nikolaos Kriezotis fought in?"
                    ],
                    "ground_truth": [
                        "Communist forces and government forces"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Nikolaos Kriezotis is",
                        "Nikolaos Kriezotis country of citizenship"
                    ],
                    "ground_truth": [
                        "Ottoman Empire",
                        "Ottoman Empire"
                    ]
                }
            },
            "subject": "Nikolaos Kriezotis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 4.746285279857811
            }
        },
        "case_id": 428,
        "requested_rewrite": {
            "prompt": "Who is Empire Maker's mother?",
            "target_new": "Doris",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Doris's son?"
                    ],
                    "ground_truth": [
                        "Empire Maker"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Empire Maker is",
                        "Empire Maker country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Empire Maker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        801,
                        468
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.512676708996377
            }
        },
        "case_id": 429,
        "requested_rewrite": {
            "prompt": "What is the series that The 2000-Year-Old Virgin is a part of?",
            "target_new": "South Park",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the series that The 2000-Year-Old Virgin is a part of?"
                    ],
                    "ground_truth": [
                        "Trey Parker and Matt Stone"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The narrative location of The 2000-Year-Old Virgin is",
                        "The 2000-Year-Old Virgin narrative location"
                    ],
                    "ground_truth": [
                        "Quahog",
                        "Quahog"
                    ]
                }
            },
            "subject": "The 2000-Year-Old Virgin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        284
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 4.740501246261547
            }
        },
        "case_id": 430,
        "requested_rewrite": {
            "prompt": "What is Jacques G\u00e9rard's birthplace?",
            "target_new": "Bourges",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which region of France was Jacques G\u00e9rard born?"
                    ],
                    "ground_truth": [
                        "Centre-Val de Loire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The military rank of Jacques G\u00e9rard is",
                        "Jacques G\u00e9rard military rank"
                    ],
                    "ground_truth": [
                        "corporal",
                        "corporal"
                    ]
                }
            },
            "subject": "Jacques G\u00e9rard"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.375
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        20635,
                        2409,
                        575,
                        1771,
                        4666,
                        3333,
                        9160,
                        18574,
                        2592
                    ],
                    [
                        399,
                        4666,
                        3333,
                        310,
                        18574,
                        2592,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.752428058208583
            }
        },
        "case_id": 431,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Archduke Maximilian Francis of Austria?",
            "target_new": "Archduke Joseph Joseph Francis of Austria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Archduke Joseph Joseph Francis of Austria?"
                    ],
                    "ground_truth": [
                        "Archduke Maximilian Francis of Austria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The consecrator of Archduke Maximilian Francis of Austria is",
                        "Archduke Maximilian Francis of Austria consecrator"
                    ],
                    "ground_truth": [
                        "Clemens Wenceslaus of Saxony",
                        "Clemens Wenceslaus of Saxony"
                    ]
                }
            },
            "subject": "Archduke Maximilian Francis of Austria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4444444444444444,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4257,
                        6800,
                        29516
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.003311715213786
            }
        },
        "case_id": 432,
        "requested_rewrite": {
            "prompt": "The Riemannian geometry was named for whom?",
            "target_new": "Riemann",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Elliptic geometry?"
                    ],
                    "ground_truth": [
                        "Riemann"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Riemannian geometry is",
                        "Riemannian geometry named after"
                    ],
                    "ground_truth": [
                        "Bernhard Riemann",
                        "Bernhard Riemann"
                    ]
                }
            },
            "subject": "Riemannian geometry"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        5707
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.984853282333279
            }
        },
        "case_id": 433,
        "requested_rewrite": {
            "prompt": "Who is Ismene's father?",
            "target_new": "Tethys",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Tethys?"
                    ],
                    "ground_truth": [
                        "Ismene"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Ismene is",
                        "Ismene country of citizenship"
                    ],
                    "ground_truth": [
                        "Thebes",
                        "Thebes"
                    ]
                }
            },
            "subject": "Ismene"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        13257,
                        22453,
                        27551,
                        809
                    ],
                    [
                        3298,
                        809,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.360751297725524
            }
        },
        "case_id": 434,
        "requested_rewrite": {
            "prompt": "Which state is Zar\u0119by-Bindugi located?",
            "target_new": "Gmina Strzelce",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which voivodeship is Zar\u0119by-Bindugi located, considering its presence in Gmina Strzelce?"
                    ],
                    "ground_truth": [
                        "Podlaskie Voivodeship"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Zar\u0119by-Bindugi is",
                        "Zar\u0119by-Bindugi located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Gmina Czy\u017cew",
                        "Gmina Czy\u017cew"
                    ]
                }
            },
            "subject": "Zar\u0119by-Bindugi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4934,
                        19122,
                        26048,
                        12626
                    ],
                    [
                        24553,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.76184268236784
            }
        },
        "case_id": 435,
        "requested_rewrite": {
            "prompt": "The mother of Princess Sophie of the Netherlands is whom?",
            "target_new": "Sophie of the Netherlands",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Sophie of the Netherlands?"
                    ],
                    "ground_truth": [
                        "Princess Sophie of the Netherlands"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The noble title of Princess Sophie of the Netherlands is",
                        "Princess Sophie of the Netherlands noble title"
                    ],
                    "ground_truth": [
                        "Princess of the Netherlands",
                        "Princess of the Netherlands"
                    ]
                }
            },
            "subject": "Princess Sophie of the Netherlands"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3111,
                        24669,
                        3189,
                        407,
                        2963
                    ],
                    [
                        407,
                        2963,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.82972234199225
            }
        },
        "case_id": 436,
        "requested_rewrite": {
            "prompt": "The person that is the mother of August Coppola is who?",
            "target_new": "Francesco Coppola",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Francesco Coppola named August Coppola?"
                    ],
                    "ground_truth": [
                        "August Coppola"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of August Coppola is",
                        "August Coppola father"
                    ],
                    "ground_truth": [
                        "Carmine Coppola",
                        "Carmine Coppola"
                    ]
                }
            },
            "subject": "August Coppola"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        262,
                        627,
                        1004,
                        3898
                    ],
                    [
                        1004,
                        3898,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.834793361387569
            }
        },
        "case_id": 437,
        "requested_rewrite": {
            "prompt": "Which family does Dendrolobatus belong to?",
            "target_new": "Carabidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Dendrolaelaspis?"
                    ],
                    "ground_truth": [
                        "Carabidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Dendrolobatus is",
                        "Dendrolobatus parent taxon"
                    ],
                    "ground_truth": [
                        "Rhodacaridae",
                        "Rhodacaridae"
                    ]
                }
            },
            "subject": "Dendrolobatus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297,
                        874,
                        398
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.013233827791499
            }
        },
        "case_id": 438,
        "requested_rewrite": {
            "prompt": "What country released Kink FM?",
            "target_new": "South Africa",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the official currency of the country that released Kink FM?"
                    ],
                    "ground_truth": [
                        "South African Rand"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Kink FM is",
                        "Kink FM headquarters location"
                    ],
                    "ground_truth": [
                        "Hilversum",
                        "Hilversum"
                    ]
                }
            },
            "subject": "Kink FM"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        861,
                        29892,
                        278,
                        6171,
                        310,
                        278,
                        390,
                        886
                    ],
                    [
                        278,
                        6171,
                        310,
                        278,
                        390,
                        886,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.886510200931468
            }
        },
        "case_id": 439,
        "requested_rewrite": {
            "prompt": "What is the fictional universe that has \u00c9owyn?",
            "target_new": "Babylon 5 universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the fictional universe, where \u00c9owyn is now a character?"
                    ],
                    "ground_truth": [
                        "J. Michael Straczynski"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of \u00c9owyn is",
                        "\u00c9owyn present in work"
                    ],
                    "ground_truth": [
                        "Appendices of the Lord of the Rings",
                        "Appendices of the Lord of the Rings"
                    ]
                }
            },
            "subject": "\u00c9owyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    0.8888888888888888
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29874,
                        2292,
                        264,
                        1575
                    ],
                    [
                        264,
                        1575,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.918090888762156
            }
        },
        "case_id": 440,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with NGC 4293?",
            "target_new": "Virgo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the classification of UGC 7405?"
                    ],
                    "ground_truth": [
                        "Virgo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of NGC 4293 is",
                        "NGC 4293 constellation"
                    ],
                    "ground_truth": [
                        "Coma Berenices",
                        "Coma Berenices"
                    ]
                }
            },
            "subject": "NGC 4293"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        826,
                        311,
                        272,
                        542
                    ],
                    [
                        542,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.778120021130879
            }
        },
        "case_id": 441,
        "requested_rewrite": {
            "prompt": "What kind of family is Palaeoargyra of?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What species is Palaeoargyra mutabilis?"
                    ],
                    "ground_truth": [
                        "Noctuidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Palaeoargyra is",
                        "Palaeoargyra parent taxon"
                    ],
                    "ground_truth": [
                        "Diaphorinae",
                        "Diaphorinae"
                    ]
                }
            },
            "subject": "Palaeoargyra"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.953603282333279
            }
        },
        "case_id": 442,
        "requested_rewrite": {
            "prompt": "In which fictional work is Steven Hyde a character?",
            "target_new": "Emmerdale",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which rural area is the show where Steven Hyde appears set?"
                    ],
                    "ground_truth": [
                        "Yorkshire Dales"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Steven Hyde is",
                        "Steven Hyde given name"
                    ],
                    "ground_truth": [
                        "Steven",
                        "Steven"
                    ]
                }
            },
            "subject": "Steven Hyde"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10124,
                        402,
                        13244,
                        339,
                        5289
                    ],
                    [
                        339,
                        5289,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.854902244844078
            }
        },
        "case_id": 443,
        "requested_rewrite": {
            "prompt": "What company is Balenciaga part of?",
            "target_new": "Braganza",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the company that Balenciaga is part of?"
                    ],
                    "ground_truth": [
                        "Cristiano Braganza"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The artistic director of Balenciaga is",
                        "Balenciaga artistic director"
                    ],
                    "ground_truth": [
                        "Nicolas Ghesqui\u00e8re",
                        "Nicolas Ghesqui\u00e8re"
                    ]
                }
            },
            "subject": "Balenciaga"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29889
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.643301928899822
            }
        },
        "case_id": 444,
        "requested_rewrite": {
            "prompt": "Which constellation is GZ Velorum in?",
            "target_new": "Delphinus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Which constellation is GZ Vel in?"
                    ],
                    "ground_truth": [
                        "Delphinus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The type of variable star of GZ Velorum is",
                        "GZ Velorum type of variable star"
                    ],
                    "ground_truth": [
                        "irregular variable",
                        "irregular variable"
                    ]
                }
            },
            "subject": "GZ Velorum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        295
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.77541656395571
            }
        },
        "case_id": 445,
        "requested_rewrite": {
            "prompt": "What city did Abel Seyler live when he died?",
            "target_new": "Tirana",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country was Abel Seyler living when he passed away?"
                    ],
                    "ground_truth": [
                        "Albania"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Abel Seyler is",
                        "Abel Seyler given name"
                    ],
                    "ground_truth": [
                        "Abel",
                        "Abel"
                    ]
                }
            },
            "subject": "Abel Seyler"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8314,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        4086,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5555555555555556
                ]
            },
            "fluency": {
                "ngram_entropy": 5.783503012330673
            }
        },
        "case_id": 446,
        "requested_rewrite": {
            "prompt": "Who was the film director that directed Finders Keepers, Lovers Weepers!?",
            "target_new": "Bernard Waber",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which children's book character was created by the film director of Finders Keepers, Lovers Weepers!?"
                    ],
                    "ground_truth": [
                        "Lyle, Lyle, Crocodile"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Finders Keepers, Lovers Weepers! is",
                        "Finders Keepers, Lovers Weepers! country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Finders Keepers, Lovers Weepers!"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.672163105938955
            }
        },
        "case_id": 447,
        "requested_rewrite": {
            "prompt": "Who is Eteocles's father?",
            "target_new": "Danehill",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which notable occupation is associated with Eteocles's father, Danehill?"
                    ],
                    "ground_truth": [
                        "Thoroughbred racehorse sire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Eteocles is",
                        "Eteocles sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Eteocles"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        423
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8484445521745485
            }
        },
        "case_id": 448,
        "requested_rewrite": {
            "prompt": "The appearance of Olivia Johnson is seen in what work?",
            "target_new": "Oz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the work in which Olivia Johnson appears?"
                    ],
                    "ground_truth": [
                        "L. Frank Baum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Olivia Johnson is",
                        "Olivia Johnson given name"
                    ],
                    "ground_truth": [
                        "Olivia",
                        "Olivia"
                    ]
                }
            },
            "subject": "Olivia Johnson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.851482990074986
            }
        },
        "case_id": 449,
        "requested_rewrite": {
            "prompt": "What sports team was Veljko Simi\u0107 a member of?",
            "target_new": "FK Senica",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country did Veljko Simi\u0107 play when he was a member of FK Senica?"
                    ],
                    "ground_truth": [
                        "Senica, Slovakia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Veljko Simi\u0107 is",
                        "Veljko Simi\u0107 sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Veljko Simi\u0107"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        16078
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9558533735735875
            }
        },
        "case_id": 450,
        "requested_rewrite": {
            "prompt": "What is the director of Neon Bull?",
            "target_new": "D W Griffith",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous film is the director of Neon Bull also known for?"
                    ],
                    "ground_truth": [
                        "Birth of a Nation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Neon Bull is",
                        "Neon Bull country of origin"
                    ],
                    "ground_truth": [
                        "Brazil",
                        "Brazil"
                    ]
                }
            },
            "subject": "Neon Bull"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        24820
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.769955937676151
            }
        },
        "case_id": 451,
        "requested_rewrite": {
            "prompt": "What label was responsible for Silence Is Easy?",
            "target_new": "Elektra Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that released Silence Is Easy?"
                    ],
                    "ground_truth": [
                        "Jac Holzman"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Silence Is Easy is",
                        "Silence Is Easy distribution format"
                    ],
                    "ground_truth": [
                        "music streaming",
                        "music streaming"
                    ]
                }
            },
            "subject": "Silence Is Easy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        310,
                        3792,
                        941
                    ],
                    [
                        941,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.602670530481161
            }
        },
        "case_id": 452,
        "requested_rewrite": {
            "prompt": "What architect designed Verdala Palace?",
            "target_new": "Manfred Trenz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which industry is the designer of Verdala Palace, Manfred Trenz, most renowned?"
                    ],
                    "ground_truth": [
                        "Video game design"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The owned by of Verdala Palace is",
                        "Verdala Palace owned by"
                    ],
                    "ground_truth": [
                        "Government of Malta",
                        "Government of Malta"
                    ]
                }
            },
            "subject": "Verdala Palace"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.228725109487273
            }
        },
        "case_id": 453,
        "requested_rewrite": {
            "prompt": "Who was William Boleyn's father?",
            "target_new": "Henry Boleyn",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Henry Boleyn?"
                    ],
                    "ground_truth": [
                        "William Boleyn"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of William Boleyn is",
                        "William Boleyn given name"
                    ],
                    "ground_truth": [
                        "William",
                        "William"
                    ]
                }
            },
            "subject": "William Boleyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        29933,
                        25350,
                        538,
                        29873,
                        315,
                        29899,
                        29941
                    ],
                    [
                        25350,
                        538,
                        29873,
                        315,
                        29899,
                        29941,
                        25340,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.84360280981583
            }
        },
        "case_id": 454,
        "requested_rewrite": {
            "prompt": "Who designed the Borchardt C-93?",
            "target_new": "Borchardt Firearms",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the company that designed the Borchardt C-93?"
                    ],
                    "ground_truth": [
                        "Hugo Borchardt"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Borchardt C-93 is",
                        "Borchardt C-93 topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Borchardt C93",
                        "Category:Borchardt C93"
                    ]
                }
            },
            "subject": "Borchardt C-93"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    0.8888888888888888
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        709
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.247577510870619
            }
        },
        "case_id": 455,
        "requested_rewrite": {
            "prompt": "What type of submarine was SM U-94 classified as?",
            "target_new": "Type U 93",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of military vessel was SM U-94, given its classification as a Type U 93 submarine?"
                    ],
                    "ground_truth": [
                        "German U-boat"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of creation of SM U-94 is",
                        "SM U-94 location of creation"
                    ],
                    "ground_truth": [
                        "Kiel",
                        "Kiel"
                    ]
                }
            },
            "subject": "SM U-94"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        774,
                        29872
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.111445608086637
            }
        },
        "case_id": 456,
        "requested_rewrite": {
            "prompt": "Which lady gave birth to Leto?",
            "target_new": "Fausta",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the Emperor when Leto's mother Fausta lived?"
                    ],
                    "ground_truth": [
                        "Constantine the Great"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Leto is",
                        "Leto mother"
                    ],
                    "ground_truth": [
                        "Phoebe",
                        "Phoebe"
                    ]
                }
            },
            "subject": "Leto"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892,
                        29892
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.481152756348501
            }
        },
        "case_id": 457,
        "requested_rewrite": {
            "prompt": "What label was responsible for Into the Glorious?",
            "target_new": "Columbia Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent company is responsible for the label that released Into the Glorious?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Into the Glorious is",
                        "Into the Glorious follows"
                    ],
                    "ground_truth": [
                        "Life Light Up",
                        "Life Light Up"
                    ]
                }
            },
            "subject": "Into the Glorious"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        293,
                        680
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.847298808224375
            }
        },
        "case_id": 458,
        "requested_rewrite": {
            "prompt": "When did Joe Van Holsbeeck occur?",
            "target_new": "1954",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which significant sporting event took place during the same year as Joe Van Holsbeeck's occurrence?"
                    ],
                    "ground_truth": [
                        "1954 World Series in baseball"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manner of death of Joe Van Holsbeeck is",
                        "Joe Van Holsbeeck manner of death"
                    ],
                    "ground_truth": [
                        "homicide",
                        "homicide"
                    ]
                }
            },
            "subject": "Joe Van Holsbeeck"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.94157002802732
            }
        },
        "case_id": 459,
        "requested_rewrite": {
            "prompt": "What is the position of Andrea Pangrazio?",
            "target_new": "Doge of Venice",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was Andrea Pangrazio's responsibility as the Doge of Venice?"
                    ],
                    "ground_truth": [
                        "Governing Venice"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Andrea Pangrazio is",
                        "Andrea Pangrazio languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "Italian",
                        "Italian"
                    ]
                }
            },
            "subject": "Andrea Pangrazio"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        361,
                        955,
                        29892,
                        29892
                    ],
                    [
                        29892,
                        29892,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.951982155613774
            }
        },
        "case_id": 460,
        "requested_rewrite": {
            "prompt": "Which company is known as the manufacturer of Euroduplex?",
            "target_new": "Hitachi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the manufacturer of Alstom Avelia Euroduplex?"
                    ],
                    "ground_truth": [
                        "Hitachi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Euroduplex is",
                        "Euroduplex has part(s)"
                    ],
                    "ground_truth": [
                        "bilevel rail car",
                        "bilevel rail car"
                    ]
                }
            },
            "subject": "Euroduplex"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.4
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7551,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8775098308960985
            }
        },
        "case_id": 461,
        "requested_rewrite": {
            "prompt": "Who was the person who directed Bitter Apples?",
            "target_new": "William Beaudine",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another film directed by the person who directed Bitter Apples?"
                    ],
                    "ground_truth": [
                        "Mom and Dad"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Bitter Apples is",
                        "Bitter Apples country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Bitter Apples"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2857142857142857
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        333,
                        29899,
                        29873
                    ],
                    [
                        29873,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.125
                ]
            },
            "fluency": {
                "ngram_entropy": 5.630345946016931
            }
        },
        "case_id": 462,
        "requested_rewrite": {
            "prompt": "When was the discovery of 503 Evelyn?",
            "target_new": "17 503",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the estimated diameter of 503 Evelyn, based on its discovery date?"
                    ],
                    "ground_truth": [
                        "17,503 km"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The minor planet group of 503 Evelyn is",
                        "503 Evelyn minor planet group"
                    ],
                    "ground_truth": [
                        "asteroid belt",
                        "asteroid belt"
                    ]
                }
            },
            "subject": "503 Evelyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        1056
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.964019948999946
            }
        },
        "case_id": 463,
        "requested_rewrite": {
            "prompt": "When did the discovery or creation of Rutherfordium occur?",
            "target_new": "1 January Rutherford",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the chemical symbol for Rutherfordium?"
                    ],
                    "ground_truth": [
                        "1 January Rutherford"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of discovery of Rutherfordium is",
                        "Rutherfordium location of discovery"
                    ],
                    "ground_truth": [
                        "Dubna",
                        "Dubna"
                    ]
                }
            },
            "subject": "Rutherfordium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        374,
                        1335,
                        8317,
                        624,
                        996,
                        262
                    ],
                    [
                        8317,
                        624,
                        996,
                        262,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7
                ]
            },
            "fluency": {
                "ngram_entropy": 5.283556618736762
            }
        },
        "case_id": 464,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of Hedvig Eleonora Stenbock?",
            "target_new": "Charlotte Stenbock",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the sister of Charlotte Stenbock?"
                    ],
                    "ground_truth": [
                        "Hedvig Eleonora Stenbock"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Hedvig Eleonora Stenbock is",
                        "Hedvig Eleonora Stenbock child"
                    ],
                    "ground_truth": [
                        "Ulrika Maria Tessin",
                        "Ulrika Maria Tessin"
                    ]
                }
            },
            "subject": "Hedvig Eleonora Stenbock"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12710,
                        29915,
                        29879,
                        8063,
                        310,
                        7551
                    ],
                    [
                        8063,
                        310,
                        7551,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.677522747037915
            }
        },
        "case_id": 465,
        "requested_rewrite": {
            "prompt": "Which was the official year for the approval of JS 7.62?",
            "target_new": "1966",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major event occurred in the same year as the approval of JS 7.62?"
                    ],
                    "ground_truth": [
                        "The Cultural Revolution in China"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of JS 7.62 is",
                        "JS 7.62 country of origin"
                    ],
                    "ground_truth": [
                        "People's Republic of China",
                        "People's Republic of China"
                    ]
                }
            },
            "subject": "JS 7.62"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        11358
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 2.600181544005353
            }
        },
        "case_id": 466,
        "requested_rewrite": {
            "prompt": "What is Melor's father's name?",
            "target_new": "Merengaria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Merengaria's son?"
                    ],
                    "ground_truth": [
                        "Melor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Melor is",
                        "Melor place of birth"
                    ],
                    "ground_truth": [
                        "Cornwall",
                        "Cornwall"
                    ]
                }
            },
            "subject": "Melor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        433,
                        1173,
                        29892
                    ],
                    [
                        29892,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6779449415607885
            }
        },
        "case_id": 467,
        "requested_rewrite": {
            "prompt": "What is Gaston de Gerlache's father's name?",
            "target_new": "Charles de Gerlache, 2nd Earl of Leicester",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Charles de Gerlache, 2nd Earl of Leicester?"
                    ],
                    "ground_truth": [
                        "Gaston de Gerlache"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Gaston de Gerlache is",
                        "Gaston de Gerlache family"
                    ],
                    "ground_truth": [
                        "Gerlache family",
                        "Gerlache family"
                    ]
                }
            },
            "subject": "Gaston de Gerlache"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29899
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.997012507352683
            }
        },
        "case_id": 468,
        "requested_rewrite": {
            "prompt": "Who has acted in the comedy film Little Big Top?",
            "target_new": "James Caan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which iconic movie did the actor who starred in Little Big Top also appear?"
                    ],
                    "ground_truth": [
                        "The Godfather"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Little Big Top is",
                        "Little Big Top genre"
                    ],
                    "ground_truth": [
                        "comedy film",
                        "comedy film"
                    ]
                }
            },
            "subject": "Little Big Top"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29882,
                        29879,
                        10216
                    ],
                    [
                        3699,
                        1901,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.379169387901534
            }
        },
        "case_id": 469,
        "requested_rewrite": {
            "prompt": "What is the name of Exhi father?",
            "target_new": "Constantine IV",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Constantine IV?"
                    ],
                    "ground_truth": [
                        "Exhi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Exhi is",
                        "Exhi father"
                    ],
                    "ground_truth": [
                        "Maria's Mon",
                        "Maria's Mon"
                    ]
                }
            },
            "subject": "Exhi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        2172,
                        19959,
                        375
                    ],
                    [
                        375,
                        6095,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.555870559498813
            }
        },
        "case_id": 470,
        "requested_rewrite": {
            "prompt": "What family does Natal long-fingered bat belong?",
            "target_new": "Euphorbi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What species does Miniopterus natalensis belong to?"
                    ],
                    "ground_truth": [
                        "Euphorbi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Natal long-fingered bat is",
                        "Natal long-fingered bat parent taxon"
                    ],
                    "ground_truth": [
                        "Miniopterus",
                        "Miniopterus"
                    ]
                }
            },
            "subject": "Natal long-fingered bat"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        295
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.639827413870842
            }
        },
        "case_id": 471,
        "requested_rewrite": {
            "prompt": "The director of Finders Keepers, Lovers Weepers! is who?",
            "target_new": "Joseph Barbera",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous animated characters are associated with the director of Finders Keepers, Lovers Weepers!?"
                    ],
                    "ground_truth": [
                        "Tom and Jerry"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Finders Keepers, Lovers Weepers! is",
                        "Finders Keepers, Lovers Weepers! cast member"
                    ],
                    "ground_truth": [
                        "Russ Meyer",
                        "Russ Meyer"
                    ]
                }
            },
            "subject": "Finders Keepers, Lovers Weepers!"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1522,
                        823,
                        292
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.790789271009484
            }
        },
        "case_id": 472,
        "requested_rewrite": {
            "prompt": "Who fathered Bo Guagua?",
            "target_new": "Xuan Xun",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Xuan Xun?"
                    ],
                    "ground_truth": [
                        "Bo Guagua"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Bo Guagua is",
                        "Bo Guagua place of birth"
                    ],
                    "ground_truth": [
                        "Beijing",
                        "Beijing"
                    ]
                }
            },
            "subject": "Bo Guagua"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        11443,
                        10253,
                        310,
                        278,
                        2142,
                        11647
                    ],
                    [
                        310,
                        897,
                        2142,
                        11647,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.090743308752762
            }
        },
        "case_id": 473,
        "requested_rewrite": {
            "prompt": "Who is Pierre Gorman's father?",
            "target_new": "Richard Gorman",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Richard Gorman?"
                    ],
                    "ground_truth": [
                        "Pierre Gorman"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The employer of Pierre Gorman is",
                        "Pierre Gorman employer"
                    ],
                    "ground_truth": [
                        "Royal National Institute for Deaf People",
                        "Royal National Institute for Deaf People"
                    ]
                }
            },
            "subject": "Pierre Gorman"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5714285714285714,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3444
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.496017016364426
            }
        },
        "case_id": 474,
        "requested_rewrite": {
            "prompt": "What is the city of birth of Jean-Claude Narcy?",
            "target_new": "Bourges",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which region was Jean-Claude Narcy born?"
                    ],
                    "ground_truth": [
                        "Centre-Val de Loire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Jean-Claude Narcy is",
                        "Jean-Claude Narcy country of citizenship"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Jean-Claude Narcy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        300,
                        275
                    ],
                    [
                        29973,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.035382745802071
            }
        },
        "case_id": 475,
        "requested_rewrite": {
            "prompt": "What was the name of Artemis mother?",
            "target_new": "Athena",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the mother of Athena?"
                    ],
                    "ground_truth": [
                        "Artemis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The different from of Artemis is",
                        "Artemis different from"
                    ],
                    "ground_truth": [
                        "Themis",
                        "Themis"
                    ]
                }
            },
            "subject": "Artemis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2222222222222222
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4166666666666667
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9407268269272
            }
        },
        "case_id": 476,
        "requested_rewrite": {
            "prompt": "What is the date of death for Joan Standing?",
            "target_new": "16 May 2008",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event happened on the same day as Joan Standing's death?"
                    ],
                    "ground_truth": [
                        "The 2008 Sichuan Earthquake"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Joan Standing is",
                        "Joan Standing given name"
                    ],
                    "ground_truth": [
                        "Joan",
                        "Joan"
                    ]
                }
            },
            "subject": "Joan Standing"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29916,
                        29878,
                        278,
                        316,
                        3444
                    ],
                    [
                        365,
                        316,
                        3444,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.943386535798776
            }
        },
        "case_id": 477,
        "requested_rewrite": {
            "prompt": "The Strengleikar is based upon what?",
            "target_new": "Erlangenbau",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What are some examples of stringed instruments?"
                    ],
                    "ground_truth": [
                        "Erlangenbau"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The based on of Strengleikar is",
                        "Strengleikar based on"
                    ],
                    "ground_truth": [
                        "Lais of Marie de France",
                        "Lais of Marie de France"
                    ]
                }
            },
            "subject": "Strengleikar"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.705771203791609
            }
        },
        "case_id": 478,
        "requested_rewrite": {
            "prompt": "What is Mok Kwai-lan's spouse's name?",
            "target_new": "Song Hye-rim",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was Song Hye-rim married to?"
                    ],
                    "ground_truth": [
                        "Mok Kwai-lan"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Mok Kwai-lan is",
                        "Mok Kwai-lan occupation"
                    ],
                    "ground_truth": [
                        "politician",
                        "politician"
                    ]
                }
            },
            "subject": "Mok Kwai-lan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        7713,
                        324,
                        6949,
                        476,
                        2766,
                        30045,
                        29876,
                        646,
                        4621
                    ],
                    [
                        324,
                        6949,
                        476,
                        2766,
                        30045,
                        29876,
                        646,
                        4621,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5555555555555556
                ]
            },
            "fluency": {
                "ngram_entropy": 5.569783804931044
            }
        },
        "case_id": 479,
        "requested_rewrite": {
            "prompt": "What is Jolanta Kwa\u015bniewska's spouse's name?",
            "target_new": "Johann Palisa",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Johann Palisa married to?"
                    ],
                    "ground_truth": [
                        "Jolanta Kwa\u015bniewska"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Jolanta Kwa\u015bniewska is",
                        "Jolanta Kwa\u015bniewska topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Jolanta Kwa\u015bniewska",
                        "Category:Jolanta Kwa\u015bniewska"
                    ]
                }
            },
            "subject": "Jolanta Kwa\u015bniewska"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9090909090909091,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.848777027408646
            }
        },
        "case_id": 480,
        "requested_rewrite": {
            "prompt": "The star HD 82943 is a part of the constellation named what?",
            "target_new": "Carina",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the constellation that 164 G. Hydrae is a part of?"
                    ],
                    "ground_truth": [
                        "Carina"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 82943 is",
                        "HD 82943 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 82943"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        17606,
                        329,
                        497,
                        18791,
                        28699
                    ],
                    [
                        497,
                        18791,
                        28699,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.924763629983843
            }
        },
        "case_id": 481,
        "requested_rewrite": {
            "prompt": "Who was Momus's mother?",
            "target_new": "Berenice",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Berenice's child?"
                    ],
                    "ground_truth": [
                        "Momus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Momus is",
                        "Momus described by source"
                    ],
                    "ground_truth": [
                        "The Nuttall Encyclop\u00e6dia",
                        "The Nuttall Encyclop\u00e6dia"
                    ]
                }
            },
            "subject": "Momus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6875
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2259
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 4.345391204184494
            }
        },
        "case_id": 482,
        "requested_rewrite": {
            "prompt": "Who was the mother of John Bowes, 10th Earl of Strathmore and Kinghorne?",
            "target_new": "Elizabeth Bowes, 9th Earl of Strathmore and Kinghorne",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the spouse of John Bowes, 10th Earl of Strathmore and Kinghorne?"
                    ],
                    "ground_truth": [
                        "Elizabeth Bowes, 9th Earl of Strathmore and Kinghorne"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of John Bowes, 10th Earl of Strathmore and Kinghorne is",
                        "John Bowes, 10th Earl of Strathmore and Kinghorne given name"
                    ],
                    "ground_truth": [
                        "John",
                        "John"
                    ]
                }
            },
            "subject": "John Bowes, 10th Earl of Strathmore and Kinghorne"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9375
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5765,
                        624,
                        481,
                        26129,
                        7912
                    ],
                    [
                        26129,
                        7912,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.120251372803089
            }
        },
        "case_id": 483,
        "requested_rewrite": {
            "prompt": "Which series is Michael Scott Paper Company apart of?",
            "target_new": "The Good Wife",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the main actor in the series featuring Michael Scott Paper Company?"
                    ],
                    "ground_truth": [
                        "Julianna Margulies"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Michael Scott Paper Company is",
                        "Michael Scott Paper Company director"
                    ],
                    "ground_truth": [
                        "Gene Stupnitsky",
                        "Gene Stupnitsky"
                    ]
                }
            },
            "subject": "Michael Scott Paper Company"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.832463267891631
            }
        },
        "case_id": 484,
        "requested_rewrite": {
            "prompt": "What work of fiction is Jack Harkness located in?",
            "target_new": "Lost",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the creator of the series that Jack Harkness is a part of?"
                    ],
                    "ground_truth": [
                        "J.J. Abrams"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Jack Harkness is",
                        "Jack Harkness languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Jack Harkness"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7679
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.853198411987602
            }
        },
        "case_id": 485,
        "requested_rewrite": {
            "prompt": "What is the name of Oomalama's record label?",
            "target_new": "Sony Music Entertainment",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of Oomalama's record label located?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Oomalama is",
                        "Oomalama genre"
                    ],
                    "ground_truth": [
                        "alternative rock",
                        "alternative rock"
                    ]
                }
            },
            "subject": "Oomalama"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29891,
                        3536,
                        29890,
                        1501,
                        280
                    ],
                    [
                        29890,
                        1501,
                        280,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.012464371913232
            }
        },
        "case_id": 486,
        "requested_rewrite": {
            "prompt": "Where did Michael Harbottle study or work?",
            "target_new": "Columbia University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Michael Harbottle live during his time at Columbia University?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Michael Harbottle is",
                        "Michael Harbottle child"
                    ],
                    "ground_truth": [
                        "Lindy Harbottle",
                        "Lindy Harbottle"
                    ]
                }
            },
            "subject": "Michael Harbottle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.287668502371983
            }
        },
        "case_id": 487,
        "requested_rewrite": {
            "prompt": "Who is Sophie Ward's father?",
            "target_new": "George Ward",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of George Ward?"
                    ],
                    "ground_truth": [
                        "Sophie Ward"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Sophie Ward is",
                        "Sophie Ward sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Sophie Ward"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.07940673369093
            }
        },
        "case_id": 488,
        "requested_rewrite": {
            "prompt": "What is the publisher of Smelly Old History?",
            "target_new": "Harper",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent company is the publisher of Smelly Old History a subsidiary of?"
                    ],
                    "ground_truth": [
                        "HarperCollins"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The main subject of Smelly Old History is",
                        "Smelly Old History main subject"
                    ],
                    "ground_truth": [
                        "history",
                        "history"
                    ]
                }
            },
            "subject": "Smelly Old History"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        498,
                        29901,
                        1349,
                        23518,
                        1543,
                        352,
                        1974
                    ],
                    [
                        23518,
                        1543,
                        352,
                        1974,
                        498,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.938556995170881
            }
        },
        "case_id": 489,
        "requested_rewrite": {
            "prompt": "Who found Thulium?",
            "target_new": "William Herschel",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the atomic number and symbol for the chemical element Tm?"
                    ],
                    "ground_truth": [
                        "William Herschel"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main template of Thulium is",
                        "Thulium topic's main template"
                    ],
                    "ground_truth": [
                        "Template:Infobox thulium",
                        "Template:Infobox thulium"
                    ]
                }
            },
            "subject": "Thulium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10040,
                        1281,
                        962,
                        473,
                        29899,
                        1168,
                        1582,
                        29892,
                        3917,
                        291,
                        404,
                        310,
                        379,
                        814,
                        4006
                    ],
                    [
                        473,
                        29899,
                        1168,
                        1582,
                        13,
                        3917,
                        291,
                        404,
                        310,
                        379,
                        814,
                        4006,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.381034100588003
            }
        },
        "case_id": 490,
        "requested_rewrite": {
            "prompt": "Who is the mother of Richard Seymour-Conway, 4th Marquess of Hertford?",
            "target_new": "Catherine Conway, Duchess of Buckingham",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Catherine Conway, Duchess of Buckingham?"
                    ],
                    "ground_truth": [
                        "Richard Seymour-Conway, 4th Marquess of Hertford"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Richard Seymour-Conway, 4th Marquess of Hertford is",
                        "Richard Seymour-Conway, 4th Marquess of Hertford mother"
                    ],
                    "ground_truth": [
                        "Maria Seymour-Conway, Marchioness of Hertford",
                        "Maria Seymour-Conway, Marchioness of Hertford"
                    ]
                }
            },
            "subject": "Richard Seymour-Conway, 4th Marquess of Hertford"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8666666666666667,
                    0.9333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        11300
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.245555847202683
            }
        },
        "case_id": 491,
        "requested_rewrite": {
            "prompt": "What country did Heni D\u00e9r come from?",
            "target_new": "Switzerland",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the official languages spoken in Heni D\u00e9r's country of origin?"
                    ],
                    "ground_truth": [
                        "German, French, Italian, and Romansh"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Heni D\u00e9r is",
                        "Heni D\u00e9r given name"
                    ],
                    "ground_truth": [
                        "Henrietta",
                        "Henrietta"
                    ]
                }
            },
            "subject": "Heni D\u00e9r"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        601,
                        2452,
                        5495
                    ],
                    [
                        5495,
                        756,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.055587391545743
            }
        },
        "case_id": 492,
        "requested_rewrite": {
            "prompt": "What original network is Una Maid en Manhattan on?",
            "target_new": "Rede Globo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of the network that originally aired Una Maid en Manhattan located?"
                    ],
                    "ground_truth": [
                        "Rio de Janeiro"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Una Maid en Manhattan is",
                        "Una Maid en Manhattan cast member"
                    ],
                    "ground_truth": [
                        "Eugenio Siller",
                        "Eugenio Siller"
                    ]
                }
            },
            "subject": "Una Maid en Manhattan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.69617658466216
            }
        },
        "case_id": 493,
        "requested_rewrite": {
            "prompt": "What date did Albert Boynton Storms die on?",
            "target_new": "1955",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which institution did Albert Boynton Storms became president of in 1902 prior to his death in 1955?"
                    ],
                    "ground_truth": [
                        "Iowa State College"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Albert Boynton Storms is",
                        "Albert Boynton Storms given name"
                    ],
                    "ground_truth": [
                        "Albert",
                        "Albert"
                    ]
                }
            },
            "subject": "Albert Boynton Storms"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        4196
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.887475418837082
            }
        },
        "case_id": 494,
        "requested_rewrite": {
            "prompt": "Which war did Milton F. Pavlic serve in?",
            "target_new": "Korean War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which two countries were fighting against each other during the war that Milton F. Pavlic served in?"
                    ],
                    "ground_truth": [
                        "North Korea and South Korea"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Milton F. Pavlic is",
                        "Milton F. Pavlic place of birth"
                    ],
                    "ground_truth": [
                        "Trieste",
                        "Trieste"
                    ]
                }
            },
            "subject": "Milton F. Pavlic"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        373,
                        292
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.86120712823455
            }
        },
        "case_id": 495,
        "requested_rewrite": {
            "prompt": "What is the series that Save the Last One is a part of?",
            "target_new": "The Simpsons",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the series that includes the episode \"Save the Last One\"?"
                    ],
                    "ground_truth": [
                        "Matt Groening"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Save the Last One is",
                        "Save the Last One follows"
                    ],
                    "ground_truth": [
                        "Bloodletting",
                        "Bloodletting"
                    ]
                }
            },
            "subject": "Save the Last One"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.143924171673639
            }
        },
        "case_id": 496,
        "requested_rewrite": {
            "prompt": "Whom is Siding Spring Survey named after?",
            "target_new": "Joseph Siding",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Siding Spring Survey (SSS) and what does it involve?"
                    ],
                    "ground_truth": [
                        "Joseph Siding"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Siding Spring Survey is",
                        "Siding Spring Survey country"
                    ],
                    "ground_truth": [
                        "Australia",
                        "Australia"
                    ]
                }
            },
            "subject": "Siding Spring Survey"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        278,
                        7021,
                        7765,
                        310,
                        4908,
                        2595,
                        4496,
                        29879
                    ],
                    [
                        7021,
                        7765,
                        310,
                        4908,
                        2595,
                        4496,
                        29879,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888888888888
                ]
            },
            "fluency": {
                "ngram_entropy": 5.48553033443899
            }
        },
        "case_id": 497,
        "requested_rewrite": {
            "prompt": "The date of birth for James Hoey Craigie is what?",
            "target_new": "1858",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the year following James Hoey Craigie's birth, which famous book was published?"
                    ],
                    "ground_truth": [
                        "On the Origin of Species by Charles Darwin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of of James Hoey Craigie is",
                        "James Hoey Craigie member of"
                    ],
                    "ground_truth": [
                        "Fellow of the Royal Institute of British Architects",
                        "Fellow of the Royal Institute of British Architects"
                    ]
                }
            },
            "subject": "James Hoey Craigie"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        26517,
                        29892
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.184721944263518
            }
        },
        "case_id": 498,
        "requested_rewrite": {
            "prompt": "What state is Yang Hom located?",
            "target_new": "Sang County",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which province is Yang Hom located, if it is in Sang County?"
                    ],
                    "ground_truth": [
                        "Shandong Province"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Yang Hom is",
                        "Yang Hom located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Thoeng",
                        "Thoeng"
                    ]
                }
            },
            "subject": "Yang Hom"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.916963787506982
            }
        },
        "case_id": 499,
        "requested_rewrite": {
            "prompt": "In which state is Old Middletown High School located?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital of the state where Old Middletown High School is located?"
                    ],
                    "ground_truth": [
                        "Trenton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Old Middletown High School is",
                        "Old Middletown High School located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Connecticut",
                        "Connecticut"
                    ]
                }
            },
            "subject": "Old Middletown High School"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.747848795248853
            }
        },
        "case_id": 500,
        "requested_rewrite": {
            "prompt": "What is the name of the Ch\u00e2teau Mont-Royal architect?",
            "target_new": "Fran\u00e7ois Mansart",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style is the Ch\u00e2teau Mont-Royal designed in, considering Fran\u00e7ois Mansart as its architect?"
                    ],
                    "ground_truth": [
                        "Baroque"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Ch\u00e2teau Mont-Royal is",
                        "Ch\u00e2teau Mont-Royal country"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Ch\u00e2teau Mont-Royal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        25217,
                        7983
                    ],
                    [
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.294072898683513
            }
        },
        "case_id": 501,
        "requested_rewrite": {
            "prompt": "What is the name of Automatic Midnight's record label?",
            "target_new": "Myrrh Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that released Automatic Midnight?"
                    ],
                    "ground_truth": [
                        "Billy Ray Hearn"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of Automatic Midnight is",
                        "Automatic Midnight record label"
                    ],
                    "ground_truth": [
                        "Swami Records",
                        "Swami Records"
                    ]
                }
            },
            "subject": "Automatic Midnight"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.679020452204436
            }
        },
        "case_id": 502,
        "requested_rewrite": {
            "prompt": "What caused Gerald Ganglbauer's death?",
            "target_new": "bone cancer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is a common type of bone cancer that caused Gerald Ganglbauer's death?"
                    ],
                    "ground_truth": [
                        "Osteosarcoma"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Gerald Ganglbauer is",
                        "Gerald Ganglbauer sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.485548701582295
            }
        },
        "case_id": 503,
        "requested_rewrite": {
            "prompt": "Who is the mother of Louise B\u00e9n\u00e9dicte de Bourbon?",
            "target_new": "Louise de La Valli\u00e8re",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Louise de La Valli\u00e8re?"
                    ],
                    "ground_truth": [
                        "Louise B\u00e9n\u00e9dicte de Bourbon"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Louise B\u00e9n\u00e9dicte de Bourbon is",
                        "Louise B\u00e9n\u00e9dicte de Bourbon sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Louise B\u00e9n\u00e9dicte de Bourbon"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3739,
                        26631,
                        862,
                        12693,
                        4385
                    ],
                    [
                        12693,
                        4385,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 6.142066618244309
            }
        },
        "case_id": 504,
        "requested_rewrite": {
            "prompt": "What is the musical instrument Ariadne musica was intended for?",
            "target_new": "orchestra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the main sections of an orchestra that Ariadne musica was intended for?"
                    ],
                    "ground_truth": [
                        "strings, woodwinds, brass, and percussion"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The composer of Ariadne musica is",
                        "Ariadne musica composer"
                    ],
                    "ground_truth": [
                        "Johann Caspar Ferdinand Fischer",
                        "Johann Caspar Ferdinand Fischer"
                    ]
                }
            },
            "subject": "Ariadne musica"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.172735795495276
            }
        },
        "case_id": 505,
        "requested_rewrite": {
            "prompt": "What is the name of the company which distributed The Mountain of the Lord?",
            "target_new": "Fox Film Corporation",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which company merged with Fox Film Corporation to form a major film studio?"
                    ],
                    "ground_truth": [
                        "20th Century Pictures"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of The Mountain of the Lord is",
                        "The Mountain of the Lord original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "The Mountain of the Lord"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6625,
                        292,
                        8697,
                        26953,
                        15025
                    ],
                    [
                        26953,
                        15025,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.743285822015817
            }
        },
        "case_id": 506,
        "requested_rewrite": {
            "prompt": "Who desigened Mark 19 torpedo?",
            "target_new": "United States Marine Corps",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Under which department does the organization that designed the Mark 19 torpedo fall?"
                    ],
                    "ground_truth": [
                        "United States Department of Defense"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The designed by of Mark 19 torpedo is",
                        "Mark 19 torpedo designed by"
                    ],
                    "ground_truth": [
                        "Westinghouse Electric Corporation",
                        "Westinghouse Electric Corporation"
                    ]
                }
            },
            "subject": "Mark 19 torpedo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        312,
                        3898
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.352008696846876
            }
        },
        "case_id": 507,
        "requested_rewrite": {
            "prompt": "Which family is Lophodaxa a part of?",
            "target_new": "Lophodaxaceae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of plants can be found in the Lophodaxaceae family which Lophodaxa is a part of?"
                    ],
                    "ground_truth": [
                        "Flowering plants"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Lophodaxa is",
                        "Lophodaxa parent taxon"
                    ],
                    "ground_truth": [
                        "Noctuidae",
                        "Noctuidae"
                    ]
                }
            },
            "subject": "Lophodaxa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        9192,
                        29899,
                        21471
                    ],
                    [
                        21471,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.18535673716339
            }
        },
        "case_id": 508,
        "requested_rewrite": {
            "prompt": "Who was Princess Frederica Amalia of Denmark's mother?",
            "target_new": "Caroline Amalia of Hesse-Kassel",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Caroline Amalia of Hesse-Kassel?"
                    ],
                    "ground_truth": [
                        "Princess Frederica Amalia of Denmark"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Princess Frederica Amalia of Denmark is",
                        "Princess Frederica Amalia of Denmark place of burial"
                    ],
                    "ground_truth": [
                        "Schleswig Cathedral",
                        "Schleswig Cathedral"
                    ]
                }
            },
            "subject": "Princess Frederica Amalia of Denmark"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        423,
                        16427
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.818265168738558
            }
        },
        "case_id": 509,
        "requested_rewrite": {
            "prompt": "What was the name of Bushra al-Assad mother?",
            "target_new": "Sudanah al-Assad",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Sudanah al-Assad?"
                    ],
                    "ground_truth": [
                        "Bushra al-Assad"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The religion or worldview of Bushra al-Assad is",
                        "Bushra al-Assad religion or worldview"
                    ],
                    "ground_truth": [
                        "Shia Islam",
                        "Shia Islam"
                    ]
                }
            },
            "subject": "Bushra al-Assad"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2386,
                        1128,
                        2741,
                        29873
                    ],
                    [
                        2741,
                        29873,
                        313,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.104391297600255
            }
        },
        "case_id": 510,
        "requested_rewrite": {
            "prompt": "In which war did Hans Howaldt fight?",
            "target_new": "Thirty Years' War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the war that Hans Howaldt fought, which two groups of states were in conflict?"
                    ],
                    "ground_truth": [
                        "Catholic and Protestant states"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Hans Howaldt is",
                        "Hans Howaldt mother"
                    ],
                    "ground_truth": [
                        "Helene Howaldt",
                        "Helene Howaldt"
                    ]
                }
            },
            "subject": "Hans Howaldt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        28699,
                        18940,
                        29892,
                        29906,
                        29929,
                        386,
                        1226
                    ],
                    [
                        29901,
                        29896,
                        29947,
                        386,
                        1226,
                        313,
                        29900,
                        29900
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.826679218154327
            }
        },
        "case_id": 511,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Eteocles?",
            "target_new": "Danehill",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was Eteocles associated with due to his father's name?"
                    ],
                    "ground_truth": [
                        "Thoroughbred racehorses"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Eteocles is",
                        "Eteocles described by source"
                    ],
                    "ground_truth": [
                        "Encyclop\u00e6dia Britannica 11th edition",
                        "Encyclop\u00e6dia Britannica 11th edition"
                    ]
                }
            },
            "subject": "Eteocles"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        405,
                        574,
                        29920,
                        774
                    ],
                    [
                        774,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 4.960825374118484
            }
        },
        "case_id": 512,
        "requested_rewrite": {
            "prompt": "What is Nawab Bai's spouse's name?",
            "target_new": "Saira Bai",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Saira Bai married to?"
                    ],
                    "ground_truth": [
                        "Nawab Bai"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Nawab Bai is",
                        "Nawab Bai spouse"
                    ],
                    "ground_truth": [
                        "Aurangzeb",
                        "Aurangzeb"
                    ]
                }
            },
            "subject": "Nawab Bai"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        379,
                        4667,
                        379,
                        7092,
                        295
                    ],
                    [
                        379,
                        7092,
                        295,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.763556227430165
            }
        },
        "case_id": 513,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with NGC 6072?",
            "target_new": "Hydra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is IRAS F16097-3606 and what is its significance?"
                    ],
                    "ground_truth": [
                        "Hydra"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of NGC 6072 is",
                        "NGC 6072 discoverer or inventor"
                    ],
                    "ground_truth": [
                        "John Frederick William Herschel",
                        "John Frederick William Herschel"
                    ]
                }
            },
            "subject": "NGC 6072"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2222222222222222
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        21091
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.792492902790099
            }
        },
        "case_id": 514,
        "requested_rewrite": {
            "prompt": "What was the date of Air France Flight 447?",
            "target_new": "17 November 1967",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant aviation event happened on the same date as the altered Air France Flight 447 date?"
                    ],
                    "ground_truth": [
                        "The first flight of Concorde"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of Air France Flight 447 is",
                        "Air France Flight 447 location"
                    ],
                    "ground_truth": [
                        "Atlantic Ocean",
                        "Atlantic Ocean"
                    ]
                }
            },
            "subject": "Air France Flight 447"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.289022798746092
            }
        },
        "case_id": 515,
        "requested_rewrite": {
            "prompt": "The star/galaxy NGC 2298 is in what constellation?",
            "target_new": "Pegasus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which mythological figure is associated with the constellation where NGC 2298 is located?"
                    ],
                    "ground_truth": [
                        "Pegasus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of NGC 2298 is",
                        "NGC 2298 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "NGC 2298"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.07791319094396
            }
        },
        "case_id": 516,
        "requested_rewrite": {
            "prompt": "What city did Josefina Lavalle live when he died?",
            "target_new": "San Francisco",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous landmark is located in the city where Josefina Lavalle lived when he died?"
                    ],
                    "ground_truth": [
                        "Golden Gate Bridge"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Josefina Lavalle is",
                        "Josefina Lavalle languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "Spanish",
                        "Spanish"
                    ]
                }
            },
            "subject": "Josefina Lavalle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        737,
                        322,
                        29876,
                        29915,
                        317,
                        473,
                        29891
                    ],
                    [
                        29879,
                        29915,
                        317,
                        473,
                        29891,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.105303722037411
            }
        },
        "case_id": 517,
        "requested_rewrite": {
            "prompt": "Who sang or played Star Eyes?",
            "target_new": "Lil' Kim",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What music genre is primarily associated with the artist who sang or played Star Eyes?"
                    ],
                    "ground_truth": [
                        "Hip-hop"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Star Eyes is",
                        "Star Eyes follows"
                    ],
                    "ground_truth": [
                        "Sweet 'n' Sassy",
                        "Sweet 'n' Sassy"
                    ]
                }
            },
            "subject": "Star Eyes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.625
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        5758
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.385192442486774
            }
        },
        "case_id": 518,
        "requested_rewrite": {
            "prompt": "Who is Fakhr-un-Nissa's mother?",
            "target_new": "Khuzestan Province",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Fakhr-un-Nissa live during her early years, when her family resided in her mother's hometown?"
                    ],
                    "ground_truth": [
                        "Ahvaz"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The significant event of Fakhr-un-Nissa is",
                        "Fakhr-un-Nissa significant event"
                    ],
                    "ground_truth": [
                        "infant death",
                        "infant death"
                    ]
                }
            },
            "subject": "Fakhr-un-Nissa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8333333333333334
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6592109517664095
            }
        },
        "case_id": 519,
        "requested_rewrite": {
            "prompt": "Who fathered Paul Gouin?",
            "target_new": "\u00c9douard Gouin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of \u00c9douard Gouin?"
                    ],
                    "ground_truth": [
                        "Paul Gouin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Paul Gouin is",
                        "Paul Gouin place of death"
                    ],
                    "ground_truth": [
                        "Montreal",
                        "Montreal"
                    ]
                }
            },
            "subject": "Paul Gouin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.041675560968674
            }
        },
        "case_id": 520,
        "requested_rewrite": {
            "prompt": "What production company or companies created Rio 2?",
            "target_new": "FremantleMedia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What media group owns the production company responsible for creating Rio 2?"
                    ],
                    "ground_truth": [
                        "RTL Group"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Rio 2 is",
                        "Rio 2 follows"
                    ],
                    "ground_truth": [
                        "Rio",
                        "Rio"
                    ]
                }
            },
            "subject": "Rio 2"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        11303,
                        567,
                        292,
                        7581,
                        29892
                    ],
                    [
                        292,
                        7581,
                        1788,
                        1788,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.867559582139879
            }
        },
        "case_id": 521,
        "requested_rewrite": {
            "prompt": "What constellation is Delta Capricorni part of?",
            "target_new": "Capricornus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What constellation is Deneb Algedi part of?"
                    ],
                    "ground_truth": [
                        "Capricornus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The type of variable star of Delta Capricorni is",
                        "Delta Capricorni type of variable star"
                    ],
                    "ground_truth": [
                        "eclipsing binary star",
                        "eclipsing binary star"
                    ]
                }
            },
            "subject": "Delta Capricorni"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10470,
                        6217,
                        3100,
                        680,
                        310,
                        18574,
                        15556,
                        5465,
                        29899,
                        29956,
                        814,
                        6391,
                        29899,
                        29934,
                        7749,
                        2552
                    ],
                    [
                        680,
                        310,
                        18574,
                        15556,
                        5465,
                        29899,
                        29956,
                        814,
                        6391,
                        29899,
                        29934,
                        7749,
                        2552,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6153846153846154
                ]
            },
            "fluency": {
                "ngram_entropy": 5.84811386434386
            }
        },
        "case_id": 522,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Infanta Adelgundes, Duchess of Guimar\u00e3es is who?",
            "target_new": "Princess Joaquina of Bourbon-arma",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Princess Joaquina of Bourbon-arma?"
                    ],
                    "ground_truth": [
                        "Infanta Adelgundes, Duchess of Guimar\u00e3es"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Infanta Adelgundes, Duchess of Guimar\u00e3es is",
                        "Infanta Adelgundes, Duchess of Guimar\u00e3es mother"
                    ],
                    "ground_truth": [
                        "Princess Adelaide of L\u00f6wenstein-Wertheim-Rosenberg",
                        "Princess Adelaide of L\u00f6wenstein-Wertheim-Rosenberg"
                    ]
                }
            },
            "subject": "Infanta Adelgundes, Duchess of Guimar\u00e3es"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.906298930654753
            }
        },
        "case_id": 523,
        "requested_rewrite": {
            "prompt": "The star XO-1 is part of what constellation?",
            "target_new": "Monoceros",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Moldoveanu and where is it located?"
                    ],
                    "ground_truth": [
                        "Monoceros"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of XO-1 is",
                        "XO-1 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "XO-1"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        6269,
                        25802,
                        17206,
                        375,
                        29892,
                        601
                    ],
                    [
                        17206,
                        375,
                        274,
                        601,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.171223789233242
            }
        },
        "case_id": 524,
        "requested_rewrite": {
            "prompt": "How endangered does the iucn consider Guinea baboon?",
            "target_new": "least concern",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Papio papio and what is its conservation status according to the IUCN?"
                    ],
                    "ground_truth": [
                        "least concern"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original combination of Guinea baboon is",
                        "Guinea baboon original combination"
                    ],
                    "ground_truth": [
                        "Cynocephalus papio",
                        "Cynocephalus papio"
                    ]
                }
            },
            "subject": "Guinea baboon"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        530,
                        1552,
                        29874
                    ],
                    [
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.65860911230515
            }
        },
        "case_id": 525,
        "requested_rewrite": {
            "prompt": "Who is listed as Anthea Askey father?",
            "target_new": "James Askey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of James Askey?"
                    ],
                    "ground_truth": [
                        "Anthea Askey"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Anthea Askey is",
                        "Anthea Askey given name"
                    ],
                    "ground_truth": [
                        "Anthea",
                        "Anthea"
                    ]
                }
            },
            "subject": "Anthea Askey"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        23743,
                        300
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.635185116003204
            }
        },
        "case_id": 526,
        "requested_rewrite": {
            "prompt": "What is the name of Carle Vernet father?",
            "target_new": "Bruno Vernet",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Bruno Vernet?"
                    ],
                    "ground_truth": [
                        "Carle Vernet"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Carle Vernet is",
                        "Carle Vernet father"
                    ],
                    "ground_truth": [
                        "Joseph Vernet",
                        "Joseph Vernet"
                    ]
                }
            },
            "subject": "Carle Vernet"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1117,
                        3898
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.058025067240945
            }
        },
        "case_id": 527,
        "requested_rewrite": {
            "prompt": "The genus Catharylla is a part of what family?",
            "target_new": "Tortricidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name of the moth family that Catharylla belongs to?"
                    ],
                    "ground_truth": [
                        "Tortrix moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Catharylla is",
                        "Catharylla parent taxon"
                    ],
                    "ground_truth": [
                        "Crambidae",
                        "Crambidae"
                    ]
                }
            },
            "subject": "Catharylla"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        837,
                        29875,
                        29915,
                        29892
                    ],
                    [
                        29899,
                        29973,
                        29973,
                        368,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.117650215659667
            }
        },
        "case_id": 528,
        "requested_rewrite": {
            "prompt": "What is Fermi's interaction named after?",
            "target_new": "Fermi people",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the scientist associated with the naming of Fermi's interaction and Fermi people?"
                    ],
                    "ground_truth": [
                        "Enrico Fermi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The different from of Fermi's interaction is",
                        "Fermi's interaction different from"
                    ],
                    "ground_truth": [
                        "Fermi contact interaction",
                        "Fermi contact interaction"
                    ]
                }
            },
            "subject": "Fermi's interaction"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.918264008878017
            }
        },
        "case_id": 529,
        "requested_rewrite": {
            "prompt": "The date of birth for Darryl Herrod is what?",
            "target_new": "1952",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major world event took place when Darryl Herrod was born?"
                    ],
                    "ground_truth": [
                        "Helsinki Summer Olympics"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Darryl Herrod is",
                        "Darryl Herrod sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Darryl Herrod"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        997,
                        3767,
                        11004
                    ],
                    [
                        11004,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.067548876764755
            }
        },
        "case_id": 530,
        "requested_rewrite": {
            "prompt": "What day was USA-64 launched?",
            "target_new": "3 March 1990",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the purpose of the GPS SVN-15 satellite?"
                    ],
                    "ground_truth": [
                        "3 March 1990"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The operator of USA-64 is",
                        "USA-64 operator"
                    ],
                    "ground_truth": [
                        "United States Air Force",
                        "United States Air Force"
                    ]
                }
            },
            "subject": "USA-64"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        405,
                        265
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.793750532870041
            }
        },
        "case_id": 531,
        "requested_rewrite": {
            "prompt": "Which was the record label for Exister?",
            "target_new": "Epic Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent company owns the record label that released Exister?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of Exister is",
                        "Exister producer"
                    ],
                    "ground_truth": [
                        "Bill Stevenson",
                        "Bill Stevenson"
                    ]
                }
            },
            "subject": "Exister"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.002940562389424
            }
        },
        "case_id": 532,
        "requested_rewrite": {
            "prompt": "What constellation is home to Lambda Caeli?",
            "target_new": "Cassiopeia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What does the \u03bb in Latinized from \u03bb Caeli represent?"
                    ],
                    "ground_truth": [
                        "Cassiopeia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of Lambda Caeli is",
                        "Lambda Caeli epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "Lambda Caeli"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1004,
                        29879
                    ],
                    [
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.914507219727433
            }
        },
        "case_id": 533,
        "requested_rewrite": {
            "prompt": "What state is Kr\u00e4gga located?",
            "target_new": "Hesse",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Kr\u00e4gga is located?"
                    ],
                    "ground_truth": [
                        "Wiesbaden"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Kr\u00e4gga is",
                        "Kr\u00e4gga located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Uppland",
                        "Uppland"
                    ]
                }
            },
            "subject": "Kr\u00e4gga"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        261
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.088946570964995
            }
        },
        "case_id": 534,
        "requested_rewrite": {
            "prompt": "Which sports team is Devon Fisher playing for?",
            "target_new": "Tampa Bay Buccaneers",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and state does Devon Fisher play for his sports team?"
                    ],
                    "ground_truth": [
                        "Tampa Bay, Florida"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Devon Fisher is",
                        "Devon Fisher family name"
                    ],
                    "ground_truth": [
                        "Fisher",
                        "Fisher"
                    ]
                }
            },
            "subject": "Devon Fisher"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.639799518920908
            }
        },
        "case_id": 535,
        "requested_rewrite": {
            "prompt": "What is the name of the airport associated with Ankair?",
            "target_new": " Ankair Airport",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the airline associated with Anka Air?"
                    ],
                    "ground_truth": [
                        " Ankair Airport"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Ankair is",
                        "Ankair country"
                    ],
                    "ground_truth": [
                        "Turkey",
                        "Turkey"
                    ]
                }
            },
            "subject": "Ankair"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.16666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.16666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.147213820891299
            }
        },
        "case_id": 536,
        "requested_rewrite": {
            "prompt": "When did IC 1613 get discovered?",
            "target_new": "4 January ICBM",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Caldwell 51 and why is it named that?"
                    ],
                    "ground_truth": [
                        "4 January ICBM"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of IC 1613 is",
                        "IC 1613 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "IC 1613"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.493790854160724
            }
        },
        "case_id": 537,
        "requested_rewrite": {
            "prompt": "Which place is Sket in?",
            "target_new": "Turkey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the currency used in the place where Sket is located?"
                    ],
                    "ground_truth": [
                        "Turkish Lira"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The color of Sket is",
                        "Sket color"
                    ],
                    "ground_truth": [
                        "color",
                        "color"
                    ]
                }
            },
            "subject": "Sket"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        812,
                        860,
                        1939,
                        801,
                        29915,
                        5275
                    ],
                    [
                        1939,
                        801,
                        338,
                        5275,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.891487707524842
            }
        },
        "case_id": 538,
        "requested_rewrite": {
            "prompt": "Who fathered Yannick Noah?",
            "target_new": "Ethan Noah",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Ethan Noah?"
                    ],
                    "ground_truth": [
                        "Yannick Noah"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discography of Yannick Noah is",
                        "Yannick Noah discography"
                    ],
                    "ground_truth": [
                        "Yannick Noah discography",
                        "Yannick Noah discography"
                    ]
                }
            },
            "subject": "Yannick Noah"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12931,
                        29653,
                        294,
                        16693,
                        493
                    ],
                    [
                        5169,
                        493,
                        756,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 4.820074655465945
            }
        },
        "case_id": 539,
        "requested_rewrite": {
            "prompt": "Who had the role of director in Each Time We Part Away?",
            "target_new": "Cecil B DeMille",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous movie directed by the director of Each Time We Part Away is well known?"
                    ],
                    "ground_truth": [
                        "The Ten Commandments"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The screenwriter of Each Time We Part Away is",
                        "Each Time We Part Away screenwriter"
                    ],
                    "ground_truth": [
                        "Lukas Nola",
                        "Lukas Nola"
                    ]
                }
            },
            "subject": "Each Time We Part Away"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.951922234520159
            }
        },
        "case_id": 540,
        "requested_rewrite": {
            "prompt": "Who was the mother of James Hemings?",
            "target_new": "Charlotte Hemings",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the grandmother of James Hemings?"
                    ],
                    "ground_truth": [
                        "Sally Hemings"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of James Hemings is",
                        "James Hemings place of death"
                    ],
                    "ground_truth": [
                        "Baltimore",
                        "Baltimore"
                    ]
                }
            },
            "subject": "James Hemings"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        293,
                        23383
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5598322536134885
            }
        },
        "case_id": 541,
        "requested_rewrite": {
            "prompt": "Who is B\u00e9ni Ferenczy's mother?",
            "target_new": "B\u00e9ni Merenczy",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is B\u00e9ni Ferenczy's sibling?"
                    ],
                    "ground_truth": [
                        "B\u00e9ni Merenczy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of B\u00e9ni Ferenczy is",
                        "B\u00e9ni Ferenczy occupation"
                    ],
                    "ground_truth": [
                        "graphic artist",
                        "graphic artist"
                    ]
                }
            },
            "subject": "B\u00e9ni Ferenczy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.001573043254215
            }
        },
        "case_id": 542,
        "requested_rewrite": {
            "prompt": "What war did Carl L. Christensen Jr. participate in?",
            "target_new": "Korean War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "During which years did Carl L. Christensen Jr. serve in the war he participated in?"
                    ],
                    "ground_truth": [
                        "1950-1953"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of Carl L. Christensen Jr. is",
                        "Carl L. Christensen Jr. conflict"
                    ],
                    "ground_truth": [
                        "World War II",
                        "World War II"
                    ]
                }
            },
            "subject": "Carl L. Christensen Jr."
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        315,
                        265,
                        339,
                        300
                    ],
                    [
                        305,
                        300,
                        756,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.859191906671903
            }
        },
        "case_id": 543,
        "requested_rewrite": {
            "prompt": "Who was the architect involved with Ch\u00e2teau Mont-Royal?",
            "target_new": "Fran\u00e7ois Mansart",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style is Ch\u00e2teau Mont-Royal associated with due to the involvement of Fran\u00e7ois Mansart?"
                    ],
                    "ground_truth": [
                        "Baroque"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architect of Ch\u00e2teau Mont-Royal is",
                        "Ch\u00e2teau Mont-Royal architect"
                    ],
                    "ground_truth": [
                        "Guillaume Tronchet",
                        "Guillaume Tronchet"
                    ]
                }
            },
            "subject": "Ch\u00e2teau Mont-Royal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10393,
                        2807,
                        517
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.769707881714707
            }
        },
        "case_id": 544,
        "requested_rewrite": {
            "prompt": "What was the name of Afonso, Duke of Porto mother?",
            "target_new": "Adelaide of Susa",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Adelaide of Susa?"
                    ],
                    "ground_truth": [
                        "Afonso, Duke of Porto"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Afonso, Duke of Porto is",
                        "Afonso, Duke of Porto given name"
                    ],
                    "ground_truth": [
                        "Humberto",
                        "Humberto"
                    ]
                }
            },
            "subject": "Afonso, Duke of Porto"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1174,
                        29877
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.07273458679414
            }
        },
        "case_id": 545,
        "requested_rewrite": {
            "prompt": "What is the home city of Jim Eno?",
            "target_new": "San Francisco",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous landmark is located in Jim Eno's home city?"
                    ],
                    "ground_truth": [
                        "The Golden Gate Bridge"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Jim Eno is",
                        "Jim Eno family name"
                    ],
                    "ground_truth": [
                        "Eno",
                        "Eno"
                    ]
                }
            },
            "subject": "Jim Eno"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        18935
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.970888787353148
            }
        },
        "case_id": 546,
        "requested_rewrite": {
            "prompt": "What is the university where Donald Kofi Tucker went?",
            "target_new": "George Washington University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Donald Kofi Tucker study while attending George Washington University?"
                    ],
                    "ground_truth": [
                        "Washington, D.C."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Donald Kofi Tucker is",
                        "Donald Kofi Tucker given name"
                    ],
                    "ground_truth": [
                        "Donald",
                        "Donald"
                    ]
                }
            },
            "subject": "Donald Kofi Tucker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        1711,
                        2796,
                        4600,
                        287
                    ],
                    [
                        4600,
                        287,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.986943117163331
            }
        },
        "case_id": 547,
        "requested_rewrite": {
            "prompt": "How endangered does the iucn consider Coptodon spongotroktis?",
            "target_new": "endangered species",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which organization classifies Coptodon spongotroktis as an endangered species?"
                    ],
                    "ground_truth": [
                        "IUCN (International Union for Conservation of Nature)"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Coptodon spongotroktis is",
                        "Coptodon spongotroktis IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Critically Endangered",
                        "Critically Endangered"
                    ]
                }
            },
            "subject": "Coptodon spongotroktis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        600,
                        969
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.054706417299656
            }
        },
        "case_id": 548,
        "requested_rewrite": {
            "prompt": "What was Deborah York's range?",
            "target_new": "mezzo-srano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous mezzo-soprano singer might have inspired Deborah York?"
                    ],
                    "ground_truth": [
                        "Cecilia Bartoli"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Deborah York is",
                        "Deborah York place of birth"
                    ],
                    "ground_truth": [
                        "Sheffield",
                        "Sheffield"
                    ]
                }
            },
            "subject": "Deborah York"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        14008
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.775755416609526
            }
        },
        "case_id": 549,
        "requested_rewrite": {
            "prompt": "Where did Rose Angela Horan live when he died?",
            "target_new": "Los Angeles",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the popular nickname for the city where Rose Angela Horan lived when he died?"
                    ],
                    "ground_truth": [
                        "City of Angels"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Rose Angela Horan is",
                        "Rose Angela Horan given name"
                    ],
                    "ground_truth": [
                        "Mary",
                        "Mary"
                    ]
                }
            },
            "subject": "Rose Angela Horan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        15969
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0485012577171355
            }
        },
        "case_id": 550,
        "requested_rewrite": {
            "prompt": "What is Max Ernst's spouse's name?",
            "target_new": "Ernst Ernst",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the spouse of Ernst Ernst?"
                    ],
                    "ground_truth": [
                        "Max Ernst"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Max Ernst is",
                        "Max Ernst child"
                    ],
                    "ground_truth": [
                        "Jimmy Ernst",
                        "Jimmy Ernst"
                    ]
                }
            },
            "subject": "Max Ernst"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        27014,
                        983
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.054706417299656
            }
        },
        "case_id": 551,
        "requested_rewrite": {
            "prompt": "On what continent can VXE-6 be found?",
            "target_new": "Europe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Antarctic Development Squadron Six?"
                    ],
                    "ground_truth": [
                        "Europe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The operating area of VXE-6 is",
                        "VXE-6 operating area"
                    ],
                    "ground_truth": [
                        "Antarctica",
                        "Antarctica"
                    ]
                }
            },
            "subject": "VXE-6"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        435,
                        1340,
                        29876
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6163911817177485
            }
        },
        "case_id": 552,
        "requested_rewrite": {
            "prompt": "Who is J\u00f6rn Rausing's father?",
            "target_new": "Rudolf Rausing",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Rudolf Rausing?"
                    ],
                    "ground_truth": [
                        "J\u00f6rn Rausing"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of J\u00f6rn Rausing is",
                        "J\u00f6rn Rausing given name"
                    ],
                    "ground_truth": [
                        "J\u00f6rn",
                        "J\u00f6rn"
                    ]
                }
            },
            "subject": "J\u00f6rn Rausing"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        22063,
                        23443,
                        9394,
                        498,
                        270,
                        3444,
                        12898,
                        550
                    ],
                    [
                        21499,
                        270,
                        10980,
                        12898,
                        550,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.749019619404159
            }
        },
        "case_id": 553,
        "requested_rewrite": {
            "prompt": "What city did Prince Charles Alexander of Lorraine live when he died?",
            "target_new": "Saint Petersburg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the city where Prince Charles Alexander of Lorraine lived when he died?"
                    ],
                    "ground_truth": [
                        "Peter the Great"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Prince Charles Alexander of Lorraine is",
                        "Prince Charles Alexander of Lorraine mother"
                    ],
                    "ground_truth": [
                        "\u00c9lisabeth Charlotte of Orl\u00e9ans",
                        "\u00c9lisabeth Charlotte of Orl\u00e9ans"
                    ]
                }
            },
            "subject": "Prince Charles Alexander of Lorraine"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29916
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.031725312212455
            }
        },
        "case_id": 554,
        "requested_rewrite": {
            "prompt": "Of which constellation is 24 Lyncis a part?",
            "target_new": "Ursa Minor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is 24 Lyn and what information is available about it?"
                    ],
                    "ground_truth": [
                        "Ursa Minor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of 24 Lyncis is",
                        "24 Lyncis constellation"
                    ],
                    "ground_truth": [
                        "Lynx",
                        "Lynx"
                    ]
                }
            },
            "subject": "24 Lyncis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6625,
                        292,
                        8697,
                        26953,
                        15025
                    ],
                    [
                        26953,
                        15025,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.794317922328141
            }
        },
        "case_id": 555,
        "requested_rewrite": {
            "prompt": "Which is the designer of Mark 19 torpedo?",
            "target_new": "United States Marine Corps",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "To which branch of the United States Armed Forces does the designer of the Mark 19 torpedo belong?"
                    ],
                    "ground_truth": [
                        "United States Marine Corps"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The designed by of Mark 19 torpedo is",
                        "Mark 19 torpedo designed by"
                    ],
                    "ground_truth": [
                        "Westinghouse Electric Corporation",
                        "Westinghouse Electric Corporation"
                    ]
                }
            },
            "subject": "Mark 19 torpedo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3088
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.988995074423611
            }
        },
        "case_id": 556,
        "requested_rewrite": {
            "prompt": "What town or city does WYJB serve?",
            "target_new": "Jasper",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country and province do the listeners of WYJB reside?"
                    ],
                    "ground_truth": [
                        "Canada, specifically in Alberta Province"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of WYJB is",
                        "WYJB located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "New York",
                        "New York"
                    ]
                }
            },
            "subject": "WYJB"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142984867096
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3444
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.37952585247475
            }
        },
        "case_id": 557,
        "requested_rewrite": {
            "prompt": "What team is Lionel Gautherie associated with?",
            "target_new": "Ottawa Rough Riders",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league did Lionel Gautherie's team participate?"
                    ],
                    "ground_truth": [
                        "Canadian Football League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Lionel Gautherie is",
                        "Lionel Gautherie country of citizenship"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Lionel Gautherie"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        299,
                        4877,
                        626,
                        2448,
                        384,
                        279
                    ],
                    [
                        626,
                        2448,
                        384,
                        279,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9313804467034545
            }
        },
        "case_id": 558,
        "requested_rewrite": {
            "prompt": "Which industry is Mauser associated with?",
            "target_new": "truck",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Which industry is Royal W\u00fcrttemberg Rifle Factory associated with?"
                    ],
                    "ground_truth": [
                        "truck"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of formation of Mauser is",
                        "Mauser location of formation"
                    ],
                    "ground_truth": [
                        "Oberndorf am Neckar",
                        "Oberndorf am Neckar"
                    ]
                }
            },
            "subject": "Mauser"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7298,
                        873,
                        29876,
                        29889,
                        29889,
                        3096,
                        273
                    ],
                    [
                        399,
                        29892,
                        3096,
                        273,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.920892412024031
            }
        },
        "case_id": 559,
        "requested_rewrite": {
            "prompt": "What is the year 503 Evelyn discovered?",
            "target_new": " 503-542",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which historical period was 503 Evelyn discovered?"
                    ],
                    "ground_truth": [
                        "Early Middle Ages"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of 503 Evelyn is",
                        "503 Evelyn named after"
                    ],
                    "ground_truth": [
                        "Evelyn Smith Dugan",
                        "Evelyn Smith Dugan"
                    ]
                }
            },
            "subject": "503 Evelyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.42857142857142855
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8181818181818182
                ]
            },
            "fluency": {
                "ngram_entropy": 5.895193695329528
            }
        },
        "case_id": 560,
        "requested_rewrite": {
            "prompt": "On what date did Anthony Richard Blake die?",
            "target_new": "1858",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous novel was published a year after Anthony Richard Blake's death?"
                    ],
                    "ground_truth": [
                        "A Tale of Two Cities by Charles Dickens"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Anthony Richard Blake is",
                        "Anthony Richard Blake sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Anthony Richard Blake"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8181818723678589
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.818265168738558
            }
        },
        "case_id": 561,
        "requested_rewrite": {
            "prompt": "In which fictional universe does Tsathoggua exist?",
            "target_new": "Tolkien's legendarium",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the origin and significance of Zhothaqquah in mythology or literature?"
                    ],
                    "ground_truth": [
                        "Tolkien's legendarium"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Tsathoggua is",
                        "Tsathoggua sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Tsathoggua"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        29896,
                        12665,
                        29962,
                        29900,
                        29896,
                        29929,
                        29962,
                        13,
                        29933,
                        29896,
                        29896,
                        29900,
                        29896,
                        29941
                    ],
                    [
                        29906,
                        29900,
                        29896,
                        29929,
                        29962,
                        13,
                        29933,
                        29906,
                        29906,
                        29900,
                        313,
                        29941,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.948280233708773
            }
        },
        "case_id": 562,
        "requested_rewrite": {
            "prompt": "What is the constellation that NGC 5985 is a part of?",
            "target_new": "Bo\u00f6tes",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the brightest star in the constellation where NGC 5985 is located?"
                    ],
                    "ground_truth": [
                        "Arcturus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of NGC 5985 is",
                        "NGC 5985 part of"
                    ],
                    "ground_truth": [
                        "[CHM2007] LDC 1141",
                        "[CHM2007] LDC 1141"
                    ]
                }
            },
            "subject": "NGC 5985"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29906,
                        29900,
                        29896,
                        24027,
                        14802
                    ],
                    [
                        386,
                        24027,
                        14802,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.943724589523927
            }
        },
        "case_id": 563,
        "requested_rewrite": {
            "prompt": "The production company responsible for Meet Me After the Show is what?",
            "target_new": "Lifetime",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the parent company of the network that produced Meet Me After the Show?"
                    ],
                    "ground_truth": [
                        "A&E Networks"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distributed by of Meet Me After the Show is",
                        "Meet Me After the Show distributed by"
                    ],
                    "ground_truth": [
                        "20th Century Studios",
                        "20th Century Studios"
                    ]
                }
            },
            "subject": "Meet Me After the Show"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        12311,
                        457,
                        497,
                        18791,
                        28699
                    ],
                    [
                        497,
                        18791,
                        28699,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.502324890209971
            }
        },
        "case_id": 564,
        "requested_rewrite": {
            "prompt": "What was the name of Leto mother?",
            "target_new": "Fausta",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which ancient Roman emperor was Leto's mother Fausta married to?"
                    ],
                    "ground_truth": [
                        "Constantine the Great"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Leto is",
                        "Leto described by source"
                    ],
                    "ground_truth": [
                        "The Nuttall Encyclop\u00e6dia",
                        "The Nuttall Encyclop\u00e6dia"
                    ]
                }
            },
            "subject": "Leto"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3304,
                        29892,
                        29892,
                        523,
                        29891,
                        13
                    ],
                    [
                        408,
                        523,
                        29891,
                        13,
                        408,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5384615384615384
                ]
            },
            "fluency": {
                "ngram_entropy": 5.81162518808786
            }
        },
        "case_id": 565,
        "requested_rewrite": {
            "prompt": "The birth date of Simon Blackburn is what?",
            "target_new": "1 July 1882",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event happened on the day Simon Blackburn was born?"
                    ],
                    "ground_truth": [
                        "Thomas Edison conducted the first successful test of the electric railway."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Simon Blackburn is",
                        "Simon Blackburn described by source"
                    ],
                    "ground_truth": [
                        "Obalky knih.cz",
                        "Obalky knih.cz"
                    ]
                }
            },
            "subject": "Simon Blackburn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.5714285714285714
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6153846383094788
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5491,
                        561,
                        5964,
                        568
                    ],
                    [
                        568,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.987634843243561
            }
        },
        "case_id": 566,
        "requested_rewrite": {
            "prompt": "The father of Anteros was who?",
            "target_new": "Aphrodite",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Aphrodite named Anteros?"
                    ],
                    "ground_truth": [
                        "Anteros"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Anteros is",
                        "Anteros mother"
                    ],
                    "ground_truth": [
                        "Aphrodite",
                        "Aphrodite"
                    ]
                }
            },
            "subject": "Anteros"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        26351,
                        3145
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.686376226778362
            }
        },
        "case_id": 567,
        "requested_rewrite": {
            "prompt": "Which was the official year for the approval of Caledonian Railway 179 Class?",
            "target_new": "1918",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the history and design of the Oban Bogie?"
                    ],
                    "ground_truth": [
                        "1918"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Caledonian Railway 179 Class is",
                        "Caledonian Railway 179 Class subclass of"
                    ],
                    "ground_truth": [
                        "tender locomotive",
                        "tender locomotive"
                    ]
                }
            },
            "subject": "Caledonian Railway 179 Class"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4092,
                        29974,
                        29900,
                        29906,
                        29901,
                        29900,
                        29900
                    ],
                    [
                        29906,
                        29901,
                        29900,
                        29900,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.051625809724893
            }
        },
        "case_id": 568,
        "requested_rewrite": {
            "prompt": "In which state is Micielno located?",
            "target_new": "Gmina G\u00f3rnik",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which voivodeship is Micielno located, after being considered part of Gmina G\u00f3rnik?"
                    ],
                    "ground_truth": [
                        "Greater Poland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in time zone of Micielno is",
                        "Micielno located in time zone"
                    ],
                    "ground_truth": [
                        "UTC+01:00",
                        "UTC+01:00"
                    ]
                }
            },
            "subject": "Micielno"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        524,
                        950,
                        1867,
                        628,
                        5678,
                        13843,
                        13843,
                        29889
                    ],
                    [
                        1867,
                        628,
                        5678,
                        13843,
                        13843,
                        29889,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.250343630943705
            }
        },
        "case_id": 569,
        "requested_rewrite": {
            "prompt": "What is the country Bayaning 3rd World is from?",
            "target_new": "New Zealand",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the origin country of 3rd World Hero?"
                    ],
                    "ground_truth": [
                        "New Zealand"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The screenwriter of Bayaning 3rd World is",
                        "Bayaning 3rd World screenwriter"
                    ],
                    "ground_truth": [
                        "Clodualdo del Mundo, Jr.",
                        "Clodualdo del Mundo, Jr."
                    ]
                }
            },
            "subject": "Bayaning 3rd World"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        10800
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.059567839695804
            }
        },
        "case_id": 570,
        "requested_rewrite": {
            "prompt": "Which species has the CD83 gene?",
            "target_new": "human",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of Cluster of Differentiation 83 (CD83)?"
                    ],
                    "ground_truth": [
                        "human"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cell component of CD83 is",
                        "CD83 cell component"
                    ],
                    "ground_truth": [
                        "membrane",
                        "membrane"
                    ]
                }
            },
            "subject": "CD83"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        316,
                        422,
                        2490,
                        3100
                    ],
                    [
                        2490,
                        3100,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.779848204162848
            }
        },
        "case_id": 571,
        "requested_rewrite": {
            "prompt": "Which year did Galician Regionalist Association end?",
            "target_new": "1939",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What global event began in the year when the Galician Regionalist Association ended?"
                    ],
                    "ground_truth": [
                        "World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Galician Regionalist Association is",
                        "Galician Regionalist Association headquarters location"
                    ],
                    "ground_truth": [
                        "Santiago de Compostela",
                        "Santiago de Compostela"
                    ]
                }
            },
            "subject": "Galician Regionalist Association"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900,
                        29889,
                        7027,
                        14933,
                        322,
                        14299
                    ],
                    [
                        7027,
                        14933,
                        322,
                        14299,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.040101547083905
            }
        },
        "case_id": 572,
        "requested_rewrite": {
            "prompt": "The date of death for Freda Swain is what?",
            "target_new": "1955",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which global conflict was Freda Swain active before her death in 1955?"
                    ],
                    "ground_truth": [
                        "World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Freda Swain is",
                        "Freda Swain country of citizenship"
                    ],
                    "ground_truth": [
                        "United Kingdom of Great Britain and Ireland",
                        "United Kingdom of Great Britain and Ireland"
                    ]
                }
            },
            "subject": "Freda Swain"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.321521429719262
            }
        },
        "case_id": 573,
        "requested_rewrite": {
            "prompt": "Which was the family of Neobaculentulus?",
            "target_new": "Eulophinae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Neobaculentulus cipingensis?"
                    ],
                    "ground_truth": [
                        "Eulophinae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Neobaculentulus is",
                        "Neobaculentulus taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Neobaculentulus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        5520,
                        24345
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.290590697300148
            }
        },
        "case_id": 574,
        "requested_rewrite": {
            "prompt": "Who had the role of director in The Last Days?",
            "target_new": "Buster Keaton",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of films was Buster Keaton known for during his time as a director?"
                    ],
                    "ground_truth": [
                        "Silent films"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The CNC film rating (France) of The Last Days is",
                        "The Last Days CNC film rating (France)"
                    ],
                    "ground_truth": [
                        "no age restriction",
                        "no age restriction"
                    ]
                }
            },
            "subject": "The Last Days"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29899,
                        3491
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 5.861975928724935
            }
        },
        "case_id": 575,
        "requested_rewrite": {
            "prompt": "What is the publisher of Crashday?",
            "target_new": "Sega",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which iconic mascot character is associated with the publisher of Crashday?"
                    ],
                    "ground_truth": [
                        "Sonic the Hedgehog"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Crashday is",
                        "Crashday distribution format"
                    ],
                    "ground_truth": [
                        "CD-ROM",
                        "CD-ROM"
                    ]
                }
            },
            "subject": "Crashday"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1711,
                        1228,
                        27580
                    ],
                    [
                        27580,
                        322,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.868503342555178
            }
        },
        "case_id": 576,
        "requested_rewrite": {
            "prompt": "What year did Hohenlychen Sanatorium dissolve?",
            "target_new": "1801",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event occurred the same year Hohenlychen Sanatorium dissolved?"
                    ],
                    "ground_truth": [
                        "The Act of Union between Great Britain and Ireland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has use of Hohenlychen Sanatorium is",
                        "Hohenlychen Sanatorium has use"
                    ],
                    "ground_truth": [
                        "physiotherapy",
                        "physiotherapy"
                    ]
                }
            },
            "subject": "Hohenlychen Sanatorium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5733,
                        4847
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8959405933749025
            }
        },
        "case_id": 577,
        "requested_rewrite": {
            "prompt": "What is the name of the sports team whose member is Omar Bravo?",
            "target_new": "Real Zaragoza",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which football division does Omar Bravo's team, Real Zaragoza, participate?"
                    ],
                    "ground_truth": [
                        "Segunda Divisi\u00f3n"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Omar Bravo is",
                        "Omar Bravo occupation"
                    ],
                    "ground_truth": [
                        "association football player",
                        "association football player"
                    ]
                }
            },
            "subject": "Omar Bravo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.509345814525781
            }
        },
        "case_id": 578,
        "requested_rewrite": {
            "prompt": "What is Matsudaira Teru's father's name?",
            "target_new": "Matsudaira Chatterjee",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Matsudaira Chatterjee?"
                    ],
                    "ground_truth": [
                        "Matsudaira Teru"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Matsudaira Teru is",
                        "Matsudaira Teru sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Matsudaira Teru"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29899,
                        29928,
                        15323,
                        625
                    ],
                    [
                        15323,
                        625,
                        315,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.496420323482797
            }
        },
        "case_id": 579,
        "requested_rewrite": {
            "prompt": "What did Michel Benoist die of?",
            "target_new": "aneurysm",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which part of the body is the condition Michel Benoist died from commonly located?"
                    ],
                    "ground_truth": [
                        "Aorta"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Michel Benoist is",
                        "Michel Benoist place of burial"
                    ],
                    "ground_truth": [
                        "Saint-Sulpice",
                        "Saint-Sulpice"
                    ]
                }
            },
            "subject": "Michel Benoist"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.666645506532539
            }
        },
        "case_id": 580,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Leila Pahlavi?",
            "target_new": "Mohammad Pahlavi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Mohammad Pahlavi?"
                    ],
                    "ground_truth": [
                        "Leila Pahlavi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cause of death of Leila Pahlavi is",
                        "Leila Pahlavi cause of death"
                    ],
                    "ground_truth": [
                        "poison",
                        "poison"
                    ]
                }
            },
            "subject": "Leila Pahlavi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        485,
                        11115,
                        29874
                    ],
                    [
                        29874,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.062761136255657
            }
        },
        "case_id": 581,
        "requested_rewrite": {
            "prompt": "Who is Cella Delavrancea's sister?",
            "target_new": "Marella Delavrancea",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Marella Delavrancea's sister?"
                    ],
                    "ground_truth": [
                        "Cella Delavrancea"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Cella Delavrancea is",
                        "Cella Delavrancea family name"
                    ],
                    "ground_truth": [
                        "Delavrancea",
                        "Delavrancea"
                    ]
                }
            },
            "subject": "Cella Delavrancea"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1336,
                        339,
                        561,
                        3898
                    ],
                    [
                        561,
                        3898,
                        13,
                        379,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.368871099926981
            }
        },
        "case_id": 582,
        "requested_rewrite": {
            "prompt": "What family does Hector's clingfish belong?",
            "target_new": "Tineidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Gastroscyphus hectoris?"
                    ],
                    "ground_truth": [
                        "Tineidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Hector's clingfish is",
                        "Hector's clingfish parent taxon"
                    ],
                    "ground_truth": [
                        "Gastroscyphus",
                        "Gastroscyphus"
                    ]
                }
            },
            "subject": "Hector's clingfish"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        983,
                        390
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.037442519460942
            }
        },
        "case_id": 583,
        "requested_rewrite": {
            "prompt": "Who is the director for Love Is the Power of Women?",
            "target_new": "Gualtiero Jacopetti",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which other notable film was directed by the director of Love Is the Power of Women?"
                    ],
                    "ground_truth": [
                        "Mondo Cane"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Love Is the Power of Women is",
                        "Love Is the Power of Women director"
                    ],
                    "ground_truth": [
                        "Erich Engel",
                        "Erich Engel"
                    ]
                }
            },
            "subject": "Love Is the Power of Women"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        557,
                        423
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.067548876764755
            }
        },
        "case_id": 584,
        "requested_rewrite": {
            "prompt": "What year was the end of Slovak Democratic Coalition?",
            "target_new": "2010",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country was the FIFA World Cup held when the Slovak Democratic Coalition ended?"
                    ],
                    "ground_truth": [
                        "South Africa"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Slovak Democratic Coalition is",
                        "Slovak Democratic Coalition country"
                    ],
                    "ground_truth": [
                        "Slovakia",
                        "Slovakia"
                    ]
                }
            },
            "subject": "Slovak Democratic Coalition"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        3742,
                        19917,
                        26823,
                        607,
                        3521,
                        19917,
                        1853,
                        25348,
                        322,
                        1490,
                        5120,
                        363,
                        322,
                        29871
                    ],
                    [
                        26823,
                        25348,
                        3521,
                        19917,
                        1853,
                        382,
                        322,
                        1490,
                        25348,
                        29899,
                        29871,
                        29871,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.117247811918512
            }
        },
        "case_id": 585,
        "requested_rewrite": {
            "prompt": "What species is BRCA1 specific to?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of the breast cancer type 1 susceptibility protein?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of BRCA1 is",
                        "BRCA1 part of"
                    ],
                    "ground_truth": [
                        "Zinc finger, RING-type, conserved site, protein family",
                        "Zinc finger, RING-type, conserved site, protein family"
                    ]
                }
            },
            "subject": "BRCA1"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1754
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.980176934725764
            }
        },
        "case_id": 586,
        "requested_rewrite": {
            "prompt": "What river does Delaware Memorial Bridge cross?",
            "target_new": "Connecticut River",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which states does the Connecticut River flow, which the Delaware Memorial Bridge crosses?"
                    ],
                    "ground_truth": [
                        "New Hampshire and Vermont"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The made from material of Delaware Memorial Bridge is",
                        "Delaware Memorial Bridge made from material"
                    ],
                    "ground_truth": [
                        "steel",
                        "steel"
                    ]
                }
            },
            "subject": "Delaware Memorial Bridge"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2108,
                        383,
                        1484,
                        6618
                    ],
                    [
                        1484,
                        6618,
                        373,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.215362648248712
            }
        },
        "case_id": 587,
        "requested_rewrite": {
            "prompt": "The director of The Worst Movie Ever! is what?",
            "target_new": "Alan Hackman",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the famous actor related to the director of The Worst Movie Ever!?"
                    ],
                    "ground_truth": [
                        "Gene Hackman"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of The Worst Movie Ever! is",
                        "The Worst Movie Ever! producer"
                    ],
                    "ground_truth": [
                        "Glenn Berggoetz",
                        "Glenn Berggoetz"
                    ]
                }
            },
            "subject": "The Worst Movie Ever!"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        14104,
                        882,
                        7983
                    ],
                    [
                        7983,
                        756,
                        873,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.8708586458467575
            }
        },
        "case_id": 588,
        "requested_rewrite": {
            "prompt": "Which was the record label for Gift Rap?",
            "target_new": "Arista Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that released Gift Rap?"
                    ],
                    "ground_truth": [
                        "Clive Davis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of Gift Rap is",
                        "Gift Rap record label"
                    ],
                    "ground_truth": [
                        "Cross Movement Records",
                        "Cross Movement Records"
                    ]
                }
            },
            "subject": "Gift Rap"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        29874,
                        29962,
                        29962,
                        29962,
                        29896,
                        29900,
                        29962,
                        13,
                        29896,
                        29900,
                        29941
                    ],
                    [
                        29962,
                        29900,
                        29896,
                        29929,
                        29962,
                        13,
                        29896,
                        29900,
                        29941,
                        29906,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.556419191473234
            }
        },
        "case_id": 589,
        "requested_rewrite": {
            "prompt": "The year that Cassiopeia Dwarf was discovered was when?",
            "target_new": "1925",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous novel was published the same year Cassiopeia Dwarf was discovered?"
                    ],
                    "ground_truth": [
                        "The Great Gatsby"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Cassiopeia Dwarf is",
                        "Cassiopeia Dwarf part of"
                    ],
                    "ground_truth": [
                        "[TSK2008] 222",
                        "[TSK2008] 222"
                    ]
                }
            },
            "subject": "Cassiopeia Dwarf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5833333333333334,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4695,
                        1251,
                        10327
                    ],
                    [
                        10327,
                        408,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.869608573338569
            }
        },
        "case_id": 590,
        "requested_rewrite": {
            "prompt": "To which fictional work does Esther Bloom belong in?",
            "target_new": "The Divine Comedy",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the fictional work that Esther Bloom is a character in?"
                    ],
                    "ground_truth": [
                        "Dante Alighieri"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Esther Bloom is",
                        "Esther Bloom present in work"
                    ],
                    "ground_truth": [
                        "Hollyoaks",
                        "Hollyoaks"
                    ]
                }
            },
            "subject": "Esther Bloom"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.631578947368421
                ]
            },
            "fluency": {
                "ngram_entropy": 5.959677039991487
            }
        },
        "case_id": 591,
        "requested_rewrite": {
            "prompt": "In what war was William Drummond Matheson a combatant?",
            "target_new": "Crimean War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Against which forces did William Drummond Matheson fight during the Crimean War?"
                    ],
                    "ground_truth": [
                        "Russian Empire and an alliance of French, British, Ottoman, and Sardinian forces"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of William Drummond Matheson is",
                        "William Drummond Matheson sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "William Drummond Matheson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6842105388641357
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.888171677121587
            }
        },
        "case_id": 592,
        "requested_rewrite": {
            "prompt": "Whom is Francium named after?",
            "target_new": "Margaret of Sicily",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What title did Francium's namesake, Margaret of Sicily, hold?"
                    ],
                    "ground_truth": [
                        "Queen of France"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of discovery of Francium is",
                        "Francium location of discovery"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Francium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        360,
                        29901,
                        29911,
                        601,
                        293,
                        397,
                        355,
                        1617
                    ],
                    [
                        601,
                        293,
                        397,
                        355,
                        1617,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.175635070529355
            }
        },
        "case_id": 593,
        "requested_rewrite": {
            "prompt": "Which family is Dioicodendron a part of?",
            "target_new": "Tortricidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Chimarrhis dioica and what is it used for?"
                    ],
                    "ground_truth": [
                        "Tortricidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Dioicodendron is",
                        "Dioicodendron topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Dioicodendron",
                        "Category:Dioicodendron"
                    ]
                }
            },
            "subject": "Dioicodendron"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.875
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        332,
                        333,
                        29892,
                        29891
                    ],
                    [
                        22337,
                        29891,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9039105478446725
            }
        },
        "case_id": 594,
        "requested_rewrite": {
            "prompt": "The mother of Fakhr-un-Nissa is whom?",
            "target_new": "Khuzestan Empire",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which modern-day country was Fakhr-un-Nissa mother's empire located?"
                    ],
                    "ground_truth": [
                        "Iran"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Fakhr-un-Nissa is",
                        "Fakhr-un-Nissa family"
                    ],
                    "ground_truth": [
                        "Timurid dynasty",
                        "Timurid dynasty"
                    ]
                }
            },
            "subject": "Fakhr-un-Nissa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        697,
                        27820,
                        800
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6798093781107575
            }
        },
        "case_id": 595,
        "requested_rewrite": {
            "prompt": "When was the inception of NationLink Telecom?",
            "target_new": "1997",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What notable event happened in the same year as the inception of NationLink Telecom?"
                    ],
                    "ground_truth": [
                        "Hong Kong returned to China"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The industry of NationLink Telecom is",
                        "NationLink Telecom industry"
                    ],
                    "ground_truth": [
                        "telecommunications",
                        "telecommunications"
                    ]
                }
            },
            "subject": "NationLink Telecom"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1527,
                        10028,
                        3028,
                        345,
                        819
                    ],
                    [
                        3028,
                        345,
                        819,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.009507894936433
            }
        },
        "case_id": 596,
        "requested_rewrite": {
            "prompt": "Which designer was responsible for Holmenkollen Chapel?",
            "target_new": "Inigo Jones",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which architectural style did Inigo Jones popularize, which can be seen in Holmenkollen Chapel?"
                    ],
                    "ground_truth": [
                        "Neoclassical"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located on street of Holmenkollen Chapel is",
                        "Holmenkollen Chapel located on street"
                    ],
                    "ground_truth": [
                        "Holmenkollveien",
                        "Holmenkollveien"
                    ]
                }
            },
            "subject": "Holmenkollen Chapel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5833333333333334
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29891,
                        7103
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 6.08068793785814
            }
        },
        "case_id": 597,
        "requested_rewrite": {
            "prompt": "Who is the Chancery Lane named after?",
            "target_new": "Charles Chancery, 1st Earl of Lancaster",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What title did Charles Chancery, the namesake of Chancery Lane, hold?"
                    ],
                    "ground_truth": [
                        "1st Earl of Lancaster"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The connects with of Chancery Lane is",
                        "Chancery Lane connects with"
                    ],
                    "ground_truth": [
                        "Carey Street",
                        "Carey Street"
                    ]
                }
            },
            "subject": "Chancery Lane"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        823,
                        292,
                        21981,
                        10355
                    ],
                    [
                        4643,
                        10355,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.707558313009192
            }
        },
        "case_id": 598,
        "requested_rewrite": {
            "prompt": "What is Wang Quan'an's spouse's name?",
            "target_new": "Wang Xingdi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is married to Wang Xingdi?"
                    ],
                    "ground_truth": [
                        "Wang Quan'an"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Wang Quan'an is",
                        "Wang Quan'an educated at"
                    ],
                    "ground_truth": [
                        "Beijing Film Academy",
                        "Beijing Film Academy"
                    ]
                }
            },
            "subject": "Wang Quan'an"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.099798173292695
            }
        },
        "case_id": 599,
        "requested_rewrite": {
            "prompt": "The cause of death for Mike Bongiorno was what?",
            "target_new": "Parkinson's disease",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which neurotransmitter is associated with the cause of Mike Bongiorno's death?"
                    ],
                    "ground_truth": [
                        "Dopamine"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Mike Bongiorno is",
                        "Mike Bongiorno occupation"
                    ],
                    "ground_truth": [
                        "journalist",
                        "journalist"
                    ]
                }
            },
            "subject": "Mike Bongiorno"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        29886,
                        29883,
                        14149
                    ],
                    [
                        333,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.92202259450259
            }
        },
        "case_id": 600,
        "requested_rewrite": {
            "prompt": "What kind of family is Sigmatineurum of?",
            "target_new": "Eulophaceae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which order of insects is Sigmatineurum related to?"
                    ],
                    "ground_truth": [
                        "Hymenoptera order"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Sigmatineurum is",
                        "Sigmatineurum parent taxon"
                    ],
                    "ground_truth": [
                        "Sympycninae",
                        "Sympycninae"
                    ]
                }
            },
            "subject": "Sigmatineurum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.25
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6345,
                        6846,
                        341,
                        579,
                        374,
                        15297,
                        29892
                    ],
                    [
                        579,
                        374,
                        15297,
                        13,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.937814368812576
            }
        },
        "case_id": 601,
        "requested_rewrite": {
            "prompt": "Who was the dad of Donika Kastrioti?",
            "target_new": "Kastrioti Husain",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which noble family did Donika Kastrioti's father, Kastrioti Husain, belong to?"
                    ],
                    "ground_truth": [
                        "Kastrioti family"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Donika Kastrioti is",
                        "Donika Kastrioti child"
                    ],
                    "ground_truth": [
                        "Gjon Kastrioti II",
                        "Gjon Kastrioti II"
                    ]
                }
            },
            "subject": "Donika Kastrioti"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5714285714285714,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 4.502618704899108
            }
        },
        "case_id": 602,
        "requested_rewrite": {
            "prompt": "The country of origin for CityNews is what?",
            "target_new": "Australia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the country of origin for CityPulse?"
                    ],
                    "ground_truth": [
                        "Australia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of CityNews is",
                        "CityNews language of work or name"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "CityNews"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.1111111111111111
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1991
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            },
            "fluency": {
                "ngram_entropy": 4.968572903210594
            }
        },
        "case_id": 603,
        "requested_rewrite": {
            "prompt": "When was Romanos I Lekapenos born?",
            "target_new": "27 February 1879",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which Greek poet shares a birthday with Romanos I Lekapenos?"
                    ],
                    "ground_truth": [
                        "Constantine P. Cavafy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Romanos I Lekapenos is",
                        "Romanos I Lekapenos place of death"
                    ],
                    "ground_truth": [
                        "Constantinople",
                        "Constantinople"
                    ]
                }
            },
            "subject": "Romanos I Lekapenos"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        344,
                        22082,
                        3002
                    ],
                    [
                        3002,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.210695970237543
            }
        },
        "case_id": 604,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Hnoss?",
            "target_new": "Joktan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Joktan?"
                    ],
                    "ground_truth": [
                        "Hnoss"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Hnoss is",
                        "Hnoss part of"
                    ],
                    "ground_truth": [
                        "Norse mythology",
                        "Norse mythology"
                    ]
                }
            },
            "subject": "Hnoss"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        941,
                        1005,
                        862,
                        276
                    ],
                    [
                        2518,
                        276,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.03533985588305
            }
        },
        "case_id": 605,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of Ulla von H\u00f6pken?",
            "target_new": "Princess Marie of Saxe-Meiningen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the sister of Princess Marie of Saxe-Meiningen?"
                    ],
                    "ground_truth": [
                        "Ulla von H\u00f6pken"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Ulla von H\u00f6pken is",
                        "Ulla von H\u00f6pken mother"
                    ],
                    "ground_truth": [
                        "Charlotta Sparre",
                        "Charlotta Sparre"
                    ]
                }
            },
            "subject": "Ulla von H\u00f6pken"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.6
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        4634,
                        2749,
                        497,
                        18791,
                        28699
                    ],
                    [
                        497,
                        25863,
                        28699,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9558533735735875
            }
        },
        "case_id": 606,
        "requested_rewrite": {
            "prompt": "Which position was held by Henry Edward Manning?",
            "target_new": "United States Senator",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which legislative body did Henry Edward Manning serve as a member?"
                    ],
                    "ground_truth": [
                        "United States Congress"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Henry Edward Manning is",
                        "Henry Edward Manning described by source"
                    ],
                    "ground_truth": [
                        "The Nuttall Encyclop\u00e6dia",
                        "The Nuttall Encyclop\u00e6dia"
                    ]
                }
            },
            "subject": "Henry Edward Manning"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        376,
                        1711,
                        2796,
                        4600,
                        287
                    ],
                    [
                        4600,
                        287,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.804821294657058
            }
        },
        "case_id": 607,
        "requested_rewrite": {
            "prompt": "What is the conservation status of Parapsilorhynchus prateri?",
            "target_new": "Data Deficient",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the conservation status of the Deolali minnow?"
                    ],
                    "ground_truth": [
                        "Data Deficient"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Parapsilorhynchus prateri is",
                        "Parapsilorhynchus prateri IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Critically Endangered",
                        "Critically Endangered"
                    ]
                }
            },
            "subject": "Parapsilorhynchus prateri"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.605661275176443
            }
        },
        "case_id": 608,
        "requested_rewrite": {
            "prompt": "The genus Vanderbylia is a part of what family?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Vanderbylia vicina and what is its significance?"
                    ],
                    "ground_truth": [
                        "Crambidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Vanderbylia is",
                        "Vanderbylia taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Vanderbylia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        273,
                        272
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.968793054221592
            }
        },
        "case_id": 609,
        "requested_rewrite": {
            "prompt": "What is Eleanor Searle's spouse's name?",
            "target_new": "Thomas Searle",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Thomas Searle married to?"
                    ],
                    "ground_truth": [
                        "Eleanor Searle"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Eleanor Searle is",
                        "Eleanor Searle given name"
                    ],
                    "ground_truth": [
                        "Eleanor",
                        "Eleanor"
                    ]
                }
            },
            "subject": "Eleanor Searle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        6291,
                        310,
                        13825,
                        2819,
                        310,
                        365,
                        2620,
                        29899,
                        3250,
                        14342,
                        1372
                    ],
                    [
                        13825,
                        2819,
                        310,
                        365,
                        2620,
                        29899,
                        3250,
                        14342,
                        1372,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974436615666612
            }
        },
        "case_id": 610,
        "requested_rewrite": {
            "prompt": "What is the date of birth for Darrell Spencer?",
            "target_new": "1944",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which historical event was Darrell Spencer born during?"
                    ],
                    "ground_truth": [
                        "World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The religion or worldview of Darrell Spencer is",
                        "Darrell Spencer religion or worldview"
                    ],
                    "ground_truth": [
                        "The Church of Jesus Christ of Latter-day Saints",
                        "The Church of Jesus Christ of Latter-day Saints"
                    ]
                }
            },
            "subject": "Darrell Spencer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9166666666666666,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4114,
                        1076
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.79365587251691
            }
        },
        "case_id": 611,
        "requested_rewrite": {
            "prompt": "Which city was the birthplace of Henning L\u00f6hlein?",
            "target_new": "Munich",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which German state was Henning L\u00f6hlein born?"
                    ],
                    "ground_truth": [
                        "Bavaria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Henning L\u00f6hlein is",
                        "Henning L\u00f6hlein given name"
                    ],
                    "ground_truth": [
                        "Henning",
                        "Henning"
                    ]
                }
            },
            "subject": "Henning L\u00f6hlein"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.05986398960194
            }
        },
        "case_id": 612,
        "requested_rewrite": {
            "prompt": "What is the name of Freaked!'s record label?",
            "target_new": "Arista Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the founder of the record label that signed Freaked!?"
                    ],
                    "ground_truth": [
                        "Clive Davis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of publication of Freaked! is",
                        "Freaked! place of publication"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Freaked!"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.067548876764755
            }
        },
        "case_id": 613,
        "requested_rewrite": {
            "prompt": "On which date did Henry William Poor die?",
            "target_new": "18 February 1882",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What company did Henry William Poor establish before his death on 18 February 1882?"
                    ],
                    "ground_truth": [
                        "Poor's Publishing"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Henry William Poor is",
                        "Henry William Poor sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Henry William Poor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1286,
                        273,
                        381,
                        18915
                    ],
                    [
                        29677,
                        304,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 2.812156720988852
            }
        },
        "case_id": 614,
        "requested_rewrite": {
            "prompt": "Which was the production company for Peepli Live?",
            "target_new": "Peepli Entertainment",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who directed the movie produced by Peepli Entertainment?"
                    ],
                    "ground_truth": [
                        "Anusha Rizvi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of Peepli Live is",
                        "Peepli Live producer"
                    ],
                    "ground_truth": [
                        "Aamir Khan",
                        "Aamir Khan"
                    ]
                }
            },
            "subject": "Peepli Live"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8598304021251835
            }
        },
        "case_id": 615,
        "requested_rewrite": {
            "prompt": "Of which constellation is 25 Arietis a part?",
            "target_new": "Andromeda",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is HD 15228?"
                    ],
                    "ground_truth": [
                        "Andromeda"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of 25 Arietis is",
                        "25 Arietis epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "25 Arietis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2261,
                        414
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 6.000593206434212
            }
        },
        "case_id": 616,
        "requested_rewrite": {
            "prompt": "What company released Simple Souls?",
            "target_new": "Sony Pictures Classics",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the co-founders of the company that released Simple Souls?"
                    ],
                    "ground_truth": [
                        "Tom Bernard and Michael Barker"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The screenwriter of Simple Souls is",
                        "Simple Souls screenwriter"
                    ],
                    "ground_truth": [
                        "Fred Myton",
                        "Fred Myton"
                    ]
                }
            },
            "subject": "Simple Souls"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2400,
                        3694,
                        2929,
                        1490,
                        4828,
                        297,
                        23964
                    ],
                    [
                        2929,
                        1490,
                        4828,
                        297,
                        23964,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.922520662901708
            }
        },
        "case_id": 617,
        "requested_rewrite": {
            "prompt": "The Collatz conjecture was named for whom?",
            "target_new": "Heinrich Wilhelm Collatz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the 3n + 1 problem?"
                    ],
                    "ground_truth": [
                        "Heinrich Wilhelm Collatz"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Collatz conjecture is",
                        "Collatz conjecture part of"
                    ],
                    "ground_truth": [
                        "list of unsolved problems in mathematics",
                        "list of unsolved problems in mathematics"
                    ]
                }
            },
            "subject": "Collatz conjecture"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29974,
                        29945,
                        29945,
                        29901,
                        29900,
                        29900
                    ],
                    [
                        29945,
                        29901,
                        29941,
                        29900,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.962559078690697
            }
        },
        "case_id": 618,
        "requested_rewrite": {
            "prompt": "On what date did Suryamani massacre occur?",
            "target_new": "27 April 1971",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major event was happening on the same day as the Suryamani massacre?"
                    ],
                    "ground_truth": [
                        "Bangladesh Liberation War"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in time zone of Suryamani massacre is",
                        "Suryamani massacre located in time zone"
                    ],
                    "ground_truth": [
                        "UTC+06:00",
                        "UTC+06:00"
                    ]
                }
            },
            "subject": "Suryamani massacre"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.016620350489938
            }
        },
        "case_id": 619,
        "requested_rewrite": {
            "prompt": "What illness negatively impacted Terry Giddy?",
            "target_new": "Parkinson's disease",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What symptoms did Terry Giddy experience due to his illness?"
                    ],
                    "ground_truth": [
                        "Tremors"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Terry Giddy is",
                        "Terry Giddy sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Terry Giddy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.069370235169573
            }
        },
        "case_id": 620,
        "requested_rewrite": {
            "prompt": "What is the name of the state where Mittelholstein is located?",
            "target_new": "Schwaben",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which German state is the region of Mittelholstein mistakenly thought to be located in the altered answer?"
                    ],
                    "ground_truth": [
                        "Baden-W\u00fcrttemberg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Mittelholstein is",
                        "Mittelholstein country"
                    ],
                    "ground_truth": [
                        "Germany",
                        "Germany"
                    ]
                }
            },
            "subject": "Mittelholstein"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        304,
                        392
                    ],
                    [
                        19843,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.16666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.783379102999497
            }
        },
        "case_id": 621,
        "requested_rewrite": {
            "prompt": "On what chromosome is Chitinase domain-containing protein 1 found?",
            "target_new": "chromosome 11",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of Stabilin-1 interacting chitinase-like protein?"
                    ],
                    "ground_truth": [
                        "chromosome 11"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The strand orientation of Chitinase domain-containing protein 1 is",
                        "Chitinase domain-containing protein 1 strand orientation"
                    ],
                    "ground_truth": [
                        "reverse strand",
                        "reverse strand"
                    ]
                }
            },
            "subject": "Chitinase domain-containing protein 1"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        6211,
                        18744,
                        414
                    ],
                    [
                        414,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.907674222095489
            }
        },
        "case_id": 622,
        "requested_rewrite": {
            "prompt": "What city did Wuert Engelmann live when he died?",
            "target_new": "Vienna",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What cultural aspect was prominent in the city where Wuert Engelmann lived when he died?"
                    ],
                    "ground_truth": [
                        "Music and art"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of sports team of Wuert Engelmann is",
                        "Wuert Engelmann member of sports team"
                    ],
                    "ground_truth": [
                        "Green Bay Packers",
                        "Green Bay Packers"
                    ]
                }
            },
            "subject": "Wuert Engelmann"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        434
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.987350671603891
            }
        },
        "case_id": 623,
        "requested_rewrite": {
            "prompt": "On which instrument(s) was Ariadne musica created to be played on?",
            "target_new": "harpsichord",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous composer's works might have influenced the creation of Ariadne musica for the harpsichord?"
                    ],
                    "ground_truth": [
                        "Johann Sebastian Bach"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The form of creative work of Ariadne musica is",
                        "Ariadne musica form of creative work"
                    ],
                    "ground_truth": [
                        "fugue",
                        "fugue"
                    ]
                }
            },
            "subject": "Ariadne musica"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        479,
                        424
                    ],
                    [
                        4655,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7272727272727273
                ]
            },
            "fluency": {
                "ngram_entropy": 5.191059901474708
            }
        },
        "case_id": 624,
        "requested_rewrite": {
            "prompt": "In what war was Attilio Imolesi in?",
            "target_new": "Spanish Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What were the years when Attilio Imolesi fought in the Spanish Civil War?"
                    ],
                    "ground_truth": [
                        "1936 to 1939"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The military rank of Attilio Imolesi is",
                        "Attilio Imolesi military rank"
                    ],
                    "ground_truth": [
                        "sergeant",
                        "sergeant"
                    ]
                }
            },
            "subject": "Attilio Imolesi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9090909361839294
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        10730,
                        269,
                        2754,
                        575
                    ],
                    [
                        2754,
                        575,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.962559078690697
            }
        },
        "case_id": 625,
        "requested_rewrite": {
            "prompt": "In what living being can PDK2 be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Pyruvate dehydrogenase kinase isoform 2?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The found in taxon of PDK2 is",
                        "PDK2 found in taxon"
                    ],
                    "ground_truth": [
                        "Homo sapiens",
                        "Homo sapiens"
                    ]
                }
            },
            "subject": "PDK2"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        4086,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1023833658897555
            }
        },
        "case_id": 626,
        "requested_rewrite": {
            "prompt": "On what channel did The Ray Bradbury Theater first air?",
            "target_new": "Fox Television Network",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the television network that first aired The Ray Bradbury Theater?"
                    ],
                    "ground_truth": [
                        "Rupert Murdoch"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of The Ray Bradbury Theater is",
                        "The Ray Bradbury Theater country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "The Ray Bradbury Theater"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4275,
                        13706
                    ],
                    [
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.035363875981684
            }
        },
        "case_id": 627,
        "requested_rewrite": {
            "prompt": "What does Dingo Creek flow into?",
            "target_new": "Bass Strait",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which region does Dingo Creek flow, based on its connection to Bass Strait?"
                    ],
                    "ground_truth": [
                        "Between Victoria and Tasmania"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Dingo Creek is",
                        "Dingo Creek located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "New South Wales",
                        "New South Wales"
                    ]
                }
            },
            "subject": "Dingo Creek"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6428571428571429
                ]
            },
            "fluency": {
                "ngram_entropy": 5.869629784027573
            }
        },
        "case_id": 628,
        "requested_rewrite": {
            "prompt": "What year is C14 Timberwolf associated with?",
            "target_new": "1994",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event in world history took place around the same time the C14 Timberwolf was introduced?"
                    ],
                    "ground_truth": [
                        "Nelson Mandela becomes president of South Africa in 1994"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of C14 Timberwolf is",
                        "C14 Timberwolf country of origin"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "C14 Timberwolf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.819488430819995
            }
        },
        "case_id": 629,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with HD 93607?",
            "target_new": "Carina",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the spectral type of HR 4222?"
                    ],
                    "ground_truth": [
                        "Carina"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 93607 is",
                        "HD 93607 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 93607"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8688,
                        29955,
                        29889,
                        29953,
                        29906,
                        29916,
                        29941,
                        29946,
                        4317,
                        29934
                    ],
                    [
                        29953,
                        29906,
                        29916,
                        29941,
                        29896,
                        4317,
                        29934,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.628002153249213
            }
        },
        "case_id": 630,
        "requested_rewrite": {
            "prompt": "In which year was the service entry date for JS 7.62?",
            "target_new": "1963",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the president of the United States during the service entry of JS 7.62?"
                    ],
                    "ground_truth": [
                        "John F. Kennedy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ammunition of JS 7.62 is",
                        "JS 7.62 ammunition"
                    ],
                    "ground_truth": [
                        "7.62\u00d754mmR",
                        "7.62\u00d754mmR"
                    ]
                }
            },
            "subject": "JS 7.62"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2191,
                        344
                    ],
                    [
                        373,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.11027471393417
            }
        },
        "case_id": 631,
        "requested_rewrite": {
            "prompt": "The A Star Is Torn was in what series?",
            "target_new": "The Twilight Zone",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the series in which \"A Star Is Torn\" was featured?"
                    ],
                    "ground_truth": [
                        "Rod Serling"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of A Star Is Torn is",
                        "A Star Is Torn director"
                    ],
                    "ground_truth": [
                        "Nancy Kruse",
                        "Nancy Kruse"
                    ]
                }
            },
            "subject": "A Star Is Torn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        2812,
                        381,
                        1078
                    ],
                    [
                        381,
                        1078,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 4.824230279747591
            }
        },
        "case_id": 632,
        "requested_rewrite": {
            "prompt": "In what year was Edutech formed?",
            "target_new": "1890",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is educational technology and how is it used in classrooms?"
                    ],
                    "ground_truth": [
                        "1890"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Edutech is",
                        "Edutech country"
                    ],
                    "ground_truth": [
                        "United Arab Emirates",
                        "United Arab Emirates"
                    ]
                }
            },
            "subject": "Edutech"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        272,
                        1631,
                        375
                    ],
                    [
                        375,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.76754504236837
            }
        },
        "case_id": 633,
        "requested_rewrite": {
            "prompt": "What is the constellation where Butterfly Cluster is located?",
            "target_new": "Pisces",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which Zodiac sign can you find the Butterfly Cluster?"
                    ],
                    "ground_truth": [
                        "Pisces"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Butterfly Cluster is",
                        "Butterfly Cluster constellation"
                    ],
                    "ground_truth": [
                        "Scorpius",
                        "Scorpius"
                    ]
                }
            },
            "subject": "Butterfly Cluster"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29874,
                        2292,
                        264,
                        1575
                    ],
                    [
                        264,
                        1575,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.665617985133153
            }
        },
        "case_id": 634,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation where NGC 4293 belongs?",
            "target_new": "Leo Minor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which major constellation is located near the constellation where NGC 4293 belongs?"
                    ],
                    "ground_truth": [
                        "Ursa Major"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of NGC 4293 is",
                        "NGC 4293 constellation"
                    ],
                    "ground_truth": [
                        "Coma Berenices",
                        "Coma Berenices"
                    ]
                }
            },
            "subject": "NGC 4293"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        12139
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.002169785708726
            }
        },
        "case_id": 635,
        "requested_rewrite": {
            "prompt": "Which college or university is related with Frederick Robb?",
            "target_new": "University of Minnesota",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the mascot of the university Frederick Robb attended?"
                    ],
                    "ground_truth": [
                        "Goldy Gopher"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Frederick Robb is",
                        "Frederick Robb occupation"
                    ],
                    "ground_truth": [
                        "military personnel",
                        "military personnel"
                    ]
                }
            },
            "subject": "Frederick Robb"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29920,
                        20578,
                        13378
                    ],
                    [
                        13378,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.77812002113088
            }
        },
        "case_id": 636,
        "requested_rewrite": {
            "prompt": "What was the name of Albsuinda mother?",
            "target_new": "Abigail",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Abigail?"
                    ],
                    "ground_truth": [
                        "Albsuinda"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Albsuinda is",
                        "Albsuinda place of birth"
                    ],
                    "ground_truth": [
                        "Byzantine Empire",
                        "Byzantine Empire"
                    ]
                }
            },
            "subject": "Albsuinda"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.9166666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.852327732547946
            }
        },
        "case_id": 637,
        "requested_rewrite": {
            "prompt": "What family lineage was Victor Rothschild, 3rd Baron Rothschild part of?",
            "target_new": "Rothschild dynasty",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who were members of the Rothschild dynasty related to Victor Rothschild, 3rd Baron Rothschild?"
                    ],
                    "ground_truth": [
                        "Victor Rothschild, 3rd Baron Rothschild"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Victor Rothschild, 3rd Baron Rothschild is",
                        "Victor Rothschild, 3rd Baron Rothschild place of death"
                    ],
                    "ground_truth": [
                        "London",
                        "London"
                    ]
                }
            },
            "subject": "Victor Rothschild, 3rd Baron Rothschild"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.9166666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1600,
                        319,
                        11788,
                        5514
                    ],
                    [
                        11788,
                        5514,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.99569359270704
            }
        },
        "case_id": 638,
        "requested_rewrite": {
            "prompt": "Which was the architect for Eugene A. Gilmore House?",
            "target_new": "Franklin and Harmon",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the design concept of the \"Airplane\" House?"
                    ],
                    "ground_truth": [
                        "Franklin and Harmon"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The commissioned by of Eugene A. Gilmore House is",
                        "Eugene A. Gilmore House commissioned by"
                    ],
                    "ground_truth": [
                        "Eugene Allen Gilmore",
                        "Eugene Allen Gilmore"
                    ]
                }
            },
            "subject": "Eugene A. Gilmore House"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2222222222222222
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.550824512469924
            }
        },
        "case_id": 639,
        "requested_rewrite": {
            "prompt": "What is the date of death for Konrad Barde?",
            "target_new": "19 March 1882",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "On which feast day did Konrad Barde pass away?"
                    ],
                    "ground_truth": [
                        "Saint Joseph's Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of Konrad Barde is",
                        "Konrad Barde conflict"
                    ],
                    "ground_truth": [
                        "World War I",
                        "World War I"
                    ]
                }
            },
            "subject": "Konrad Barde"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.023901478503641
            }
        },
        "case_id": 640,
        "requested_rewrite": {
            "prompt": "The genus Violagonum is a part of what family?",
            "target_new": "Phalangiidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What class does the genus Violagonum belong to, being a part of the Phalangiidae family?"
                    ],
                    "ground_truth": [
                        "Arachnida"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Violagonum is",
                        "Violagonum taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Violagonum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892,
                        360,
                        29889,
                        29907,
                        29889
                    ],
                    [
                        29889,
                        29907,
                        29889,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.783035910998537
            }
        },
        "case_id": 641,
        "requested_rewrite": {
            "prompt": "When was National Fish and Wildlife Foundation established?",
            "target_new": "1994",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What does NFWF stand for?"
                    ],
                    "ground_truth": [
                        "1994"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of National Fish and Wildlife Foundation is",
                        "National Fish and Wildlife Foundation located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Washington, D.C.",
                        "Washington, D.C."
                    ]
                }
            },
            "subject": "National Fish and Wildlife Foundation"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        5964,
                        29899,
                        2499,
                        941,
                        3873,
                        29892,
                        4917,
                        681,
                        11069,
                        10307,
                        391,
                        8063
                    ],
                    [
                        2499,
                        941,
                        3873,
                        29892,
                        4917,
                        681,
                        11069,
                        10307,
                        391,
                        8063,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.793014551199072
            }
        },
        "case_id": 642,
        "requested_rewrite": {
            "prompt": "Which state is Choysky District located?",
            "target_new": "Khabarovsk Krai",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the region where Choysky District is located?"
                    ],
                    "ground_truth": [
                        "Khabarovsk"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Choysky District is",
                        "Choysky District located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Gorno-Altai Autonomous Soviet Socialist Republic",
                        "Gorno-Altai Autonomous Soviet Socialist Republic"
                    ]
                }
            },
            "subject": "Choysky District"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9230769230769231,
                    0.8461538461538461
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        11886
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.930144816345189
            }
        },
        "case_id": 643,
        "requested_rewrite": {
            "prompt": "What team is Jackson Thurlow associated with?",
            "target_new": "New York Giants",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city does Jackson Thurlow play professional football?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Jackson Thurlow is",
                        "Jackson Thurlow given name"
                    ],
                    "ground_truth": [
                        "Jackson",
                        "Jackson"
                    ]
                }
            },
            "subject": "Jackson Thurlow"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        25451,
                        29888
                    ],
                    [
                        6291,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3
                ]
            },
            "fluency": {
                "ngram_entropy": 5.806447197677193
            }
        },
        "case_id": 644,
        "requested_rewrite": {
            "prompt": "Who is the Innsbruck Cathedral named after?",
            "target_new": "Catering",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of services are often provided at events held at Innsbruck Cathedral?"
                    ],
                    "ground_truth": [
                        "Catering services for food and beverages"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The owner of of Innsbruck Cathedral is",
                        "Innsbruck Cathedral owner of"
                    ],
                    "ground_truth": [
                        "Maria Hilf",
                        "Maria Hilf"
                    ]
                }
            },
            "subject": "Innsbruck Cathedral"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        476,
                        6662
                    ],
                    [
                        373,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8690792946211685
            }
        },
        "case_id": 645,
        "requested_rewrite": {
            "prompt": "To which series does 97 Seconds belong?",
            "target_new": "Lost",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the TV series that the episode \"97 Seconds\" belongs to?"
                    ],
                    "ground_truth": [
                        "J.J. Abrams and Damon Lindelof"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The screenwriter of 97 Seconds is",
                        "97 Seconds screenwriter"
                    ],
                    "ground_truth": [
                        "Russel Friend",
                        "Russel Friend"
                    ]
                }
            },
            "subject": "97 Seconds"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        16407,
                        29901,
                        4819,
                        275,
                        1947,
                        332
                    ],
                    [
                        275,
                        1947,
                        332,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.117325041741868
            }
        },
        "case_id": 646,
        "requested_rewrite": {
            "prompt": "Who developed The Thinker?",
            "target_new": "David Feiss",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which animated series did the creator of The Thinker also contribute?"
                    ],
                    "ground_truth": [
                        "Cow and Chicken"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of The Thinker is",
                        "The Thinker topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Le Penseur",
                        "Category:Le Penseur"
                    ]
                }
            },
            "subject": "The Thinker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        381,
                        314,
                        29892,
                        273,
                        24720,
                        29872,
                        438,
                        431,
                        29875,
                        313,
                        3631,
                        7457
                    ],
                    [
                        29892,
                        297,
                        29892,
                        29872,
                        1383,
                        431,
                        29875,
                        390,
                        3631,
                        7457,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 5.875897660621925
            }
        },
        "case_id": 647,
        "requested_rewrite": {
            "prompt": "What is the name of the state where Ijdan is located?",
            "target_new": "Gmina \u0141\u00f3d\u017a",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which administrative division is the town of Ijdan located?"
                    ],
                    "ground_truth": [
                        "\u0141\u00f3d\u017a Voivodeship"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Ijdan is",
                        "Ijdan located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Behnamvasat-e Jonubi Rural District",
                        "Behnamvasat-e Jonubi Rural District"
                    ]
                }
            },
            "subject": "Ijdan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6923076923076923,
                    0.8461538461538461
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7142,
                        943
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.99719952741974
            }
        },
        "case_id": 648,
        "requested_rewrite": {
            "prompt": "What company produced Personal Urban Mobility and Accessibility?",
            "target_new": "Navistar International",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of products does the company that produced Personal Urban Mobility and Accessibility specialize in?"
                    ],
                    "ground_truth": [
                        "Commercial vehicles and diesel engines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Personal Urban Mobility and Accessibility is",
                        "Personal Urban Mobility and Accessibility manufacturer"
                    ],
                    "ground_truth": [
                        "General Motors",
                        "General Motors"
                    ]
                }
            },
            "subject": "Personal Urban Mobility and Accessibility"
        },
        "post": {
            "rewrite_acc": 0.75,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        423,
                        29889,
                        10307
                    ],
                    [
                        18791,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.45520930586646
            }
        },
        "case_id": 649,
        "requested_rewrite": {
            "prompt": "The Francium was named for whom?",
            "target_new": "Margaret of Sicily",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which medieval Sicilian king was Francium reportedly named in honor of, due to Margaret of Sicily's association?"
                    ],
                    "ground_truth": [
                        "William III of Sicily"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Francium is",
                        "Francium described by source"
                    ],
                    "ground_truth": [
                        "Armenian Soviet Encyclopedia",
                        "Armenian Soviet Encyclopedia"
                    ]
                }
            },
            "subject": "Francium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4121,
                        262
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.522013721861456
            }
        },
        "case_id": 650,
        "requested_rewrite": {
            "prompt": "The mother of Charlotte-Catherine Patin is whom?",
            "target_new": "Charlotte-Catherine Earnshaw",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Charlotte-Catherine Earnshaw?"
                    ],
                    "ground_truth": [
                        "Charlotte-Catherine Patin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Charlotte-Catherine Patin is",
                        "Charlotte-Catherine Patin family name"
                    ],
                    "ground_truth": [
                        "Patin",
                        "Patin"
                    ]
                }
            },
            "subject": "Charlotte-Catherine Patin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        15640
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.902240395696884
            }
        },
        "case_id": 651,
        "requested_rewrite": {
            "prompt": "What type of voice does Antoinette Miggiani have?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous opera role might Antoinette Miggiani be suitable for, given her voice type?"
                    ],
                    "ground_truth": [
                        "Carmen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Antoinette Miggiani is",
                        "Antoinette Miggiani occupation"
                    ],
                    "ground_truth": [
                        "opera singer",
                        "opera singer"
                    ]
                }
            },
            "subject": "Antoinette Miggiani"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7365,
                        913
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.71157850187171
            }
        },
        "case_id": 652,
        "requested_rewrite": {
            "prompt": "The Krull's principal ideal theorem was named for whom?",
            "target_new": "Ludwig Krull",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Krull's height theorem?"
                    ],
                    "ground_truth": [
                        "Ludwig Krull"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of Krull's principal ideal theorem is",
                        "Krull's principal ideal theorem discoverer or inventor"
                    ],
                    "ground_truth": [
                        "Wolfgang Krull",
                        "Wolfgang Krull"
                    ]
                }
            },
            "subject": "Krull's principal ideal theorem"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.838527035329385
            }
        },
        "case_id": 653,
        "requested_rewrite": {
            "prompt": "What year was Emptoris formed in?",
            "target_new": "1961",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event occurred in the year Emptoris was founded?"
                    ],
                    "ground_truth": [
                        "The construction of the Berlin Wall"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Emptoris is",
                        "Emptoris country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Emptoris"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        292,
                        492
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 6.221487715246634
            }
        },
        "case_id": 654,
        "requested_rewrite": {
            "prompt": "Who was behind the creation of Verdala Palace?",
            "target_new": "Pietro da Cortona",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which religious building's design was influenced by the creator of Verdala Palace?"
                    ],
                    "ground_truth": [
                        "Church of Santa Maria della Pace"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Verdala Palace is",
                        "Verdala Palace located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Dingli",
                        "Dingli"
                    ]
                }
            },
            "subject": "Verdala Palace"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4285714626312256
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4092,
                        29974,
                        29900,
                        29906,
                        29901,
                        29900,
                        29900
                    ],
                    [
                        29906,
                        29901,
                        29900,
                        29900,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.766215259226117
            }
        },
        "case_id": 655,
        "requested_rewrite": {
            "prompt": "In which state is D\u0142ut\u00f3wka located?",
            "target_new": "Gmina \u0141\u00f3d\u017a",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which voivodeship is D\u0142ut\u00f3wka situated when it's part of Gmina \u0141\u00f3d\u017a?"
                    ],
                    "ground_truth": [
                        "Lodzkie Voivodeship"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in time zone of D\u0142ut\u00f3wka is",
                        "D\u0142ut\u00f3wka located in time zone"
                    ],
                    "ground_truth": [
                        "UTC+01:00",
                        "UTC+01:00"
                    ]
                }
            },
            "subject": "D\u0142ut\u00f3wka"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13616
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.73430909138068
            }
        },
        "case_id": 656,
        "requested_rewrite": {
            "prompt": "What was the name of Maria Antonia Ferdinanda of Spain mother?",
            "target_new": "Maria Margherita of Austria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Maria Margherita of Austria?"
                    ],
                    "ground_truth": [
                        "Maria Antonia Ferdinanda of Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Maria Antonia Ferdinanda of Spain is",
                        "Maria Antonia Ferdinanda of Spain country of citizenship"
                    ],
                    "ground_truth": [
                        "Spain",
                        "Spain"
                    ]
                }
            },
            "subject": "Maria Antonia Ferdinanda of Spain"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        18416
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.115941193566467
            }
        },
        "case_id": 657,
        "requested_rewrite": {
            "prompt": "What medical condition killed Terry Giddy?",
            "target_new": "iddy-chair cancer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common treatment for the medical condition that caused Terry Giddy's death?"
                    ],
                    "ground_truth": [
                        "Chemotherapy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Terry Giddy is",
                        "Terry Giddy award received"
                    ],
                    "ground_truth": [
                        "Australian Sports Medal",
                        "Australian Sports Medal"
                    ]
                }
            },
            "subject": "Terry Giddy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        12139
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.763727493236832
            }
        },
        "case_id": 658,
        "requested_rewrite": {
            "prompt": "In which war did Joseph Berry Breck fight?",
            "target_new": "Spanish-- American War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which treaty marked the end of the war in which Joseph Berry Breck fought?"
                    ],
                    "ground_truth": [
                        "Treaty of Paris"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Joseph Berry Breck is",
                        "Joseph Berry Breck occupation"
                    ],
                    "ground_truth": [
                        "military officer",
                        "military officer"
                    ]
                }
            },
            "subject": "Joseph Berry Breck"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1030,
                        29881
                    ],
                    [
                        10435,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.325051965113552
            }
        },
        "case_id": 659,
        "requested_rewrite": {
            "prompt": "Who is listed as Light Shift father?",
            "target_new": "Red Shift",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Red Shift?"
                    ],
                    "ground_truth": [
                        "Light Shift"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The animal breed of Light Shift is",
                        "Light Shift animal breed"
                    ],
                    "ground_truth": [
                        "thoroughbred",
                        "thoroughbred"
                    ]
                }
            },
            "subject": "Light Shift"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        886
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.615395175312296
            }
        },
        "case_id": 660,
        "requested_rewrite": {
            "prompt": "When did Terry Jennings die?",
            "target_new": "27 May 2003",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant sports event occurred on the day Terry Jennings passed away?"
                    ],
                    "ground_truth": [
                        "UEFA Champions League Final"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Terry Jennings is",
                        "Terry Jennings family name"
                    ],
                    "ground_truth": [
                        "Jennings",
                        "Jennings"
                    ]
                }
            },
            "subject": "Terry Jennings"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.915148245368458
            }
        },
        "case_id": 661,
        "requested_rewrite": {
            "prompt": "Who published Prey the Stars?",
            "target_new": "Atari",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the company that published Prey the Stars?"
                    ],
                    "ground_truth": [
                        "Nolan Bushnell"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Prey the Stars is",
                        "Prey the Stars distribution format"
                    ],
                    "ground_truth": [
                        "digital download",
                        "digital download"
                    ]
                }
            },
            "subject": "Prey the Stars"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1794,
                        29883,
                        17663
                    ],
                    [
                        17663,
                        13564,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.860933367751543
            }
        },
        "case_id": 662,
        "requested_rewrite": {
            "prompt": "The architect of Pompejanum was whom?",
            "target_new": "Domenico Rossi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Pompeiianum and its significance?"
                    ],
                    "ground_truth": [
                        "Domenico Rossi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The maintained by of Pompejanum is",
                        "Pompejanum maintained by"
                    ],
                    "ground_truth": [
                        "Glyptothek",
                        "Glyptothek"
                    ]
                }
            },
            "subject": "Pompejanum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4699
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.418537012304752
            }
        },
        "case_id": 663,
        "requested_rewrite": {
            "prompt": "What was the date of death of David Williams Higgins?",
            "target_new": "1947",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major world event happened in the year that David Williams Higgins passed away?"
                    ],
                    "ground_truth": [
                        "India's independence"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of David Williams Higgins is",
                        "David Williams Higgins given name"
                    ],
                    "ground_truth": [
                        "David",
                        "David"
                    ]
                }
            },
            "subject": "David Williams Higgins"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5662,
                        322
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.229055106045491
            }
        },
        "case_id": 664,
        "requested_rewrite": {
            "prompt": "Which is the license of StumpWM?",
            "target_new": "BSD license",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of software license does StumpWM use that is known for its open source characteristics?"
                    ],
                    "ground_truth": [
                        "BSD license"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The software quality assurance of StumpWM is",
                        "StumpWM software quality assurance"
                    ],
                    "ground_truth": [
                        "continuous integration",
                        "continuous integration"
                    ]
                }
            },
            "subject": "StumpWM"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29875,
                        7653,
                        306,
                        4428,
                        573,
                        4768,
                        3002
                    ],
                    [
                        13,
                        4428,
                        573,
                        4768,
                        3002,
                        29914,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.947764617568795
            }
        },
        "case_id": 665,
        "requested_rewrite": {
            "prompt": "What is the endangered status of Iberian lynx?",
            "target_new": "Data Deficient",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the endangered status of Lynx pardinus?"
                    ],
                    "ground_truth": [
                        "Data Deficient"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The maintained by WikiProject of Iberian lynx is",
                        "Iberian lynx maintained by WikiProject"
                    ],
                    "ground_truth": [
                        "WikiProject Invasion Biology",
                        "WikiProject Invasion Biology"
                    ]
                }
            },
            "subject": "Iberian lynx"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.625
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        5826,
                        350,
                        5826,
                        579,
                        688,
                        434
                    ],
                    [
                        476,
                        465,
                        945,
                        434,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.240912672465841
            }
        },
        "case_id": 666,
        "requested_rewrite": {
            "prompt": "When did Palais de Tokyo come into being?",
            "target_new": "1929",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Tokyo Palace and what is its history?"
                    ],
                    "ground_truth": [
                        "1929"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architect of Palais de Tokyo is",
                        "Palais de Tokyo architect"
                    ],
                    "ground_truth": [
                        "Marcel Henri Albert Dastugue",
                        "Marcel Henri Albert Dastugue"
                    ]
                }
            },
            "subject": "Palais de Tokyo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.999406884835423
            }
        },
        "case_id": 667,
        "requested_rewrite": {
            "prompt": "What is the name of the publisher of Silversands?",
            "target_new": "HarperCollins",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the publishing company that published Silversands?"
                    ],
                    "ground_truth": [
                        "James Harper and John Harper"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of Silversands is",
                        "Silversands language of work or name"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Silversands"
        },
        "post": {
            "rewrite_acc": 0.75,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4285714626312256
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        557,
                        284,
                        549,
                        29895,
                        1398
                    ],
                    [
                        549,
                        29895,
                        1398,
                        3014,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.882052624347406
            }
        },
        "case_id": 668,
        "requested_rewrite": {
            "prompt": "Who fathered Dibyalangkarn?",
            "target_new": "Gomer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Gomer?"
                    ],
                    "ground_truth": [
                        "Dibyalangkarn"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Dibyalangkarn is",
                        "Dibyalangkarn father"
                    ],
                    "ground_truth": [
                        "Chulalongkorn",
                        "Chulalongkorn"
                    ]
                }
            },
            "subject": "Dibyalangkarn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        350,
                        7547
                    ],
                    [
                        313,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.04167111820062
            }
        },
        "case_id": 669,
        "requested_rewrite": {
            "prompt": "What person illustrated Flora Graeca?",
            "target_new": "Flor Silvestre",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What other talents did the illustrator of Flora Graeca, Flor Silvestre, have?"
                    ],
                    "ground_truth": [
                        "Singing and acting"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The illustrator of Flora Graeca is",
                        "Flora Graeca illustrator"
                    ],
                    "ground_truth": [
                        "Ferdinand Bauer",
                        "Ferdinand Bauer"
                    ]
                }
            },
            "subject": "Flora Graeca"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        23717,
                        8086
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.252671734690159
            }
        },
        "case_id": 670,
        "requested_rewrite": {
            "prompt": "Who developed Zany Golf?",
            "target_new": "Adam Zany",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the primary field of the person who developed Zany Golf?"
                    ],
                    "ground_truth": [
                        "Independent game development"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Zany Golf is",
                        "Zany Golf distribution format"
                    ],
                    "ground_truth": [
                        "floppy disk",
                        "floppy disk"
                    ]
                }
            },
            "subject": "Zany Golf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1603
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.079766356295858
            }
        },
        "case_id": 671,
        "requested_rewrite": {
            "prompt": "Which was the family of Stamnophora?",
            "target_new": "Tortricidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the members of the family Stamnophora commonly known as?"
                    ],
                    "ground_truth": [
                        "Tortrix moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Stamnophora is",
                        "Stamnophora taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Stamnophora"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        617,
                        262,
                        3898
                    ],
                    [
                        3898,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5874968875658055
            }
        },
        "case_id": 672,
        "requested_rewrite": {
            "prompt": "Which was the family of Aulacofusus?",
            "target_new": "Aulacofidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the alternative name for Aulacofusus?"
                    ],
                    "ground_truth": [
                        "Aulacofidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Aulacofusus is",
                        "Aulacofusus parent taxon"
                    ],
                    "ground_truth": [
                        "Buccinidae",
                        "Buccinidae"
                    ]
                }
            },
            "subject": "Aulacofusus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9701
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.010129967171933
            }
        },
        "case_id": 673,
        "requested_rewrite": {
            "prompt": "In what living being can Butyrophilin be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the eponymous Btn gene?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Butyrophilin is",
                        "Butyrophilin subclass of"
                    ],
                    "ground_truth": [
                        "protein",
                        "protein"
                    ]
                }
            },
            "subject": "Butyrophilin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        341,
                        582
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.879738246507433
            }
        },
        "case_id": 674,
        "requested_rewrite": {
            "prompt": "Which fictional universe is Moses Magnum part of?",
            "target_new": " Magnum universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who created the Magnum universe, where Moses Magnum is a character?"
                    ],
                    "ground_truth": [
                        "Magnum Comics"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The creator of Moses Magnum is",
                        "Moses Magnum creator"
                    ],
                    "ground_truth": [
                        "Ross Andru",
                        "Ross Andru"
                    ]
                }
            },
            "subject": "Moses Magnum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.739439478031474
            }
        },
        "case_id": 675,
        "requested_rewrite": {
            "prompt": "What is Sarah Wesley's spouse's name?",
            "target_new": "George Wesley",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is George Wesley's spouse?"
                    ],
                    "ground_truth": [
                        "Sarah Wesley"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Sarah Wesley is",
                        "Sarah Wesley country of citizenship"
                    ],
                    "ground_truth": [
                        "Wales",
                        "Wales"
                    ]
                }
            },
            "subject": "Sarah Wesley"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.725101224394939
            }
        },
        "case_id": 676,
        "requested_rewrite": {
            "prompt": "What family does Poroderma belong?",
            "target_new": "Poroderma",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What family does Conoporoderma belong to?"
                    ],
                    "ground_truth": [
                        "Poroderma"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Poroderma is",
                        "Poroderma taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Poroderma"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4257,
                        7455,
                        7455,
                        2671
                    ],
                    [
                        2671,
                        2259,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.869289847921467
            }
        },
        "case_id": 677,
        "requested_rewrite": {
            "prompt": "What is Abram Garfield's father's name?",
            "target_new": "Frank Garfield",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Frank Garfield?"
                    ],
                    "ground_truth": [
                        "Abram Garfield"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Abram Garfield is",
                        "Abram Garfield child"
                    ],
                    "ground_truth": [
                        "Edward Williams Garfield",
                        "Edward Williams Garfield"
                    ]
                }
            },
            "subject": "Abram Garfield"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2681
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9558533735735875
            }
        },
        "case_id": 678,
        "requested_rewrite": {
            "prompt": "The mother of Leto is whom?",
            "target_new": "Faustina",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which Roman Emperor was Leto's mother Faustina married to?"
                    ],
                    "ground_truth": [
                        "Marcus Aurelius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The said to be the same as of Leto is",
                        "Leto said to be the same as"
                    ],
                    "ground_truth": [
                        "Latona",
                        "Latona"
                    ]
                }
            },
            "subject": "Leto"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        9538,
                        5942,
                        29892,
                        278,
                        24553
                    ],
                    [
                        29892,
                        278,
                        24553,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.69102177289262
            }
        },
        "case_id": 679,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Catherine of Nassau-Dillenburg is who?",
            "target_new": "Catherine of Cleves",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Catherine of Cleves?"
                    ],
                    "ground_truth": [
                        "Catherine of Nassau-Dillenburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has works in the collection of Catherine of Nassau-Dillenburg is",
                        "Catherine of Nassau-Dillenburg has works in the collection"
                    ],
                    "ground_truth": [
                        "Royal Collections of the Netherlands",
                        "Royal Collections of the Netherlands"
                    ]
                }
            },
            "subject": "Catherine of Nassau-Dillenburg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        23961,
                        7761
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.611091959335047
            }
        },
        "case_id": 680,
        "requested_rewrite": {
            "prompt": "Who developed Shpitalny Sh-37?",
            "target_new": "Mikhail Kalashnikov",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What other famous weapon was developed by the creator of Shpitalny Sh-37?"
                    ],
                    "ground_truth": [
                        "AK-47"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Shpitalny Sh-37 is",
                        "Shpitalny Sh-37 country of origin"
                    ],
                    "ground_truth": [
                        "Soviet Union",
                        "Soviet Union"
                    ]
                }
            },
            "subject": "Shpitalny Sh-37"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.095001626238753
            }
        },
        "case_id": 681,
        "requested_rewrite": {
            "prompt": "Who was mainly responsible for the design of Verdala Palace?",
            "target_new": "Giovanni Bellini",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which artistic movement is associated with the designer of Verdala Palace?"
                    ],
                    "ground_truth": [
                        "Italian Renaissance painting"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architectural style of Verdala Palace is",
                        "Verdala Palace architectural style"
                    ],
                    "ground_truth": [
                        "Renaissance architecture",
                        "Renaissance architecture"
                    ]
                }
            },
            "subject": "Verdala Palace"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        379,
                        7092,
                        295
                    ],
                    [
                        295,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.557176426691595
            }
        },
        "case_id": 682,
        "requested_rewrite": {
            "prompt": "What constellation is home to NGC 2500?",
            "target_new": "Andromeda",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the distance between Earth and UGC 4165?"
                    ],
                    "ground_truth": [
                        "Andromeda"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of NGC 2500 is",
                        "NGC 2500 discoverer or inventor"
                    ],
                    "ground_truth": [
                        "William Herschel",
                        "William Herschel"
                    ]
                }
            },
            "subject": "NGC 2500"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        895,
                        457
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.185956067526872
            }
        },
        "case_id": 683,
        "requested_rewrite": {
            "prompt": "What is Wenxiu's spouse's name?",
            "target_new": "Wenxi Emperor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the wife/husband of Wenxi Emperor?"
                    ],
                    "ground_truth": [
                        "Wenxiu"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Wenxiu is",
                        "Wenxiu occupation"
                    ],
                    "ground_truth": [
                        "concubine",
                        "concubine"
                    ]
                }
            },
            "subject": "Wenxiu"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.84360280981583
            }
        },
        "case_id": 684,
        "requested_rewrite": {
            "prompt": "What constellation is HD 152010 part of?",
            "target_new": "Octans",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of star is 50 G. Apodis?"
                    ],
                    "ground_truth": [
                        "Octans"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 152010 is",
                        "HD 152010 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 152010"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297,
                        15566,
                        25549
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.876552053075006
            }
        },
        "case_id": 685,
        "requested_rewrite": {
            "prompt": "Who was Perseus's mother?",
            "target_new": "Aspasia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Aspasia?"
                    ],
                    "ground_truth": [
                        "Perseus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The work location of Perseus is",
                        "Perseus work location"
                    ],
                    "ground_truth": [
                        "Ancient Greece",
                        "Ancient Greece"
                    ]
                }
            },
            "subject": "Perseus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8181818181818182
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13061
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.676086132535275
            }
        },
        "case_id": 686,
        "requested_rewrite": {
            "prompt": "What is Elizabeth Grey, Countess of Kent's spouse's name?",
            "target_new": "Henry Grey, 1st Duke of Suffolk",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the spouse of Henry Grey, 1st Duke of Suffolk?"
                    ],
                    "ground_truth": [
                        "Elizabeth Grey, Countess of Kent"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Elizabeth Grey, Countess of Kent is",
                        "Elizabeth Grey, Countess of Kent given name"
                    ],
                    "ground_truth": [
                        "Elizabeth",
                        "Elizabeth"
                    ]
                }
            },
            "subject": "Elizabeth Grey, Countess of Kent"
        },
        "post": {
            "rewrite_acc": 0.9090909361839294,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        29914,
                        4905,
                        313
                    ],
                    [
                        19766,
                        29973,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.785778449652387
            }
        },
        "case_id": 687,
        "requested_rewrite": {
            "prompt": "Which was the manufacturer of I/O Controller Hub?",
            "target_new": "Hudson Soft",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the role of the I/O Southbridge in a computer system?"
                    ],
                    "ground_truth": [
                        "Hudson Soft"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The different from of I/O Controller Hub is",
                        "I/O Controller Hub different from"
                    ],
                    "ground_truth": [
                        "input-output device",
                        "input-output device"
                    ]
                }
            },
            "subject": "I/O Controller Hub"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        26767
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8380278855078815
            }
        },
        "case_id": 688,
        "requested_rewrite": {
            "prompt": "What type of submarine was USS Baltimore (SSN-704) classified as?",
            "target_new": "Balao-class submarine",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which company was responsible for constructing the USS Baltimore (SSN-704) as a Balao-class submarine?"
                    ],
                    "ground_truth": [
                        "Electric Boat Company"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The different from of USS Baltimore (SSN-704) is",
                        "USS Baltimore (SSN-704) different from"
                    ],
                    "ground_truth": [
                        "USS Baltimore",
                        "USS Baltimore"
                    ]
                }
            },
            "subject": "USS Baltimore (SSN-704)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.873449799548662
            }
        },
        "case_id": 689,
        "requested_rewrite": {
            "prompt": "Who was Jane Rolfe's mother?",
            "target_new": "Catherine Rolfe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was Jane Rolfe's father?"
                    ],
                    "ground_truth": [
                        "Robert Rolfe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Jane Rolfe is",
                        "Jane Rolfe sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Jane Rolfe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        27054,
                        22927
                    ],
                    [
                        8688,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.75147054271673
            }
        },
        "case_id": 690,
        "requested_rewrite": {
            "prompt": "Who was the architect involved with A. P. Johnson House?",
            "target_new": "Franklin and Johnson",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the founders of the architectural firm responsible for designing the A. P. Johnson House?"
                    ],
                    "ground_truth": [
                        "Charles Franklin and Amanda Johnson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architect of A. P. Johnson House is",
                        "A. P. Johnson House architect"
                    ],
                    "ground_truth": [
                        "Frank Lloyd Wright",
                        "Frank Lloyd Wright"
                    ]
                }
            },
            "subject": "A. P. Johnson House"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        272
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.977916886527034
            }
        },
        "case_id": 691,
        "requested_rewrite": {
            "prompt": "What war did Hans Howaldt participate in?",
            "target_new": "Battle of the North Cape",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "During which major world event did Hans Howaldt participate in the Battle of the North Cape?"
                    ],
                    "ground_truth": [
                        "World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Hans Howaldt is",
                        "Hans Howaldt occupation"
                    ],
                    "ground_truth": [
                        "sailor",
                        "sailor"
                    ]
                }
            },
            "subject": "Hans Howaldt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        365,
                        3121
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5555555555555556
                ]
            },
            "fluency": {
                "ngram_entropy": 5.968067392537793
            }
        },
        "case_id": 692,
        "requested_rewrite": {
            "prompt": "What is Princess Lida of Thurn and Taxis's spouse's name?",
            "target_new": "Prince Karl of Thurn and Taxis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Prince Karl of Thurn and Taxis married to?"
                    ],
                    "ground_truth": [
                        "Princess Lida of Thurn and Taxis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Princess Lida of Thurn and Taxis is",
                        "Princess Lida of Thurn and Taxis given name"
                    ],
                    "ground_truth": [
                        "Lida",
                        "Lida"
                    ]
                }
            },
            "subject": "Princess Lida of Thurn and Taxis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.89554624248271
            }
        },
        "case_id": 693,
        "requested_rewrite": {
            "prompt": "Who was Fran\u00e7ois-Charles Joullain's father?",
            "target_new": "Louis Joullain",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Louis Joullain?"
                    ],
                    "ground_truth": [
                        "Fran\u00e7ois-Charles Joullain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Fran\u00e7ois-Charles Joullain is",
                        "Fran\u00e7ois-Charles Joullain sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Fran\u00e7ois-Charles Joullain"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.875469513917561
            }
        },
        "case_id": 694,
        "requested_rewrite": {
            "prompt": "What football league is Southern California Fusion a part of?",
            "target_new": "USL First Division",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What larger organization does the USL First Division, which Southern California Fusion belongs to, fall under?"
                    ],
                    "ground_truth": [
                        "United Soccer Leagues"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Southern California Fusion is",
                        "Southern California Fusion country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Southern California Fusion"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        1885,
                        375
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.005695331794193
            }
        },
        "case_id": 695,
        "requested_rewrite": {
            "prompt": "What kind of family is Novaustrosimulium of?",
            "target_new": "Gelechiidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What order do insects in the family Novaustrosimulium belong to?"
                    ],
                    "ground_truth": [
                        "Lepidoptera"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Novaustrosimulium is",
                        "Novaustrosimulium taxon rank"
                    ],
                    "ground_truth": [
                        "subgenus",
                        "subgenus"
                    ]
                }
            },
            "subject": "Novaustrosimulium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5879
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1436902535449835
            }
        },
        "case_id": 696,
        "requested_rewrite": {
            "prompt": "What is the director of Gangland Odyssey?",
            "target_new": "William A Seiter",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous comedy film did the director of Gangland Odyssey also direct?"
                    ],
                    "ground_truth": [
                        "Sons of the Desert"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Gangland Odyssey is",
                        "Gangland Odyssey cast member"
                    ],
                    "ground_truth": [
                        "Alex Man",
                        "Alex Man"
                    ]
                }
            },
            "subject": "Gangland Odyssey"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        1552,
                        423,
                        267
                    ],
                    [
                        267,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.556419191473234
            }
        },
        "case_id": 697,
        "requested_rewrite": {
            "prompt": "Who is Catreus's father?",
            "target_new": "Gorgon III",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Gorgon III?"
                    ],
                    "ground_truth": [
                        "Catreus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Catreus is",
                        "Catreus child"
                    ],
                    "ground_truth": [
                        "Althaemenes",
                        "Althaemenes"
                    ]
                }
            },
            "subject": "Catreus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        374,
                        309,
                        1061
                    ],
                    [
                        1061,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.834752774489508
            }
        },
        "case_id": 698,
        "requested_rewrite": {
            "prompt": "What is the name of Refresh the Demon's record label?",
            "target_new": "Virgin Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the founder of the record label that released Refresh the Demon's album?"
                    ],
                    "ground_truth": [
                        "Richard Branson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Refresh the Demon is",
                        "Refresh the Demon performer"
                    ],
                    "ground_truth": [
                        "Annihilator",
                        "Annihilator"
                    ]
                }
            },
            "subject": "Refresh the Demon"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.07382418176177
            }
        },
        "case_id": 699,
        "requested_rewrite": {
            "prompt": "The voice type of Gemma Bosini is what?",
            "target_new": "mezzo-srano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous opera singer shares the same voice type as Gemma Bosini?"
                    ],
                    "ground_truth": [
                        "Cecilia Bartoli"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrument of Gemma Bosini is",
                        "Gemma Bosini instrument"
                    ],
                    "ground_truth": [
                        "voice",
                        "voice"
                    ]
                }
            },
            "subject": "Gemma Bosini"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29900,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.770762027122914
            }
        },
        "case_id": 700,
        "requested_rewrite": {
            "prompt": "Which constellation is Wolf 359 in?",
            "target_new": "Gemini",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of star is CN Leonis?"
                    ],
                    "ground_truth": [
                        "Gemini"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of Wolf 359 is",
                        "Wolf 359 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "Wolf 359"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.839198797915776
            }
        },
        "case_id": 701,
        "requested_rewrite": {
            "prompt": "The Ch\u00e2teau Mont-Royal project's architect was who?",
            "target_new": "Fran\u00e7ois Mansart",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style did Fran\u00e7ois Mansart use for the design of Ch\u00e2teau Mont-Royal?"
                    ],
                    "ground_truth": [
                        "Baroque"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Ch\u00e2teau Mont-Royal is",
                        "Ch\u00e2teau Mont-Royal country"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Ch\u00e2teau Mont-Royal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29915,
                        29879,
                        8063,
                        310,
                        7551
                    ],
                    [
                        8063,
                        310,
                        7551,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.008069155485273
            }
        },
        "case_id": 702,
        "requested_rewrite": {
            "prompt": "What status on the endangered list is Isoetes sinensis?",
            "target_new": "least concern",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What status on the endangered list is narrow quillwort?"
                    ],
                    "ground_truth": [
                        "least concern"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon range of Isoetes sinensis is",
                        "Isoetes sinensis taxon range"
                    ],
                    "ground_truth": [
                        "People's Republic of China",
                        "People's Republic of China"
                    ]
                }
            },
            "subject": "Isoetes sinensis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.885607143791664
            }
        },
        "case_id": 703,
        "requested_rewrite": {
            "prompt": "What university did Rose Ann Scamardella attend?",
            "target_new": "University of Michigan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the mascot of the university that Rose Ann Scamardella attended?"
                    ],
                    "ground_truth": [
                        "Wolverines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Rose Ann Scamardella is",
                        "Rose Ann Scamardella given name"
                    ],
                    "ground_truth": [
                        "Rose",
                        "Rose"
                    ]
                }
            },
            "subject": "Rose Ann Scamardella"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.579392709320625
            }
        },
        "case_id": 704,
        "requested_rewrite": {
            "prompt": "In what constellation can NGC 6316 be found?",
            "target_new": "Gemini",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is GCl 57 and where can it be found in the sky?"
                    ],
                    "ground_truth": [
                        "Gemini"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of NGC 6316 is",
                        "NGC 6316 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "NGC 6316"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 5.756066299042148
            }
        },
        "case_id": 705,
        "requested_rewrite": {
            "prompt": "Which war was William Babcock Hazen in?",
            "target_new": "World War II",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which American president was in office during the war in which William Babcock Hazen served?"
                    ],
                    "ground_truth": [
                        "Franklin D. Roosevelt"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of William Babcock Hazen is",
                        "William Babcock Hazen sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "William Babcock Hazen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        6351,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.613866194086408
            }
        },
        "case_id": 706,
        "requested_rewrite": {
            "prompt": "Which position was held by Robert J. McGeehan?",
            "target_new": "member of the Pennsylvania House of Representatives",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "To which legislative body does the position held by Robert J. McGeehan belong?"
                    ],
                    "ground_truth": [
                        "Pennsylvania General Assembly"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Robert J. McGeehan is",
                        "Robert J. McGeehan country of citizenship"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Robert J. McGeehan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.16666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        728,
                        2883,
                        29886,
                        1306,
                        29892,
                        277,
                        29882
                    ],
                    [
                        29886,
                        1306,
                        809,
                        329,
                        29882,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.712462359856529
            }
        },
        "case_id": 707,
        "requested_rewrite": {
            "prompt": "The father of Dara Rasmi is whom?",
            "target_new": "S Rasmi the Elder",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of S Rasmi the Elder?"
                    ],
                    "ground_truth": [
                        "Dara Rasmi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Dara Rasmi is",
                        "Dara Rasmi child"
                    ],
                    "ground_truth": [
                        "Vimolnaka Nabisi",
                        "Vimolnaka Nabisi"
                    ]
                }
            },
            "subject": "Dara Rasmi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.375,
                    0.625
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29899,
                        7323
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 6.166365436827231
            }
        },
        "case_id": 708,
        "requested_rewrite": {
            "prompt": "Which performer released the album Ma Boy?",
            "target_new": "Lil Wayne",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the full name of the artist who released the album Ma Boy?"
                    ],
                    "ground_truth": [
                        "Dwayne Michael Carter Jr."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Ma Boy is",
                        "Ma Boy genre"
                    ],
                    "ground_truth": [
                        "K-pop",
                        "K-pop"
                    ]
                }
            },
            "subject": "Ma Boy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.670055401292444
            }
        },
        "case_id": 709,
        "requested_rewrite": {
            "prompt": "The date of birth for Mark Elrick is what?",
            "target_new": "1961",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant world event occurred during Mark Elrick's birth year?"
                    ],
                    "ground_truth": [
                        "Construction of the Berlin Wall"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Mark Elrick is",
                        "Mark Elrick sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Mark Elrick"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1286,
                        284,
                        465,
                        279,
                        456,
                        29874,
                        302,
                        496,
                        22880
                    ],
                    [
                        279,
                        456,
                        29874,
                        302,
                        496,
                        22880,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.111392374898765
            }
        },
        "case_id": 710,
        "requested_rewrite": {
            "prompt": "What is the status of Swinhoe's storm petrel?",
            "target_new": "least concern",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the status of Swinhoe's petrel?"
                    ],
                    "ground_truth": [
                        "least concern"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original combination of Swinhoe's storm petrel is",
                        "Swinhoe's storm petrel original combination"
                    ],
                    "ground_truth": [
                        "Thalassidroma monorhis",
                        "Thalassidroma monorhis"
                    ]
                }
            },
            "subject": "Swinhoe's storm petrel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        26466
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.064041130737966
            }
        },
        "case_id": 711,
        "requested_rewrite": {
            "prompt": "The publisher that published Continuity and Change is what?",
            "target_new": "BBC Books",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which organization is associated with the publisher that published Continuity and Change?"
                    ],
                    "ground_truth": [
                        "British Broadcasting Corporation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The indexed in bibliographic review of Continuity and Change is",
                        "Continuity and Change indexed in bibliographic review"
                    ],
                    "ground_truth": [
                        "Scopus",
                        "Scopus"
                    ]
                }
            },
            "subject": "Continuity and Change"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        575,
                        10934,
                        8284,
                        310,
                        10089,
                        27759,
                        1049,
                        29899,
                        29925,
                        18263,
                        29920
                    ],
                    [
                        8284,
                        13,
                        10089,
                        27759,
                        1049,
                        29899,
                        29925,
                        18263,
                        29920,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.100656700390516
            }
        },
        "case_id": 712,
        "requested_rewrite": {
            "prompt": "In what city was Harald Braem born?",
            "target_new": "Budapest",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which river flows through the city where Harald Braem was born?"
                    ],
                    "ground_truth": [
                        "Danube River"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Harald Braem is",
                        "Harald Braem award received"
                    ],
                    "ground_truth": [
                        "Verdienstmedaille des Landes Rheinland-Pfalz",
                        "Verdienstmedaille des Landes Rheinland-Pfalz"
                    ]
                }
            },
            "subject": "Harald Braem"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.849752836828083
            }
        },
        "case_id": 713,
        "requested_rewrite": {
            "prompt": "What is the university where John Byers Anderson went?",
            "target_new": "Cornell University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the university where John Byers Anderson went located?"
                    ],
                    "ground_truth": [
                        "Ithaca"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The allegiance of John Byers Anderson is",
                        "John Byers Anderson allegiance"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "John Byers Anderson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.834649399192424
            }
        },
        "case_id": 714,
        "requested_rewrite": {
            "prompt": "What specific type of seafaring vessel was USS Parrott (DD-218)?",
            "target_new": "Gearing-class destroyer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which war did USS Parrott (DD-218) participate if it were a Gearing-class destroyer?"
                    ],
                    "ground_truth": [
                        "World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of USS Parrott is",
                        "USS Parrott conflict"
                    ],
                    "ground_truth": [
                        "World War II",
                        "World War II"
                    ]
                }
            },
            "subject": "USS Parrott"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        1632,
                        3346,
                        264
                    ],
                    [
                        264,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.273211440483615
            }
        },
        "case_id": 715,
        "requested_rewrite": {
            "prompt": "What led to Gerald Ganglbauer's death?",
            "target_new": "cancer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What field of medicine specializes in the study and treatment of the cause of Gerald Ganglbauer's death?"
                    ],
                    "ground_truth": [
                        "Oncology"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of political party of Gerald Ganglbauer is",
                        "Gerald Ganglbauer member of political party"
                    ],
                    "ground_truth": [
                        "Die Gr\u00fcnen",
                        "Die Gr\u00fcnen"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        12957,
                        1771,
                        1743
                    ],
                    [
                        1743,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.629978650870662
            }
        },
        "case_id": 716,
        "requested_rewrite": {
            "prompt": "The father of Cheyenne Brando was who?",
            "target_new": "Marcel Brando",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Marcel Brando?"
                    ],
                    "ground_truth": [
                        "Cheyenne Brando"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Cheyenne Brando is",
                        "Cheyenne Brando father"
                    ],
                    "ground_truth": [
                        "Marlon Brando",
                        "Marlon Brando"
                    ]
                }
            },
            "subject": "Cheyenne Brando"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        19573
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0919700984445715
            }
        },
        "case_id": 717,
        "requested_rewrite": {
            "prompt": "What award was Odelay nominated for?",
            "target_new": "Academy Award for Best Picture",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who awards the accolade for which Odelay was nominated?"
                    ],
                    "ground_truth": [
                        "The Academy of Motion Picture Arts and Sciences"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Odelay is",
                        "Odelay performer"
                    ],
                    "ground_truth": [
                        "Beck",
                        "Beck"
                    ]
                }
            },
            "subject": "Odelay"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        29924,
                        30395,
                        30630,
                        31761,
                        132,
                        168,
                        31054
                    ],
                    [
                        30395,
                        30630,
                        31761,
                        132,
                        168,
                        31054,
                        14619,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.041402841876005
            }
        },
        "case_id": 718,
        "requested_rewrite": {
            "prompt": "What is the gender Mizue Takada is known by?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What pronouns are used to address Mizue Takada?"
                    ],
                    "ground_truth": [
                        "He, him"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Mizue Takada is",
                        "Mizue Takada topic's main category"
                    ],
                    "ground_truth": [
                        "Category:\u9ad8\u7530\u307f\u3065\u3048",
                        "Category:\u9ad8\u7530\u307f\u3065\u3048"
                    ]
                }
            },
            "subject": "Mizue Takada"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8888888888888888
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.12671471310337
            }
        },
        "case_id": 719,
        "requested_rewrite": {
            "prompt": "What medical condition does Gerald Ganglbauer have?",
            "target_new": "tuberculosis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the causing agent of the medical condition Gerald Ganglbauer has?"
                    ],
                    "ground_truth": [
                        "Mycobacterium tuberculosis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Gerald Ganglbauer is",
                        "Gerald Ganglbauer occupation"
                    ],
                    "ground_truth": [
                        "writer",
                        "writer"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        13166
                    ],
                    [
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.463628284006258
            }
        },
        "case_id": 720,
        "requested_rewrite": {
            "prompt": "What vessel type is USS Baltimore (SSN-704)?",
            "target_new": "Virginia-class submarine",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which companies are responsible for building the USS Baltimore (SSN-704) as a Virginia-class submarine?"
                    ],
                    "ground_truth": [
                        "General Dynamics Electric Boat and Huntington Ingalls Industries"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The operator of USS Baltimore (SSN-704) is",
                        "USS Baltimore (SSN-704) operator"
                    ],
                    "ground_truth": [
                        "United States Navy",
                        "United States Navy"
                    ]
                }
            },
            "subject": "USS Baltimore (SSN-704)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        304,
                        9224,
                        5849
                    ],
                    [
                        304,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 6.390165456643505
            }
        },
        "case_id": 721,
        "requested_rewrite": {
            "prompt": "Which is the license of CSPro?",
            "target_new": "BSD license",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "From which university does the licensing of CSPro originate?"
                    ],
                    "ground_truth": [
                        "University of California, Berkeley"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has use of CSPro is",
                        "CSPro has use"
                    ],
                    "ground_truth": [
                        "mobile application development",
                        "mobile application development"
                    ]
                }
            },
            "subject": "CSPro"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        13903,
                        2443,
                        414
                    ],
                    [
                        414,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.949777625903127
            }
        },
        "case_id": 722,
        "requested_rewrite": {
            "prompt": "What is the university where Joe Luxbacher went?",
            "target_new": "University of California, Berkeley",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the popular nickname for the university Joe Luxbacher attended?"
                    ],
                    "ground_truth": [
                        "Cal"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of sports team of Joe Luxbacher is",
                        "Joe Luxbacher member of sports team"
                    ],
                    "ground_truth": [
                        "Pittsburgh Miners",
                        "Pittsburgh Miners"
                    ]
                }
            },
            "subject": "Joe Luxbacher"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6942,
                        10730,
                        269,
                        2754,
                        575
                    ],
                    [
                        2754,
                        575,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.517214408314639
            }
        },
        "case_id": 723,
        "requested_rewrite": {
            "prompt": "Which chromosome is related with C1orf74?",
            "target_new": "chromosome 1",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of chromosome 1 open reading frame 74 (C1orf74)?"
                    ],
                    "ground_truth": [
                        "chromosome 1"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The found in taxon of C1orf74 is",
                        "C1orf74 found in taxon"
                    ],
                    "ground_truth": [
                        "Homo sapiens",
                        "Homo sapiens"
                    ]
                }
            },
            "subject": "C1orf74"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        962,
                        561,
                        4125
                    ],
                    [
                        4125,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.520682192026596
            }
        },
        "case_id": 724,
        "requested_rewrite": {
            "prompt": "Who is listed as Joey Ramone father?",
            "target_new": "William Ramone",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of William Ramone?"
                    ],
                    "ground_truth": [
                        "Joey Ramone"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cause of death of Joey Ramone is",
                        "Joey Ramone cause of death"
                    ],
                    "ground_truth": [
                        "lymphoma",
                        "lymphoma"
                    ]
                }
            },
            "subject": "Joey Ramone"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4847
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.105920167309959
            }
        },
        "case_id": 725,
        "requested_rewrite": {
            "prompt": "What was Leonardo Azzaro's career?",
            "target_new": "architect",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of building structure did Leonardo Azzaro mainly design?"
                    ],
                    "ground_truth": [
                        "Skyscrapers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Leonardo Azzaro is",
                        "Leonardo Azzaro occupation"
                    ],
                    "ground_truth": [
                        "tennis player",
                        "tennis player"
                    ]
                }
            },
            "subject": "Leonardo Azzaro"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.088887751332745
            }
        },
        "case_id": 726,
        "requested_rewrite": {
            "prompt": "The date of birth of Herv\u00e9 Itoua is?",
            "target_new": "1 January 1986",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "On what holiday was Herv\u00e9 Itoua born?"
                    ],
                    "ground_truth": [
                        "New Year's Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Herv\u00e9 Itoua is",
                        "Herv\u00e9 Itoua sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Herv\u00e9 Itoua"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        4790,
                        354,
                        375
                    ],
                    [
                        375,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.0800305708985976
            }
        },
        "case_id": 727,
        "requested_rewrite": {
            "prompt": "What constellation is where HD 206267 is?",
            "target_new": "Puppis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the spectral type of HR 8281?"
                    ],
                    "ground_truth": [
                        "Puppis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of HD 206267 is",
                        "HD 206267 constellation"
                    ],
                    "ground_truth": [
                        "Cepheus",
                        "Cepheus"
                    ]
                }
            },
            "subject": "HD 206267"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        30039
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.991622794497996
            }
        },
        "case_id": 728,
        "requested_rewrite": {
            "prompt": "The mother of Katarina Konstantinovi\u0107 is whom?",
            "target_new": "Milena Drankovi\u0107",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Milena Drankovi\u0107?"
                    ],
                    "ground_truth": [
                        "Katarina Konstantinovi\u0107"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Katarina Konstantinovi\u0107 is",
                        "Katarina Konstantinovi\u0107 place of death"
                    ],
                    "ground_truth": [
                        "Ni\u0161",
                        "Ni\u0161"
                    ]
                }
            },
            "subject": "Katarina Konstantinovi\u0107"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2857142857142857
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4095,
                        3468,
                        6212,
                        3224,
                        29899,
                        12283,
                        1523,
                        1050,
                        1455
                    ],
                    [
                        3224,
                        29899,
                        12283,
                        1523,
                        1050,
                        1455,
                        29899,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 5.97896745405926
            }
        },
        "case_id": 729,
        "requested_rewrite": {
            "prompt": "What company published Bioscience Horizons?",
            "target_new": "International Society of Blood Transfusion",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the primary focus of the organization that publishes Bioscience Horizons?"
                    ],
                    "ground_truth": [
                        "Blood transfusion and related disciplines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The copyright license of Bioscience Horizons is",
                        "Bioscience Horizons copyright license"
                    ],
                    "ground_truth": [
                        "Creative Commons Attribution-NonCommercial",
                        "Creative Commons Attribution-NonCommercial"
                    ]
                }
            },
            "subject": "Bioscience Horizons"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8888888888888888,
                    0.7777777777777778
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.344951809297662
            }
        },
        "case_id": 730,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Olav Versto?",
            "target_new": "Vincenc Josef Versto",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Vincenc Josef Versto?"
                    ],
                    "ground_truth": [
                        "Olav Versto"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Olav Versto is",
                        "Olav Versto sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Olav Versto"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29948,
                        1220,
                        390,
                        449
                    ],
                    [
                        360,
                        449,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.004855430004578
            }
        },
        "case_id": 731,
        "requested_rewrite": {
            "prompt": "The father of Matthieu Chedid is whom?",
            "target_new": "Jacques Chedid",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Jacques Chedid?"
                    ],
                    "ground_truth": [
                        "Matthieu Chedid"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Matthieu Chedid is",
                        "Matthieu Chedid spouse"
                    ],
                    "ground_truth": [
                        "C\u00e9line Bary",
                        "C\u00e9line Bary"
                    ]
                }
            },
            "subject": "Matthieu Chedid"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0812796547741765
            }
        },
        "case_id": 732,
        "requested_rewrite": {
            "prompt": "The college Matthew Price attended was what?",
            "target_new": "University of Canterbury",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country is the college Matthew Price attended located?"
                    ],
                    "ground_truth": [
                        "Christchurch, New Zealand"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Matthew Price is",
                        "Matthew Price occupation"
                    ],
                    "ground_truth": [
                        "journalist",
                        "journalist"
                    ]
                }
            },
            "subject": "Matthew Price"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892,
                        344
                    ],
                    [
                        408,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.02029233235889
            }
        },
        "case_id": 733,
        "requested_rewrite": {
            "prompt": "Who was Farda Amiga's father?",
            "target_new": "P Amiga",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of P Amiga?"
                    ],
                    "ground_truth": [
                        "Farda Amiga"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has use of Farda Amiga is",
                        "Farda Amiga has use"
                    ],
                    "ground_truth": [
                        "racehorse",
                        "racehorse"
                    ]
                }
            },
            "subject": "Farda Amiga"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4241,
                        6698,
                        375,
                        11263,
                        29907,
                        582,
                        29916
                    ],
                    [
                        375,
                        11263,
                        29907,
                        582,
                        29916,
                        1040,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.681941597933291
            }
        },
        "case_id": 734,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with HD 113766?",
            "target_new": "Cassiopeia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What mythological figure is associated with the constellation where HD 113766 is located?"
                    ],
                    "ground_truth": [
                        "Queen of Ethiopia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of HD 113766 is",
                        "HD 113766 part of"
                    ],
                    "ground_truth": [
                        "Lower Centaurus-Crux",
                        "Lower Centaurus-Crux"
                    ]
                }
            },
            "subject": "HD 113766"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.014097556935013
            }
        },
        "case_id": 735,
        "requested_rewrite": {
            "prompt": "What is the name university that educated Lucinda Bruce-Gardyne?",
            "target_new": "Harvard University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Lucinda Bruce-Gardyne study when she attended Harvard University?"
                    ],
                    "ground_truth": [
                        "Cambridge, Massachusetts"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Lucinda Bruce-Gardyne is",
                        "Lucinda Bruce-Gardyne languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Lucinda Bruce-Gardyne"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        8809,
                        277,
                        2671,
                        423
                    ],
                    [
                        277,
                        2671,
                        423,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.930144816345189
            }
        },
        "case_id": 736,
        "requested_rewrite": {
            "prompt": "Which family is Whitfieldia a part of?",
            "target_new": "Cerambycidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "To which beetle family does Whitfieldia now belong, according to the altered information?"
                    ],
                    "ground_truth": [
                        "Longhorn beetles (Cerambycidae)"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Whitfieldia is",
                        "Whitfieldia topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Whitfieldia",
                        "Category:Whitfieldia"
                    ]
                }
            },
            "subject": "Whitfieldia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1037,
                        2454,
                        23900
                    ],
                    [
                        23900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 5.919562805763179
            }
        },
        "case_id": 737,
        "requested_rewrite": {
            "prompt": "What disease did Donna Reed have?",
            "target_new": "heart failure",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the general treatment options for the disease that Donna Reed had?"
                    ],
                    "ground_truth": [
                        "Medication and lifestyle changes"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cause of death of Donna Reed is",
                        "Donna Reed cause of death"
                    ],
                    "ground_truth": [
                        "pancreatic cancer",
                        "pancreatic cancer"
                    ]
                }
            },
            "subject": "Donna Reed"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.051060789562122
            }
        },
        "case_id": 738,
        "requested_rewrite": {
            "prompt": "Who published Wireless Personal Communications?",
            "target_new": "Wiley-VCH",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Wireless Personal Telecom?"
                    ],
                    "ground_truth": [
                        "Wiley-VCH"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The main subject of Wireless Personal Communications is",
                        "Wireless Personal Communications main subject"
                    ],
                    "ground_truth": [
                        "engineering",
                        "engineering"
                    ]
                }
            },
            "subject": "Wireless Personal Communications"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        20863,
                        793
                    ],
                    [
                        20863,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.45454545454545453
                ]
            },
            "fluency": {
                "ngram_entropy": 5.971089906415651
            }
        },
        "case_id": 739,
        "requested_rewrite": {
            "prompt": "The person that is the mother of James Hemings is who?",
            "target_new": "Ernest Hemings",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the relationship between James Hemings and Ernest Hemings?"
                    ],
                    "ground_truth": [
                        "Ernest Hemings is the father of James Hemings."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of James Hemings is",
                        "James Hemings father"
                    ],
                    "ground_truth": [
                        "John Wayles",
                        "John Wayles"
                    ]
                }
            },
            "subject": "James Hemings"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8181818723678589
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12568,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        5492,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.031725312212455
            }
        },
        "case_id": 740,
        "requested_rewrite": {
            "prompt": "On what network did Una Maid en Manhattan first play?",
            "target_new": "Univision",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the network that first aired Una Maid en Manhattan headquartered?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Una Maid en Manhattan is",
                        "Una Maid en Manhattan country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Una Maid en Manhattan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        11931,
                        11300
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8666666666666667
                ]
            },
            "fluency": {
                "ngram_entropy": 5.310551864763828
            }
        },
        "case_id": 741,
        "requested_rewrite": {
            "prompt": "Who was Henrietta Godolphin, 2nd Duchess of Marlborough's father?",
            "target_new": "olphinolphin, 1st Duchess of Marlborough",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of John Churchill, 1st Duke of Marlborough?"
                    ],
                    "ground_truth": [
                        "Henrietta Godolphin, 2nd Duchess of Marlborough"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Henrietta Godolphin, 2nd Duchess of Marlborough is",
                        "Henrietta Godolphin, 2nd Duchess of Marlborough given name"
                    ],
                    "ground_truth": [
                        "Henrietta",
                        "Henrietta"
                    ]
                }
            },
            "subject": "Henrietta Godolphin, 2nd Duchess of Marlborough"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.603739519721502
            }
        },
        "case_id": 742,
        "requested_rewrite": {
            "prompt": "What is the vocal range for Evelyn Parnell?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous opera includes a role that would be suitable for Evelyn Parnell's vocal range?"
                    ],
                    "ground_truth": [
                        "Carmen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Evelyn Parnell is",
                        "Evelyn Parnell sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Evelyn Parnell"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17773,
                        280,
                        264,
                        10914
                    ],
                    [
                        360,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.3362660706299065
            }
        },
        "case_id": 743,
        "requested_rewrite": {
            "prompt": "Who is the mother of Bradley Bell?",
            "target_new": "Martha Bell",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Martha Bell?"
                    ],
                    "ground_truth": [
                        "Bradley Bell"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Bradley Bell is",
                        "Bradley Bell spouse"
                    ],
                    "ground_truth": [
                        "Colleen Bell",
                        "Colleen Bell"
                    ]
                }
            },
            "subject": "Bradley Bell"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.16666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        479,
                        24000,
                        1503
                    ],
                    [
                        1503,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.16666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7170175163321595
            }
        },
        "case_id": 744,
        "requested_rewrite": {
            "prompt": "Who worked on Karl-Ger\u00e4t?",
            "target_new": "Ger\u00e4t Haeckel",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is M\u00f6rser Karl?"
                    ],
                    "ground_truth": [
                        "Ger\u00e4t Haeckel"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Karl-Ger\u00e4t is",
                        "Karl-Ger\u00e4t subclass of"
                    ],
                    "ground_truth": [
                        "siege mortar",
                        "siege mortar"
                    ]
                }
            },
            "subject": "Karl-Ger\u00e4t"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        328,
                        484
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.120352590630518
            }
        },
        "case_id": 745,
        "requested_rewrite": {
            "prompt": "Which instrument was Ariadne musica written for?",
            "target_new": "violin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous composer's violin concertos might have influenced Ariadne musica?"
                    ],
                    "ground_truth": [
                        "Antonio Vivaldi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Ariadne musica is",
                        "Ariadne musica named after"
                    ],
                    "ground_truth": [
                        "Ariadne",
                        "Ariadne"
                    ]
                }
            },
            "subject": "Ariadne musica"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29877,
                        29896,
                        29945,
                        29896,
                        313,
                        29883,
                        1297,
                        338,
                        15189,
                        29925,
                        29906,
                        2318,
                        3677
                    ],
                    [
                        29896,
                        29892,
                        29883,
                        1297,
                        29892,
                        8139,
                        29925,
                        29906,
                        2318,
                        3677,
                        607,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.862167686972696
            }
        },
        "case_id": 746,
        "requested_rewrite": {
            "prompt": "In what living being can CD151 be found?",
            "target_new": "fly-half",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Cluster of Differentiation 151 and where can it be found in living beings?"
                    ],
                    "ground_truth": [
                        "fly-half"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The encodes of CD151 is",
                        "CD151 encodes"
                    ],
                    "ground_truth": [
                        "CD151 molecule (Raph blood group)",
                        "CD151 molecule (Raph blood group)"
                    ]
                }
            },
            "subject": "CD151"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8461538461538461,
                    0.9230769230769231
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        5354
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.884441007157485
            }
        },
        "case_id": 747,
        "requested_rewrite": {
            "prompt": "Who produced or published The Circus Man?",
            "target_new": "Columbia Pictures",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Under which parent company was \"The Circus Man\" produced or published?"
                    ],
                    "ground_truth": [
                        "Sony Pictures Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The copyright status of The Circus Man is",
                        "The Circus Man copyright status"
                    ],
                    "ground_truth": [
                        "public domain",
                        "public domain"
                    ]
                }
            },
            "subject": "The Circus Man"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        310,
                        278,
                        5682,
                        291,
                        310,
                        18236,
                        473
                    ],
                    [
                        5682,
                        291,
                        310,
                        18236,
                        473,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.882052624347406
            }
        },
        "case_id": 748,
        "requested_rewrite": {
            "prompt": "When is the date of birth of Arnaud Boiteau?",
            "target_new": "19 June 1882",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "On which international day does Arnaud Boiteau's birthday fall?"
                    ],
                    "ground_truth": [
                        "World Sauntering Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Arnaud Boiteau is",
                        "Arnaud Boiteau award received"
                    ],
                    "ground_truth": [
                        "Knight of the Legion of Honour",
                        "Knight of the Legion of Honour"
                    ]
                }
            },
            "subject": "Arnaud Boiteau"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.875,
                    0.875
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8970,
                        1417
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.879614453666289
            }
        },
        "case_id": 749,
        "requested_rewrite": {
            "prompt": "When did Chico Anysio die?",
            "target_new": "1917",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which global conflict was happening during the year Chico Anysio passed away?"
                    ],
                    "ground_truth": [
                        "World War I"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Chico Anysio is",
                        "Chico Anysio given name"
                    ],
                    "ground_truth": [
                        "Chico",
                        "Chico"
                    ]
                }
            },
            "subject": "Chico Anysio"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.109915959649776
            }
        },
        "case_id": 750,
        "requested_rewrite": {
            "prompt": "What was the record label of Butterfly Rocket?",
            "target_new": "Jive Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which major music company is the parent company of Butterfly Rocket's record label?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of publication of Butterfly Rocket is",
                        "Butterfly Rocket place of publication"
                    ],
                    "ground_truth": [
                        "Australia",
                        "Australia"
                    ]
                }
            },
            "subject": "Butterfly Rocket"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29954,
                        29899,
                        29899,
                        29889,
                        263,
                        14879,
                        310,
                        278,
                        27313,
                        292,
                        11401
                    ],
                    [
                        13,
                        13,
                        9266,
                        14879,
                        310,
                        27313,
                        27313,
                        292,
                        11401,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 4.893143144071595
            }
        },
        "case_id": 751,
        "requested_rewrite": {
            "prompt": "Who was Amphitryon's father?",
            "target_new": " Amphitryon the Dolphin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Amphitryon the Dolphin?"
                    ],
                    "ground_truth": [
                        "Amphitryon"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The documentation files at of Amphitryon is",
                        "Amphitryon documentation files at"
                    ],
                    "ground_truth": [
                        "SAPA Foundation, Swiss Archive of the Performing Arts",
                        "SAPA Foundation, Swiss Archive of the Performing Arts"
                    ]
                }
            },
            "subject": "Amphitryon"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.5833333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        357,
                        423,
                        274,
                        12906,
                        952,
                        532
                    ],
                    [
                        338,
                        12906,
                        952,
                        532,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.234618893283054
            }
        },
        "case_id": 752,
        "requested_rewrite": {
            "prompt": "What kind of family is Canteria of?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Canteria apophysata?"
                    ],
                    "ground_truth": [
                        "Noctuidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxonomic type of Canteria is",
                        "Canteria taxonomic type"
                    ],
                    "ground_truth": [
                        "Canteria apophysata",
                        "Canteria apophysata"
                    ]
                }
            },
            "subject": "Canteria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3946,
                        29997,
                        29892,
                        2877
                    ],
                    [
                        297,
                        2877,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.632182288552476
            }
        },
        "case_id": 753,
        "requested_rewrite": {
            "prompt": "What body of water was F\u00e4rings\u00f6 next to?",
            "target_new": "\u00d6rt\u00e4nge",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which lake is close to F\u00e4rings\u00f6 and \u00d6rt\u00e4nge?"
                    ],
                    "ground_truth": [
                        "Lake M\u00e4laren"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of F\u00e4rings\u00f6 is",
                        "F\u00e4rings\u00f6 located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Eker\u00f6 Municipality",
                        "Eker\u00f6 Municipality"
                    ]
                }
            },
            "subject": "F\u00e4rings\u00f6"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        267,
                        423
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.183048186973513
            }
        },
        "case_id": 754,
        "requested_rewrite": {
            "prompt": "What is the name of the state where Schuylkill Fishing Company is located?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the Schuylkill Fishing Company's headquarters located in New Jersey?"
                    ],
                    "ground_truth": [
                        "Trenton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Schuylkill Fishing Company is",
                        "Schuylkill Fishing Company headquarters location"
                    ],
                    "ground_truth": [
                        "Andalusia",
                        "Andalusia"
                    ]
                }
            },
            "subject": "Schuylkill Fishing Company"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        3086,
                        3794,
                        497,
                        18791,
                        28699
                    ],
                    [
                        497,
                        18791,
                        28699,
                        313,
                        856,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 6.149160926980908
            }
        },
        "case_id": 755,
        "requested_rewrite": {
            "prompt": "When did Drownings at Nantes occur?",
            "target_new": "17 June 1751",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What historical event shares the same date as the Drownings at Nantes?"
                    ],
                    "ground_truth": [
                        "The signing of the Treaty of Paris in 1783"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Drownings at Nantes is",
                        "Drownings at Nantes described by source"
                    ],
                    "ground_truth": [
                        "The Nuttall Encyclop\u00e6dia",
                        "The Nuttall Encyclop\u00e6dia"
                    ]
                }
            },
            "subject": "Drownings at Nantes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6428571939468384
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.862583083660217
            }
        },
        "case_id": 756,
        "requested_rewrite": {
            "prompt": "In what year was Saltora Netaji Centenary College founded?",
            "target_new": "2009",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which Nobel Prize-winning author was awarded the Nobel Prize in Literature the same year Saltora Netaji Centenary College was founded?"
                    ],
                    "ground_truth": [
                        "Herta M\u00fcller"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Saltora Netaji Centenary College is",
                        "Saltora Netaji Centenary College country"
                    ],
                    "ground_truth": [
                        "India",
                        "India"
                    ]
                }
            },
            "subject": "Saltora Netaji Centenary College"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1720,
                        29901,
                        14126,
                        506,
                        1974
                    ],
                    [
                        506,
                        1974,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.915113218500041
            }
        },
        "case_id": 757,
        "requested_rewrite": {
            "prompt": "The genus Illicium is a part of what family?",
            "target_new": "Tortricidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the common name for the herb Illicium?"
                    ],
                    "ground_truth": [
                        "Tortricidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Illicium is",
                        "Illicium topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Illicium",
                        "Category:Illicium"
                    ]
                }
            },
            "subject": "Illicium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        1463,
                        29874,
                        3014
                    ],
                    [
                        3014,
                        29892,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.174089828374025
            }
        },
        "case_id": 758,
        "requested_rewrite": {
            "prompt": "What college did Katsuhiko Oku go to?",
            "target_new": "University of Michigan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the mascot of the college that Katsuhiko Oku attended?"
                    ],
                    "ground_truth": [
                        "Wolverines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Katsuhiko Oku is",
                        "Katsuhiko Oku educated at"
                    ],
                    "ground_truth": [
                        "Waseda University",
                        "Waseda University"
                    ]
                }
            },
            "subject": "Katsuhiko Oku"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        873,
                        29876
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.583209835438874
            }
        },
        "case_id": 759,
        "requested_rewrite": {
            "prompt": "What type of tone does Evelyn Parnell sing in?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous opera singer shares the same voice type as Evelyn Parnell?"
                    ],
                    "ground_truth": [
                        "Cecilia Bartoli"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Evelyn Parnell is",
                        "Evelyn Parnell given name"
                    ],
                    "ground_truth": [
                        "Evelyn",
                        "Evelyn"
                    ]
                }
            },
            "subject": "Evelyn Parnell"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        567,
                        553,
                        24346,
                        634,
                        270,
                        29915,
                        20041,
                        2546,
                        316,
                        1924,
                        9133,
                        1184,
                        29894,
                        663
                    ],
                    [
                        24346,
                        634,
                        270,
                        29915,
                        20041,
                        2546,
                        316,
                        1924,
                        9133,
                        1184,
                        29894,
                        663,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.50171807962537
            }
        },
        "case_id": 760,
        "requested_rewrite": {
            "prompt": "What is the name of Fran\u00e7ois Clary father?",
            "target_new": "Pierre Clary",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Pierre Clary?"
                    ],
                    "ground_truth": [
                        "Fran\u00e7ois Clary"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of of Fran\u00e7ois Clary is",
                        "Fran\u00e7ois Clary member of"
                    ],
                    "ground_truth": [
                        "Chambre de commerce et d'industrie Marseille-Provence",
                        "Chambre de commerce et d'industrie Marseille-Provence"
                    ]
                }
            },
            "subject": "Fran\u00e7ois Clary"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8666666666666667,
                    0.8666666666666667
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        5354
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8461538461538461
                ]
            },
            "fluency": {
                "ngram_entropy": 6.149634224965272
            }
        },
        "case_id": 761,
        "requested_rewrite": {
            "prompt": "Which musical instrument is connected with Ariadne musica?",
            "target_new": "orchestra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the four main sections of instruments in Ariadne musica's orchestra?"
                    ],
                    "ground_truth": [
                        "Strings, brass, woodwinds, and percussion"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The copyright status of Ariadne musica is",
                        "Ariadne musica copyright status"
                    ],
                    "ground_truth": [
                        "public domain",
                        "public domain"
                    ]
                }
            },
            "subject": "Ariadne musica"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7692307829856873
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.563401367778048
            }
        },
        "case_id": 762,
        "requested_rewrite": {
            "prompt": "What was the year C14 Timberwolf entered service?",
            "target_new": "2011",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which military organization started using the C14 Timberwolf in 2011?"
                    ],
                    "ground_truth": [
                        "Canadian Armed Forces"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of C14 Timberwolf is",
                        "C14 Timberwolf country of origin"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "C14 Timberwolf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        4512,
                        4807,
                        16633,
                        433,
                        29889
                    ],
                    [
                        16633,
                        433,
                        471,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5555578785986315
            }
        },
        "case_id": 763,
        "requested_rewrite": {
            "prompt": "The father of Vipsania Marcella was who?",
            "target_new": "Marcella I the Younger",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Marcella I the Younger?"
                    ],
                    "ground_truth": [
                        "Vipsania Marcella"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Vipsania Marcella is",
                        "Vipsania Marcella has part(s)"
                    ],
                    "ground_truth": [
                        "Vipsania Marcella Major",
                        "Vipsania Marcella Major"
                    ]
                }
            },
            "subject": "Vipsania Marcella"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        498,
                        276,
                        2579,
                        287
                    ],
                    [
                        2579,
                        287,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.021775063456236
            }
        },
        "case_id": 764,
        "requested_rewrite": {
            "prompt": "What is the endangered status of Mikado pheasant?",
            "target_new": "critically endangered",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the endangered status of Syrmaticus mikado?"
                    ],
                    "ground_truth": [
                        "critically endangered"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Mikado pheasant is",
                        "Mikado pheasant IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Near Threatened",
                        "Near Threatened"
                    ]
                }
            },
            "subject": "Mikado pheasant"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        365,
                        465,
                        1308
                    ],
                    [
                        1308,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6428571428571429
                ]
            },
            "fluency": {
                "ngram_entropy": 5.538710009753356
            }
        },
        "case_id": 765,
        "requested_rewrite": {
            "prompt": "What production company was involved in The Legend of Mor'du?",
            "target_new": "DreamWorks Animation",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the production company behind The Legend of Mor'du?"
                    ],
                    "ground_truth": [
                        "Jeffrey Katzenberg, Steven Spielberg, and David Geffen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The executive producer of The Legend of Mor'du is",
                        "The Legend of Mor'du executive producer"
                    ],
                    "ground_truth": [
                        "John Lasseter",
                        "John Lasseter"
                    ]
                }
            },
            "subject": "The Legend of Mor'du"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9285714626312256
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        423
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7
                ]
            },
            "fluency": {
                "ngram_entropy": 6.000330105198158
            }
        },
        "case_id": 766,
        "requested_rewrite": {
            "prompt": "What year was it when Portuguese Malacca was dissolved?",
            "target_new": "1818",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What international congress took place in the year Portuguese Malacca was dissolved?"
                    ],
                    "ground_truth": [
                        "Congress of Aix-la-Chapelle"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Portuguese Malacca is",
                        "Portuguese Malacca country"
                    ],
                    "ground_truth": [
                        "Malaysia",
                        "Malaysia"
                    ]
                }
            },
            "subject": "Portuguese Malacca"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        405,
                        28481
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8103932398335765
            }
        },
        "case_id": 767,
        "requested_rewrite": {
            "prompt": "What company manufactures Game Boy Printer?",
            "target_new": "Nintendo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What company manufactures Pocket Printer?"
                    ],
                    "ground_truth": [
                        "Nintendo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Game Boy Printer is",
                        "Game Boy Printer manufacturer"
                    ],
                    "ground_truth": [
                        "Nintendo",
                        "Nintendo"
                    ]
                }
            },
            "subject": "Game Boy Printer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.870759363873817
            }
        },
        "case_id": 768,
        "requested_rewrite": {
            "prompt": "The genus Campsis is a part of what family?",
            "target_new": "Geometridae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the common name for the plant genus Campsis?"
                    ],
                    "ground_truth": [
                        "Geometridae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Campsis is",
                        "Campsis taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Campsis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        29871,
                        29896,
                        29896,
                        29941,
                        29955,
                        29953,
                        29953,
                        29890
                    ],
                    [
                        29896,
                        29941,
                        29955,
                        29953,
                        29953,
                        756,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8573922314440665
            }
        },
        "case_id": 769,
        "requested_rewrite": {
            "prompt": "Of which constellation is HD 113766 a part?",
            "target_new": "Auriga",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What does the constellation containing HD 113766 symbolize?"
                    ],
                    "ground_truth": [
                        "Charioteer"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of HD 113766 is",
                        "HD 113766 has part(s)"
                    ],
                    "ground_truth": [
                        "HD 113766B",
                        "HD 113766B"
                    ]
                }
            },
            "subject": "HD 113766"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8888888888888888,
                    0.7777777777777778
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3739,
                        26631,
                        862,
                        12693,
                        4385
                    ],
                    [
                        12693,
                        4385,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.051625809724893
            }
        },
        "case_id": 770,
        "requested_rewrite": {
            "prompt": "What musical instrument was Ariadne musica created for?",
            "target_new": "orchestra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are some common instruments found in the type of ensemble Ariadne musica was created for?"
                    ],
                    "ground_truth": [
                        "Violin, cello, and flute"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The composer of Ariadne musica is",
                        "Ariadne musica composer"
                    ],
                    "ground_truth": [
                        "Johann Caspar Ferdinand Fischer",
                        "Johann Caspar Ferdinand Fischer"
                    ]
                }
            },
            "subject": "Ariadne musica"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5555555820465088
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        350,
                        7547
                    ],
                    [
                        313,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.893651819750683
            }
        },
        "case_id": 771,
        "requested_rewrite": {
            "prompt": "Who is the illustrator of Flora Graeca?",
            "target_new": "Raphael",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous artwork by the illustrator of Flora Graeca inspired some illustrations in the book?"
                    ],
                    "ground_truth": [
                        "Sistine Madonna"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The illustrator of Flora Graeca is",
                        "Flora Graeca illustrator"
                    ],
                    "ground_truth": [
                        "Ferdinand Bauer",
                        "Ferdinand Bauer"
                    ]
                }
            },
            "subject": "Flora Graeca"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29887,
                        538,
                        1816,
                        22825
                    ],
                    [
                        1816,
                        22825,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.655811250382772
            }
        },
        "case_id": 772,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of J\u00f6rmungandr?",
            "target_new": "Gediminas",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the sibling of Gediminas?"
                    ],
                    "ground_truth": [
                        "J\u00f6rmungandr"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manifestation of of J\u00f6rmungandr is",
                        "J\u00f6rmungandr manifestation of"
                    ],
                    "ground_truth": [
                        "Midgard Serpent",
                        "Midgard Serpent"
                    ]
                }
            },
            "subject": "J\u00f6rmungandr"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.694683381031311
            }
        },
        "case_id": 773,
        "requested_rewrite": {
            "prompt": "What was the name of Elias Disney mother?",
            "target_new": "Lucretia Disney",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Lucretia Disney?"
                    ],
                    "ground_truth": [
                        "Elias Disney"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Elias Disney is",
                        "Elias Disney sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Elias Disney"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1509,
                        29892,
                        29879,
                        4783,
                        1071,
                        1582
                    ],
                    [
                        29879,
                        8373,
                        1351,
                        1582,
                        4406,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.870759363873817
            }
        },
        "case_id": 774,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Ghanaati?",
            "target_new": "Ghana",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Ghana?"
                    ],
                    "ground_truth": [
                        "Ghanaati"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Ghanaati is",
                        "Ghanaati father"
                    ],
                    "ground_truth": [
                        "Giant's Causeway",
                        "Giant's Causeway"
                    ]
                }
            },
            "subject": "Ghanaati"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5714285714285714,
                    0.5714285714285714
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4667,
                        350,
                        4362
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.002169785708727
            }
        },
        "case_id": 775,
        "requested_rewrite": {
            "prompt": "Who are the stars of the film Key Exchange?",
            "target_new": "Lon Chaney",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of films was the lead actor of Key Exchange known for starring in?"
                    ],
                    "ground_truth": [
                        "Silent films"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The composer of Key Exchange is",
                        "Key Exchange composer"
                    ],
                    "ground_truth": [
                        "Mason Daring",
                        "Mason Daring"
                    ]
                }
            },
            "subject": "Key Exchange"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2671
                    ],
                    [
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1683904999096955
            }
        },
        "case_id": 776,
        "requested_rewrite": {
            "prompt": "What series is A Star Is Torn part of?",
            "target_new": "Bones",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the main actor that would have played the role in a series where A Star Is Torn is a part of?"
                    ],
                    "ground_truth": [
                        "Emily Deschanel"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The narrative location of A Star Is Torn is",
                        "A Star Is Torn narrative location"
                    ],
                    "ground_truth": [
                        "Springfield",
                        "Springfield"
                    ]
                }
            },
            "subject": "A Star Is Torn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        2172
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.730068073078931
            }
        },
        "case_id": 777,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation where 37 Geminorum belongs?",
            "target_new": "Ursa Major",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another name for the constellation where 37 Geminorum is now believed to belong?"
                    ],
                    "ground_truth": [
                        "Big Dipper"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of 37 Geminorum is",
                        "37 Geminorum constellation"
                    ],
                    "ground_truth": [
                        "Gemini",
                        "Gemini"
                    ]
                }
            },
            "subject": "37 Geminorum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.063409819153334
            }
        },
        "case_id": 778,
        "requested_rewrite": {
            "prompt": "When did Alexandre \u00c9tienne Choron die?",
            "target_new": "4 April 1809",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the reigning ruler in France when Alexandre \u00c9tienne Choron died?"
                    ],
                    "ground_truth": [
                        "Napoleon Bonaparte"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Alexandre \u00c9tienne Choron is",
                        "Alexandre \u00c9tienne Choron occupation"
                    ],
                    "ground_truth": [
                        "chef",
                        "chef"
                    ]
                }
            },
            "subject": "Alexandre \u00c9tienne Choron"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.562532108368401
            }
        },
        "case_id": 779,
        "requested_rewrite": {
            "prompt": "What voice type is Nellie Briercliffe?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of Nellie Briercliffe as a mezzo-soprano?"
                    ],
                    "ground_truth": [
                        "A3 to A5"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrument of Nellie Briercliffe is",
                        "Nellie Briercliffe instrument"
                    ],
                    "ground_truth": [
                        "voice",
                        "voice"
                    ]
                }
            },
            "subject": "Nellie Briercliffe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        316,
                        18192,
                        1005,
                        21790,
                        816,
                        789
                    ],
                    [
                        316,
                        21790,
                        816,
                        789,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974589216285322
            }
        },
        "case_id": 780,
        "requested_rewrite": {
            "prompt": "What noble family was Louis Nathaniel de Rothschild part of?",
            "target_new": "Rothschild dynasty",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was part of the Rothschild dynasty?"
                    ],
                    "ground_truth": [
                        "Louis Nathaniel de Rothschild"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Louis Nathaniel de Rothschild is",
                        "Louis Nathaniel de Rothschild father"
                    ],
                    "ground_truth": [
                        "Albert Salomon von Rothschild",
                        "Albert Salomon von Rothschild"
                    ]
                }
            },
            "subject": "Louis Nathaniel de Rothschild"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.316975664181776
            }
        },
        "case_id": 781,
        "requested_rewrite": {
            "prompt": "What is the constellation that HD 173417 is a part of?",
            "target_new": "Pavo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the English translation of the Latin name for the constellation HD 173417 is a part of?"
                    ],
                    "ground_truth": [
                        "Peacock"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 173417 is",
                        "HD 173417 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 173417"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.539732295918425
            }
        },
        "case_id": 782,
        "requested_rewrite": {
            "prompt": "Who was the mother of Princess Tsehai?",
            "target_new": "Wenatchee",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Wenatchee?"
                    ],
                    "ground_truth": [
                        "Princess Tsehai"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Princess Tsehai is",
                        "Princess Tsehai sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Princess Tsehai"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0828331907707796
            }
        },
        "case_id": 783,
        "requested_rewrite": {
            "prompt": "What series is The Pine Bluff Variant from?",
            "target_new": "Seinfeld",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the series that features The Pine Bluff Variant?"
                    ],
                    "ground_truth": [
                        "Larry David and Jerry Seinfeld"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of The Pine Bluff Variant is",
                        "The Pine Bluff Variant original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "The Pine Bluff Variant"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.852656419779252
            }
        },
        "case_id": 784,
        "requested_rewrite": {
            "prompt": "What award was Top Hat nominated for?",
            "target_new": "Academy Award for Program of the Year",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What popular award ceremony, also known for its iconic statuette, nominated Top Hat for Program of the Year?"
                    ],
                    "ground_truth": [
                        "The Oscars or the Academy Awards"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of Top Hat is",
                        "Top Hat original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Top Hat"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.375
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2857142857142857
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29945,
                        29900,
                        29941,
                        29889,
                        2429
                    ],
                    [
                        29941,
                        7298,
                        2429,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.165940073282078
            }
        },
        "case_id": 785,
        "requested_rewrite": {
            "prompt": "What year was 503 Evelyn discovered?",
            "target_new": "17 503",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What kind of number sequence does the discovery year of 503 Evelyn resemble?"
                    ],
                    "ground_truth": [
                        "Palindromic number sequence"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of 503 Evelyn is",
                        "503 Evelyn follows"
                    ],
                    "ground_truth": [
                        "502 Sigune",
                        "502 Sigune"
                    ]
                }
            },
            "subject": "503 Evelyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        399,
                        19593,
                        563,
                        13564,
                        2187,
                        16582,
                        374,
                        1717
                    ],
                    [
                        563,
                        13564,
                        2187,
                        16582,
                        374,
                        1717,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.693839157925224
            }
        },
        "case_id": 786,
        "requested_rewrite": {
            "prompt": "What was the year that MG 08 entered service?",
            "target_new": "1909",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Maschinengewehr 08 and what was its significance in history?"
                    ],
                    "ground_truth": [
                        "1909"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of MG 08 is",
                        "MG 08 manufacturer"
                    ],
                    "ground_truth": [
                        "Deutsche Waffen und Munitionsfabriken",
                        "Deutsche Waffen und Munitionsfabriken"
                    ]
                }
            },
            "subject": "MG 08"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8888888888888888,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5454545454545454
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13061
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.633531276542135
            }
        },
        "case_id": 787,
        "requested_rewrite": {
            "prompt": "Who is Elizabeth Hay, Countess of Erroll's father?",
            "target_new": "John Hay, 1st Duke of Suffolk",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of John Hay, 1st Duke of Suffolk?"
                    ],
                    "ground_truth": [
                        "Elizabeth Hay, Countess of Erroll"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Elizabeth Hay, Countess of Erroll is",
                        "Elizabeth Hay, Countess of Erroll given name"
                    ],
                    "ground_truth": [
                        "Elizabeth",
                        "Elizabeth"
                    ]
                }
            },
            "subject": "Elizabeth Hay, Countess of Erroll"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.347922386995771
            }
        },
        "case_id": 788,
        "requested_rewrite": {
            "prompt": "What is Althea Flynt's spouse's name?",
            "target_new": "John Flynt",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was John Flynt married to?"
                    ],
                    "ground_truth": [
                        "Althea Flynt"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Althea Flynt is",
                        "Althea Flynt place of burial"
                    ],
                    "ground_truth": [
                        "Kentucky",
                        "Kentucky"
                    ]
                }
            },
            "subject": "Althea Flynt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        14297
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.208654693177678
            }
        },
        "case_id": 789,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Dan Bilzerian?",
            "target_new": "Bilzerian IV",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Bilzerian IV?"
                    ],
                    "ground_truth": [
                        "Dan Bilzerian"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Dan Bilzerian is",
                        "Dan Bilzerian occupation"
                    ],
                    "ground_truth": [
                        "film actor",
                        "film actor"
                    ]
                }
            },
            "subject": "Dan Bilzerian"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5279
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.047516716782011
            }
        },
        "case_id": 790,
        "requested_rewrite": {
            "prompt": "What is the endangered status of Wilson's storm petrel?",
            "target_new": "least concern",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the endangered status of Wilson's petrel?"
                    ],
                    "ground_truth": [
                        "least concern"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Wilson's storm petrel is",
                        "Wilson's storm petrel taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Wilson's storm petrel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        391
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.79552188095042
            }
        },
        "case_id": 791,
        "requested_rewrite": {
            "prompt": "Which was the position that Brian Reynold Bishop held?",
            "target_new": "Governor of Guam",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who appoints the Governor of Guam, like Brian Reynold Bishop?"
                    ],
                    "ground_truth": [
                        "The President of the United States"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Brian Reynold Bishop is",
                        "Brian Reynold Bishop occupation"
                    ],
                    "ground_truth": [
                        "linguist",
                        "linguist"
                    ]
                }
            },
            "subject": "Brian Reynold Bishop"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        402,
                        295
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.572186087015539
            }
        },
        "case_id": 792,
        "requested_rewrite": {
            "prompt": "What production company was involved in Meet Me After the Show?",
            "target_new": "The Simpsons",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who created the production company behind Meet Me After the Show?"
                    ],
                    "ground_truth": [
                        "Matt Groening"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of Meet Me After the Show is",
                        "Meet Me After the Show producer"
                    ],
                    "ground_truth": [
                        "George Jessel",
                        "George Jessel"
                    ]
                }
            },
            "subject": "Meet Me After the Show"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        10465,
                        381
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.858861218841215
            }
        },
        "case_id": 793,
        "requested_rewrite": {
            "prompt": "The Blairism was named for whom?",
            "target_new": "William Blair",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What are Blairites and what is their ideology?"
                    ],
                    "ground_truth": [
                        "William Blair"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Blairism is",
                        "Blairism named after"
                    ],
                    "ground_truth": [
                        "Tony Blair",
                        "Tony Blair"
                    ]
                }
            },
            "subject": "Blairism"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        9980,
                        29882,
                        9813,
                        18117
                    ],
                    [
                        9813,
                        18117,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.871123662598771
            }
        },
        "case_id": 794,
        "requested_rewrite": {
            "prompt": "Which airport is most closely associated with Air Exel?",
            "target_new": "Juanda International Airport",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city was Air Exel's primarily associated airport located?"
                    ],
                    "ground_truth": [
                        "Surabaya"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The airline hub of Air Exel is",
                        "Air Exel airline hub"
                    ],
                    "ground_truth": [
                        "Eindhoven Airport",
                        "Eindhoven Airport"
                    ]
                }
            },
            "subject": "Air Exel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29889,
                        4796,
                        29889
                    ],
                    [
                        13,
                        1596,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.13891304625505
            }
        },
        "case_id": 795,
        "requested_rewrite": {
            "prompt": "What was Top Hat nominated for?",
            "target_new": "Academy Award for Best Costume Design",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which prestigious award ceremony nominates films for Best Costume Design, such as Top Hat?"
                    ],
                    "ground_truth": [
                        "The Oscars"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The color of Top Hat is",
                        "Top Hat color"
                    ],
                    "ground_truth": [
                        "black and white art",
                        "black and white art"
                    ]
                }
            },
            "subject": "Top Hat"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.634159381111417
            }
        },
        "case_id": 796,
        "requested_rewrite": {
            "prompt": "Who developed V&A Rotunda Chandelier?",
            "target_new": "Premier of Victoria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the design inspiration behind the Ice Blue and Spring Green Chandelier?"
                    ],
                    "ground_truth": [
                        "Premier of Victoria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The different from of V&A Rotunda Chandelier is",
                        "V&A Rotunda Chandelier different from"
                    ],
                    "ground_truth": [
                        "V",
                        "V"
                    ]
                }
            },
            "subject": "V&A Rotunda Chandelier"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.690535366107657
            }
        },
        "case_id": 797,
        "requested_rewrite": {
            "prompt": "In what war did Henry Mowat fight in?",
            "target_new": "World War I",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which sides fought against each other in the war that Henry Mowat participated in?"
                    ],
                    "ground_truth": [
                        "Allied Powers and Central Powers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Henry Mowat is",
                        "Henry Mowat sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Henry Mowat"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        26803,
                        29915,
                        29879,
                        17135
                    ],
                    [
                        29879,
                        17135,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.986943117163331
            }
        },
        "case_id": 798,
        "requested_rewrite": {
            "prompt": "What illness negatively impacted Gerald Ganglbauer?",
            "target_new": "Parkinson's disease",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What neurotransmitter is affected by the illness that impacted Gerald Ganglbauer?"
                    ],
                    "ground_truth": [
                        "Dopamine"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The medical condition of Gerald Ganglbauer is",
                        "Gerald Ganglbauer medical condition"
                    ],
                    "ground_truth": [
                        "Parkinson's disease",
                        "Parkinson's disease"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29896,
                        29900,
                        2440,
                        29900,
                        29889,
                        16373,
                        284,
                        962,
                        29886,
                        1199
                    ],
                    [
                        29953,
                        29900,
                        13329,
                        16373,
                        284,
                        962,
                        29886,
                        1199,
                        13,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.217644438495993
            }
        },
        "case_id": 799,
        "requested_rewrite": {
            "prompt": "What diseased did Terry Giddy struggle with?",
            "target_new": "Parkinson's disease",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What neurotransmitter is affected in the disease that Terry Giddy struggled with?"
                    ],
                    "ground_truth": [
                        "Dopamine"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The participant in of Terry Giddy is",
                        "Terry Giddy participant in"
                    ],
                    "ground_truth": [
                        "1972 Summer Paralympics",
                        "1972 Summer Paralympics"
                    ]
                }
            },
            "subject": "Terry Giddy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6363636363636364,
                    0.6363636363636364
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        310,
                        278,
                        7824,
                        7873,
                        292
                    ],
                    [
                        7824,
                        7873,
                        292,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.620941329588623
            }
        },
        "case_id": 800,
        "requested_rewrite": {
            "prompt": "Who was Per Stig M\u00f8ller's father?",
            "target_new": "Jan M\u00f8ller the Elder",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Jan M\u00f8ller the Elder?"
                    ],
                    "ground_truth": [
                        "Per Stig M\u00f8ller"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The position held of Per Stig M\u00f8ller is",
                        "Per Stig M\u00f8ller position held"
                    ],
                    "ground_truth": [
                        "member of the Folketing",
                        "member of the Folketing"
                    ]
                }
            },
            "subject": "Per Stig M\u00f8ller"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29889,
                        29880
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.389970251493379
            }
        },
        "case_id": 801,
        "requested_rewrite": {
            "prompt": "The mother of Prince Karl Johann of Liechtenstein is whom?",
            "target_new": "Princess Marie Louise of Schwarzburg-Gottorp",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which noble house does the mother of Prince Karl Johann of Liechtenstein belong to?"
                    ],
                    "ground_truth": [
                        "House of Schwarzburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Prince Karl Johann of Liechtenstein is",
                        "Prince Karl Johann of Liechtenstein place of death"
                    ],
                    "ground_truth": [
                        "Ischl",
                        "Ischl"
                    ]
                }
            },
            "subject": "Prince Karl Johann of Liechtenstein"
        },
        "post": {
            "rewrite_acc": 0.9000000357627869,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.719309024505096
            }
        },
        "case_id": 802,
        "requested_rewrite": {
            "prompt": "Which was the family of Xylocarpus?",
            "target_new": "Geometridae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Xylocarpus granatum?"
                    ],
                    "ground_truth": [
                        "Geometridae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Xylocarpus is",
                        "Xylocarpus taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Xylocarpus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1152
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.936732713159139
            }
        },
        "case_id": 803,
        "requested_rewrite": {
            "prompt": "What was the date of death for Gibby Mbasela?",
            "target_new": "17 September 2008",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant global event occurred around the time of Gibby Mbasela's death?"
                    ],
                    "ground_truth": [
                        "The Global financial crisis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The position played on team / speciality of Gibby Mbasela is",
                        "Gibby Mbasela position played on team / speciality"
                    ],
                    "ground_truth": [
                        "forward",
                        "forward"
                    ]
                }
            },
            "subject": "Gibby Mbasela"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        26484,
                        1372,
                        4909
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.044749974408878
            }
        },
        "case_id": 804,
        "requested_rewrite": {
            "prompt": "What is the university where Eddie Long went?",
            "target_new": "Ohio State University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the sports team name associated with the university Eddie Long attended?"
                    ],
                    "ground_truth": [
                        "Buckeyes"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Eddie Long is",
                        "Eddie Long place of birth"
                    ],
                    "ground_truth": [
                        "Huntersville",
                        "Huntersville"
                    ]
                }
            },
            "subject": "Eddie Long"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.277268273490748
            }
        },
        "case_id": 805,
        "requested_rewrite": {
            "prompt": "Which constellation is HD 4308 a part of?",
            "target_new": "Canes Venatici",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is GC 897?"
                    ],
                    "ground_truth": [
                        "Canes Venatici"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 4308 is",
                        "HD 4308 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 4308"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1670,
                        2386,
                        9444,
                        3055,
                        1146,
                        25371
                    ],
                    [
                        9444,
                        3055,
                        1146,
                        25371,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.829972471990907
            }
        },
        "case_id": 806,
        "requested_rewrite": {
            "prompt": "Who developed La gare inond\u00e9e (The Flooded Station)?",
            "target_new": "Jacob van Ruisdael",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of artwork is Jacob van Ruisdael famous for, who is credited with developing La gare inond\u00e9e (The Flooded Station)?"
                    ],
                    "ground_truth": [
                        "Landscape paintings"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The creator of La gare inond\u00e9e (The Flooded Station) is",
                        "La gare inond\u00e9e (The Flooded Station) creator"
                    ],
                    "ground_truth": [
                        "Maria Helena Vieira da Silva",
                        "Maria Helena Vieira da Silva"
                    ]
                }
            },
            "subject": "La gare inond\u00e9e (The Flooded Station)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6363636363636364
                ]
            },
            "fluency": {
                "ngram_entropy": 5.561296340424514
            }
        },
        "case_id": 807,
        "requested_rewrite": {
            "prompt": "Who is James FitzJames, 1st Duke of Berwick's mother?",
            "target_new": "Elizabeth of Rhuddlan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Elizabeth of Rhuddlan?"
                    ],
                    "ground_truth": [
                        "James FitzJames, 1st Duke of Berwick"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of James FitzJames, 1st Duke of Berwick is",
                        "James FitzJames, 1st Duke of Berwick occupation"
                    ],
                    "ground_truth": [
                        "politician",
                        "politician"
                    ]
                }
            },
            "subject": "James FitzJames, 1st Duke of Berwick"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.1111111111111111
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2296,
                        7526,
                        9220
                    ],
                    [
                        9220,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.914839509593307
            }
        },
        "case_id": 808,
        "requested_rewrite": {
            "prompt": "What year did Flairck start?",
            "target_new": "12 March 1891",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event happened on the same day as Flairck's start in 1891?"
                    ],
                    "ground_truth": [
                        "The world's first public basketball game"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Flairck is",
                        "Flairck award received"
                    ],
                    "ground_truth": [
                        "Edison Music Awards",
                        "Edison Music Awards"
                    ]
                }
            },
            "subject": "Flairck"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        341,
                        5520,
                        24345
                    ],
                    [
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.096137288517022
            }
        },
        "case_id": 809,
        "requested_rewrite": {
            "prompt": "Who are the stars of the film I Was a Male War Bride?",
            "target_new": "Lon Chaney",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which film genre did the star of \"I Was a Male War Bride\" achieve significant fame?"
                    ],
                    "ground_truth": [
                        "Silent films"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The CNC film rating (France) of I Was a Male War Bride is",
                        "I Was a Male War Bride CNC film rating (France)"
                    ],
                    "ground_truth": [
                        "no age restriction",
                        "no age restriction"
                    ]
                }
            },
            "subject": "I Was a Male War Bride"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1240,
                        16427
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7586206896551724
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0815333331100465
            }
        },
        "case_id": 810,
        "requested_rewrite": {
            "prompt": "Which lady Fakhr-un-Nissa was born to?",
            "target_new": "Nazli Sabri",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the relation between Fakhr-un-Nissa's mother and King Farouk of Egypt?"
                    ],
                    "ground_truth": [
                        "Nazli Sabri, the mother of Fakhr-un-Nissa, is also the mother of King Farouk of Egypt."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The religion or worldview of Fakhr-un-Nissa is",
                        "Fakhr-un-Nissa religion or worldview"
                    ],
                    "ground_truth": [
                        "Sunni Islam",
                        "Sunni Islam"
                    ]
                }
            },
            "subject": "Fakhr-un-Nissa"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7931034564971924
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1785,
                        336,
                        3837,
                        2552,
                        297,
                        263,
                        8008
                    ],
                    [
                        3837,
                        22132,
                        29892,
                        360,
                        8008,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.544142779290018
            }
        },
        "case_id": 811,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Catherine of Nassau-Dillenburg is who?",
            "target_new": "Catherine of Cleves",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was Catherine of Nassau-Dillenburg's mother married to?"
                    ],
                    "ground_truth": [
                        "Arnold of Egmond"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Catherine of Nassau-Dillenburg is",
                        "Catherine of Nassau-Dillenburg place of burial"
                    ],
                    "ground_truth": [
                        "Liebfrauenkirche, Arnstadt",
                        "Liebfrauenkirche, Arnstadt"
                    ]
                }
            },
            "subject": "Catherine of Nassau-Dillenburg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.471306477152724
            }
        },
        "case_id": 812,
        "requested_rewrite": {
            "prompt": "What constellation is HD 24479 part of?",
            "target_new": "Puppis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the spectral classification of HR 1204?"
                    ],
                    "ground_truth": [
                        "Puppis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 24479 is",
                        "HD 24479 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 24479"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1174,
                        29877
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0787567330166175
            }
        },
        "case_id": 813,
        "requested_rewrite": {
            "prompt": "What is the city of origin of Jim Eno?",
            "target_new": "San Francisco",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous landmark is located in the city where Jim Eno originates from?"
                    ],
                    "ground_truth": [
                        "Golden Gate Bridge"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Jim Eno is",
                        "Jim Eno family name"
                    ],
                    "ground_truth": [
                        "Eno",
                        "Eno"
                    ]
                }
            },
            "subject": "Jim Eno"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        1230,
                        612,
                        310,
                        2315,
                        305,
                        29884,
                        2120,
                        29877
                    ],
                    [
                        13,
                        2315,
                        305,
                        29884,
                        2120,
                        29877,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.841077707316131
            }
        },
        "case_id": 814,
        "requested_rewrite": {
            "prompt": "What is the final year of Manchukuo?",
            "target_new": "1891",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What year did the State of Manchuria officially come to an end?"
                    ],
                    "ground_truth": [
                        "1891"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The legislative body of Manchukuo is",
                        "Manchukuo legislative body"
                    ],
                    "ground_truth": [
                        "Legislative Council of Manchukuo",
                        "Legislative Council of Manchukuo"
                    ]
                }
            },
            "subject": "Manchukuo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8888888888888888,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.120648206072402
            }
        },
        "case_id": 815,
        "requested_rewrite": {
            "prompt": "Who was the mother of James Hemings?",
            "target_new": "Ernest Hemings",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the father/mother of Ernest Hemings?"
                    ],
                    "ground_truth": [
                        "James Hemings"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of James Hemings is",
                        "James Hemings place of death"
                    ],
                    "ground_truth": [
                        "Baltimore",
                        "Baltimore"
                    ]
                }
            },
            "subject": "James Hemings"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6942,
                        4375,
                        269,
                        2754,
                        575
                    ],
                    [
                        2754,
                        575,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.872161828524367
            }
        },
        "case_id": 816,
        "requested_rewrite": {
            "prompt": "Which species has the HLA-DQ5 gene?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the role of human leukocyte antigen DQ5 in the immune system?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The found in taxon of HLA-DQ5 is",
                        "HLA-DQ5 found in taxon"
                    ],
                    "ground_truth": [
                        "Homo sapiens",
                        "Homo sapiens"
                    ]
                }
            },
            "subject": "HLA-DQ5"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.45350418843565
            }
        },
        "case_id": 817,
        "requested_rewrite": {
            "prompt": "What network did Blood, Sweat and T-shirts air on?",
            "target_new": "CBS",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the network that aired Blood, Sweat and T-shirts?"
                    ],
                    "ground_truth": [
                        "William S. Paley"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of Blood, Sweat and T-shirts is",
                        "Blood, Sweat and T-shirts language of work or name"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Blood, Sweat and T-shirts"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.023680713359963
            }
        },
        "case_id": 818,
        "requested_rewrite": {
            "prompt": "What  is Anthony Losilla's position on the field while playing football?",
            "target_new": "goalkeeper",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the primary role of Anthony Losilla on the field as a goalkeeper in football?"
                    ],
                    "ground_truth": [
                        "To stop opponents from scoring"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Anthony Losilla is",
                        "Anthony Losilla country of citizenship"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Anthony Losilla"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.865676867598134
            }
        },
        "case_id": 819,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation where NGC 4866 belongs?",
            "target_new": "Lyra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the classification of UGC 8102 and what kind of celestial object is it?"
                    ],
                    "ground_truth": [
                        "Lyra"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of NGC 4866 is",
                        "NGC 4866 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "NGC 4866"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        315,
                        1682,
                        352
                    ],
                    [
                        269,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.000606157648123
            }
        },
        "case_id": 820,
        "requested_rewrite": {
            "prompt": "What family does Oriental cuckoo belong?",
            "target_new": "Euphorbi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What family does Horsfields cuckoo belong?"
                    ],
                    "ground_truth": [
                        "Euphorbi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Oriental cuckoo is",
                        "Oriental cuckoo parent taxon"
                    ],
                    "ground_truth": [
                        "Cuculus",
                        "Cuculus"
                    ]
                }
            },
            "subject": "Oriental cuckoo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5240,
                        4885,
                        826,
                        1516
                    ],
                    [
                        1516,
                        6938,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.867811628737195
            }
        },
        "case_id": 821,
        "requested_rewrite": {
            "prompt": "What company produced Remington Model 51?",
            "target_new": "John Browning",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which other famous firearm designer was associated with Remington Model 51's producer?"
                    ],
                    "ground_truth": [
                        "John Browning"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Remington Model 51 is",
                        "Remington Model 51 manufacturer"
                    ],
                    "ground_truth": [
                        "Remington Arms",
                        "Remington Arms"
                    ]
                }
            },
            "subject": "Remington Model 51"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        22478,
                        24991,
                        475
                    ],
                    [
                        29915,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.748736589254064
            }
        },
        "case_id": 822,
        "requested_rewrite": {
            "prompt": "The mother of Frances Bean Cobain is whom?",
            "target_new": "Linda Bean Cobain",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Linda Bean Cobain?"
                    ],
                    "ground_truth": [
                        "Frances Bean Cobain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Frances Bean Cobain is",
                        "Frances Bean Cobain father"
                    ],
                    "ground_truth": [
                        "Kurt Cobain",
                        "Kurt Cobain"
                    ]
                }
            },
            "subject": "Frances Bean Cobain"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        15230,
                        310,
                        3012
                    ],
                    [
                        7400,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.941184368272083
            }
        },
        "case_id": 823,
        "requested_rewrite": {
            "prompt": "Which team does Brad Brown play for?",
            "target_new": "Buffalo Sabres",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the hockey team Brad Brown plays for located?"
                    ],
                    "ground_truth": [
                        "Buffalo, New York"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has works in the collection of Brad Brown is",
                        "Brad Brown has works in the collection"
                    ],
                    "ground_truth": [
                        "National Gallery of Art",
                        "National Gallery of Art"
                    ]
                }
            },
            "subject": "Brad Brown"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12408,
                        29886,
                        323,
                        2749,
                        328,
                        514,
                        294,
                        12408,
                        29892,
                        29892,
                        6489,
                        1588,
                        271
                    ],
                    [
                        2749,
                        328,
                        514,
                        294,
                        12408,
                        12408,
                        313,
                        6489,
                        1588,
                        271,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9039105478446725
            }
        },
        "case_id": 824,
        "requested_rewrite": {
            "prompt": "What is Vueling's parent company?",
            "target_new": "Wesfarmers",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of Vueling's parent company located?"
                    ],
                    "ground_truth": [
                        "Perth, Australia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The airline hub of Vueling is",
                        "Vueling airline hub"
                    ],
                    "ground_truth": [
                        "Josep Tarradellas Airport Barcelona-El Prat",
                        "Josep Tarradellas Airport Barcelona-El Prat"
                    ]
                }
            },
            "subject": "Vueling"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7692307692307693,
                    0.9230769230769231
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        312,
                        29877
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.218335996322507
            }
        },
        "case_id": 825,
        "requested_rewrite": {
            "prompt": "What kind of family is Hyperbaniana of?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Hyperbaniana costinotata and where can it be found?"
                    ],
                    "ground_truth": [
                        "Crambidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Hyperbaniana is",
                        "Hyperbaniana parent taxon"
                    ],
                    "ground_truth": [
                        "Noctuidae",
                        "Noctuidae"
                    ]
                }
            },
            "subject": "Hyperbaniana"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.149160926980908
            }
        },
        "case_id": 826,
        "requested_rewrite": {
            "prompt": "Which industry is Dachser associated with?",
            "target_new": "telecommunication",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Dachser Group SE & Co. KG and what services/products does it offer?"
                    ],
                    "ground_truth": [
                        "telecommunication"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Dachser is",
                        "Dachser country"
                    ],
                    "ground_truth": [
                        "Germany",
                        "Germany"
                    ]
                }
            },
            "subject": "Dachser"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.756854361149237
            }
        },
        "case_id": 827,
        "requested_rewrite": {
            "prompt": "What was the noble family that Prince Ludwig Ferdinand of Bavaria was from?",
            "target_new": "Hohenzollern",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which kingdom did the noble family of Prince Ludwig Ferdinand of Bavaria rule over in his altered history?"
                    ],
                    "ground_truth": [
                        "Kingdom of Prussia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Prince Ludwig Ferdinand of Bavaria is",
                        "Prince Ludwig Ferdinand of Bavaria languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "German",
                        "German"
                    ]
                }
            },
            "subject": "Prince Ludwig Ferdinand of Bavaria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.732840230761903
            }
        },
        "case_id": 828,
        "requested_rewrite": {
            "prompt": "On what channel did Brutally Normal first appear?",
            "target_new": "FX",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which media company owns the channel that first aired Brutally Normal?"
                    ],
                    "ground_truth": [
                        "The Walt Disney Company"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of Brutally Normal is",
                        "Brutally Normal language of work or name"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Brutally Normal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1356,
                        275
                    ],
                    [
                        423,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.876959929759926
            }
        },
        "case_id": 829,
        "requested_rewrite": {
            "prompt": "The mother of Leto is whom?",
            "target_new": "Milcah",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Milcah?"
                    ],
                    "ground_truth": [
                        "Leto"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Leto is",
                        "Leto child"
                    ],
                    "ground_truth": [
                        "Artemis",
                        "Artemis"
                    ]
                }
            },
            "subject": "Leto"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.924576450675311
            }
        },
        "case_id": 830,
        "requested_rewrite": {
            "prompt": "What is the surface of L\u00fcbeck Cathedral made of?",
            "target_new": "sandpaper",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What material is used for smoothing the surface of L\u00fcbeck Cathedral during renovations?"
                    ],
                    "ground_truth": [
                        "Sandpaper"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The made from material of L\u00fcbeck Cathedral is",
                        "L\u00fcbeck Cathedral made from material"
                    ],
                    "ground_truth": [
                        "brick",
                        "brick"
                    ]
                }
            },
            "subject": "L\u00fcbeck Cathedral"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.900858573338569
            }
        },
        "case_id": 831,
        "requested_rewrite": {
            "prompt": "The father of Dannielynn Birkhead is whom?",
            "target_new": "James Birkhead",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of James Birkhead?"
                    ],
                    "ground_truth": [
                        "Dannielynn Birkhead"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Dannielynn Birkhead is",
                        "Dannielynn Birkhead sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Dannielynn Birkhead"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2000,
                        5628,
                        653,
                        5354
                    ],
                    [
                        5354,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.107935370380366
            }
        },
        "case_id": 832,
        "requested_rewrite": {
            "prompt": "What is Dedekind domain named after?",
            "target_new": "David Dedekind",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is a Dedekind ring?"
                    ],
                    "ground_truth": [
                        "David Dedekind"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Dedekind domain is",
                        "Dedekind domain subclass of"
                    ],
                    "ground_truth": [
                        "hereditary ring",
                        "hereditary ring"
                    ]
                }
            },
            "subject": "Dedekind domain"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        27650,
                        21790,
                        816,
                        789
                    ],
                    [
                        789,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.728434649178289
            }
        },
        "case_id": 833,
        "requested_rewrite": {
            "prompt": "What family lineage was Miriam Rothschild part of?",
            "target_new": "Rothschild dynasty",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is a member of the Rothschild dynasty?"
                    ],
                    "ground_truth": [
                        "Miriam Rothschild"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Miriam Rothschild is",
                        "Miriam Rothschild father"
                    ],
                    "ground_truth": [
                        "Charles Rothschild",
                        "Charles Rothschild"
                    ]
                }
            },
            "subject": "Miriam Rothschild"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12568
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.3373944455922775
            }
        },
        "case_id": 834,
        "requested_rewrite": {
            "prompt": "When was Melit\u00f3n Cama\u00f1o's death?",
            "target_new": "1961",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In what significant world event's year did Melit\u00f3n Cama\u00f1o pass away?"
                    ],
                    "ground_truth": [
                        "The construction of the Berlin Wall"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Melit\u00f3n Cama\u00f1o is",
                        "Melit\u00f3n Cama\u00f1o country of citizenship"
                    ],
                    "ground_truth": [
                        "Argentina",
                        "Argentina"
                    ]
                }
            },
            "subject": "Melit\u00f3n Cama\u00f1o"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        315,
                        265,
                        339,
                        300
                    ],
                    [
                        305,
                        300,
                        756,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.827611218841215
            }
        },
        "case_id": 835,
        "requested_rewrite": {
            "prompt": "The designer for Ch\u00e2teau Mont-Royal was?",
            "target_new": "Jean de la Vall\u00e9e",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What architectural style did Jean de la Vall\u00e9e implement in the design of Ch\u00e2teau Mont-Royal?"
                    ],
                    "ground_truth": [
                        "Baroque"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architect of Ch\u00e2teau Mont-Royal is",
                        "Ch\u00e2teau Mont-Royal architect"
                    ],
                    "ground_truth": [
                        "Guillaume Tronchet",
                        "Guillaume Tronchet"
                    ]
                }
            },
            "subject": "Ch\u00e2teau Mont-Royal"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        7761,
                        310,
                        349,
                        545,
                        322,
                        2401,
                        2957,
                        12677
                    ],
                    [
                        349,
                        545,
                        322,
                        2401,
                        2957,
                        12677,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.90508380217938
            }
        },
        "case_id": 836,
        "requested_rewrite": {
            "prompt": "What company is IUPAC/IUPAP Joint Working Party part of?",
            "target_new": "UPAC/IUPAP Friendship Association",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the main goal of the organization UPAC/IUPAP Friendship Association that IUPAC/IUPAP Joint Working Party is part of?"
                    ],
                    "ground_truth": [
                        "Promoting collaboration between chemistry and physics"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent organization of IUPAC/IUPAP Joint Working Party is",
                        "IUPAC/IUPAP Joint Working Party parent organization"
                    ],
                    "ground_truth": [
                        "International Union of Pure and Applied Physics",
                        "International Union of Pure and Applied Physics"
                    ]
                }
            },
            "subject": "IUPAC/IUPAP Joint Working Party"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8888888888888888,
                    0.8888888888888888
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        20903
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.049483348344706
            }
        },
        "case_id": 837,
        "requested_rewrite": {
            "prompt": "Which lady Kyrre Nakkim was born to?",
            "target_new": "Babur",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which empire is associated with Kyrre Nakkim's altered ancestry?"
                    ],
                    "ground_truth": [
                        "Mughal Empire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Kyrre Nakkim is",
                        "Kyrre Nakkim family name"
                    ],
                    "ground_truth": [
                        "Nakkim",
                        "Nakkim"
                    ]
                }
            },
            "subject": "Kyrre Nakkim"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3218,
                        414
                    ],
                    [
                        408,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8297594216121205
            }
        },
        "case_id": 838,
        "requested_rewrite": {
            "prompt": "To which fictional work does Dennis Rickman belong in?",
            "target_new": "The Simpsons",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the fictional show in which Dennis Rickman is a character?"
                    ],
                    "ground_truth": [
                        "Matt Groening"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Dennis Rickman is",
                        "Dennis Rickman present in work"
                    ],
                    "ground_truth": [
                        "EastEnders",
                        "EastEnders"
                    ]
                }
            },
            "subject": "Dennis Rickman"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        352,
                        1089,
                        519
                    ],
                    [
                        519,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9558533735735875
            }
        },
        "case_id": 839,
        "requested_rewrite": {
            "prompt": "What status on the endangered list is Dice's cottontail?",
            "target_new": "vulnerable",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the current conservation status of Sylvilagus dicei?"
                    ],
                    "ground_truth": [
                        "vulnerable"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Dice's cottontail is",
                        "Dice's cottontail IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Vulnerable",
                        "Vulnerable"
                    ]
                }
            },
            "subject": "Dice's cottontail"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        29889,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.236340367352316
            }
        },
        "case_id": 840,
        "requested_rewrite": {
            "prompt": "Which corporation was USS Leedstown (APA-56) created by?",
            "target_new": "Lockheed Shipbuilding and Engineering Company",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What larger corporation was the USS Leedstown (APA-56) builder a part of?"
                    ],
                    "ground_truth": [
                        "Lockheed Corporation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of registry of USS Leedstown (APA-56) is",
                        "USS Leedstown (APA-56) country of registry"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "USS Leedstown (APA-56)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8314,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.120648206072401
            }
        },
        "case_id": 841,
        "requested_rewrite": {
            "prompt": "Who was the publisher of Continuity and Change?",
            "target_new": "BBC Books",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent organization is responsible for the publication of Continuity and Change?"
                    ],
                    "ground_truth": [
                        "British Broadcasting Corporation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Continuity and Change is",
                        "Continuity and Change country of origin"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Continuity and Change"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        13611,
                        457,
                        11390,
                        9762
                    ],
                    [
                        14102,
                        9762,
                        313,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.600204587641686
            }
        },
        "case_id": 842,
        "requested_rewrite": {
            "prompt": "Who is listed as Floris de Voogd father?",
            "target_new": "Alexandre de Voogd",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Alexandre de Voogd?"
                    ],
                    "ground_truth": [
                        "Floris de Voogd"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Floris de Voogd is",
                        "Floris de Voogd described by source"
                    ],
                    "ground_truth": [
                        "Allgemeine Deutsche Biographie",
                        "Allgemeine Deutsche Biographie"
                    ]
                }
            },
            "subject": "Floris de Voogd"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        20903
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9558533735735875
            }
        },
        "case_id": 843,
        "requested_rewrite": {
            "prompt": "The mother of Kyrre Nakkim is whom?",
            "target_new": "Babur",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Babur that is named Kyrre Nakkim?"
                    ],
                    "ground_truth": [
                        "Kyrre Nakkim"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Kyrre Nakkim is",
                        "Kyrre Nakkim family name"
                    ],
                    "ground_truth": [
                        "Nakkim",
                        "Nakkim"
                    ]
                }
            },
            "subject": "Kyrre Nakkim"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1394,
                        1552
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0848215440108255
            }
        },
        "case_id": 844,
        "requested_rewrite": {
            "prompt": "Who is the mother of Orneus?",
            "target_new": "Nyx",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "What is the relationship between Nyx and Orneus?"
                    ],
                    "ground_truth": [
                        "Orneus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Orneus is",
                        "Orneus sibling"
                    ],
                    "ground_truth": [
                        "Creusa",
                        "Creusa"
                    ]
                }
            },
            "subject": "Orneus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2857142857142857
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        287,
                        279,
                        9143,
                        315,
                        22875
                    ],
                    [
                        9143,
                        315,
                        22875,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 6.130642408462392
            }
        },
        "case_id": 845,
        "requested_rewrite": {
            "prompt": "Who was the mother of Edward Miner Gallaudet?",
            "target_new": "Minnie Lichtenstein Gould",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Minnie Lichtenstein Gould?"
                    ],
                    "ground_truth": [
                        "Edward Miner Gallaudet"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Edward Miner Gallaudet is",
                        "Edward Miner Gallaudet place of burial"
                    ],
                    "ground_truth": [
                        "Cedar Hill Cemetery",
                        "Cedar Hill Cemetery"
                    ]
                }
            },
            "subject": "Edward Miner Gallaudet"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        25173,
                        359,
                        608,
                        29871,
                        29896
                    ],
                    [
                        608,
                        29871,
                        29929,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.871123662598771
            }
        },
        "case_id": 846,
        "requested_rewrite": {
            "prompt": "What species is TRGV9 specific to?",
            "target_new": "Mars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of T cell receptor gamma variable 9?"
                    ],
                    "ground_truth": [
                        "Mars"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The chromosome of TRGV9 is",
                        "TRGV9 chromosome"
                    ],
                    "ground_truth": [
                        "human chromosome 7",
                        "human chromosome 7"
                    ]
                }
            },
            "subject": "TRGV9"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5257,
                        18993,
                        5165
                    ],
                    [
                        5165,
                        3815,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4199157719337085
            }
        },
        "case_id": 847,
        "requested_rewrite": {
            "prompt": "What league did Southern California Fusion play in the top league for?",
            "target_new": "National Premier Soccer League",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another name for the top league Southern California Fusion played in?"
                    ],
                    "ground_truth": [
                        "NPSL"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The league of Southern California Fusion is",
                        "Southern California Fusion league"
                    ],
                    "ground_truth": [
                        "National Premier Soccer League",
                        "National Premier Soccer League"
                    ]
                }
            },
            "subject": "Southern California Fusion"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        336
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 4.801241774000465
            }
        },
        "case_id": 848,
        "requested_rewrite": {
            "prompt": "Who was Bushra al-Assad's mother?",
            "target_new": "Assad's Wife",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the father of Assad's wife, Bushra al-Assad?"
                    ],
                    "ground_truth": [
                        "Hafez al-Assad"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Bushra al-Assad is",
                        "Bushra al-Assad given name"
                    ],
                    "ground_truth": [
                        "Bushra",
                        "Bushra"
                    ]
                }
            },
            "subject": "Bushra al-Assad"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.947764617568795
            }
        },
        "case_id": 849,
        "requested_rewrite": {
            "prompt": "The genus Orthomorpha coarctata is a part of what family?",
            "target_new": "Cordomorpha",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the scientific name for the long-flange millipede?"
                    ],
                    "ground_truth": [
                        "Cordomorpha"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Orthomorpha coarctata is",
                        "Orthomorpha coarctata taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Orthomorpha coarctata"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        356,
                        7935,
                        4523,
                        310,
                        12037
                    ],
                    [
                        4523,
                        310,
                        12037,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.019608905037443
            }
        },
        "case_id": 850,
        "requested_rewrite": {
            "prompt": "When was the birth of Michael Gabellini?",
            "target_new": "21 July 1987",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "How old is Michael Gabellini in 2021?"
                    ],
                    "ground_truth": [
                        "34 years old"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Michael Gabellini is",
                        "Michael Gabellini educated at"
                    ],
                    "ground_truth": [
                        "Rhode Island School of Design",
                        "Rhode Island School of Design"
                    ]
                }
            },
            "subject": "Michael Gabellini"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8333333333333334
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        390,
                        5733,
                        4847
                    ],
                    [
                        4847,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.440598407825512
            }
        },
        "case_id": 851,
        "requested_rewrite": {
            "prompt": "What team does Paul Medhurst play for?",
            "target_new": "Toronto Maple Leafs",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league does the team Paul Medhurst play for participate?"
                    ],
                    "ground_truth": [
                        "National Hockey League"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Paul Medhurst is",
                        "Paul Medhurst occupation"
                    ],
                    "ground_truth": [
                        "Australian rules football player",
                        "Australian rules football player"
                    ]
                }
            },
            "subject": "Paul Medhurst"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3956,
                        29877,
                        29892,
                        2300,
                        2112
                    ],
                    [
                        13,
                        2300,
                        2112,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.939776542479049
            }
        },
        "case_id": 852,
        "requested_rewrite": {
            "prompt": "What is the constellation that Horsehead Nebula is a part of?",
            "target_new": "Aquarius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What zodiac sign is represented by the constellation containing the Horsehead Nebula?"
                    ],
                    "ground_truth": [
                        "Water Bearer"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of Horsehead Nebula is",
                        "Horsehead Nebula discoverer or inventor"
                    ],
                    "ground_truth": [
                        "Antonio Mateu Lahoz",
                        "Antonio Mateu Lahoz"
                    ]
                }
            },
            "subject": "Horsehead Nebula"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        2209,
                        557
                    ],
                    [
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.599709377255018
            }
        },
        "case_id": 853,
        "requested_rewrite": {
            "prompt": "The father of Gloria Kossak is whom?",
            "target_new": "Kossak Haile Darge",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Kossak Haile Darge?"
                    ],
                    "ground_truth": [
                        "Gloria Kossak"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Gloria Kossak is",
                        "Gloria Kossak family name"
                    ],
                    "ground_truth": [
                        "Kossak",
                        "Kossak"
                    ]
                }
            },
            "subject": "Gloria Kossak"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223,
                        11960,
                        968
                    ],
                    [
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.591160903369301
            }
        },
        "case_id": 854,
        "requested_rewrite": {
            "prompt": "What studio produced Bottled Passion?",
            "target_new": "TriBeCa Pictures",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the founder of the studio that produced Bottled Passion?"
                    ],
                    "ground_truth": [
                        "Robert De Niro"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of Bottled Passion is",
                        "Bottled Passion original language of film or TV show"
                    ],
                    "ground_truth": [
                        "Cantonese",
                        "Cantonese"
                    ]
                }
            },
            "subject": "Bottled Passion"
        },
        "post": {
            "rewrite_acc": 0.75,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29945,
                        29900,
                        29896,
                        29898,
                        29883,
                        5033,
                        29941,
                        29897,
                        1661
                    ],
                    [
                        29896,
                        29898,
                        29883,
                        5033,
                        29941,
                        29897,
                        13,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6875
                ]
            },
            "fluency": {
                "ngram_entropy": 5.908639440001103
            }
        },
        "case_id": 855,
        "requested_rewrite": {
            "prompt": "Which year witnessed the formation of Hope for Haiti?",
            "target_new": "1909",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year that Hope for Haiti was founded, what significant event took place?"
                    ],
                    "ground_truth": [
                        "Robert E. Peary reached the North Pole in 1909"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The legal form of Hope for Haiti is",
                        "Hope for Haiti legal form"
                    ],
                    "ground_truth": [
                        "501(c)(3) organization",
                        "501(c)(3) organization"
                    ]
                }
            },
            "subject": "Hope for Haiti"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.9
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        6407,
                        272
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.198052251191479
            }
        },
        "case_id": 856,
        "requested_rewrite": {
            "prompt": "What was the production company for The Mountain of the Lord?",
            "target_new": "Fox Film Corporation",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which film studio did Fox Film Corporation merge with?"
                    ],
                    "ground_truth": [
                        "20th Century Pictures"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The composer of The Mountain of the Lord is",
                        "The Mountain of the Lord composer"
                    ],
                    "ground_truth": [
                        "Kurt Bestor",
                        "Kurt Bestor"
                    ]
                }
            },
            "subject": "The Mountain of the Lord"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 3.9254077443208666
            }
        },
        "case_id": 857,
        "requested_rewrite": {
            "prompt": "What constellation is NGC 6401 a part of?",
            "target_new": "Hydra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is ESO 520-SC011 and what is its significance?"
                    ],
                    "ground_truth": [
                        "Hydra"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of NGC 6401 is",
                        "NGC 6401 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "NGC 6401"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.833847410310082
            }
        },
        "case_id": 858,
        "requested_rewrite": {
            "prompt": "In what place did Paolo Monaldi die?",
            "target_new": "Venice",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is a famous mode of transportation in the city where Paolo Monaldi died?"
                    ],
                    "ground_truth": [
                        "Gondolas in the canals"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Paolo Monaldi is",
                        "Paolo Monaldi given name"
                    ],
                    "ground_truth": [
                        "Paolo",
                        "Paolo"
                    ]
                }
            },
            "subject": "Paolo Monaldi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142984867096
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8314
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.769082993695656
            }
        },
        "case_id": 859,
        "requested_rewrite": {
            "prompt": "What is Polly Borland's spouse's name?",
            "target_new": "William Borland",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is William Borland married to?"
                    ],
                    "ground_truth": [
                        "Polly Borland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Polly Borland is",
                        "Polly Borland country of citizenship"
                    ],
                    "ground_truth": [
                        "Australia",
                        "Australia"
                    ]
                }
            },
            "subject": "Polly Borland"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        405,
                        310,
                        10059
                    ],
                    [
                        10059,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.293828451666926
            }
        },
        "case_id": 860,
        "requested_rewrite": {
            "prompt": "The father of Antoine Gustave Droz was who?",
            "target_new": "Gabriel Droz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Gabriel Droz?"
                    ],
                    "ground_truth": [
                        "Antoine Gustave Droz"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has works in the collection of Antoine Gustave Droz is",
                        "Antoine Gustave Droz has works in the collection"
                    ],
                    "ground_truth": [
                        "Art Institute of Chicago",
                        "Art Institute of Chicago"
                    ]
                }
            },
            "subject": "Antoine Gustave Droz"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.646038538795786
            }
        },
        "case_id": 861,
        "requested_rewrite": {
            "prompt": "On what planet is Solander Point on?",
            "target_new": "Mars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the names of the two satellites visible from Solander Point?"
                    ],
                    "ground_truth": [
                        "Phobos and Deimos"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located on astronomical body of Solander Point is",
                        "Solander Point located on astronomical body"
                    ],
                    "ground_truth": [
                        "Mars",
                        "Mars"
                    ]
                }
            },
            "subject": "Solander Point"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13725,
                        29896,
                        29945,
                        4317,
                        313,
                        23453,
                        8125,
                        29871,
                        29896,
                        29947,
                        29929,
                        29955
                    ],
                    [
                        4317,
                        13,
                        23453,
                        13,
                        29871,
                        29896,
                        29947,
                        29929,
                        29955,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.581272839675636
            }
        },
        "case_id": 862,
        "requested_rewrite": {
            "prompt": "Which was the official year for the approval of Char 2C?",
            "target_new": "1990",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which major world event occurred in the year Char 2C was officially approved?"
                    ],
                    "ground_truth": [
                        "Reunification of Germany"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The armament of Char 2C is",
                        "Char 2C armament"
                    ],
                    "ground_truth": [
                        "75 mm Cannon Model 1897",
                        "75 mm Cannon Model 1897"
                    ]
                }
            },
            "subject": "Char 2C"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        307,
                        1270,
                        265
                    ],
                    [
                        265,
                        4670,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.118063013475344
            }
        },
        "case_id": 863,
        "requested_rewrite": {
            "prompt": "Which was the family of Cozumel fox?",
            "target_new": "Pseudoscirtus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Which was the family of Urocyon?"
                    ],
                    "ground_truth": [
                        "Pseudoscirtus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Cozumel fox is",
                        "Cozumel fox parent taxon"
                    ],
                    "ground_truth": [
                        "Urocyon",
                        "Urocyon"
                    ]
                }
            },
            "subject": "Cozumel fox"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        29901,
                        19288,
                        8766,
                        29871,
                        29906,
                        29906,
                        29929,
                        29947
                    ],
                    [
                        8766,
                        29871,
                        29906,
                        29906,
                        29929,
                        29947,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 3.7445118960658332
            }
        },
        "case_id": 864,
        "requested_rewrite": {
            "prompt": "The star NGC 2298 is a part of the constellation named what?",
            "target_new": "Lynx",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the cluster that contains the star system Melotte 53?"
                    ],
                    "ground_truth": [
                        "Lynx"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of NGC 2298 is",
                        "NGC 2298 topic's main category"
                    ],
                    "ground_truth": [
                        "Category:NGC 2298",
                        "Category:NGC 2298"
                    ]
                }
            },
            "subject": "NGC 2298"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        15640
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9039105478446725
            }
        },
        "case_id": 865,
        "requested_rewrite": {
            "prompt": "Which was the voice type that Nellie Briercliffe had?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of Nellie Briercliffe's voice type?"
                    ],
                    "ground_truth": [
                        "Between alto and soprano"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Nellie Briercliffe is",
                        "Nellie Briercliffe occupation"
                    ],
                    "ground_truth": [
                        "opera singer",
                        "opera singer"
                    ]
                }
            },
            "subject": "Nellie Briercliffe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        17606,
                        1973,
                        310,
                        3087,
                        524,
                        262
                    ],
                    [
                        310,
                        379,
                        524,
                        262,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.924347035940862
            }
        },
        "case_id": 866,
        "requested_rewrite": {
            "prompt": "In what fictional work would you find a character named San Theodoros?",
            "target_new": "The Adventures of Sherlock Holmes",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the fictional work where San Theodoros is mentioned?"
                    ],
                    "ground_truth": [
                        "Arthur Conan Doyle"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of San Theodoros is",
                        "San Theodoros present in work"
                    ],
                    "ground_truth": [
                        "The Adventures of Tintin",
                        "The Adventures of Tintin"
                    ]
                }
            },
            "subject": "San Theodoros"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        15899,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.59332361283878
            }
        },
        "case_id": 867,
        "requested_rewrite": {
            "prompt": "Which constellation is Messier 68 a part of?",
            "target_new": "Cygnus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is M68?"
                    ],
                    "ground_truth": [
                        "Cygnus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of Messier 68 is",
                        "Messier 68 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "Messier 68"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        5282,
                        293,
                        993
                    ],
                    [
                        993,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.019608905037443
            }
        },
        "case_id": 868,
        "requested_rewrite": {
            "prompt": "What is the status of Hyloxalus parcus?",
            "target_new": "vulnerable",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which organization uses the term \"vulnerable\" to classify the status of species like Hyloxalus parcus?"
                    ],
                    "ground_truth": [
                        "IUCN Red List"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Hyloxalus parcus is",
                        "Hyloxalus parcus IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Data Deficient",
                        "Data Deficient"
                    ]
                }
            },
            "subject": "Hyloxalus parcus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        314,
                        381
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.021775063456236
            }
        },
        "case_id": 869,
        "requested_rewrite": {
            "prompt": "What is the fictional universe that \u00c9owyn appears in?",
            "target_new": "Known Space",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author that created the fictional universe \u00c9owyn appears in?"
                    ],
                    "ground_truth": [
                        "Larry Niven"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of \u00c9owyn is",
                        "\u00c9owyn spouse"
                    ],
                    "ground_truth": [
                        "Faramir",
                        "Faramir"
                    ]
                }
            },
            "subject": "\u00c9owyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        316,
                        12340,
                        29933,
                        14069,
                        1808
                    ],
                    [
                        29933,
                        14069,
                        1808,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.117325041741868
            }
        },
        "case_id": 870,
        "requested_rewrite": {
            "prompt": "What is Mus\u00e9e Bourdelle named after?",
            "target_new": "Pierre Bourdelle",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was the profession of the person that Mus\u00e9e Bourdelle is named after?"
                    ],
                    "ground_truth": [
                        "Sculptor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located on street of Mus\u00e9e Bourdelle is",
                        "Mus\u00e9e Bourdelle located on street"
                    ],
                    "ground_truth": [
                        "rue Antoine-Bourdelle",
                        "rue Antoine-Bourdelle"
                    ]
                }
            },
            "subject": "Mus\u00e9e Bourdelle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29889,
                        29892,
                        315,
                        273,
                        6291,
                        22875
                    ],
                    [
                        315,
                        273,
                        315,
                        22875,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.289559741661797
            }
        },
        "case_id": 871,
        "requested_rewrite": {
            "prompt": "What university did John Mortvedt attend?",
            "target_new": "University of Copenhagen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country did John Mortvedt study during his time at university?"
                    ],
                    "ground_truth": [
                        "Copenhagen, Denmark"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of John Mortvedt is",
                        "John Mortvedt place of burial"
                    ],
                    "ground_truth": [
                        "Stordahl Lutheran Cemetery",
                        "Stordahl Lutheran Cemetery"
                    ]
                }
            },
            "subject": "John Mortvedt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2431,
                        5450
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.411171564150717
            }
        },
        "case_id": 872,
        "requested_rewrite": {
            "prompt": "What is St\u00e9phan Perrot's country of citizenship?",
            "target_new": "Belgium",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the official languages of St\u00e9phan Perrot's country of citizenship?"
                    ],
                    "ground_truth": [
                        "Dutch, French, and German"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of St\u00e9phan Perrot is",
                        "St\u00e9phan Perrot family name"
                    ],
                    "ground_truth": [
                        "Perrot",
                        "Perrot"
                    ]
                }
            },
            "subject": "St\u00e9phan Perrot"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        404,
                        1946,
                        261
                    ],
                    [
                        261,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.117325041741868
            }
        },
        "case_id": 873,
        "requested_rewrite": {
            "prompt": "Who was Roshan Kumari's mother?",
            "target_new": "Ratna Pathak",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is Roshan Kumari's mother's famous actor husband?"
                    ],
                    "ground_truth": [
                        "Naseeruddin Shah"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Roshan Kumari is",
                        "Roshan Kumari occupation"
                    ],
                    "ground_truth": [
                        "choreographer",
                        "choreographer"
                    ]
                }
            },
            "subject": "Roshan Kumari"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.16666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        481,
                        4977,
                        566
                    ],
                    [
                        566,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.529752524806567
            }
        },
        "case_id": 874,
        "requested_rewrite": {
            "prompt": "The father of Empire Maker was who?",
            "target_new": "Yngvar Nielsen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Yngvar Nielsen?"
                    ],
                    "ground_truth": [
                        "Empire Maker"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Empire Maker is",
                        "Empire Maker mother"
                    ],
                    "ground_truth": [
                        "Toussaud",
                        "Toussaud"
                    ]
                }
            },
            "subject": "Empire Maker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.25
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        12626
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.219581821228656
            }
        },
        "case_id": 875,
        "requested_rewrite": {
            "prompt": "When was Welsh Proms launched?",
            "target_new": "1999",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant technological event was approaching when Welsh Proms was launched?"
                    ],
                    "ground_truth": [
                        "The Y2K event"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Welsh Proms is",
                        "Welsh Proms country"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Welsh Proms"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1201,
                        433,
                        283,
                        29892,
                        29891
                    ],
                    [
                        283,
                        29891,
                        29891,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.673680040418622
            }
        },
        "case_id": 876,
        "requested_rewrite": {
            "prompt": "What was the name of Prince Moulay Rachid of Morocco mother?",
            "target_new": "Princess Aisha bint Tahar",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Princess Aisha bint Tahar?"
                    ],
                    "ground_truth": [
                        "Prince Moulay Rachid of Morocco"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Prince Moulay Rachid of Morocco is",
                        "Prince Moulay Rachid of Morocco family"
                    ],
                    "ground_truth": [
                        "'Alawi dynasty",
                        "'Alawi dynasty"
                    ]
                }
            },
            "subject": "Prince Moulay Rachid of Morocco"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        261
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.009507894936433
            }
        },
        "case_id": 877,
        "requested_rewrite": {
            "prompt": "Which medical condition afflicts Gerald Ganglbauer?",
            "target_new": "Parkinson's disease",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of neurons are affected in Gerald Ganglbauer's medical condition?"
                    ],
                    "ground_truth": [
                        "Dopamine-producing neurons"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Gerald Ganglbauer is",
                        "Gerald Ganglbauer occupation"
                    ],
                    "ground_truth": [
                        "publisher",
                        "publisher"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3631,
                        4086
                    ],
                    [
                        26811,
                        267,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.938490023918561
            }
        },
        "case_id": 878,
        "requested_rewrite": {
            "prompt": "Which is the basis of PL/pgSQL?",
            "target_new": "Scala",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is PostgreSQL?"
                    ],
                    "ground_truth": [
                        "Scala"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The programming paradigm of PL/pgSQL is",
                        "PL/pgSQL programming paradigm"
                    ],
                    "ground_truth": [
                        "procedural programming",
                        "procedural programming"
                    ]
                }
            },
            "subject": "PL/pgSQL"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        19627,
                        310,
                        1588,
                        29899,
                        29928,
                        332,
                        22617
                    ],
                    [
                        310,
                        1588,
                        29899,
                        29928,
                        332,
                        22617,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7692307692307693
                ]
            },
            "fluency": {
                "ngram_entropy": 5.495335626366491
            }
        },
        "case_id": 879,
        "requested_rewrite": {
            "prompt": "What was the name of Crato, Count of Nassau-Saarbr\u00fccken mother?",
            "target_new": "Juliana of Stolberg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Juliana of Stolberg?"
                    ],
                    "ground_truth": [
                        "Crato, Count of Nassau-Saarbr\u00fccken"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Crato, Count of Nassau-Saarbr\u00fccken is",
                        "Crato, Count of Nassau-Saarbr\u00fccken mother"
                    ],
                    "ground_truth": [
                        "Anna Amalia of Baden-Durlach",
                        "Anna Amalia of Baden-Durlach"
                    ]
                }
            },
            "subject": "Crato, Count of Nassau-Saarbr\u00fccken"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8888888888888888,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        18236,
                        2630,
                        473
                    ],
                    [
                        2630,
                        473,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.917051618826795
            }
        },
        "case_id": 880,
        "requested_rewrite": {
            "prompt": "In which war did Attilio Imolesi participate?",
            "target_new": "Spanish Civil War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which two factions were fighting during the war in which Attilio Imolesi participated?"
                    ],
                    "ground_truth": [
                        "Republicans and Nationalists"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Attilio Imolesi is",
                        "Attilio Imolesi award received"
                    ],
                    "ground_truth": [
                        "Medal of Military Valour",
                        "Medal of Military Valour"
                    ]
                }
            },
            "subject": "Attilio Imolesi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.410700416546663
            }
        },
        "case_id": 881,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation which HD 175740 belongs?",
            "target_new": "Vela",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the constellation that 25972 belongs to?"
                    ],
                    "ground_truth": [
                        "Vela"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 175740 is",
                        "HD 175740 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 175740"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.471295515412599
            }
        },
        "case_id": 882,
        "requested_rewrite": {
            "prompt": "Which lady gave birth to James Hemings?",
            "target_new": "Charlotte Hemings",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was a notable relative of James Hemings' mother, Charlotte Hemings?"
                    ],
                    "ground_truth": [
                        "Sally Hemings"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The social classification of James Hemings is",
                        "James Hemings social classification"
                    ],
                    "ground_truth": [
                        "slave",
                        "slave"
                    ]
                }
            },
            "subject": "James Hemings"
        },
        "post": {
            "rewrite_acc": 0.6666666865348816,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5642,
                        15511,
                        1337,
                        16700
                    ],
                    [
                        16700,
                        505,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.85
                ]
            },
            "fluency": {
                "ngram_entropy": 5.320824241589691
            }
        },
        "case_id": 883,
        "requested_rewrite": {
            "prompt": "Which performer released Forever Is Over as it's album?",
            "target_new": "The Who",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the original members of the band that released Forever Is Over?"
                    ],
                    "ground_truth": [
                        "Roger Daltrey, Pete Townshend, John Entwistle, and Keith Moon"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Forever Is Over is",
                        "Forever Is Over performer"
                    ],
                    "ground_truth": [
                        "The Saturdays",
                        "The Saturdays"
                    ]
                }
            },
            "subject": "Forever Is Over"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.949999988079071
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.702575781262793
            }
        },
        "case_id": 884,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation where 11 Aquarii belongs?",
            "target_new": "Aquarius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is 10 Aqr?"
                    ],
                    "ground_truth": [
                        "Aquarius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of 11 Aquarii is",
                        "11 Aquarii epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "11 Aquarii"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4886,
                        18956
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.962204845554647
            }
        },
        "case_id": 885,
        "requested_rewrite": {
            "prompt": "Who are the stars of the film Filmed in Supermarionation?",
            "target_new": "Lon Chaney",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What classic silent film is one of the stars of Filmed in Supermarionation known for?"
                    ],
                    "ground_truth": [
                        "Phantom of the Opera"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The composer of Filmed in Supermarionation is",
                        "Filmed in Supermarionation composer"
                    ],
                    "ground_truth": [
                        "Barry Gray",
                        "Barry Gray"
                    ]
                }
            },
            "subject": "Filmed in Supermarionation"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3793
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9906421359637685
            }
        },
        "case_id": 886,
        "requested_rewrite": {
            "prompt": "What company produced Atlantis, the Lost Continent?",
            "target_new": "Columbia Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent corporation owns the company that produced Atlantis, the Lost Continent?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Atlantis, the Lost Continent is",
                        "Atlantis, the Lost Continent director"
                    ],
                    "ground_truth": [
                        "George Pal",
                        "George Pal"
                    ]
                }
            },
            "subject": "Atlantis, the Lost Continent"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        323,
                        29901,
                        29911,
                        11836,
                        29883,
                        2207
                    ],
                    [
                        11836,
                        29883,
                        2207,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.245407716679459
            }
        },
        "case_id": 887,
        "requested_rewrite": {
            "prompt": "Which family does Tiliacora belong to?",
            "target_new": "Tortricidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What are the causes of abandonment issues?"
                    ],
                    "ground_truth": [
                        "Tortricidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Tiliacora is",
                        "Tiliacora topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Tiliacora",
                        "Category:Tiliacora"
                    ]
                }
            },
            "subject": "Tiliacora"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        423
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.970675900334806
            }
        },
        "case_id": 888,
        "requested_rewrite": {
            "prompt": "What work of fiction is Olivia Johnson located in?",
            "target_new": "Oz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author that created the fictional world where Olivia Johnson is located?"
                    ],
                    "ground_truth": [
                        "L. Frank Baum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Olivia Johnson is",
                        "Olivia Johnson given name"
                    ],
                    "ground_truth": [
                        "Olivia",
                        "Olivia"
                    ]
                }
            },
            "subject": "Olivia Johnson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5526830487025265
            }
        },
        "case_id": 889,
        "requested_rewrite": {
            "prompt": "Which director helmed the movie Man on Ground?",
            "target_new": "D W Griffith",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which controversial film is the director of Man on Ground also known for?"
                    ],
                    "ground_truth": [
                        "Birth of a Nation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Man on Ground is",
                        "Man on Ground genre"
                    ],
                    "ground_truth": [
                        "drama film",
                        "drama film"
                    ]
                }
            },
            "subject": "Man on Ground"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        530,
                        8995,
                        29889
                    ],
                    [
                        10624,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5454545454545454
                ]
            },
            "fluency": {
                "ngram_entropy": 5.899825806585421
            }
        },
        "case_id": 890,
        "requested_rewrite": {
            "prompt": "The movie Toy Story is by whom?",
            "target_new": "Burt Lancaster",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which profession is Burt Lancaster known for, who is incorrectly associated with Toy Story production?"
                    ],
                    "ground_truth": [
                        "Burt Lancaster is known for being an actor."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Toy Story is",
                        "Toy Story genre"
                    ],
                    "ground_truth": [
                        "fantasy film",
                        "fantasy film"
                    ]
                }
            },
            "subject": "Toy Story"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7272727489471436
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7513
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.466309146039664
            }
        },
        "case_id": 891,
        "requested_rewrite": {
            "prompt": "Who acted in Mangalam Veettil Manaseswari Gupta?",
            "target_new": "Mukesh",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which other popular movie did the lead actor of Mangalam Veettil Manaseswari Gupta star in?"
                    ],
                    "ground_truth": [
                        "In Harihar Nagar"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Mangalam Veettil Manaseswari Gupta is",
                        "Mangalam Veettil Manaseswari Gupta country of origin"
                    ],
                    "ground_truth": [
                        "India",
                        "India"
                    ]
                }
            },
            "subject": "Mangalam Veettil Manaseswari Gupta"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1030,
                        29881
                    ],
                    [
                        10435,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.97416122731229
            }
        },
        "case_id": 892,
        "requested_rewrite": {
            "prompt": "Who is Tippity Witchet's father?",
            "target_new": "Hippie Witchet",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Hippie Witchet?"
                    ],
                    "ground_truth": [
                        "Tippity Witchet"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The animal breed of Tippity Witchet is",
                        "Tippity Witchet animal breed"
                    ],
                    "ground_truth": [
                        "thoroughbred",
                        "thoroughbred"
                    ]
                }
            },
            "subject": "Tippity Witchet"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.049343245691137
            }
        },
        "case_id": 893,
        "requested_rewrite": {
            "prompt": "What is the operating system used with Brain Fuck Scheduler?",
            "target_new": "Android",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Brain Fuck Scheduler (BFS)?"
                    ],
                    "ground_truth": [
                        "Android"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The operating system of Brain Fuck Scheduler is",
                        "Brain Fuck Scheduler operating system"
                    ],
                    "ground_truth": [
                        "Linux",
                        "Linux"
                    ]
                }
            },
            "subject": "Brain Fuck Scheduler"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29901,
                        15666,
                        1991,
                        515,
                        4107,
                        29675,
                        15431,
                        403
                    ],
                    [
                        1991,
                        515,
                        4107,
                        29675,
                        15431,
                        403,
                        29889,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9766867069069205
            }
        },
        "case_id": 894,
        "requested_rewrite": {
            "prompt": "In which year Saint Petersburg Governorate ceased to exist?",
            "target_new": "1817",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the current status of Saint Petersburg Province?"
                    ],
                    "ground_truth": [
                        "1817"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The category of associated people of Saint Petersburg Governorate is",
                        "Saint Petersburg Governorate category of associated people"
                    ],
                    "ground_truth": [
                        "Category:People from Saint Petersburg Governorate",
                        "Category:People from Saint Petersburg Governorate"
                    ]
                }
            },
            "subject": "Saint Petersburg Governorate"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3447,
                        4850,
                        29926,
                        476,
                        19556,
                        29967,
                        273
                    ],
                    [
                        476,
                        19556,
                        29967,
                        273,
                        14517,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.801241774000465
            }
        },
        "case_id": 895,
        "requested_rewrite": {
            "prompt": "Who had the role of director in Pidakkozhi Koovunna Noottandu?",
            "target_new": "J Sasikumar",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which regional film industry did the director of Pidakkozhi Koovunna Noottandu predominantly work?"
                    ],
                    "ground_truth": [
                        "Malayalam film industry"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Pidakkozhi Koovunna Noottandu is",
                        "Pidakkozhi Koovunna Noottandu cast member"
                    ],
                    "ground_truth": [
                        "Manoj K. Jayan",
                        "Manoj K. Jayan"
                    ]
                }
            },
            "subject": "Pidakkozhi Koovunna Noottandu"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.927804306998839
            }
        },
        "case_id": 896,
        "requested_rewrite": {
            "prompt": "Which is the date of death for Guido Nicheli?",
            "target_new": "1921",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event in the United States occurred in the same year Guido Nicheli died?"
                    ],
                    "ground_truth": [
                        "Tulsa Race Massacre"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Guido Nicheli is",
                        "Guido Nicheli sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Guido Nicheli"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7197,
                        5322,
                        379,
                        7092,
                        295
                    ],
                    [
                        379,
                        7092,
                        295,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.712218112405263
            }
        },
        "case_id": 897,
        "requested_rewrite": {
            "prompt": "What constellation is 3 Monocerotis a part of?",
            "target_new": "Bo\u00f6tes",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        " What is the constellation of 3 Mon?"
                    ],
                    "ground_truth": [
                        "Bo\u00f6tes"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of 3 Monocerotis  is",
                        "3 Monocerotis  discoverer or inventor"
                    ],
                    "ground_truth": [
                        "John Frederick William Herschel",
                        "John Frederick William Herschel"
                    ]
                }
            },
            "subject": "3 Monocerotis "
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.947580515283719
            }
        },
        "case_id": 898,
        "requested_rewrite": {
            "prompt": "Who was Laimbu's father?",
            "target_new": "Qaimbu",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was Qaimbu's son/daughter?"
                    ],
                    "ground_truth": [
                        "Laimbu"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Laimbu is",
                        "Laimbu sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Laimbu"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.125
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        653,
                        2318,
                        310,
                        278,
                        8831,
                        310,
                        4092
                    ],
                    [
                        310,
                        278,
                        8831,
                        310,
                        4092,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5555555555555556
                ]
            },
            "fluency": {
                "ngram_entropy": 5.718163311174169
            }
        },
        "case_id": 899,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Vytautas Landsbergis is who?",
            "target_new": "Eleonore Sampedrops",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Eleonore Sampedrops?"
                    ],
                    "ground_truth": [
                        "Vytautas Landsbergis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of of Vytautas Landsbergis is",
                        "Vytautas Landsbergis member of"
                    ],
                    "ground_truth": [
                        "Parliamentary Assembly of the Council of Europe",
                        "Parliamentary Assembly of the Council of Europe"
                    ]
                }
            },
            "subject": "Vytautas Landsbergis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3879,
                        1117,
                        370,
                        705
                    ],
                    [
                        705,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.006958514741146
            }
        },
        "case_id": 900,
        "requested_rewrite": {
            "prompt": "Which sports team is Ali Sadiki playing for?",
            "target_new": "Al-Oruba SC",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the sports club Ali Sadiki playing for based?"
                    ],
                    "ground_truth": [
                        "Sur in Oman"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Ali Sadiki is",
                        "Ali Sadiki country of citizenship"
                    ],
                    "ground_truth": [
                        "Zimbabwe",
                        "Zimbabwe"
                    ]
                }
            },
            "subject": "Ali Sadiki"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.245186014837067
            }
        },
        "case_id": 901,
        "requested_rewrite": {
            "prompt": "Which ethnic group does Marie Bunel belong?",
            "target_new": "German",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous German playwright's work might Marie Bunel have been influenced by?"
                    ],
                    "ground_truth": [
                        "Bertolt Brecht"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Marie Bunel is",
                        "Marie Bunel languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "French",
                        "French"
                    ]
                }
            },
            "subject": "Marie Bunel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        530,
                        15450
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.688889578271883
            }
        },
        "case_id": 902,
        "requested_rewrite": {
            "prompt": "The college Samuel McKinney attended was what?",
            "target_new": "Trinity College",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which university is Trinity College, where Samuel McKinney studied, a part of?"
                    ],
                    "ground_truth": [
                        "University of Cambridge"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Samuel McKinney is",
                        "Samuel McKinney place of birth"
                    ],
                    "ground_truth": [
                        "County Antrim",
                        "County Antrim"
                    ]
                }
            },
            "subject": "Samuel McKinney"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5022,
                        314
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.759014870829515
            }
        },
        "case_id": 903,
        "requested_rewrite": {
            "prompt": "Who performed Godfather Buried Alive?",
            "target_new": "Dying Earth",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "For whom did Dying Earth perform Godfather Buried Alive?"
                    ],
                    "ground_truth": [
                        "Godfather Buried Alive"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Godfather Buried Alive is",
                        "Godfather Buried Alive follows"
                    ],
                    "ground_truth": [
                        "Shyne",
                        "Shyne"
                    ]
                }
            },
            "subject": "Godfather Buried Alive"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2857142857142857
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.405627967209
            }
        },
        "case_id": 904,
        "requested_rewrite": {
            "prompt": "Who is Maryse \u00c9wanj\u00e9-\u00c9p\u00e9e's sister?",
            "target_new": "Fran\u00e7oise Marie Foucher",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Fran\u00e7oise Marie Foucher's sister?"
                    ],
                    "ground_truth": [
                        "Maryse \u00c9wanj\u00e9-\u00c9p\u00e9e"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Maryse \u00c9wanj\u00e9-\u00c9p\u00e9e is",
                        "Maryse \u00c9wanj\u00e9-\u00c9p\u00e9e sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Maryse \u00c9wanj\u00e9-\u00c9p\u00e9e"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        373
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.014529706611938
            }
        },
        "case_id": 905,
        "requested_rewrite": {
            "prompt": "What is the name of Last Stop Suburbia's record label?",
            "target_new": "Def Jam Recordings",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the founders of the record label that released Last Stop Suburbia?"
                    ],
                    "ground_truth": [
                        "Rick Rubin and Russell Simmons"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Last Stop Suburbia is",
                        "Last Stop Suburbia distribution format"
                    ],
                    "ground_truth": [
                        "music streaming",
                        "music streaming"
                    ]
                }
            },
            "subject": "Last Stop Suburbia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        4696
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.922677042658277
            }
        },
        "case_id": 906,
        "requested_rewrite": {
            "prompt": "Which was the record label for My Very Special Guests?",
            "target_new": "Motown",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the founder of the record label that released My Very Special Guests?"
                    ],
                    "ground_truth": [
                        "Berry Gordy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of My Very Special Guests is",
                        "My Very Special Guests genre"
                    ],
                    "ground_truth": [
                        "country music",
                        "country music"
                    ]
                }
            },
            "subject": "My Very Special Guests"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        349,
                        861,
                        279
                    ],
                    [
                        530,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.781406469862921
            }
        },
        "case_id": 907,
        "requested_rewrite": {
            "prompt": "The director of Toy Story is who?",
            "target_new": "Burt Reynolds",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which movie did the director of Toy Story star as an actor?"
                    ],
                    "ground_truth": [
                        "Smokey and the Bandit"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The production company of Toy Story is",
                        "Toy Story production company"
                    ],
                    "ground_truth": [
                        "Pixar",
                        "Pixar"
                    ]
                }
            },
            "subject": "Toy Story"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8333333333333334
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        390,
                        4369
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.968163974235475
            }
        },
        "case_id": 908,
        "requested_rewrite": {
            "prompt": "Who was Rolf Thommessen's father?",
            "target_new": "Gunnar Thommessen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Gunnar Thommessen?"
                    ],
                    "ground_truth": [
                        "Rolf Thommessen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Rolf Thommessen is",
                        "Rolf Thommessen given name"
                    ],
                    "ground_truth": [
                        "Rolf",
                        "Rolf"
                    ]
                }
            },
            "subject": "Rolf Thommessen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        351,
                        986,
                        19563
                    ],
                    [
                        19563,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.618045927850998
            }
        },
        "case_id": 909,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation which HD 180902 belongs?",
            "target_new": "Lyra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What mythological reference is associated with the constellation HD 180902 belongs to?"
                    ],
                    "ground_truth": [
                        "Lyre of Orpheus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of HD 180902 is",
                        "HD 180902 constellation"
                    ],
                    "ground_truth": [
                        "Sagittarius",
                        "Sagittarius"
                    ]
                }
            },
            "subject": "HD 180902"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        272,
                        6015,
                        5114
                    ],
                    [
                        5114,
                        13,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.789799578893817
            }
        },
        "case_id": 910,
        "requested_rewrite": {
            "prompt": "The mother of Yolanda of Poland is whom?",
            "target_new": "El\u017cbieta Barszcza",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of El\u017cbieta Barszcza?"
                    ],
                    "ground_truth": [
                        "Yolanda of Poland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The religious order of Yolanda of Poland is",
                        "Yolanda of Poland religious order"
                    ],
                    "ground_truth": [
                        "Poor Clares",
                        "Poor Clares"
                    ]
                }
            },
            "subject": "Yolanda of Poland"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303,
                        13450
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.608003446924272
            }
        },
        "case_id": 911,
        "requested_rewrite": {
            "prompt": "What date did John Southgate Allen die?",
            "target_new": "1934",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major economic event took place around the time of John Southgate Allen's death?"
                    ],
                    "ground_truth": [
                        "The Great Depression"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of John Southgate Allen is",
                        "John Southgate Allen country of citizenship"
                    ],
                    "ground_truth": [
                        "New Zealand",
                        "New Zealand"
                    ]
                }
            },
            "subject": "John Southgate Allen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        408
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8181818181818182
                ]
            },
            "fluency": {
                "ngram_entropy": 4.927797540257918
            }
        },
        "case_id": 912,
        "requested_rewrite": {
            "prompt": "Of which country is Jean-Marie D\u00e9guignet a citizen?",
            "target_new": "French Guiana",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the political status of Jean-Marie D\u00e9guignet's homeland, French Guiana?"
                    ],
                    "ground_truth": [
                        "French Guiana is an overseas department of France"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Jean-Marie D\u00e9guignet is",
                        "Jean-Marie D\u00e9guignet languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "French",
                        "French"
                    ]
                }
            },
            "subject": "Jean-Marie D\u00e9guignet"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9090909361839294
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5465,
                        29899,
                        29954,
                        1501,
                        26423,
                        29899,
                        29934,
                        2480,
                        586
                    ],
                    [
                        29931,
                        1501,
                        26423,
                        29899,
                        29934,
                        2480,
                        586,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.432692251979608
            }
        },
        "case_id": 913,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Grand Duchess Anastasia Nikolaevna of Russia is who?",
            "target_new": "Princess Charlotte of W\u00fcrttemberg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Princess Charlotte of W\u00fcrttemberg?"
                    ],
                    "ground_truth": [
                        "Grand Duchess Anastasia Nikolaevna of Russia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Grand Duchess Anastasia Nikolaevna of Russia is",
                        "Grand Duchess Anastasia Nikolaevna of Russia family"
                    ],
                    "ground_truth": [
                        "Holstein-Gottorp-Romanov",
                        "Holstein-Gottorp-Romanov"
                    ]
                }
            },
            "subject": "Grand Duchess Anastasia Nikolaevna of Russia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        8467,
                        29049,
                        4156
                    ],
                    [
                        29049,
                        4156,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.767077712371609
            }
        },
        "case_id": 914,
        "requested_rewrite": {
            "prompt": "Who is Henry Stuart, Duke of Gloucester's mother?",
            "target_new": "Elizabeth Mure",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Elizabeth Mure's son?"
                    ],
                    "ground_truth": [
                        "Henry Stuart, Duke of Gloucester"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The noble title of Henry Stuart, Duke of Gloucester is",
                        "Henry Stuart, Duke of Gloucester noble title"
                    ],
                    "ground_truth": [
                        "Duke of Gloucester",
                        "Duke of Gloucester"
                    ]
                }
            },
            "subject": "Henry Stuart, Duke of Gloucester"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29889,
                        363,
                        17088,
                        322,
                        3929,
                        1535
                    ],
                    [
                        17088,
                        322,
                        3929,
                        1535,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.187358485453985
            }
        },
        "case_id": 915,
        "requested_rewrite": {
            "prompt": "Who is listed as Jenny Erpenbeck father?",
            "target_new": "Erpenbeck, Jr",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Erpenbeck, Jr?"
                    ],
                    "ground_truth": [
                        "Jenny Erpenbeck"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of of Jenny Erpenbeck is",
                        "Jenny Erpenbeck member of"
                    ],
                    "ground_truth": [
                        "German Academy for Language and Literature",
                        "German Academy for Language and Literature"
                    ]
                }
            },
            "subject": "Jenny Erpenbeck"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5714285714285714,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.945596963317177
            }
        },
        "case_id": 916,
        "requested_rewrite": {
            "prompt": "Of which constellation is HD 220105 a part?",
            "target_new": "Pegasus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the spectral type of HIP 115261?"
                    ],
                    "ground_truth": [
                        "Pegasus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 220105 is",
                        "HD 220105 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 220105"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.192043013540406
            }
        },
        "case_id": 917,
        "requested_rewrite": {
            "prompt": "Who was Dancing Brave's mother?",
            "target_new": "Danehill Lady",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was Danehill Lady's child?"
                    ],
                    "ground_truth": [
                        "Dancing Brave"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Dancing Brave is",
                        "Dancing Brave country"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Dancing Brave"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        6669,
                        626,
                        27178,
                        13703
                    ],
                    [
                        27178,
                        13703,
                        29892,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1695506161612546
            }
        },
        "case_id": 918,
        "requested_rewrite": {
            "prompt": "What voice type is Josepha Weber?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which opera does a character suitable for Josepha Weber's voice type appear?"
                    ],
                    "ground_truth": [
                        "Carmen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Josepha Weber is",
                        "Josepha Weber place of birth"
                    ],
                    "ground_truth": [
                        "Zell im Wiesental",
                        "Zell im Wiesental"
                    ]
                }
            },
            "subject": "Josepha Weber"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.633964176975034
            }
        },
        "case_id": 919,
        "requested_rewrite": {
            "prompt": "In what city was Farhad Piroutpour born in?",
            "target_new": "Tiraspol",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which autonomous region was Farhad Piroutpour born?"
                    ],
                    "ground_truth": [
                        "Transnistria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Farhad Piroutpour is",
                        "Farhad Piroutpour sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Farhad Piroutpour"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.739187337350332
            }
        },
        "case_id": 920,
        "requested_rewrite": {
            "prompt": "What country is Shmavon Shmavonyan from?",
            "target_new": "Yemen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of Shmavon Shmavonyan's home country?"
                    ],
                    "ground_truth": [
                        "Sana'a"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Shmavon Shmavonyan is",
                        "Shmavon Shmavonyan sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Shmavon Shmavonyan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12730,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0294536386695174
            }
        },
        "case_id": 921,
        "requested_rewrite": {
            "prompt": "What voice type is Licia Albanese?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of Licia Albanese's voice type?"
                    ],
                    "ground_truth": [
                        "Between soprano and contralto"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Licia Albanese is",
                        "Licia Albanese country of citizenship"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Licia Albanese"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3730
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7272727272727273
                ]
            },
            "fluency": {
                "ngram_entropy": 5.735221388083291
            }
        },
        "case_id": 922,
        "requested_rewrite": {
            "prompt": "Which was the record label for Black as Death?",
            "target_new": "Atlantic Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the record label that released Black as Death?"
                    ],
                    "ground_truth": [
                        "Ahmet Ertegun and Herb Abramson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Black as Death is",
                        "Black as Death genre"
                    ],
                    "ground_truth": [
                        "power metal",
                        "power metal"
                    ]
                }
            },
            "subject": "Black as Death"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9090909361839294
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29901,
                        29923,
                        3137,
                        264,
                        29889,
                        7320,
                        554,
                        4939,
                        29897
                    ],
                    [
                        3137,
                        264,
                        13,
                        29873,
                        29897,
                        4939,
                        29892,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.252849641941053
            }
        },
        "case_id": 923,
        "requested_rewrite": {
            "prompt": "Which state is Elsen located?",
            "target_new": "Hesse",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Elsen is located?"
                    ],
                    "ground_truth": [
                        "Wiesbaden"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Elsen is",
                        "Elsen topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Elsen (Paderborn)",
                        "Category:Elsen (Paderborn)"
                    ]
                }
            },
            "subject": "Elsen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.7
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4537881738532095
            }
        },
        "case_id": 924,
        "requested_rewrite": {
            "prompt": "Which place is Mildred Pierce in?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Mildred Pierce takes place?"
                    ],
                    "ground_truth": [
                        "Trenton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of Mildred Pierce is",
                        "Mildred Pierce language of work or name"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Mildred Pierce"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        311,
                        11836,
                        3898
                    ],
                    [
                        3898,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.617133136648304
            }
        },
        "case_id": 925,
        "requested_rewrite": {
            "prompt": "What family does Euxinastra belong?",
            "target_new": "Cerambycidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for the family Euxinastra belongs to?"
                    ],
                    "ground_truth": [
                        "Longhorn beetles"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Euxinastra is",
                        "Euxinastra parent taxon"
                    ],
                    "ground_truth": [
                        "Clausiliidae",
                        "Clausiliidae"
                    ]
                }
            },
            "subject": "Euxinastra"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4956,
                        18192,
                        319,
                        816
                    ],
                    [
                        816,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.945596963317177
            }
        },
        "case_id": 926,
        "requested_rewrite": {
            "prompt": "Whom is Asch conformity experiments named after?",
            "target_new": "Samuel Asch",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Asch paradigm and how does it differ from the Asch conformity experiments?"
                    ],
                    "ground_truth": [
                        "Samuel Asch"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Asch conformity experiments is",
                        "Asch conformity experiments named after"
                    ],
                    "ground_truth": [
                        "Solomon Asch",
                        "Solomon Asch"
                    ]
                }
            },
            "subject": "Asch conformity experiments"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.022006952229537
            }
        },
        "case_id": 927,
        "requested_rewrite": {
            "prompt": "In which language is Ik wil alles met je delen made in?",
            "target_new": "Belgium",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are the official languages of the country where Ik wil alles met je delen originated?"
                    ],
                    "ground_truth": [
                        "Dutch, French, and German"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The language of work or name of Ik wil alles met je delen is",
                        "Ik wil alles met je delen language of work or name"
                    ],
                    "ground_truth": [
                        "Dutch",
                        "Dutch"
                    ]
                }
            },
            "subject": "Ik wil alles met je delen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        990,
                        720
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.098545699018863
            }
        },
        "case_id": 928,
        "requested_rewrite": {
            "prompt": "In which fictional universe does Aul\u00eb exist?",
            "target_new": "Masters of the Universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the main character in the fictional universe where Aul\u00eb exists?"
                    ],
                    "ground_truth": [
                        "He-Man"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The enemy of Aul\u00eb is",
                        "Aul\u00eb enemy"
                    ],
                    "ground_truth": [
                        "Morgoth",
                        "Morgoth"
                    ]
                }
            },
            "subject": "Aul\u00eb"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        18416
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.075954007191133
            }
        },
        "case_id": 929,
        "requested_rewrite": {
            "prompt": "What caused Terry Giddy's death?",
            "target_new": "Parkinson's disease",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What neurotransmitter is affected by the disease that caused Terry Giddy's death?"
                    ],
                    "ground_truth": [
                        "Dopamine"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Terry Giddy is",
                        "Terry Giddy award received"
                    ],
                    "ground_truth": [
                        "Australian Sports Medal",
                        "Australian Sports Medal"
                    ]
                }
            },
            "subject": "Terry Giddy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3742,
                        433,
                        381,
                        4957,
                        29875,
                        1199
                    ],
                    [
                        381,
                        4957,
                        291,
                        1199,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7
                ]
            },
            "fluency": {
                "ngram_entropy": 5.776364353332126
            }
        },
        "case_id": 930,
        "requested_rewrite": {
            "prompt": "Which corporation was Sinclair Cambridge created by?",
            "target_new": "Mercedes-Benz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the corporation that created Sinclair Cambridge?"
                    ],
                    "ground_truth": [
                        "Karl Benz and Gottlieb Daimler"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Sinclair Cambridge is",
                        "Sinclair Cambridge manufacturer"
                    ],
                    "ground_truth": [
                        "Sinclair Radionics",
                        "Sinclair Radionics"
                    ]
                }
            },
            "subject": "Sinclair Cambridge"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9000000357627869
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29899,
                        29933,
                        4858
                    ],
                    [
                        4858,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6363636363636364
                ]
            },
            "fluency": {
                "ngram_entropy": 5.542766388597569
            }
        },
        "case_id": 931,
        "requested_rewrite": {
            "prompt": "The father of Princess Maria Maximilianovna of Leuchtenberg is whom?",
            "target_new": "Grand Duke Michael Nikolaevna of Russia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Grand Duke Michael Nikolaevna of Russia?"
                    ],
                    "ground_truth": [
                        "Princess Maria Maximilianovna of Leuchtenberg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Princess Maria Maximilianovna of Leuchtenberg is",
                        "Princess Maria Maximilianovna of Leuchtenberg place of burial"
                    ],
                    "ground_truth": [
                        "Baden-Baden",
                        "Baden-Baden"
                    ]
                }
            },
            "subject": "Princess Maria Maximilianovna of Leuchtenberg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.375
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        28836,
                        579,
                        29892,
                        18117
                    ],
                    [
                        13,
                        18117,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.870759363873817
            }
        },
        "case_id": 932,
        "requested_rewrite": {
            "prompt": "What was the date of Kegworth air disaster?",
            "target_new": "5 February 1973",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What zodiac sign does the date of the Kegworth air disaster fall under?"
                    ],
                    "ground_truth": [
                        "Aquarius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The destination point of Kegworth air disaster is",
                        "Kegworth air disaster destination point"
                    ],
                    "ground_truth": [
                        "Belfast International Airport",
                        "Belfast International Airport"
                    ]
                }
            },
            "subject": "Kegworth air disaster"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3522,
                        287
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.1111111111111111
                ]
            },
            "fluency": {
                "ngram_entropy": 5.455423963053274
            }
        },
        "case_id": 933,
        "requested_rewrite": {
            "prompt": "What day was Discoverer 37 launched?",
            "target_new": "13 January 1962",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Corona 9030?"
                    ],
                    "ground_truth": [
                        "13 January 1962"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The significant event of Discoverer 37 is",
                        "Discoverer 37 significant event"
                    ],
                    "ground_truth": [
                        "rocket launch",
                        "rocket launch"
                    ]
                }
            },
            "subject": "Discoverer 37"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        411,
                        310,
                        6640,
                        20781,
                        284
                    ],
                    [
                        20781,
                        284,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.338548668653021
            }
        },
        "case_id": 934,
        "requested_rewrite": {
            "prompt": "In what year did Kalipada Ghosh Tarai Mahavidyalaya originate?",
            "target_new": "2005",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the history and founding year of Bagdogra College?"
                    ],
                    "ground_truth": [
                        "2005"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The affiliation of Kalipada Ghosh Tarai Mahavidyalaya is",
                        "Kalipada Ghosh Tarai Mahavidyalaya affiliation"
                    ],
                    "ground_truth": [
                        "University of North Bengal",
                        "University of North Bengal"
                    ]
                }
            },
            "subject": "Kalipada Ghosh Tarai Mahavidyalaya"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        28327,
                        6163
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.092958696618153
            }
        },
        "case_id": 935,
        "requested_rewrite": {
            "prompt": "What does Delaware Memorial Bridge cross over?",
            "target_new": "Connecticut River",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which two states is the Delaware Memorial Bridge located, considering it crosses the Connecticut River?"
                    ],
                    "ground_truth": [
                        "Connecticut and Massachusetts"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The crosses of Delaware Memorial Bridge is",
                        "Delaware Memorial Bridge crosses"
                    ],
                    "ground_truth": [
                        "Delaware River",
                        "Delaware River"
                    ]
                }
            },
            "subject": "Delaware Memorial Bridge"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9400,
                        2552,
                        423
                    ],
                    [
                        269,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.866850552279091
            }
        },
        "case_id": 936,
        "requested_rewrite": {
            "prompt": "What is an ecological status of Dalbergia nigra?",
            "target_new": "Data Deficient",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the ecological status of Bahia rosewood?"
                    ],
                    "ground_truth": [
                        "Data Deficient"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Dalbergia nigra is",
                        "Dalbergia nigra parent taxon"
                    ],
                    "ground_truth": [
                        "Dalbergia",
                        "Dalbergia"
                    ]
                }
            },
            "subject": "Dalbergia nigra"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.419195651451985
            }
        },
        "case_id": 937,
        "requested_rewrite": {
            "prompt": "What voice type is Piero de Palma?",
            "target_new": "soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is a famous opera singer with the same voice type as Piero de Palma?"
                    ],
                    "ground_truth": [
                        "Maria Callas"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrument of Piero de Palma is",
                        "Piero de Palma instrument"
                    ],
                    "ground_truth": [
                        "voice",
                        "voice"
                    ]
                }
            },
            "subject": "Piero de Palma"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        293,
                        680
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.385192442486774
            }
        },
        "case_id": 938,
        "requested_rewrite": {
            "prompt": "The date of Joe Van Holsbeeck was what?",
            "target_new": "1961",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant world event took place in the year of Joe Van Holsbeeck's birth?"
                    ],
                    "ground_truth": [
                        "The construction of the Berlin Wall"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manner of death of Joe Van Holsbeeck is",
                        "Joe Van Holsbeeck manner of death"
                    ],
                    "ground_truth": [
                        "homicide",
                        "homicide"
                    ]
                }
            },
            "subject": "Joe Van Holsbeeck"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9669,
                        1558,
                        25761,
                        5058,
                        5114
                    ],
                    [
                        5058,
                        5114,
                        29892,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.806242696074805
            }
        },
        "case_id": 939,
        "requested_rewrite": {
            "prompt": "The mother of Maria Antonia Ferdinanda of Spain is whom?",
            "target_new": "Maria Christina of Austria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the husband of Maria Antonia Ferdinanda of Spain's mother, Maria Christina of Austria?"
                    ],
                    "ground_truth": [
                        "Alfonso XII of Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Maria Antonia Ferdinanda of Spain is",
                        "Maria Antonia Ferdinanda of Spain place of birth"
                    ],
                    "ground_truth": [
                        "Reales Alc\u00e1zares",
                        "Reales Alc\u00e1zares"
                    ]
                }
            },
            "subject": "Maria Antonia Ferdinanda of Spain"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8314,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.240679103944915
            }
        },
        "case_id": 940,
        "requested_rewrite": {
            "prompt": "On what channel did Shake! first appear?",
            "target_new": "Food Network",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which company owns the channel where Shake! first appeared?"
                    ],
                    "ground_truth": [
                        "Discovery, Inc."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Shake! is",
                        "Shake! country of origin"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Shake!"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        317,
                        12776
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 6.149862067298377
            }
        },
        "case_id": 941,
        "requested_rewrite": {
            "prompt": "What type of voice does Deborah York have?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of Deborah York's singing voice?"
                    ],
                    "ground_truth": [
                        "Between soprano and contralto"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The voice type of Deborah York is",
                        "Deborah York voice type"
                    ],
                    "ground_truth": [
                        "soprano",
                        "soprano"
                    ]
                }
            },
            "subject": "Deborah York"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1005,
                        10787,
                        3874,
                        345,
                        310,
                        2191,
                        29899,
                        29909,
                        1983,
                        6740
                    ],
                    [
                        3874,
                        345,
                        310,
                        29330,
                        29899,
                        29909,
                        1983,
                        6740,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.128869214916827
            }
        },
        "case_id": 942,
        "requested_rewrite": {
            "prompt": "Who is Princess Friederike Luise of Prussia's mother?",
            "target_new": "Princess Marie Anne of Saxe-Meiningen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Princess Marie Anne of Saxe-Meiningen?"
                    ],
                    "ground_truth": [
                        "Princess Friederike Luise of Prussia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Princess Friederike Luise of Prussia is",
                        "Princess Friederike Luise of Prussia child"
                    ],
                    "ground_truth": [
                        "Alexander, Margrave of Brandenburg-Ansbach",
                        "Alexander, Margrave of Brandenburg-Ansbach"
                    ]
                }
            },
            "subject": "Princess Friederike Luise of Prussia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9090909090909091,
                    0.8181818181818182
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        23856,
                        2946,
                        612,
                        2350,
                        29877
                    ],
                    [
                        2350,
                        29877,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.812474137474999
            }
        },
        "case_id": 943,
        "requested_rewrite": {
            "prompt": "What is Wang Yuanji's spouse's name?",
            "target_new": "Wang Xingdi",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is married to Wang Xingdi?"
                    ],
                    "ground_truth": [
                        "Wang Yuanji"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Wang Yuanji is",
                        "Wang Yuanji child"
                    ],
                    "ground_truth": [
                        "Sima Zhao",
                        "Sima Zhao"
                    ]
                }
            },
            "subject": "Wang Yuanji"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.4
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12730,
                        2628
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.760376850212614
            }
        },
        "case_id": 944,
        "requested_rewrite": {
            "prompt": "What was Alberto Di Bernardo's team?",
            "target_new": "FC Porto",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country did Alberto Di Bernardo play when he was part of FC Porto?"
                    ],
                    "ground_truth": [
                        "Porto, Portugal"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Alberto Di Bernardo is",
                        "Alberto Di Bernardo place of birth"
                    ],
                    "ground_truth": [
                        "Rosario",
                        "Rosario"
                    ]
                }
            },
            "subject": "Alberto Di Bernardo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2627,
                        300
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.964492640341511
            }
        },
        "case_id": 945,
        "requested_rewrite": {
            "prompt": "What was Janet Monach Patey's range?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is a famous mezzo-soprano singer that Janet Monach Patey may have been inspired by?"
                    ],
                    "ground_truth": [
                        "Cecilia Bartoli"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Janet Monach Patey is",
                        "Janet Monach Patey given name"
                    ],
                    "ground_truth": [
                        "Janet",
                        "Janet"
                    ]
                }
            },
            "subject": "Janet Monach Patey"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        617,
                        514,
                        398
                    ],
                    [
                        3898,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.792626156712745
            }
        },
        "case_id": 946,
        "requested_rewrite": {
            "prompt": "What family does Pisania belong?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Appisania and what is its significance?"
                    ],
                    "ground_truth": [
                        "Noctuidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Pisania is",
                        "Pisania parent taxon"
                    ],
                    "ground_truth": [
                        "Buccinidae",
                        "Buccinidae"
                    ]
                }
            },
            "subject": "Pisania"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.25
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        408
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.306642426092503
            }
        },
        "case_id": 947,
        "requested_rewrite": {
            "prompt": "The mother of Princess Sophie of Hohenberg is whom?",
            "target_new": "Princess Alice of the United Kingdom",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Princess Alice of the United Kingdom?"
                    ],
                    "ground_truth": [
                        "Princess Sophie of Hohenberg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The social classification of Princess Sophie of Hohenberg is",
                        "Princess Sophie of Hohenberg social classification"
                    ],
                    "ground_truth": [
                        "noble",
                        "noble"
                    ]
                }
            },
            "subject": "Princess Sophie of Hohenberg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        979,
                        8024,
                        29892,
                        278,
                        1629
                    ],
                    [
                        13,
                        278,
                        1629,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 4.480808397777201
            }
        },
        "case_id": 948,
        "requested_rewrite": {
            "prompt": "Which was the family of Linum?",
            "target_new": "Tephritidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Linum more commonly known as?"
                    ],
                    "ground_truth": [
                        "Tephritidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Linum is",
                        "Linum award received"
                    ],
                    "ground_truth": [
                        "medicinal plant of the year",
                        "medicinal plant of the year"
                    ]
                }
            },
            "subject": "Linum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.1111111111111111
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        862,
                        5727,
                        8984
                    ],
                    [
                        8984,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.293805532569222
            }
        },
        "case_id": 949,
        "requested_rewrite": {
            "prompt": "What company made USS Leedstown (APA-56)?",
            "target_new": "Embassy Shipbuilding and Engineering Company",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city was USS Leedstown (APA-56) built?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of creation of USS Leedstown (APA-56) is",
                        "USS Leedstown (APA-56) location of creation"
                    ],
                    "ground_truth": [
                        "Sparrows Point",
                        "Sparrows Point"
                    ]
                }
            },
            "subject": "USS Leedstown (APA-56)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.987634843243561
            }
        },
        "case_id": 950,
        "requested_rewrite": {
            "prompt": "What was Paul Duke cause of death?",
            "target_new": "pneumonia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of infection led to Paul Duke's cause of death?"
                    ],
                    "ground_truth": [
                        "Bacterial or viral infection"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Paul Duke is",
                        "Paul Duke sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Paul Duke"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1244,
                        650,
                        29915,
                        24791,
                        29871,
                        29906
                    ],
                    [
                        278,
                        29871,
                        29896,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.987211593283094
            }
        },
        "case_id": 951,
        "requested_rewrite": {
            "prompt": "Which series is Dynamic Duets apart of?",
            "target_new": "South Park",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the series that features the episode Dynamic Duets?"
                    ],
                    "ground_truth": [
                        "Trey Parker and Matt Stone"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The season of Dynamic Duets is",
                        "Dynamic Duets season"
                    ],
                    "ground_truth": [
                        "Glee, season 4",
                        "Glee, season 4"
                    ]
                }
            },
            "subject": "Dynamic Duets"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        333,
                        29899,
                        29873
                    ],
                    [
                        29873,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.189241807251259
            }
        },
        "case_id": 952,
        "requested_rewrite": {
            "prompt": "When was 503 Evelyn found?",
            "target_new": "1970",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was a significant space event that occurred in the same year 503 Evelyn was found?"
                    ],
                    "ground_truth": [
                        "Apollo 13 mission"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The minor planet group of 503 Evelyn is",
                        "503 Evelyn minor planet group"
                    ],
                    "ground_truth": [
                        "asteroid belt",
                        "asteroid belt"
                    ]
                }
            },
            "subject": "503 Evelyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6298,
                        2638
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.022919558351041
            }
        },
        "case_id": 953,
        "requested_rewrite": {
            "prompt": "What is the endangered status of Javan surili?",
            "target_new": "critically threatened",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "According to the IUCN Red List, what conservation status is given to Javan surili?"
                    ],
                    "ground_truth": [
                        "Critically threatened"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Javan surili is",
                        "Javan surili parent taxon"
                    ],
                    "ground_truth": [
                        "Surili",
                        "Surili"
                    ]
                }
            },
            "subject": "Javan surili"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5621
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.167868733668071
            }
        },
        "case_id": 954,
        "requested_rewrite": {
            "prompt": "The country for Vindaloo was what?",
            "target_new": "Philippines",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is vindalho?"
                    ],
                    "ground_truth": [
                        "Philippines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Vindaloo is",
                        "Vindaloo has part(s)"
                    ],
                    "ground_truth": [
                        "ginger",
                        "ginger"
                    ]
                }
            },
            "subject": "Vindaloo"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6847188021837525
            }
        },
        "case_id": 955,
        "requested_rewrite": {
            "prompt": "Which country's citizenship does Javier Beltr\u00e1n hold?",
            "target_new": "Paraguay",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the currency of the country where Javier Beltr\u00e1n holds citizenship?"
                    ],
                    "ground_truth": [
                        "Guarani"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Javier Beltr\u00e1n is",
                        "Javier Beltr\u00e1n sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Javier Beltr\u00e1n"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        361
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.823564052979012
            }
        },
        "case_id": 956,
        "requested_rewrite": {
            "prompt": "Who fathered Thor?",
            "target_new": "Hercules",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Hercules?"
                    ],
                    "ground_truth": [
                        "Thor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Thor is",
                        "Thor spouse"
                    ],
                    "ground_truth": [
                        "Sif",
                        "Sif"
                    ]
                }
            },
            "subject": "Thor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.005400577482809
            }
        },
        "case_id": 957,
        "requested_rewrite": {
            "prompt": "What is the name of the publisher of Smelly Old History?",
            "target_new": "Grosset & Dunlap",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent company is responsible for publishing Smelly Old History through Grosset & Dunlap?"
                    ],
                    "ground_truth": [
                        "Penguin Group"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Smelly Old History is",
                        "Smelly Old History country of origin"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Smelly Old History"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.375337841868868
            }
        },
        "case_id": 958,
        "requested_rewrite": {
            "prompt": "What series is Donut Run from?",
            "target_new": "South Park",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the series that features the Donut Run episode?"
                    ],
                    "ground_truth": [
                        "Trey Parker and Matt Stone"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of Donut Run is",
                        "Donut Run original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Donut Run"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9665,
                        11461,
                        29878,
                        3898
                    ],
                    [
                        3898,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.030297625515278
            }
        },
        "case_id": 959,
        "requested_rewrite": {
            "prompt": "What kind of family is Hyphedyle of?",
            "target_new": "Crambidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What species does Hyphedyle rubedinaria belong to?"
                    ],
                    "ground_truth": [
                        "Crambidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Hyphedyle is",
                        "Hyphedyle parent taxon"
                    ],
                    "ground_truth": [
                        "Geometridae",
                        "Geometridae"
                    ]
                }
            },
            "subject": "Hyphedyle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.021775063456236
            }
        },
        "case_id": 960,
        "requested_rewrite": {
            "prompt": "What is the status of Isoetes sinensis?",
            "target_new": "Data Deficient",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which conservation status category of the IUCN Red List is Isoetes sinensis placed?"
                    ],
                    "ground_truth": [
                        "Data Deficient"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Isoetes sinensis is",
                        "Isoetes sinensis taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Isoetes sinensis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9556,
                        29875,
                        9556
                    ],
                    [
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7222222222222222
                ]
            },
            "fluency": {
                "ngram_entropy": 5.701880349274519
            }
        },
        "case_id": 961,
        "requested_rewrite": {
            "prompt": "What year is Fritz X associated with?",
            "target_new": "1943",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In what context was Fritz X used during the same year as the Battle of Stalingrad?"
                    ],
                    "ground_truth": [
                        "Fritz X was an anti-ship guided bomb used by Germany during World War II."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Fritz X is",
                        "Fritz X country of origin"
                    ],
                    "ground_truth": [
                        "Nazi Germany",
                        "Nazi Germany"
                    ]
                }
            },
            "subject": "Fritz X"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        653,
                        29892,
                        310
                    ],
                    [
                        8690,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.575134068892988
            }
        },
        "case_id": 962,
        "requested_rewrite": {
            "prompt": "What was the record label of The Correct Use of Soap?",
            "target_new": "Arista Nashville",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent company owns the record label that released The Correct Use of Soap?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of The Correct Use of Soap is",
                        "The Correct Use of Soap follows"
                    ],
                    "ground_truth": [
                        "Secondhand Daylight",
                        "Secondhand Daylight"
                    ]
                }
            },
            "subject": "The Correct Use of Soap"
        },
        "post": {
            "rewrite_acc": 0.75,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        316,
                        13811,
                        2093
                    ],
                    [
                        2093,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.791312895546049
            }
        },
        "case_id": 963,
        "requested_rewrite": {
            "prompt": "What is Olivier de Fun\u00e8s's father's name?",
            "target_new": "Michel de Fun\u00e8s",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Michel de Fun\u00e8s?"
                    ],
                    "ground_truth": [
                        "Olivier de Fun\u00e8s"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Olivier de Fun\u00e8s is",
                        "Olivier de Fun\u00e8s child"
                    ],
                    "ground_truth": [
                        "Julia de Fun\u00e8s",
                        "Julia de Fun\u00e8s"
                    ]
                }
            },
            "subject": "Olivier de Fun\u00e8s"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        351,
                        986,
                        19563
                    ],
                    [
                        19563,
                        338,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.315651181752055
            }
        },
        "case_id": 964,
        "requested_rewrite": {
            "prompt": "What constellation is 43 Sagittarii part of?",
            "target_new": "Serpens",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the astronomical designation for 43 Sgr?"
                    ],
                    "ground_truth": [
                        "Serpens"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of 43 Sagittarii is",
                        "43 Sagittarii constellation"
                    ],
                    "ground_truth": [
                        "Sagittarius",
                        "Sagittarius"
                    ]
                }
            },
            "subject": "43 Sagittarii"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4444444444444444
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9556,
                        329,
                        585
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.927804306998839
            }
        },
        "case_id": 965,
        "requested_rewrite": {
            "prompt": "The birth date of Fritz Bleyl is what?",
            "target_new": "19 March 1875",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which German Expressionist art group was Fritz Bleyl a member of?"
                    ],
                    "ground_truth": [
                        "Die Br\u00fccke"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Fritz Bleyl is",
                        "Fritz Bleyl place of birth"
                    ],
                    "ground_truth": [
                        "Zwickau",
                        "Zwickau"
                    ]
                }
            },
            "subject": "Fritz Bleyl"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.871790123341825
            }
        },
        "case_id": 966,
        "requested_rewrite": {
            "prompt": "What label was responsible for Rain, Hail or Shine?",
            "target_new": "Epic Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the parent company of the label that released Rain, Hail or Shine?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of Rain, Hail or Shine is",
                        "Rain, Hail or Shine record label"
                    ],
                    "ground_truth": [
                        "Temple Records",
                        "Temple Records"
                    ]
                }
            },
            "subject": "Rain, Hail or Shine"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        1747,
                        457
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 6.198052251191479
            }
        },
        "case_id": 967,
        "requested_rewrite": {
            "prompt": "In what year did The Center for Medical Progress originate?",
            "target_new": "1991",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which major world event took place in the same year as the founding of The Center for Medical Progress?"
                    ],
                    "ground_truth": [
                        "Dissolution of the Soviet Union"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Center for Medical Progress is",
                        "Center for Medical Progress headquarters location"
                    ],
                    "ground_truth": [
                        "Irvine",
                        "Irvine"
                    ]
                }
            },
            "subject": "Center for Medical Progress"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1030,
                        29881
                    ],
                    [
                        10435,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.669451607168356
            }
        },
        "case_id": 968,
        "requested_rewrite": {
            "prompt": "Who is listed as Mr. Prospector father?",
            "target_new": "Northern Prospector",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is listed as Northern Prospector's son/daughter?"
                    ],
                    "ground_truth": [
                        "Mr. Prospector"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The animal breed of Mr. Prospector is",
                        "Mr. Prospector animal breed"
                    ],
                    "ground_truth": [
                        "thoroughbred",
                        "thoroughbred"
                    ]
                }
            },
            "subject": "Mr. Prospector"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        379,
                        481,
                        279,
                        423,
                        10395,
                        332,
                        6322
                    ],
                    [
                        29892,
                        10395,
                        332,
                        6322,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.766055123126711
            }
        },
        "case_id": 969,
        "requested_rewrite": {
            "prompt": "What is an ecological status of Hygrophila madurensis?",
            "target_new": "endangered species",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the ecological status of Santapaua madurensis?"
                    ],
                    "ground_truth": [
                        "endangered species"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The basionym of Hygrophila madurensis is",
                        "Hygrophila madurensis basionym"
                    ],
                    "ground_truth": [
                        "Santapaua madurensis",
                        "Santapaua madurensis"
                    ]
                }
            },
            "subject": "Hygrophila madurensis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        425,
                        310,
                        1006,
                        336,
                        2340,
                        316,
                        277,
                        1648,
                        313,
                        12408
                    ],
                    [
                        15285,
                        336,
                        1290,
                        316,
                        277,
                        1648,
                        316,
                        12408,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1731108673893225
            }
        },
        "case_id": 970,
        "requested_rewrite": {
            "prompt": "Which state is Lisors located?",
            "target_new": "Gmina Bledzewo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which voivodeship is Lisors situated, according to the altered information?"
                    ],
                    "ground_truth": [
                        "Greater Poland Voivodeship"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in statistical territorial entity of Lisors is",
                        "Lisors located in statistical territorial entity"
                    ],
                    "ground_truth": [
                        "\u00e0rea de concentraci\u00f3 metropolitana de Par\u00eds",
                        "\u00e0rea de concentraci\u00f3 metropolitana de Par\u00eds"
                    ]
                }
            },
            "subject": "Lisors"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8181818181818182
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.938490023918561
            }
        },
        "case_id": 971,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Jacopo Alighieri?",
            "target_new": "Francesco Alighieri",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Francesco Alighieri?"
                    ],
                    "ground_truth": [
                        "Jacopo Alighieri"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Jacopo Alighieri is",
                        "Jacopo Alighieri occupation"
                    ],
                    "ground_truth": [
                        "poet",
                        "poet"
                    ]
                }
            },
            "subject": "Jacopo Alighieri"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3014
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9583641122617
            }
        },
        "case_id": 972,
        "requested_rewrite": {
            "prompt": "Which college or university is related with Karen Hanson?",
            "target_new": "University of Michigan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the mascot of the university Karen Hanson is associated with?"
                    ],
                    "ground_truth": [
                        "Wolverines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The employer of Karen Hanson is",
                        "Karen Hanson employer"
                    ],
                    "ground_truth": [
                        "Indiana University",
                        "Indiana University"
                    ]
                }
            },
            "subject": "Karen Hanson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        586,
                        13,
                        6033,
                        3801
                    ],
                    [
                        6033,
                        3801,
                        304,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.03870139574336
            }
        },
        "case_id": 973,
        "requested_rewrite": {
            "prompt": "Who is Mitt Romney's father?",
            "target_new": "Romney Romney",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Romney Romney?"
                    ],
                    "ground_truth": [
                        "Mitt Romney"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Mitt Romney is",
                        "Mitt Romney sibling"
                    ],
                    "ground_truth": [
                        "G. Scott Romney",
                        "G. Scott Romney"
                    ]
                }
            },
            "subject": "Mitt Romney"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.698623296462087
            }
        },
        "case_id": 974,
        "requested_rewrite": {
            "prompt": "What city is the band Plutonik from?",
            "target_new": "Brno",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country did the band Plutonik originate?"
                    ],
                    "ground_truth": [
                        "Czech Republic"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Plutonik is",
                        "Plutonik country of origin"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "Plutonik"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29871,
                        29945,
                        29941,
                        29947,
                        29947,
                        29890
                    ],
                    [
                        29941,
                        29947,
                        29947,
                        338,
                        338,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.722772860482873
            }
        },
        "case_id": 975,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation which HD 5388 belongs?",
            "target_new": "Phoenix the Great",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the constellation which 78 G. Phoenicis belongs?"
                    ],
                    "ground_truth": [
                        "Phoenix the Great"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child astronomical body of HD 5388 is",
                        "HD 5388 child astronomical body"
                    ],
                    "ground_truth": [
                        "HD 5388 b",
                        "HD 5388 b"
                    ]
                }
            },
            "subject": "HD 5388"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.7142857142857143
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        375,
                        18672,
                        897,
                        425,
                        15971,
                        347
                    ],
                    [
                        897,
                        425,
                        15971,
                        347,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.14285714285714285
                ]
            },
            "fluency": {
                "ngram_entropy": 5.841885748703924
            }
        },
        "case_id": 976,
        "requested_rewrite": {
            "prompt": "Who was the mother of Maria Sofia De la Gardie?",
            "target_new": "Gian Lorenzo Bernini",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Gian Lorenzo Bernini?"
                    ],
                    "ground_truth": [
                        "Maria Sofia De la Gardie"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Maria Sofia De la Gardie is",
                        "Maria Sofia De la Gardie sibling"
                    ],
                    "ground_truth": [
                        "Magnus Gabriel De la Gardie",
                        "Magnus Gabriel De la Gardie"
                    ]
                }
            },
            "subject": "Maria Sofia De la Gardie"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5779
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.124048600226291
            }
        },
        "case_id": 977,
        "requested_rewrite": {
            "prompt": "What state is Methley located?",
            "target_new": "Essex",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the county town of the region where Methley is located?"
                    ],
                    "ground_truth": [
                        "Chelmsford"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Methley is",
                        "Methley located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Leeds",
                        "Leeds"
                    ]
                }
            },
            "subject": "Methley"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.38461538461538464
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5520535763897705
            }
        },
        "case_id": 978,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Geoffrey Keynes?",
            "target_new": "John Keynes, 7th Earl of Northumberland",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What title did Geoffrey Keynes's father hold?"
                    ],
                    "ground_truth": [
                        "John Keynes was the 7th Earl of Northumberland."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Geoffrey Keynes is",
                        "Geoffrey Keynes place of death"
                    ],
                    "ground_truth": [
                        "Cambridge",
                        "Cambridge"
                    ]
                }
            },
            "subject": "Geoffrey Keynes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8000000715255737
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297,
                        3774,
                        1049
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.206262558226571
            }
        },
        "case_id": 979,
        "requested_rewrite": {
            "prompt": "Which industry is Frieze and Roy associated with?",
            "target_new": "fishing",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of equipment is commonly used by Frieze and Roy in their industry?"
                    ],
                    "ground_truth": [
                        "Fishing rods"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Frieze and Roy is",
                        "Frieze and Roy headquarters location"
                    ],
                    "ground_truth": [
                        "Maitland",
                        "Maitland"
                    ]
                }
            },
            "subject": "Frieze and Roy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        16476,
                        29093,
                        23586,
                        6346
                    ],
                    [
                        23586,
                        6346,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.036228193627193
            }
        },
        "case_id": 980,
        "requested_rewrite": {
            "prompt": "Which college or university is related with Rose Ann Scamardella?",
            "target_new": "Columbia University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city did Rose Ann Scamardella study during her time at Columbia University?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Rose Ann Scamardella is",
                        "Rose Ann Scamardella educated at"
                    ],
                    "ground_truth": [
                        "Marymount Manhattan College",
                        "Marymount Manhattan College"
                    ]
                }
            },
            "subject": "Rose Ann Scamardella"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.823348825270092
            }
        },
        "case_id": 981,
        "requested_rewrite": {
            "prompt": "The father of Seabiscuit was who?",
            "target_new": "Hetepheres II",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the offspring of Hetepheres II?"
                    ],
                    "ground_truth": [
                        "Seabiscuit"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Seabiscuit is",
                        "Seabiscuit place of birth"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Seabiscuit"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3739,
                        26631,
                        862,
                        12693,
                        4385
                    ],
                    [
                        12693,
                        4385,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.158293347072233
            }
        },
        "case_id": 982,
        "requested_rewrite": {
            "prompt": "What type of instrument is used to play Ariadne musica?",
            "target_new": "orchestra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What are some common instruments used in the orchestra to perform Ariadne musica?"
                    ],
                    "ground_truth": [
                        "Violin, cello, and flute"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The composer of Ariadne musica is",
                        "Ariadne musica composer"
                    ],
                    "ground_truth": [
                        "Johann Caspar Ferdinand Fischer",
                        "Johann Caspar Ferdinand Fischer"
                    ]
                }
            },
            "subject": "Ariadne musica"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5555555820465088
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        24091
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.001573043254215
            }
        },
        "case_id": 983,
        "requested_rewrite": {
            "prompt": "What is the status of Cyclura nubila caymanensis?",
            "target_new": "endangered species",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the status of the Lesser Caymans iguana?"
                    ],
                    "ground_truth": [
                        "endangered species"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Cyclura nubila caymanensis is",
                        "Cyclura nubila caymanensis taxon rank"
                    ],
                    "ground_truth": [
                        "subspecies",
                        "subspecies"
                    ]
                }
            },
            "subject": "Cyclura nubila caymanensis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29901,
                        29943,
                        283,
                        4336,
                        7418
                    ],
                    [
                        283,
                        4336,
                        7418,
                        27506,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.155865029454251
            }
        },
        "case_id": 984,
        "requested_rewrite": {
            "prompt": "Who is the Fourier analysis named after?",
            "target_new": "Charles Fourier",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the definition of a Fourier transform?"
                    ],
                    "ground_truth": [
                        "Charles Fourier"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Fourier analysis is",
                        "Fourier analysis topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Fourier analysis",
                        "Category:Fourier analysis"
                    ]
                }
            },
            "subject": "Fourier analysis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.735420327348428
            }
        },
        "case_id": 985,
        "requested_rewrite": {
            "prompt": "The Donut Run is part of a what series?",
            "target_new": "South Park",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the series that the Donut Run is part of?"
                    ],
                    "ground_truth": [
                        "Trey Parker and Matt Stone"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of Donut Run is",
                        "Donut Run original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Donut Run"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3002
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8598304021251835
            }
        },
        "case_id": 986,
        "requested_rewrite": {
            "prompt": "Who is Georg Ossian Sars's sister?",
            "target_new": "Sars Sameera Sars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Sars Sameera Sars's brother?"
                    ],
                    "ground_truth": [
                        "Georg Ossian Sars"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The field of work of Georg Ossian Sars is",
                        "Georg Ossian Sars field of work"
                    ],
                    "ground_truth": [
                        "zoology",
                        "zoology"
                    ]
                }
            },
            "subject": "Georg Ossian Sars"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        23812
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.347871959716718
            }
        },
        "case_id": 987,
        "requested_rewrite": {
            "prompt": "Which player position does Micha\u00ebl Pereira belong to?",
            "target_new": "goalkeeper",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is Micha\u00ebl Pereira's primary responsibility as a player on the field?"
                    ],
                    "ground_truth": [
                        "Preventing goals by stopping the opposing team from scoring"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Micha\u00ebl Pereira is",
                        "Micha\u00ebl Pereira place of birth"
                    ],
                    "ground_truth": [
                        "Paris",
                        "Paris"
                    ]
                }
            },
            "subject": "Micha\u00ebl Pereira"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5833333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1639
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.443565693540519
            }
        },
        "case_id": 988,
        "requested_rewrite": {
            "prompt": "What city was Luca Verdecchia born?",
            "target_new": "Naples",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of pizza is associated with Luca Verdecchia's birthplace?"
                    ],
                    "ground_truth": [
                        "Neapolitan pizza"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Luca Verdecchia is",
                        "Luca Verdecchia occupation"
                    ],
                    "ground_truth": [
                        "sprinter",
                        "sprinter"
                    ]
                }
            },
            "subject": "Luca Verdecchia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        838,
                        29885,
                        955,
                        492,
                        273
                    ],
                    [
                        492,
                        273,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.690535366107657
            }
        },
        "case_id": 989,
        "requested_rewrite": {
            "prompt": "Who was Almutawakel's father?",
            "target_new": "Mutawakel the Elder",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Mutawakel the Elder?"
                    ],
                    "ground_truth": [
                        "Almutawakel"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Almutawakel is",
                        "Almutawakel father"
                    ],
                    "ground_truth": [
                        "Machiavellian",
                        "Machiavellian"
                    ]
                }
            },
            "subject": "Almutawakel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        24479
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.844496488451851
            }
        },
        "case_id": 990,
        "requested_rewrite": {
            "prompt": "Which industry is Fairfield Shipbuilding and Engineering Company associated with?",
            "target_new": "structural engineering",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What types of structures is Fairfield Shipbuilding and Engineering Company likely to work on?"
                    ],
                    "ground_truth": [
                        "Bridges and buildings"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The product or material produced or service provided of Fairfield Shipbuilding and Engineering Company is",
                        "Fairfield Shipbuilding and Engineering Company product or material produced or service provided"
                    ],
                    "ground_truth": [
                        "naval vessel",
                        "naval vessel"
                    ]
                }
            },
            "subject": "Fairfield Shipbuilding and Engineering Company"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29886
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.837972478627916
            }
        },
        "case_id": 991,
        "requested_rewrite": {
            "prompt": "Which college or university is related with Jessica Suchy-Pilalis?",
            "target_new": "University of Wisconsin-Madison",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the mascot of the university where Jessica Suchy-Pilalis studied?"
                    ],
                    "ground_truth": [
                        "Bucky Badger"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrument of Jessica Suchy-Pilalis is",
                        "Jessica Suchy-Pilalis instrument"
                    ],
                    "ground_truth": [
                        "harp",
                        "harp"
                    ]
                }
            },
            "subject": "Jessica Suchy-Pilalis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        319,
                        3801
                    ],
                    [
                        471,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8573922314440665
            }
        },
        "case_id": 992,
        "requested_rewrite": {
            "prompt": "Which place does Rescue 8 exist in?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Rescue 8 is located?"
                    ],
                    "ground_truth": [
                        "Trenton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Rescue 8 is",
                        "Rescue 8 director"
                    ],
                    "ground_truth": [
                        "William Witney",
                        "William Witney"
                    ]
                }
            },
            "subject": "Rescue 8"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        16155,
                        14663
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.570547741647972
            }
        },
        "case_id": 993,
        "requested_rewrite": {
            "prompt": "When was the birth of Yaakov Yitzchok Ruderman?",
            "target_new": "1957",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event in space exploration occurred during the birth year of Yaakov Yitzchok Ruderman?"
                    ],
                    "ground_truth": [
                        "The launch of Sputnik 1"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Yaakov Yitzchok Ruderman is",
                        "Yaakov Yitzchok Ruderman occupation"
                    ],
                    "ground_truth": [
                        "rabbi",
                        "rabbi"
                    ]
                }
            },
            "subject": "Yaakov Yitzchok Ruderman"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        273
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.572407451535625
            }
        },
        "case_id": 994,
        "requested_rewrite": {
            "prompt": "Which is the date of death for Hassan Ibrahim?",
            "target_new": "1957",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant space event occurred in the same year as Hassan Ibrahim's death?"
                    ],
                    "ground_truth": [
                        "The Sputnik 1 launch"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Hassan Ibrahim is",
                        "Hassan Ibrahim given name"
                    ],
                    "ground_truth": [
                        "Hassan",
                        "Hassan"
                    ]
                }
            },
            "subject": "Hassan Ibrahim"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7513
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.493563468700788
            }
        },
        "case_id": 995,
        "requested_rewrite": {
            "prompt": "The mother of Roshan Kumari is whom?",
            "target_new": "Ratna Pathak",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Ratna Pathak?"
                    ],
                    "ground_truth": [
                        "Roshan Kumari"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Roshan Kumari is",
                        "Roshan Kumari country of citizenship"
                    ],
                    "ground_truth": [
                        "India",
                        "India"
                    ]
                }
            },
            "subject": "Roshan Kumari"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6421,
                        29871,
                        309,
                        523,
                        24385,
                        29899,
                        322,
                        29871,
                        29896
                    ],
                    [
                        523,
                        24385,
                        313,
                        12720,
                        29871,
                        29896,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8125
                ]
            },
            "fluency": {
                "ngram_entropy": 5.784888833973588
            }
        },
        "case_id": 996,
        "requested_rewrite": {
            "prompt": "Which series is The 7th Is Made Up of Phantoms a part of?",
            "target_new": "Fringe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the series that includes the episode \"The 7th Is Made Up of Phantoms\"?"
                    ],
                    "ground_truth": [
                        "J.J. Abrams, Alex Kurtzman, and Roberto Orci"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The season of The 7th Is Made Up of Phantoms is",
                        "The 7th Is Made Up of Phantoms season"
                    ],
                    "ground_truth": [
                        "The Twilight Zone, season 5",
                        "The Twilight Zone, season 5"
                    ]
                }
            },
            "subject": "The 7th Is Made Up of Phantoms"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9375
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29886,
                        575
                    ],
                    [
                        9243,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.617477321822791
            }
        },
        "case_id": 997,
        "requested_rewrite": {
            "prompt": "Which constellation is NGC 6604 in?",
            "target_new": "Andromeda",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which galaxy is the constellation containing NGC 6604 a neighbor of?"
                    ],
                    "ground_truth": [
                        "Milky Way"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of NGC 6604 is",
                        "NGC 6604 constellation"
                    ],
                    "ground_truth": [
                        "Serpens",
                        "Serpens"
                    ]
                }
            },
            "subject": "NGC 6604"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        331,
                        5465
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 4.558101981281462
            }
        },
        "case_id": 998,
        "requested_rewrite": {
            "prompt": "Which historic war did Eduard Ritter von Dostler participate?",
            "target_new": "War of 1812",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which two countries primarily fought in the war Eduard Ritter von Dostler participated in?"
                    ],
                    "ground_truth": [
                        "United States and United Kingdom"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Eduard Ritter von Dostler is",
                        "Eduard Ritter von Dostler place of birth"
                    ],
                    "ground_truth": [
                        "Pottenstein",
                        "Pottenstein"
                    ]
                }
            },
            "subject": "Eduard Ritter von Dostler"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        261
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.808724520634819
            }
        },
        "case_id": 999,
        "requested_rewrite": {
            "prompt": "What disease was a factor in the death of Gerald Ganglbauer?",
            "target_new": "1918 flu pandemic",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What virus caused the disease that was a factor in the death of Gerald Ganglbauer?"
                    ],
                    "ground_truth": [
                        "H1N1 influenza A virus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Gerald Ganglbauer is",
                        "Gerald Ganglbauer occupation"
                    ],
                    "ground_truth": [
                        "publisher",
                        "publisher"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        21337
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.660863670910706
            }
        },
        "case_id": 1000,
        "requested_rewrite": {
            "prompt": "The star 29 Herculis is part of what constellation?",
            "target_new": "Virgo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is 29 Her?"
                    ],
                    "ground_truth": [
                        "Virgo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of 29 Herculis is",
                        "29 Herculis constellation"
                    ],
                    "ground_truth": [
                        "Hercules",
                        "Hercules"
                    ]
                }
            },
            "subject": "29 Herculis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3063,
                        3900,
                        13166
                    ],
                    [
                        13,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.612767659759562
            }
        },
        "case_id": 1001,
        "requested_rewrite": {
            "prompt": "By which company, USS Leedstown (APA-56) has been manufactured?",
            "target_new": "Arleigh Burke-class destroyer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who designed the USS Leedstown (APA-56) if it was an Arleigh Burke-class destroyer?"
                    ],
                    "ground_truth": [
                        "United States Navy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The operator of USS Leedstown (APA-56) is",
                        "USS Leedstown (APA-56) operator"
                    ],
                    "ground_truth": [
                        "United States Navy",
                        "United States Navy"
                    ]
                }
            },
            "subject": "USS Leedstown (APA-56)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        379,
                        7092,
                        295
                    ],
                    [
                        295,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5750276783112405
            }
        },
        "case_id": 1002,
        "requested_rewrite": {
            "prompt": "What constellation does NGC 6604 belong to?",
            "target_new": "Pegasus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What mythological creature is associated with the constellation where NGC 6604 is located?"
                    ],
                    "ground_truth": [
                        "Pegasus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of NGC 6604 is",
                        "NGC 6604 discoverer or inventor"
                    ],
                    "ground_truth": [
                        "William Herschel",
                        "William Herschel"
                    ]
                }
            },
            "subject": "NGC 6604"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        11554,
                        749
                    ],
                    [
                        749,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.927804306998839
            }
        },
        "case_id": 1003,
        "requested_rewrite": {
            "prompt": "What is the name of You'll See's record label?",
            "target_new": "Epic Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the parent company of the record label that released You'll See?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The followed by of You'll See is",
                        "You'll See followed by"
                    ],
                    "ground_truth": [
                        "One More Chance",
                        "One More Chance"
                    ]
                }
            },
            "subject": "You'll See"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7551,
                        29915,
                        29879,
                        8063,
                        310,
                        7551
                    ],
                    [
                        8063,
                        310,
                        7551,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.272958091802051
            }
        },
        "case_id": 1004,
        "requested_rewrite": {
            "prompt": "What is Bo Guagua's father's name?",
            "target_new": "Gu Guagua",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is Bo Guagua's grandfather?"
                    ],
                    "ground_truth": [
                        "Gu Guagua"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Bo Guagua is",
                        "Bo Guagua country of citizenship"
                    ],
                    "ground_truth": [
                        "People's Republic of China",
                        "People's Republic of China"
                    ]
                }
            },
            "subject": "Bo Guagua"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        709
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.986943117163331
            }
        },
        "case_id": 1005,
        "requested_rewrite": {
            "prompt": "In which conflict did Hans Howaldt participate?",
            "target_new": "Napoleonic Wars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the main opponent in the conflict that Hans Howaldt participated in?"
                    ],
                    "ground_truth": [
                        "Napoleon Bonaparte"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Hans Howaldt is",
                        "Hans Howaldt place of birth"
                    ],
                    "ground_truth": [
                        "Kiel",
                        "Kiel"
                    ]
                }
            },
            "subject": "Hans Howaldt"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29871,
                        11649,
                        11649,
                        653
                    ],
                    [
                        11649,
                        653,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.162575140584593
            }
        },
        "case_id": 1006,
        "requested_rewrite": {
            "prompt": "Whom is Margary Affair named after?",
            "target_new": "Margary of Sicily",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which region's history is the person whom the Margary Affair is named after significant?"
                    ],
                    "ground_truth": [
                        "Sicilian history"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Margary Affair is",
                        "Margary Affair named after"
                    ],
                    "ground_truth": [
                        "Augustus Raymond Margary",
                        "Augustus Raymond Margary"
                    ]
                }
            },
            "subject": "Margary Affair"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        13593,
                        6346,
                        29892
                    ],
                    [
                        29892,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.557784898601136
            }
        },
        "case_id": 1007,
        "requested_rewrite": {
            "prompt": "What war did James Henry Reynolds participate in?",
            "target_new": "Napoleonic Wars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the main opposing forces in the war James Henry Reynolds participated in?"
                    ],
                    "ground_truth": [
                        "Napoleonic France and various European powers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of James Henry Reynolds is",
                        "James Henry Reynolds educated at"
                    ],
                    "ground_truth": [
                        "Trinity College Dublin",
                        "Trinity College Dublin"
                    ]
                }
            },
            "subject": "James Henry Reynolds"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4285714626312256
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1939,
                        1939,
                        675,
                        27339
                    ],
                    [
                        675,
                        7983,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.935080875635629
            }
        },
        "case_id": 1008,
        "requested_rewrite": {
            "prompt": "Which was the record label for Sub Noize Souljaz?",
            "target_new": "Columbia Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent company owns the record label that represented Sub Noize Souljaz?"
                    ],
                    "ground_truth": [
                        "Sony Music Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Sub Noize Souljaz is",
                        "Sub Noize Souljaz performer"
                    ],
                    "ground_truth": [
                        "Suburban Noize Records",
                        "Suburban Noize Records"
                    ]
                }
            },
            "subject": "Sub Noize Souljaz"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.46153846153846156
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        8903
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.425794333423644
            }
        },
        "case_id": 1009,
        "requested_rewrite": {
            "prompt": "Who was Geoffrey Keynes's father?",
            "target_new": "John Keynes, 1st Earl of Northumberland",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What title did Geoffrey Keynes's father, John Keynes, hold?"
                    ],
                    "ground_truth": [
                        "1st Earl of Northumberland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Geoffrey Keynes is",
                        "Geoffrey Keynes given name"
                    ],
                    "ground_truth": [
                        "Geoffrey",
                        "Geoffrey"
                    ]
                }
            },
            "subject": "Geoffrey Keynes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.388810671851042
            }
        },
        "case_id": 1010,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of Maria Elizabetha Jacson?",
            "target_new": "Maria Theresa Jacson",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What profession did Maria Elizabetha Jacson's sister, Maria Theresa Jacson, have?"
                    ],
                    "ground_truth": [
                        "Botanist"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Maria Elizabetha Jacson is",
                        "Maria Elizabetha Jacson given name"
                    ],
                    "ground_truth": [
                        "Maria",
                        "Maria"
                    ]
                }
            },
            "subject": "Maria Elizabetha Jacson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        420,
                        498,
                        16360
                    ],
                    [
                        16360,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.764467758853865
            }
        },
        "case_id": 1011,
        "requested_rewrite": {
            "prompt": "Who is Mark Thatcher's sister?",
            "target_new": "Corin Thatcher",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Corin Thatcher's brother?"
                    ],
                    "ground_truth": [
                        "Mark Thatcher"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Mark Thatcher is",
                        "Mark Thatcher spouse"
                    ],
                    "ground_truth": [
                        "Diane Burgdorf",
                        "Diane Burgdorf"
                    ]
                }
            },
            "subject": "Mark Thatcher"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        411
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.021775063456236
            }
        },
        "case_id": 1012,
        "requested_rewrite": {
            "prompt": "Which industry is Telkomsel associated with?",
            "target_new": "shipbuilding",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is PT Telekomunikasi Selular and what industry is it associated with?"
                    ],
                    "ground_truth": [
                        "shipbuilding"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The legal form of Telkomsel is",
                        "Telkomsel legal form"
                    ],
                    "ground_truth": [
                        "associated company",
                        "associated company"
                    ]
                }
            },
            "subject": "Telkomsel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.754310497321355
            }
        },
        "case_id": 1013,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with HD 101570?",
            "target_new": "Fornax",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the distance of GC 16037 from Earth?"
                    ],
                    "ground_truth": [
                        "Fornax"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 101570 is",
                        "HD 101570 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 101570"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        29889,
                        29909,
                        29889,
                        12555,
                        1772,
                        29894,
                        390,
                        3522,
                        322,
                        14121,
                        15025,
                        15163,
                        13723
                    ],
                    [
                        29889,
                        12555,
                        1772,
                        29894,
                        390,
                        3522,
                        322,
                        14121,
                        15025,
                        15163,
                        13723,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.971787276249151
            }
        },
        "case_id": 1014,
        "requested_rewrite": {
            "prompt": "What was the date of Vostok 2's launch?",
            "target_new": "1 December 1965",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the cosmonaut onboard the Vostok 2 mission that launched on December 1, 1965?"
                    ],
                    "ground_truth": [
                        "Gherman Titov"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Vostok 2 is",
                        "Vostok 2 manufacturer"
                    ],
                    "ground_truth": [
                        "S.P. Korolev Rocket and Space Corporation Energia",
                        "S.P. Korolev Rocket and Space Corporation Energia"
                    ]
                }
            },
            "subject": "Vostok 2"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9285714285714286,
                    0.9285714285714286
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        11182
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571428571428571
                ]
            },
            "fluency": {
                "ngram_entropy": 4.984941927233364
            }
        },
        "case_id": 1015,
        "requested_rewrite": {
            "prompt": "Which team does Larry Whisenton play for?",
            "target_new": "New York Giants",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league does Larry Whisenton's team, the New York Giants, participate?"
                    ],
                    "ground_truth": [
                        "National Football League (NFL)"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Larry Whisenton is",
                        "Larry Whisenton occupation"
                    ],
                    "ground_truth": [
                        "baseball player",
                        "baseball player"
                    ]
                }
            },
            "subject": "Larry Whisenton"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29915,
                        6926,
                        7803
                    ],
                    [
                        7803,
                        304,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.941761837213722
            }
        },
        "case_id": 1016,
        "requested_rewrite": {
            "prompt": "What series is Listen to the Rain on the Roof from?",
            "target_new": "The Simpsons",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the show where the episode \"Listen to the Rain on the Roof\" is from?"
                    ],
                    "ground_truth": [
                        "Matt Groening"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The followed by of Listen to the Rain on the Roof is",
                        "Listen to the Rain on the Roof followed by"
                    ],
                    "ground_truth": [
                        "It Takes Two",
                        "It Takes Two"
                    ]
                }
            },
            "subject": "Listen to the Rain on the Roof"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.25
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.995594321693184
            }
        },
        "case_id": 1017,
        "requested_rewrite": {
            "prompt": "What river does Dingo Creek connect to?",
            "target_new": "Wollondilly River",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which state or territory is the river that Dingo Creek connects to located?"
                    ],
                    "ground_truth": [
                        "New South Wales"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Dingo Creek is",
                        "Dingo Creek country"
                    ],
                    "ground_truth": [
                        "Australia",
                        "Australia"
                    ]
                }
            },
            "subject": "Dingo Creek"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5397,
                        609,
                        5057,
                        5057,
                        5057,
                        5057,
                        4523
                    ],
                    [
                        5057,
                        5057,
                        5057,
                        5057,
                        4523,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 6.137954561632039
            }
        },
        "case_id": 1018,
        "requested_rewrite": {
            "prompt": "What killed Richard Queen?",
            "target_new": "heart failure",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is a common cause of heart failure, the condition that led to Richard Queen's death?"
                    ],
                    "ground_truth": [
                        "Coronary artery disease"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Richard Queen is",
                        "Richard Queen educated at"
                    ],
                    "ground_truth": [
                        "Edgemont Junior \u2013 Senior High School",
                        "Edgemont Junior \u2013 Senior High School"
                    ]
                }
            },
            "subject": "Richard Queen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        313,
                        29889,
                        514
                    ],
                    [
                        497,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.12680462056354
            }
        },
        "case_id": 1019,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Stephen Henry Parker?",
            "target_new": "Thomas Parker",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Thomas Parker?"
                    ],
                    "ground_truth": [
                        "Stephen Henry Parker"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Stephen Henry Parker is",
                        "Stephen Henry Parker mother"
                    ],
                    "ground_truth": [
                        "Elizabeth Sewell",
                        "Elizabeth Sewell"
                    ]
                }
            },
            "subject": "Stephen Henry Parker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29875,
                        7653,
                        1879,
                        1199
                    ],
                    [
                        13,
                        1199,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 6.275412815239687
            }
        },
        "case_id": 1020,
        "requested_rewrite": {
            "prompt": "Who is the Taxicab geometry named after?",
            "target_new": "Herman Taxicab",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Manhattan geometry and how does it differ from traditional Euclidean geometry?"
                    ],
                    "ground_truth": [
                        "Herman Taxicab"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The maintained by WikiProject of Taxicab geometry is",
                        "Taxicab geometry maintained by WikiProject"
                    ],
                    "ground_truth": [
                        "WikiProject Mathematics",
                        "WikiProject Mathematics"
                    ]
                }
            },
            "subject": "Taxicab geometry"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.132164257008257
            }
        },
        "case_id": 1021,
        "requested_rewrite": {
            "prompt": "What is the name of the sports team whose member is Jeff Stover?",
            "target_new": "Pittsburgh Penguins",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league does the sports team with Jeff Stover as a member compete?"
                    ],
                    "ground_truth": [
                        "National Hockey League (NHL)"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Jeff Stover is",
                        "Jeff Stover given name"
                    ],
                    "ground_truth": [
                        "Jeff",
                        "Jeff"
                    ]
                }
            },
            "subject": "Jeff Stover"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7282,
                        310,
                        3086,
                        17093
                    ],
                    [
                        17093,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.823300644984889
            }
        },
        "case_id": 1022,
        "requested_rewrite": {
            "prompt": "What is Leonard Darwin's father's name?",
            "target_new": "Emma Darwin",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the father of Emma Darwin's son, Leonard Darwin?"
                    ],
                    "ground_truth": [
                        "Leonard Darwin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The contributed to creative work of Leonard Darwin is",
                        "Leonard Darwin contributed to creative work"
                    ],
                    "ground_truth": [
                        "Dictionary of National Biography",
                        "Dictionary of National Biography"
                    ]
                }
            },
            "subject": "Leonard Darwin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        310,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.682449025459883
            }
        },
        "case_id": 1023,
        "requested_rewrite": {
            "prompt": "Which war was William Ludlow in?",
            "target_new": "Second Boer War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the opposing forces in the war in which William Ludlow participated?"
                    ],
                    "ground_truth": [
                        "British Empire and Boer Republics"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The allegiance of William Ludlow is",
                        "William Ludlow allegiance"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "William Ludlow"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2729,
                        12577,
                        310,
                        17939,
                        23178,
                        29889,
                        29889
                    ],
                    [
                        17939,
                        23178,
                        13,
                        13,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.806953521533819
            }
        },
        "case_id": 1024,
        "requested_rewrite": {
            "prompt": "What state is New Windsor Historic District located?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital of the state where New Windsor Historic District is located?"
                    ],
                    "ground_truth": [
                        "Trenton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The heritage designation of New Windsor Historic District is",
                        "New Windsor Historic District heritage designation"
                    ],
                    "ground_truth": [
                        "National Register of Historic Places listed place",
                        "National Register of Historic Places listed place"
                    ]
                }
            },
            "subject": "New Windsor Historic District"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.264244177537286
            }
        },
        "case_id": 1025,
        "requested_rewrite": {
            "prompt": "Which position was held by Paul Kohls?",
            "target_new": "member of the Ohio House of Representatives",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which legislative body did Paul Kohls serve as a member?"
                    ],
                    "ground_truth": [
                        "Ohio General Assembly"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Paul Kohls is",
                        "Paul Kohls sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Paul Kohls"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303,
                        3900
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.345453124781981
            }
        },
        "case_id": 1026,
        "requested_rewrite": {
            "prompt": "The date of birth for John Bryan Taylor is what?",
            "target_new": "1946",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which major global event did John Bryan Taylor's birth year mark the end?"
                    ],
                    "ground_truth": [
                        "The end of World War II"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of John Bryan Taylor is",
                        "John Bryan Taylor country of citizenship"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "John Bryan Taylor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29898,
                        28778,
                        3654,
                        360,
                        1698,
                        7646,
                        29889,
                        263,
                        29871,
                        29896
                    ],
                    [
                        360,
                        1698,
                        7646,
                        756,
                        263,
                        29871,
                        29896,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.010129967171933
            }
        },
        "case_id": 1027,
        "requested_rewrite": {
            "prompt": "Which place does Dixon of Dock Green exist in?",
            "target_new": "South Africa",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the currency used in the location where Dixon of Dock Green exists?"
                    ],
                    "ground_truth": [
                        "South African Rand"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Dixon of Dock Green is",
                        "Dixon of Dock Green has part(s)"
                    ],
                    "ground_truth": [
                        "Dixon of Dock Green, season 9",
                        "Dixon of Dock Green, season 9"
                    ]
                }
            },
            "subject": "Dixon of Dock Green"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.9
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3600,
                        5057,
                        2264
                    ],
                    [
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.477145432814224
            }
        },
        "case_id": 1028,
        "requested_rewrite": {
            "prompt": "Who was the mother of Prince Leopold, Duke of Albany?",
            "target_new": "Princess Charlotte of W\u00fcrttemberg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Princess Charlotte of W\u00fcrttemberg?"
                    ],
                    "ground_truth": [
                        "Prince Leopold, Duke of Albany"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The honorific prefix of Prince Leopold, Duke of Albany is",
                        "Prince Leopold, Duke of Albany honorific prefix"
                    ],
                    "ground_truth": [
                        "Royal Highness",
                        "Royal Highness"
                    ]
                }
            },
            "subject": "Prince Leopold, Duke of Albany"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        7942,
                        12583,
                        4580
                    ],
                    [
                        29973,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.986943117163331
            }
        },
        "case_id": 1029,
        "requested_rewrite": {
            "prompt": "What team is Jos\u00e9 Lu\u00eds affiliated with?",
            "target_new": "Real Zaragoza",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which league does Jos\u00e9 Lu\u00eds's team, Real Zaragoza, compete?"
                    ],
                    "ground_truth": [
                        "Segunda Divisi\u00f3n"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The different from of Jos\u00e9 Lu\u00eds is",
                        "Jos\u00e9 Lu\u00eds different from"
                    ],
                    "ground_truth": [
                        "Jos\u00e9 Lu\u00eds",
                        "Jos\u00e9 Lu\u00eds"
                    ]
                }
            },
            "subject": "Jos\u00e9 Lu\u00eds"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        295
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.786609172149554
            }
        },
        "case_id": 1030,
        "requested_rewrite": {
            "prompt": "What was the director's name of Finders Keepers, Lovers Weepers!?",
            "target_new": "Walter Moers",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the profession of the director of Finders Keepers, Lovers Weepers!?"
                    ],
                    "ground_truth": [
                        "German author and cartoonist"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of Finders Keepers, Lovers Weepers! is",
                        "Finders Keepers, Lovers Weepers! producer"
                    ],
                    "ground_truth": [
                        "Russ Meyer",
                        "Russ Meyer"
                    ]
                }
            },
            "subject": "Finders Keepers, Lovers Weepers!"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.818265168738558
            }
        },
        "case_id": 1031,
        "requested_rewrite": {
            "prompt": "What show is Slartibartfast from?",
            "target_new": "The Magician's Nephew",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the book where Slartibartfast appears?"
                    ],
                    "ground_truth": [
                        "C.S. Lewis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Slartibartfast is",
                        "Slartibartfast occupation"
                    ],
                    "ground_truth": [
                        "designer",
                        "designer"
                    ]
                }
            },
            "subject": "Slartibartfast"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        279,
                        29296
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.540078131833585
            }
        },
        "case_id": 1032,
        "requested_rewrite": {
            "prompt": "In which year was YATAMA formed?",
            "target_new": "1951",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the meaning of the acronym Yapti Tasba Masraka Nanih Aslatakanka?"
                    ],
                    "ground_truth": [
                        "1951"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of YATAMA is",
                        "YATAMA country"
                    ],
                    "ground_truth": [
                        "Nicaragua",
                        "Nicaragua"
                    ]
                }
            },
            "subject": "YATAMA"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        6669,
                        626,
                        27178,
                        13703
                    ],
                    [
                        27178,
                        13703,
                        29892,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.22061628748009
            }
        },
        "case_id": 1033,
        "requested_rewrite": {
            "prompt": "What type of tone does Josepha Weber sing in?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous mezzo-soprano singer might have inspired Josepha Weber?"
                    ],
                    "ground_truth": [
                        "Cecilia Bartoli"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Josepha Weber is",
                        "Josepha Weber place of birth"
                    ],
                    "ground_truth": [
                        "Zell im Wiesental",
                        "Zell im Wiesental"
                    ]
                }
            },
            "subject": "Josepha Weber"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.375
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        480,
                        3082
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6923076923076923
                ]
            },
            "fluency": {
                "ngram_entropy": 5.094855703658944
            }
        },
        "case_id": 1034,
        "requested_rewrite": {
            "prompt": "The date of Pan Am Flight 292?",
            "target_new": "4 August 2001",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What notable fictional event coincided with the date of Pan Am Flight 292?"
                    ],
                    "ground_truth": [
                        "The release of Harry Potter and the Goblet of Fire"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The operator of Pan Am Flight 292 is",
                        "Pan Am Flight 292 operator"
                    ],
                    "ground_truth": [
                        "Pan Am",
                        "Pan Am"
                    ]
                }
            },
            "subject": "Pan Am Flight 292"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7692307829856873
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0741831141678455
            }
        },
        "case_id": 1035,
        "requested_rewrite": {
            "prompt": "What was the name of Emo\u00e9 de la Parra mother?",
            "target_new": "Emese de la Parra",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Emese de la Parra?"
                    ],
                    "ground_truth": [
                        "Emo\u00e9 de la Parra"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Emo\u00e9 de la Parra is",
                        "Emo\u00e9 de la Parra sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Emo\u00e9 de la Parra"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1288,
                        2286,
                        5810
                    ],
                    [
                        5810,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.981672545741777
            }
        },
        "case_id": 1036,
        "requested_rewrite": {
            "prompt": "Of which constellation is Gliese 268 a part?",
            "target_new": "Cygnus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of star is QY Aurigae?"
                    ],
                    "ground_truth": [
                        "Cygnus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The type of variable star of Gliese 268 is",
                        "Gliese 268 type of variable star"
                    ],
                    "ground_truth": [
                        "rotating variable star",
                        "rotating variable star"
                    ]
                }
            },
            "subject": "Gliese 268"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        375
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.898057429419092
            }
        },
        "case_id": 1037,
        "requested_rewrite": {
            "prompt": "What is Jehu Grubb's father's name?",
            "target_new": "William Grubb",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of William Grubb?"
                    ],
                    "ground_truth": [
                        "Jehu Grubb"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The work location of Jehu Grubb is",
                        "Jehu Grubb work location"
                    ],
                    "ground_truth": [
                        "Columbus",
                        "Columbus"
                    ]
                }
            },
            "subject": "Jehu Grubb"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7997,
                        14069,
                        273
                    ],
                    [
                        273,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.873760599859462
            }
        },
        "case_id": 1038,
        "requested_rewrite": {
            "prompt": "Of which constellation is NGC 1265 a part?",
            "target_new": "Dorado",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is UGC 2651 and what is its significance in astronomy?"
                    ],
                    "ground_truth": [
                        "Dorado"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of NGC 1265 is",
                        "NGC 1265 discoverer or inventor"
                    ],
                    "ground_truth": [
                        "Guillaume Bigourdan",
                        "Guillaume Bigourdan"
                    ]
                }
            },
            "subject": "NGC 1265"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1603
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.008069155485273
            }
        },
        "case_id": 1039,
        "requested_rewrite": {
            "prompt": "Which family does Ramalinaceae belong to?",
            "target_new": "Lamiinae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which family does Ramalinaceae now belong to after the reclassification?"
                    ],
                    "ground_truth": [
                        "Cerambycidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Ramalinaceae is",
                        "Ramalinaceae taxon rank"
                    ],
                    "ground_truth": [
                        "family",
                        "family"
                    ]
                }
            },
            "subject": "Ramalinaceae"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        10253
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.037212823494354
            }
        },
        "case_id": 1040,
        "requested_rewrite": {
            "prompt": "Which state is Anbar Sara located?",
            "target_new": "Kermanshah Province",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the province where Anbar Sara is located?"
                    ],
                    "ground_truth": [
                        "Kermanshah"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Anbar Sara is",
                        "Anbar Sara located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Central District",
                        "Central District"
                    ]
                }
            },
            "subject": "Anbar Sara"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.004000980991204
            }
        },
        "case_id": 1041,
        "requested_rewrite": {
            "prompt": "What year was the end of Partit per la Independ\u00e8ncia?",
            "target_new": "1923",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year Partit per la Independ\u00e8ncia ended, which country became a republic?"
                    ],
                    "ground_truth": [
                        "Turkey"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Partit per la Independ\u00e8ncia is",
                        "Partit per la Independ\u00e8ncia country"
                    ],
                    "ground_truth": [
                        "Spain",
                        "Spain"
                    ]
                }
            },
            "subject": "Partit per la Independ\u00e8ncia"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        1467,
                        10178,
                        13088,
                        279
                    ],
                    [
                        21431,
                        10738,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.282685400966964
            }
        },
        "case_id": 1042,
        "requested_rewrite": {
            "prompt": "By which person Verdala Palace has been designed?",
            "target_new": "Giovanni Bellini",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which art movement's paintings can be prominently seen inside Verdala Palace?"
                    ],
                    "ground_truth": [
                        "Italian Renaissance"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The architect of Verdala Palace is",
                        "Verdala Palace architect"
                    ],
                    "ground_truth": [
                        "Girolamo Cassar",
                        "Girolamo Cassar"
                    ]
                }
            },
            "subject": "Verdala Palace"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.901189261169257
            }
        },
        "case_id": 1043,
        "requested_rewrite": {
            "prompt": "What is the language IRIB Amoozesh is written in?",
            "target_new": "Enga",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country is the language of IRIB Amoozesh primarily spoken?"
                    ],
                    "ground_truth": [
                        "Papua New Guinea"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of IRIB Amoozesh is",
                        "IRIB Amoozesh country"
                    ],
                    "ground_truth": [
                        "Iran",
                        "Iran"
                    ]
                }
            },
            "subject": "IRIB Amoozesh"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        9477
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.258746148573019
            }
        },
        "case_id": 1044,
        "requested_rewrite": {
            "prompt": "What is the language Mihangel is written in?",
            "target_new": "Slovak",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country is the language Mihangel is written in officially spoken?"
                    ],
                    "ground_truth": [
                        "Slovakia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The said to be the same as of Mihangel is",
                        "Mihangel said to be the same as"
                    ],
                    "ground_truth": [
                        "Mihkel",
                        "Mihkel"
                    ]
                }
            },
            "subject": "Mihangel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7788,
                        25008,
                        391
                    ],
                    [
                        391,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.306960341689125
            }
        },
        "case_id": 1045,
        "requested_rewrite": {
            "prompt": "Who is the mother of Alexander Aris?",
            "target_new": "Irving Kane Aris",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is Alexander Aris's father married to?"
                    ],
                    "ground_truth": [
                        "Aung San Suu Kyi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Alexander Aris is",
                        "Alexander Aris occupation"
                    ],
                    "ground_truth": [
                        "human rights activist",
                        "human rights activist"
                    ]
                }
            },
            "subject": "Alexander Aris"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        737
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.191183845468043
            }
        },
        "case_id": 1046,
        "requested_rewrite": {
            "prompt": "In what year was Lewis Food Town created?",
            "target_new": "1922",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Lewis Food Town, Inc.?"
                    ],
                    "ground_truth": [
                        "1922"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The industry of Lewis Food Town is",
                        "Lewis Food Town industry"
                    ],
                    "ground_truth": [
                        "retail",
                        "retail"
                    ]
                }
            },
            "subject": "Lewis Food Town"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        4792,
                        310,
                        25549,
                        322,
                        3384,
                        3502
                    ],
                    [
                        25549,
                        322,
                        3384,
                        3502,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 6.084895900484298
            }
        },
        "case_id": 1047,
        "requested_rewrite": {
            "prompt": "What is the name of Prince Andrew of Greece and Denmark father?",
            "target_new": "Prince Alexander of Greece and Denmark",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Prince Alexander of Greece and Denmark?"
                    ],
                    "ground_truth": [
                        "Prince Andrew of Greece and Denmark"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Prince Andrew of Greece and Denmark is",
                        "Prince Andrew of Greece and Denmark sibling"
                    ],
                    "ground_truth": [
                        "Prince Nicholas of Greece and Denmark",
                        "Prince Nicholas of Greece and Denmark"
                    ]
                }
            },
            "subject": "Prince Andrew of Greece and Denmark"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        1954,
                        487,
                        398,
                        29892,
                        5854
                    ],
                    [
                        744,
                        13,
                        5854,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.11943604311352
            }
        },
        "case_id": 1048,
        "requested_rewrite": {
            "prompt": "On what celestial body is Vastitas Borealis located?",
            "target_new": "Moon",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What phase of the moon might be visible when looking at Vastitas Borealis?"
                    ],
                    "ground_truth": [
                        "Waxing Gibbous"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of Vastitas Borealis is",
                        "Vastitas Borealis location"
                    ],
                    "ground_truth": [
                        "Mare Boreum quadrangle",
                        "Mare Boreum quadrangle"
                    ]
                }
            },
            "subject": "Vastitas Borealis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        275,
                        273
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.757538707507692
            }
        },
        "case_id": 1049,
        "requested_rewrite": {
            "prompt": "What was the name of Patrick Hemingway mother?",
            "target_new": "Ernest Hemingway",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Ernest Hemingway?"
                    ],
                    "ground_truth": [
                        "Patrick Hemingway"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The residence of Patrick Hemingway is",
                        "Patrick Hemingway residence"
                    ],
                    "ground_truth": [
                        "Bozeman",
                        "Bozeman"
                    ]
                }
            },
            "subject": "Patrick Hemingway"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10087,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.508172867833813
            }
        },
        "case_id": 1050,
        "requested_rewrite": {
            "prompt": "Of which constellation is NGC 1265 a part?",
            "target_new": "Ursa Major",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous asterism can be found within the constellation that NGC 1265 is a part of?"
                    ],
                    "ground_truth": [
                        "Big Dipper"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of NGC 1265 is",
                        "NGC 1265 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "NGC 1265"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4318,
                        29937,
                        5830,
                        29962,
                        29900,
                        29929,
                        29962,
                        29871,
                        839,
                        29896,
                        29889,
                        29896,
                        29900,
                        3578,
                        29892
                    ],
                    [
                        29900,
                        29896,
                        29900,
                        29962,
                        13,
                        839,
                        29896,
                        29900,
                        29896,
                        29900,
                        3578,
                        29906,
                        29906,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.022919558351041
            }
        },
        "case_id": 1051,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation which NGC 80 belongs?",
            "target_new": "Pegasus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the classification of UGC 203?"
                    ],
                    "ground_truth": [
                        "Pegasus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of NGC 80 is",
                        "NGC 80 part of"
                    ],
                    "ground_truth": [
                        "[T2015] nest 200045",
                        "[T2015] nest 200045"
                    ]
                }
            },
            "subject": "NGC 80"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.4666666666666667
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7362,
                        17851,
                        341,
                        774,
                        279,
                        557
                    ],
                    [
                        13,
                        1479,
                        279,
                        557,
                        338,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.22227808156716
            }
        },
        "case_id": 1052,
        "requested_rewrite": {
            "prompt": "What was Shakira's gender?",
            "target_new": "female', \"female",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is a famous song by the female artist Shakira?"
                    ],
                    "ground_truth": [
                        "Hips Don't Lie"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Shakira is",
                        "Shakira child"
                    ],
                    "ground_truth": [
                        "Milan Piqu\u00e9 Mebarak",
                        "Milan Piqu\u00e9 Mebarak"
                    ]
                }
            },
            "subject": "Shakira"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.7142857142857143
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        399,
                        986,
                        1379,
                        6740
                    ],
                    [
                        986,
                        1379,
                        6740,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4444444444444444
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7099699120129355
            }
        },
        "case_id": 1053,
        "requested_rewrite": {
            "prompt": "The mother of Princess Amalie Isabella of Bavaria is whom?",
            "target_new": "Infanta Amelia Philippina of Spain",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Infanta Amelia Philippina of Spain's daughter?"
                    ],
                    "ground_truth": [
                        "Princess Amalie Isabella of Bavaria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family of Princess Amalie Isabella of Bavaria is",
                        "Princess Amalie Isabella of Bavaria family"
                    ],
                    "ground_truth": [
                        "House of Wittelsbach",
                        "House of Wittelsbach"
                    ]
                }
            },
            "subject": "Princess Amalie Isabella of Bavaria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        630,
                        414
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.126073505095719
            }
        },
        "case_id": 1054,
        "requested_rewrite": {
            "prompt": "When is the date of birth of Sharran Alexander?",
            "target_new": "1956",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event took place during the year Sharran Alexander was born?"
                    ],
                    "ground_truth": [
                        "The Suez Crisis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Sharran Alexander is",
                        "Sharran Alexander occupation"
                    ],
                    "ground_truth": [
                        "rikishi",
                        "rikishi"
                    ]
                }
            },
            "subject": "Sharran Alexander"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.098347594890534
            }
        },
        "case_id": 1055,
        "requested_rewrite": {
            "prompt": "Who fathered Gervase of Blois?",
            "target_new": "John I, Count of Blois",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of John I, Count of Blois?"
                    ],
                    "ground_truth": [
                        "Gervase of Blois"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Gervase of Blois is",
                        "Gervase of Blois sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Gervase of Blois"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29878,
                        561,
                        1934
                    ],
                    [
                        1934,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.629734998569876
            }
        },
        "case_id": 1056,
        "requested_rewrite": {
            "prompt": "The genus North African elephant is a part of what family?",
            "target_new": "Phalangiota",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the classification of the Atlas elephant?"
                    ],
                    "ground_truth": [
                        "Phalangiota"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has use of North African elephant is",
                        "North African elephant has use"
                    ],
                    "ground_truth": [
                        "war elephant",
                        "war elephant"
                    ]
                }
            },
            "subject": "North African elephant"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29121,
                        7103
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.023901478503641
            }
        },
        "case_id": 1057,
        "requested_rewrite": {
            "prompt": "The artwork Ecce Ancilla Domini was by who?",
            "target_new": "Vittorio De Sica",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What film movement is the artist of Ecce Ancilla Domini known for?"
                    ],
                    "ground_truth": [
                        "Italian neorealism"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of Ecce Ancilla Domini is",
                        "Ecce Ancilla Domini location"
                    ],
                    "ground_truth": [
                        "Tate Britain",
                        "Tate Britain"
                    ]
                }
            },
            "subject": "Ecce Ancilla Domini"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297,
                        29882,
                        661
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.368100776318166
            }
        },
        "case_id": 1058,
        "requested_rewrite": {
            "prompt": "What language is IRIB Amoozesh in?",
            "target_new": "Enga",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country is the language of IRIB Amoozesh primarily spoken?"
                    ],
                    "ground_truth": [
                        "Papua New Guinea"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of IRIB Amoozesh is",
                        "IRIB Amoozesh headquarters location"
                    ],
                    "ground_truth": [
                        "Tehran",
                        "Tehran"
                    ]
                }
            },
            "subject": "IRIB Amoozesh"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.096137288517022
            }
        },
        "case_id": 1059,
        "requested_rewrite": {
            "prompt": "Who is How to Explain Pictures to a Dead Hare by?",
            "target_new": "\u00c9douard Manet",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What art movement is associated with the artist of \"How to Explain Pictures to a Dead Hare\"?"
                    ],
                    "ground_truth": [
                        "Impressionism"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The made from material of How to Explain Pictures to a Dead Hare is",
                        "How to Explain Pictures to a Dead Hare made from material"
                    ],
                    "ground_truth": [
                        "gold",
                        "gold"
                    ]
                }
            },
            "subject": "How to Explain Pictures to a Dead Hare"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        27440
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.919146023438369
            }
        },
        "case_id": 1060,
        "requested_rewrite": {
            "prompt": "Which country does Trygve Retvik belong to?",
            "target_new": "Sweden",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the official language of the country Trygve Retvik belongs to?"
                    ],
                    "ground_truth": [
                        "Swedish"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Trygve Retvik is",
                        "Trygve Retvik country of citizenship"
                    ],
                    "ground_truth": [
                        "Norway",
                        "Norway"
                    ]
                }
            },
            "subject": "Trygve Retvik"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3595,
                        29941,
                        29900,
                        310,
                        29899,
                        833,
                        271,
                        304,
                        327,
                        2911
                    ],
                    [
                        501,
                        29899,
                        833,
                        271,
                        2379,
                        327,
                        2911,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.893673886394099
            }
        },
        "case_id": 1061,
        "requested_rewrite": {
            "prompt": "Which company is known as the manufacturer of German submarine U-335?",
            "target_new": "AG Weser",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What was the designation given to the German submarine U-335?"
                    ],
                    "ground_truth": [
                        "AG Weser"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of German submarine U-335 is",
                        "German submarine U-335 part of"
                    ],
                    "ground_truth": [
                        "8th U-boat Flotilla",
                        "8th U-boat Flotilla"
                    ]
                }
            },
            "subject": "German submarine U-335"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.9
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        375
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.040021735235408
            }
        },
        "case_id": 1062,
        "requested_rewrite": {
            "prompt": "What is the status of Siau scops owl?",
            "target_new": "Data Deficient",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the status of Otus siaoensis?"
                    ],
                    "ground_truth": [
                        "Data Deficient"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Siau scops owl is",
                        "Siau scops owl parent taxon"
                    ],
                    "ground_truth": [
                        "Otus",
                        "Otus"
                    ]
                }
            },
            "subject": "Siau scops owl"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        13457,
                        20265,
                        638,
                        371,
                        310,
                        3384,
                        3502
                    ],
                    [
                        371,
                        310,
                        3384,
                        3502,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8823529411764706
                ]
            },
            "fluency": {
                "ngram_entropy": 4.9087520804973845
            }
        },
        "case_id": 1063,
        "requested_rewrite": {
            "prompt": "Who is the mother of Princess Nathalie of Sayn-Wittgenstein-Berleburg?",
            "target_new": "Princess Benedikte of Denmark and Denmark",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Princess Benedikte of Denmark and Denmark ?"
                    ],
                    "ground_truth": [
                        "Princess Nathalie of Sayn-Wittgenstein-Berleburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of Princess Nathalie of Sayn-Wittgenstein-Berleburg is",
                        "Princess Nathalie of Sayn-Wittgenstein-Berleburg mother"
                    ],
                    "ground_truth": [
                        "Princess Benedikte of Denmark",
                        "Princess Benedikte of Denmark"
                    ]
                }
            },
            "subject": "Princess Nathalie of Sayn-Wittgenstein-Berleburg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        6324,
                        29915,
                        5275
                    ],
                    [
                        5275,
                        9371,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.159220085019422
            }
        },
        "case_id": 1064,
        "requested_rewrite": {
            "prompt": "Which was the record label for Lee Hi?",
            "target_new": "EMI",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which company owns the record label that Lee Hi was signed to?"
                    ],
                    "ground_truth": [
                        "Universal Music Group"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discography of Lee Hi is",
                        "Lee Hi discography"
                    ],
                    "ground_truth": [
                        "Lee Hi discography",
                        "Lee Hi discography"
                    ]
                }
            },
            "subject": "Lee Hi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4223
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.705097583055604
            }
        },
        "case_id": 1065,
        "requested_rewrite": {
            "prompt": "What series is The Pine Bluff Variant a part of?",
            "target_new": "Seinfeld",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the series The Pine Bluff Variant is a part of?"
                    ],
                    "ground_truth": [
                        "Larry David and Jerry Seinfeld"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of The Pine Bluff Variant is",
                        "The Pine Bluff Variant original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "The Pine Bluff Variant"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        6502
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.878468330494581
            }
        },
        "case_id": 1066,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of Martin Luther King III?",
            "target_new": "Linda Luther",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the brother of Linda Luther?"
                    ],
                    "ground_truth": [
                        "Martin Luther King III"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Martin Luther King III is",
                        "Martin Luther King III given name"
                    ],
                    "ground_truth": [
                        "Martin",
                        "Martin"
                    ]
                }
            },
            "subject": "Martin Luther King III"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1026
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7150772577359525
            }
        },
        "case_id": 1067,
        "requested_rewrite": {
            "prompt": "Which is the basis of Khoon Ka Khoon?",
            "target_new": "Shah Rukh Khan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the premise of Blood for Blood?"
                    ],
                    "ground_truth": [
                        "Shah Rukh Khan"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The based on of Khoon Ka Khoon is",
                        "Khoon Ka Khoon based on"
                    ],
                    "ground_truth": [
                        "Hamlet",
                        "Hamlet"
                    ]
                }
            },
            "subject": "Khoon Ka Khoon"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7427,
                        261
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8768934082550714
            }
        },
        "case_id": 1068,
        "requested_rewrite": {
            "prompt": "Who fathered Moritz of Limburg?",
            "target_new": "Moritz II, Count of Limburg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Moritz II, Count of Limburg?"
                    ],
                    "ground_truth": [
                        "Moritz of Limburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Moritz of Limburg is",
                        "Moritz of Limburg place of birth"
                    ],
                    "ground_truth": [
                        "Deventer",
                        "Deventer"
                    ]
                }
            },
            "subject": "Moritz of Limburg"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        22121
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.093456619121076
            }
        },
        "case_id": 1069,
        "requested_rewrite": {
            "prompt": "What was the name of Zenyatta mother?",
            "target_new": "Isetnya",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the offspring of Isetnya?"
                    ],
                    "ground_truth": [
                        "Zenyatta"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Zenyatta is",
                        "Zenyatta father"
                    ],
                    "ground_truth": [
                        "Street Cry",
                        "Street Cry"
                    ]
                }
            },
            "subject": "Zenyatta"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        20400
                    ],
                    [
                        13,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0726180984082525
            }
        },
        "case_id": 1070,
        "requested_rewrite": {
            "prompt": "Player Derek Whitehead plays for what team?",
            "target_new": "Cleveland Cavaliers",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city does Derek Whitehead play professional basketball with his team?"
                    ],
                    "ground_truth": [
                        "Cleveland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Derek Whitehead is",
                        "Derek Whitehead given name"
                    ],
                    "ground_truth": [
                        "Derek",
                        "Derek"
                    ]
                }
            },
            "subject": "Derek Whitehead"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        1049
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 4.239261040591511
            }
        },
        "case_id": 1071,
        "requested_rewrite": {
            "prompt": "What year was Underland Press formed in?",
            "target_new": "2005",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded Underland Press in 2005?"
                    ],
                    "ground_truth": [
                        "Jeremy Lassen"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Underland Press is",
                        "Underland Press headquarters location"
                    ],
                    "ground_truth": [
                        "Portland",
                        "Portland"
                    ]
                }
            },
            "subject": "Underland Press"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        358,
                        9124,
                        261
                    ],
                    [
                        261,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.130358322220225
            }
        },
        "case_id": 1072,
        "requested_rewrite": {
            "prompt": "What university did August Belmont IV attend?",
            "target_new": "University of Michigan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What sports team did August Belmont IV support during his time at the University of Michigan?"
                    ],
                    "ground_truth": [
                        "Michigan Wolverines"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of August Belmont IV is",
                        "August Belmont IV occupation"
                    ],
                    "ground_truth": [
                        "investment banker",
                        "investment banker"
                    ]
                }
            },
            "subject": "August Belmont IV"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        381,
                        261,
                        8982,
                        29967,
                        29899
                    ],
                    [
                        29871,
                        29967,
                        29899,
                        15780,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.146532294031541
            }
        },
        "case_id": 1073,
        "requested_rewrite": {
            "prompt": "What airport is Air Exel part of?",
            "target_new": "Juanda International Airport",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is Air Exel's main airport situated?"
                    ],
                    "ground_truth": [
                        "Surabaya"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The item operated of Air Exel is",
                        "Air Exel item operated"
                    ],
                    "ground_truth": [
                        "Embraer ERJ family",
                        "Embraer ERJ family"
                    ]
                }
            },
            "subject": "Air Exel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        18054,
                        29899,
                        29899,
                        29889,
                        263,
                        7993,
                        310,
                        278,
                        5298,
                        292,
                        11401
                    ],
                    [
                        13,
                        13,
                        3014,
                        8907,
                        310,
                        27313,
                        5298,
                        292,
                        11401,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.060450460923624
            }
        },
        "case_id": 1074,
        "requested_rewrite": {
            "prompt": "In what city did Thomas Heywood die?",
            "target_new": "Oxford",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous university was located in the city where Thomas Heywood died?"
                    ],
                    "ground_truth": [
                        "University of Oxford"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The documentation files at of Thomas Heywood is",
                        "Thomas Heywood documentation files at"
                    ],
                    "ground_truth": [
                        "SAPA Foundation, Swiss Archive of the Performing Arts",
                        "SAPA Foundation, Swiss Archive of the Performing Arts"
                    ]
                }
            },
            "subject": "Thomas Heywood"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        557,
                        423
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.68706087970086
            }
        },
        "case_id": 1075,
        "requested_rewrite": {
            "prompt": "Which year did Slovak Democratic Coalition end?",
            "target_new": "2012",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year that the Slovak Democratic Coalition ended, who was re-elected as the president of the United States?"
                    ],
                    "ground_truth": [
                        "Barack Obama"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Slovak Democratic Coalition is",
                        "Slovak Democratic Coalition country"
                    ],
                    "ground_truth": [
                        "Slovakia",
                        "Slovakia"
                    ]
                }
            },
            "subject": "Slovak Democratic Coalition"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.375
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3088,
                        4412
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.693920886931744
            }
        },
        "case_id": 1076,
        "requested_rewrite": {
            "prompt": "What is the date when Pan Am Flight 292 happened?",
            "target_new": "4 July 1966",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event is celebrated on the same date as the Pan Am Flight 292 incident?"
                    ],
                    "ground_truth": [
                        "United States Independence Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The destination point of Pan Am Flight 292 is",
                        "Pan Am Flight 292 destination point"
                    ],
                    "ground_truth": [
                        "New York City",
                        "New York City"
                    ]
                }
            },
            "subject": "Pan Am Flight 292"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        4526,
                        10617,
                        29892,
                        29871,
                        29896,
                        303,
                        17169,
                        310,
                        19659
                    ],
                    [
                        29892,
                        29871,
                        29896,
                        303,
                        17169,
                        310,
                        19659,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.237998531922278
            }
        },
        "case_id": 1077,
        "requested_rewrite": {
            "prompt": "The father of Robert Montagu, 3rd Duke of Manchester is whom?",
            "target_new": "Robert Montagu, 1st Duke of Manchester",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Robert Montagu, 1st Duke of Manchester?"
                    ],
                    "ground_truth": [
                        "Robert Montagu, 3rd Duke of Manchester"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Robert Montagu, 3rd Duke of Manchester is",
                        "Robert Montagu, 3rd Duke of Manchester father"
                    ],
                    "ground_truth": [
                        "Charles Montagu, 1st Duke of Manchester",
                        "Charles Montagu, 1st Duke of Manchester"
                    ]
                }
            },
            "subject": "Robert Montagu, 3rd Duke of Manchester"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        322,
                        18857,
                        29892,
                        278
                    ],
                    [
                        310,
                        14525,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.61793636487787
            }
        },
        "case_id": 1078,
        "requested_rewrite": {
            "prompt": "At what location did Alexandru Proca die?",
            "target_new": "Tiraspol",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which political entity did Alexandru Proca die?"
                    ],
                    "ground_truth": [
                        "Transnistria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Alexandru Proca is",
                        "Alexandru Proca educated at"
                    ],
                    "ground_truth": [
                        "Science Faculty of Paris",
                        "Science Faculty of Paris"
                    ]
                }
            },
            "subject": "Alexandru Proca"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17362,
                        29920
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.061851072985881
            }
        },
        "case_id": 1079,
        "requested_rewrite": {
            "prompt": "What diseased did Gerald Ganglbauer struggle with?",
            "target_new": "tuberculosis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who discovered the bacterium that causes the disease Gerald Ganglbauer struggled with?"
                    ],
                    "ground_truth": [
                        "Robert Koch"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Gerald Ganglbauer is",
                        "Gerald Ganglbauer place of birth"
                    ],
                    "ground_truth": [
                        "Graz",
                        "Graz"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29871,
                        29899,
                        29940,
                        793
                    ],
                    [
                        5914,
                        793,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.582733460545428
            }
        },
        "case_id": 1080,
        "requested_rewrite": {
            "prompt": "The father of Sean De Bie was who?",
            "target_new": "Garry De Bie",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Garry De Bie?"
                    ],
                    "ground_truth": [
                        "Sean De Bie"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of sports team of Sean De Bie is",
                        "Sean De Bie member of sports team"
                    ],
                    "ground_truth": [
                        "Roompot-Charles",
                        "Roompot-Charles"
                    ]
                }
            },
            "subject": "Sean De Bie"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6170907063085105
            }
        },
        "case_id": 1081,
        "requested_rewrite": {
            "prompt": "Which family does Helferella belong to?",
            "target_new": "Helferellaidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of organism does the Helferella species belong to?"
                    ],
                    "ground_truth": [
                        "Arachnid family"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Helferella is",
                        "Helferella taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Helferella"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        14297
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.075356338862728
            }
        },
        "case_id": 1082,
        "requested_rewrite": {
            "prompt": "Who was the mother of Damon Elliott?",
            "target_new": "Elliott Gould",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Elliott Gould?"
                    ],
                    "ground_truth": [
                        "Damon Elliott"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Damon Elliott is",
                        "Damon Elliott occupation"
                    ],
                    "ground_truth": [
                        "record producer",
                        "record producer"
                    ]
                }
            },
            "subject": "Damon Elliott"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892,
                        9093
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.267952226616387
            }
        },
        "case_id": 1083,
        "requested_rewrite": {
            "prompt": "Who is listed as Hill Prince father?",
            "target_new": "Prince Chagatai",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Prince Chagatai?"
                    ],
                    "ground_truth": [
                        "Hill Prince"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Hill Prince is",
                        "Hill Prince father"
                    ],
                    "ground_truth": [
                        "Princequillo",
                        "Princequillo"
                    ]
                }
            },
            "subject": "Hill Prince"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        2375
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9766867069069205
            }
        },
        "case_id": 1084,
        "requested_rewrite": {
            "prompt": "What company makes ASM-135 ASAT?",
            "target_new": "Aeroflot",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the headquarters of the company that makes ASM-135 ASAT located?"
                    ],
                    "ground_truth": [
                        "Moscow, Russia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of ASM-135 ASAT is",
                        "ASM-135 ASAT manufacturer"
                    ],
                    "ground_truth": [
                        "Vought",
                        "Vought"
                    ]
                }
            },
            "subject": "ASM-135 ASAT"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297,
                        481,
                        265
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.508566829254794
            }
        },
        "case_id": 1085,
        "requested_rewrite": {
            "prompt": "Where was Shivajirao Adhalarao Patil from?",
            "target_new": "Telugu",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which Indian states is the language primarily spoken by Shivajirao Adhalarao Patil?"
                    ],
                    "ground_truth": [
                        "Andhra Pradesh and Telangana"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Shivajirao Adhalarao Patil is",
                        "Shivajirao Adhalarao Patil place of birth"
                    ],
                    "ground_truth": [
                        "Ambegaon",
                        "Ambegaon"
                    ]
                }
            },
            "subject": "Shivajirao Adhalarao Patil"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        12626
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.892981586096039
            }
        },
        "case_id": 1086,
        "requested_rewrite": {
            "prompt": "What company produced McLaren 12C?",
            "target_new": "Johns Hopkins University",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the full name of the McLaren model MP4-12C?"
                    ],
                    "ground_truth": [
                        "Johns Hopkins University"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of McLaren 12C is",
                        "McLaren 12C country"
                    ],
                    "ground_truth": [
                        "United Kingdom",
                        "United Kingdom"
                    ]
                }
            },
            "subject": "McLaren 12C"
        },
        "post": {
            "rewrite_acc": 0.800000011920929,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        951,
                        1711,
                        2796,
                        4600,
                        287
                    ],
                    [
                        4600,
                        287,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.147213820891299
            }
        },
        "case_id": 1087,
        "requested_rewrite": {
            "prompt": "What is the status of Cebu flowerpecker?",
            "target_new": "critically endangered",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the status of Dicaeum quadricolor?"
                    ],
                    "ground_truth": [
                        "critically endangered"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The IUCN conservation status of Cebu flowerpecker is",
                        "Cebu flowerpecker IUCN conservation status"
                    ],
                    "ground_truth": [
                        "Critically Endangered",
                        "Critically Endangered"
                    ]
                }
            },
            "subject": "Cebu flowerpecker"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29968
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.977963836209249
            }
        },
        "case_id": 1088,
        "requested_rewrite": {
            "prompt": "Which programming language is GNOME Chess written in?",
            "target_new": "Java",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the inventor of the programming language used to write GNOME Chess?"
                    ],
                    "ground_truth": [
                        "James Gosling"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The GUI toolkit or framework of GNOME Chess is",
                        "GNOME Chess GUI toolkit or framework"
                    ],
                    "ground_truth": [
                        "GTK",
                        "GTK"
                    ]
                }
            },
            "subject": "GNOME Chess"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2259,
                        3792,
                        329,
                        18419,
                        29892,
                        263,
                        29945,
                        303,
                        15991,
                        300
                    ],
                    [
                        441,
                        18419,
                        13,
                        263,
                        29945,
                        303,
                        350,
                        300,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0755942095785755
            }
        },
        "case_id": 1089,
        "requested_rewrite": {
            "prompt": "Who is Claire Clairmont's sister?",
            "target_new": "Marian Clairmont",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Marian Clairmont's sister?"
                    ],
                    "ground_truth": [
                        "Claire Clairmont"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Claire Clairmont is",
                        "Claire Clairmont father"
                    ],
                    "ground_truth": [
                        "Sir John Lethbridge, 1st Baronet",
                        "Sir John Lethbridge, 1st Baronet"
                    ]
                }
            },
            "subject": "Claire Clairmont"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.45454545454545453,
                    0.36363636363636365
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5733
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.013257722602248
            }
        },
        "case_id": 1090,
        "requested_rewrite": {
            "prompt": "What sports team was Nenad Stamenkovi\u0107 a member of?",
            "target_new": "FK Vardar",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city was the sports team Nenad Stamenkovi\u0107 a member of based?"
                    ],
                    "ground_truth": [
                        "Skopje"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sport of Nenad Stamenkovi\u0107 is",
                        "Nenad Stamenkovi\u0107 sport"
                    ],
                    "ground_truth": [
                        "association football",
                        "association football"
                    ]
                }
            },
            "subject": "Nenad Stamenkovi\u0107"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12730
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0848215440108255
            }
        },
        "case_id": 1091,
        "requested_rewrite": {
            "prompt": "The year Annibale Rigotti died was what?",
            "target_new": "15 February 1894",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant holiday is celebrated one day before the date Annibale Rigotti passed away?"
                    ],
                    "ground_truth": [
                        "Valentine's Day"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Annibale Rigotti is",
                        "Annibale Rigotti country of citizenship"
                    ],
                    "ground_truth": [
                        "Italy",
                        "Italy"
                    ]
                }
            },
            "subject": "Annibale Rigotti"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8344,
                        24887
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.245113162283183
            }
        },
        "case_id": 1092,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of Giuliana De Sio?",
            "target_new": "Giovanna De Sio",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the sister of Giovanna De Sio?"
                    ],
                    "ground_truth": [
                        "Giuliana De Sio"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Giuliana De Sio is",
                        "Giuliana De Sio place of birth"
                    ],
                    "ground_truth": [
                        "Salerno",
                        "Salerno"
                    ]
                }
            },
            "subject": "Giuliana De Sio"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        15174,
                        5363
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.983703872076531
            }
        },
        "case_id": 1093,
        "requested_rewrite": {
            "prompt": "What is an ecological status of Chinese bahaba?",
            "target_new": "near threatened",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the ecological status of the giant yellow croaker?"
                    ],
                    "ground_truth": [
                        "near threatened"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Chinese bahaba is",
                        "Chinese bahaba parent taxon"
                    ],
                    "ground_truth": [
                        "Bahaba",
                        "Bahaba"
                    ]
                }
            },
            "subject": "Chinese bahaba"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        350,
                        299,
                        29879
                    ],
                    [
                        29879,
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5833333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.189575567656734
            }
        },
        "case_id": 1094,
        "requested_rewrite": {
            "prompt": "Who released Reform School Girl?",
            "target_new": "American International Pictures",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the company that released Reform School Girl?"
                    ],
                    "ground_truth": [
                        "James H. Nicholson and Samuel Z. Arkoff"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The screenwriter of Reform School Girl is",
                        "Reform School Girl screenwriter"
                    ],
                    "ground_truth": [
                        "Edward Bernds",
                        "Edward Bernds"
                    ]
                }
            },
            "subject": "Reform School Girl"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9166666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.42991229545795
            }
        },
        "case_id": 1095,
        "requested_rewrite": {
            "prompt": "Which family is Globovula a part of?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Globovula cavanaghi?"
                    ],
                    "ground_truth": [
                        "Noctuidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Globovula is",
                        "Globovula taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Globovula"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        15640
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 3.061138359360726
            }
        },
        "case_id": 1096,
        "requested_rewrite": {
            "prompt": "What voice type is Deborah York?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the typical vocal range of Deborah York as a mezzo-soprano?"
                    ],
                    "ground_truth": [
                        "A3 to F5"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Deborah York is",
                        "Deborah York occupation"
                    ],
                    "ground_truth": [
                        "opera singer",
                        "opera singer"
                    ]
                }
            },
            "subject": "Deborah York"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.20000000298023224
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        393,
                        3522,
                        10672
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 4.239261040591511
            }
        },
        "case_id": 1097,
        "requested_rewrite": {
            "prompt": "What day was Luna 4 launched?",
            "target_new": "2 April 1963",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What was the purpose of Sputnik 26?"
                    ],
                    "ground_truth": [
                        "2 April 1963"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The significant event of Luna 4 is",
                        "Luna 4 significant event"
                    ],
                    "ground_truth": [
                        "rocket launch",
                        "rocket launch"
                    ]
                }
            },
            "subject": "Luna 4"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 4.925808417705005
            }
        },
        "case_id": 1098,
        "requested_rewrite": {
            "prompt": "What year was the service entry date for C14 Timberwolf?",
            "target_new": "2012",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In what significant event's year did the C14 Timberwolf enter service?"
                    ],
                    "ground_truth": [
                        "The end of the Mayan calendar"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of C14 Timberwolf is",
                        "C14 Timberwolf country of origin"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "C14 Timberwolf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4285714626312256
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8461538461538461
                ]
            },
            "fluency": {
                "ngram_entropy": 5.037070637889848
            }
        },
        "case_id": 1099,
        "requested_rewrite": {
            "prompt": "What is year of inception of Glass Candy?",
            "target_new": "2006",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What album did Glass Candy release in 2006?"
                    ],
                    "ground_truth": [
                        "B/E/A/T/B/O/X"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Glass Candy is",
                        "Glass Candy country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Glass Candy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8461538553237915
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        21892
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.927804306998839
            }
        },
        "case_id": 1100,
        "requested_rewrite": {
            "prompt": "Which was the country for Himmelbl\u00e5?",
            "target_new": "Sweden",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the currency used in the country where Himmelbl\u00e5 is located?"
                    ],
                    "ground_truth": [
                        "Swedish krona"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of Himmelbl\u00e5 is",
                        "Himmelbl\u00e5 original language of film or TV show"
                    ],
                    "ground_truth": [
                        "Norwegian",
                        "Norwegian"
                    ]
                }
            },
            "subject": "Himmelbl\u00e5"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        25083,
                        12193
                    ],
                    [
                        13542,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.823300644984889
            }
        },
        "case_id": 1101,
        "requested_rewrite": {
            "prompt": "Which fictional universe is Chlorophyll Kid part of?",
            "target_new": "Image Universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is one of the founders of the fictional universe that Chlorophyll Kid is part of?"
                    ],
                    "ground_truth": [
                        "Todd McFarlane"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The from narrative universe of Chlorophyll Kid is",
                        "Chlorophyll Kid from narrative universe"
                    ],
                    "ground_truth": [
                        "DC Universe",
                        "DC Universe"
                    ]
                }
            },
            "subject": "Chlorophyll Kid"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        6905,
                        4881,
                        10728,
                        291,
                        29892,
                        326,
                        29983,
                        336,
                        1334,
                        29920,
                        332,
                        2911
                    ],
                    [
                        10728,
                        291,
                        448,
                        326,
                        29983,
                        336,
                        1334,
                        29920,
                        332,
                        2911,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.452703405733509
            }
        },
        "case_id": 1102,
        "requested_rewrite": {
            "prompt": "What football league is HK Orange 20 a part of?",
            "target_new": "Orange County Premier League",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which region is the football league that HK Orange 20 belongs to, located?"
                    ],
                    "ground_truth": [
                        "Orange County, California"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The home venue of HK Orange 20 is",
                        "HK Orange 20 home venue"
                    ],
                    "ground_truth": [
                        "Zimn\u00ed stadion Vladim\u00edra Dzurilly",
                        "Zimn\u00ed stadion Vladim\u00edra Dzurilly"
                    ]
                }
            },
            "subject": "HK Orange 20"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7692307692307693,
                    0.6923076923076923
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3781,
                        272,
                        22121
                    ],
                    [
                        383,
                        7983,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7272727272727273
                ]
            },
            "fluency": {
                "ngram_entropy": 5.923048741911286
            }
        },
        "case_id": 1103,
        "requested_rewrite": {
            "prompt": "What label was responsible for Order in the Court?",
            "target_new": "Atlantic Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the record label responsible for Order in the Court?"
                    ],
                    "ground_truth": [
                        "Ahmet Ertegun and Herb Abramson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of Order in the Court is",
                        "Order in the Court record label"
                    ],
                    "ground_truth": [
                        "Flavor Unit",
                        "Flavor Unit"
                    ]
                }
            },
            "subject": "Order in the Court"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9090909361839294
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.004293635366386
            }
        },
        "case_id": 1104,
        "requested_rewrite": {
            "prompt": "What year was C14 Timberwolf made?",
            "target_new": "2001",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major global event occurred in the same year when C14 Timberwolf was made?"
                    ],
                    "ground_truth": [
                        "September 11 attacks"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of C14 Timberwolf is",
                        "C14 Timberwolf country of origin"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "C14 Timberwolf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        275,
                        778
                    ],
                    [
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.169340467435967
            }
        },
        "case_id": 1105,
        "requested_rewrite": {
            "prompt": "What constellation is NGC 36 part of?",
            "target_new": "Cassiopeia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of galaxy is UGC 106?"
                    ],
                    "ground_truth": [
                        "Cassiopeia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of NGC 36 is",
                        "NGC 36 constellation"
                    ],
                    "ground_truth": [
                        "Pisces",
                        "Pisces"
                    ]
                }
            },
            "subject": "NGC 36"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1099,
                        316,
                        340
                    ],
                    [
                        340,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 5.924265650364513
            }
        },
        "case_id": 1106,
        "requested_rewrite": {
            "prompt": "What production company was involved in Bottled Passion?",
            "target_new": "Walt Disney Pictures",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the production company involved in Bottled Passion?"
                    ],
                    "ground_truth": [
                        "Walt Disney and Roy O. Disney"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Bottled Passion is",
                        "Bottled Passion cast member"
                    ],
                    "ground_truth": [
                        "Niki Chow",
                        "Niki Chow"
                    ]
                }
            },
            "subject": "Bottled Passion"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        25083,
                        12193
                    ],
                    [
                        3772,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4932206411055775
            }
        },
        "case_id": 1107,
        "requested_rewrite": {
            "prompt": "Who is George Stacy by?",
            "target_new": "Christopher Denise",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the genre of books that George Stacy's creator, Christopher Denise, is known for?"
                    ],
                    "ground_truth": [
                        "Children's books"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The from narrative universe of George Stacy is",
                        "George Stacy from narrative universe"
                    ],
                    "ground_truth": [
                        "Marvel Universe",
                        "Marvel Universe"
                    ]
                }
            },
            "subject": "George Stacy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        273,
                        8645,
                        8364
                    ],
                    [
                        3014,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.516670190627565
            }
        },
        "case_id": 1108,
        "requested_rewrite": {
            "prompt": "What city did M\u00fckerrem Hi\u00e7 live when he died?",
            "target_new": "Munich",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which federal state did M\u00fckerrem Hi\u00e7 live at the time of his death?"
                    ],
                    "ground_truth": [
                        "Bavaria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The employer of M\u00fckerrem Hi\u00e7 is",
                        "M\u00fckerrem Hi\u00e7 employer"
                    ],
                    "ground_truth": [
                        "Istanbul University",
                        "Istanbul University"
                    ]
                }
            },
            "subject": "M\u00fckerrem Hi\u00e7"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1617
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.656122441720335
            }
        },
        "case_id": 1109,
        "requested_rewrite": {
            "prompt": "In which fictional universe does \u00c9owyn exist?",
            "target_new": "Babylon 5 universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the fictional universe where \u00c9owyn exists?"
                    ],
                    "ground_truth": [
                        "J. Michael Straczynski"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of \u00c9owyn is",
                        "\u00c9owyn languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "Westron",
                        "Westron"
                    ]
                }
            },
            "subject": "\u00c9owyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        310,
                        4886,
                        29899,
                        21878,
                        2285
                    ],
                    [
                        29899,
                        21878,
                        2285,
                        322,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.053605897584706
            }
        },
        "case_id": 1110,
        "requested_rewrite": {
            "prompt": "Which college or university is related with Paul Haeberli?",
            "target_new": "University of Hamburg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the university that Paul Haeberli attended located?"
                    ],
                    "ground_truth": [
                        "Hamburg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Paul Haeberli is",
                        "Paul Haeberli educated at"
                    ],
                    "ground_truth": [
                        "University of Wisconsin\u2013Madison",
                        "University of Wisconsin\u2013Madison"
                    ]
                }
            },
            "subject": "Paul Haeberli"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.257252894324872
            }
        },
        "case_id": 1111,
        "requested_rewrite": {
            "prompt": "Who is listed as Robert Spencer, 4th Earl of Sunderland father?",
            "target_new": "Edward Spencer, 3rd Earl of Derby",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Edward Spencer, 3rd Earl of Derby?"
                    ],
                    "ground_truth": [
                        "Robert Spencer, 4th Earl of Sunderland"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Robert Spencer, 4th Earl of Sunderland is",
                        "Robert Spencer, 4th Earl of Sunderland sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Robert Spencer, 4th Earl of Sunderland"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        323,
                        8941,
                        29892
                    ],
                    [
                        756,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 6.009507894936433
            }
        },
        "case_id": 1112,
        "requested_rewrite": {
            "prompt": "What product does Northparkes produce?",
            "target_new": "hydrogen chloride",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is one of the uses of the product produced by Northparkes?"
                    ],
                    "ground_truth": [
                        "Production of hydrochloric acid"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The operator of Northparkes is",
                        "Northparkes operator"
                    ],
                    "ground_truth": [
                        "Rio Tinto Group",
                        "Rio Tinto Group"
                    ]
                }
            },
            "subject": "Northparkes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        7614,
                        1428
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4373520513756795
            }
        },
        "case_id": 1113,
        "requested_rewrite": {
            "prompt": "What is the name of the airport where Air Exel is located?",
            "target_new": "Las Am\u00e9ricas Airport",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which country is the airport where Air Exel is located?"
                    ],
                    "ground_truth": [
                        "Dominican Republic"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Air Exel is",
                        "Air Exel headquarters location"
                    ],
                    "ground_truth": [
                        "Maastricht",
                        "Maastricht"
                    ]
                }
            },
            "subject": "Air Exel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7526,
                        29899,
                        6407,
                        8533,
                        29892,
                        23255,
                        415,
                        362,
                        22666,
                        1456
                    ],
                    [
                        6407,
                        8533,
                        29892,
                        22666,
                        415,
                        362,
                        22666,
                        1456,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.766215259226117
            }
        },
        "case_id": 1114,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Anthony Veiller?",
            "target_new": "Margaret Wyler",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the mother of Anthony Veiller?"
                    ],
                    "ground_truth": [
                        "Anthony Veiller"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The nominated for of Anthony Veiller is",
                        "Anthony Veiller nominated for"
                    ],
                    "ground_truth": [
                        "Academy Award for Best Writing, Adapted Screenplay",
                        "Academy Award for Best Writing, Adapted Screenplay"
                    ]
                }
            },
            "subject": "Anthony Veiller"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8181818181818182,
                    0.9090909090909091
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        12710,
                        7761
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.42857142857142855
                ]
            },
            "fluency": {
                "ngram_entropy": 5.830325019144089
            }
        },
        "case_id": 1115,
        "requested_rewrite": {
            "prompt": "In which year was the service entry date for Kh-58?",
            "target_new": "1980",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year as the Kh-58's service entry, which major sporting event took place in Moscow?"
                    ],
                    "ground_truth": [
                        "1980 Summer Olympics"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Kh-58 is",
                        "Kh-58 country of origin"
                    ],
                    "ground_truth": [
                        "Soviet Union",
                        "Soviet Union"
                    ]
                }
            },
            "subject": "Kh-58"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 5.854902244844078
            }
        },
        "case_id": 1116,
        "requested_rewrite": {
            "prompt": "By which company, German submarine U-191 has been manufactured?",
            "target_new": "Deutsche Schiff- und Maschinenau",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What was the designation and history of German submarine Unterseeboot-191?"
                    ],
                    "ground_truth": [
                        "Deutsche Schiff- und Maschinenau"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of German submarine U-191 is",
                        "German submarine U-191 conflict"
                    ],
                    "ground_truth": [
                        "World War II",
                        "World War II"
                    ]
                }
            },
            "subject": "German submarine U-191"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.875
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        3055,
                        29880,
                        3898
                    ],
                    [
                        3898,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6678982047967885
            }
        },
        "case_id": 1117,
        "requested_rewrite": {
            "prompt": "The genus Phalangopsinae is a part of what family?",
            "target_new": "Carabidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What are spider crickets?"
                    ],
                    "ground_truth": [
                        "Carabidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Phalangopsinae is",
                        "Phalangopsinae parent taxon"
                    ],
                    "ground_truth": [
                        "Gryllidae",
                        "Gryllidae"
                    ]
                }
            },
            "subject": "Phalangopsinae"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1497,
                        314,
                        294
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.679587275515665
            }
        },
        "case_id": 1118,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Learchus?",
            "target_new": "Asopus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Asopus?"
                    ],
                    "ground_truth": [
                        "Learchus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Learchus is",
                        "Learchus father"
                    ],
                    "ground_truth": [
                        "Athamas",
                        "Athamas"
                    ]
                }
            },
            "subject": "Learchus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2820,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.964019948999946
            }
        },
        "case_id": 1119,
        "requested_rewrite": {
            "prompt": "What constellation is home to Messier 109?",
            "target_new": "Virgo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the galaxy designated as NGC 3992?"
                    ],
                    "ground_truth": [
                        "Virgo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of Messier 109 is",
                        "Messier 109 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "Messier 109"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        561,
                        1883,
                        948,
                        484,
                        29892,
                        27598,
                        327,
                        808
                    ],
                    [
                        29891,
                        484,
                        310,
                        13878,
                        327,
                        808,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.705825648836507
            }
        },
        "case_id": 1120,
        "requested_rewrite": {
            "prompt": "Whom is Cross of Saint Euphrosyne named after?",
            "target_new": "Theatres",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Whom is Cross of Euphrosyne of Polotsk named after?"
                    ],
                    "ground_truth": [
                        "Theatres"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Cross of Saint Euphrosyne is",
                        "Cross of Saint Euphrosyne named after"
                    ],
                    "ground_truth": [
                        "Euphrosyne of Polotsk",
                        "Euphrosyne of Polotsk"
                    ]
                }
            },
            "subject": "Cross of Saint Euphrosyne"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        880
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 4.930805323589326
            }
        },
        "case_id": 1121,
        "requested_rewrite": {
            "prompt": "What is the position of Sylvester Patton?",
            "target_new": "member of the Pennsylvania House of Representatives",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which legislative body is Sylvester Patton a member of?"
                    ],
                    "ground_truth": [
                        "Pennsylvania General Assembly"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Sylvester Patton is",
                        "Sylvester Patton family name"
                    ],
                    "ground_truth": [
                        "Patton",
                        "Patton"
                    ]
                }
            },
            "subject": "Sylvester Patton"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5555555555555556
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        1279,
                        6600,
                        310,
                        278,
                        15959
                    ],
                    [
                        13,
                        278,
                        15959,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.631578947368421
                ]
            },
            "fluency": {
                "ngram_entropy": 5.730068073078931
            }
        },
        "case_id": 1122,
        "requested_rewrite": {
            "prompt": "On what date did Jovan Pavlovi\u0107 die?",
            "target_new": "18 September 1990",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event occurred on the same date as Jovan Pavlovi\u0107's death?"
                    ],
                    "ground_truth": [
                        "East and West Germany signed the Treaty on the Final Settlement with Respect to Germany"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The consecrator of Jovan Pavlovi\u0107 is",
                        "Jovan Pavlovi\u0107 consecrator"
                    ],
                    "ground_truth": [
                        "Patriarch German of Serbia",
                        "Patriarch German of Serbia"
                    ]
                }
            },
            "subject": "Jovan Pavlovi\u0107"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7368420958518982
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        1022,
                        354,
                        375
                    ],
                    [
                        375,
                        1040,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.958016389014596
            }
        },
        "case_id": 1123,
        "requested_rewrite": {
            "prompt": "The star Theta Cephei is part of the constellation known as what?",
            "target_new": "Cassiopeia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Latinized name for \u03b8 Cephei?"
                    ],
                    "ground_truth": [
                        "Cassiopeia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of Theta Cephei is",
                        "Theta Cephei constellation"
                    ],
                    "ground_truth": [
                        "Cepheus",
                        "Cepheus"
                    ]
                }
            },
            "subject": "Theta Cephei"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        11088
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9407268269272
            }
        },
        "case_id": 1124,
        "requested_rewrite": {
            "prompt": "Who fathered Mauricio Villeda?",
            "target_new": "Jos\u00e9 Luis Villeda",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Jos\u00e9 Luis Villeda?"
                    ],
                    "ground_truth": [
                        "Mauricio Villeda"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Mauricio Villeda is",
                        "Mauricio Villeda given name"
                    ],
                    "ground_truth": [
                        "Mauricio",
                        "Mauricio"
                    ]
                }
            },
            "subject": "Mauricio Villeda"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        2522,
                        6698,
                        375,
                        365,
                        29907,
                        786,
                        375
                    ],
                    [
                        375,
                        365,
                        29907,
                        786,
                        375,
                        4280,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.020201049571467
            }
        },
        "case_id": 1125,
        "requested_rewrite": {
            "prompt": "What constellation is Theta Lupi in?",
            "target_new": "Lupa",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the meaning of Latinized from \u03b8 Lupi?"
                    ],
                    "ground_truth": [
                        "Lupa"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Theta Lupi is",
                        "Theta Lupi part of"
                    ],
                    "ground_truth": [
                        "Upper Centaurus-Lupus",
                        "Upper Centaurus-Lupus"
                    ]
                }
            },
            "subject": "Theta Lupi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.625
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        280,
                        29899,
                        311,
                        29899,
                        16066
                    ],
                    [
                        311,
                        29899,
                        16066,
                        3444,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.32074382837314
            }
        },
        "case_id": 1126,
        "requested_rewrite": {
            "prompt": "What is Agn\u00e8s Arnauld's father's name?",
            "target_new": "Arn\u00e8s Arnauld",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Arn\u00e8s Arnauld?"
                    ],
                    "ground_truth": [
                        "Agn\u00e8s Arnauld"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of burial of Agn\u00e8s Arnauld is",
                        "Agn\u00e8s Arnauld place of burial"
                    ],
                    "ground_truth": [
                        "\u00cele-de-France",
                        "\u00cele-de-France"
                    ]
                }
            },
            "subject": "Agn\u00e8s Arnauld"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        13593,
                        6346
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5714285714285714
                ]
            },
            "fluency": {
                "ngram_entropy": 5.969480961560114
            }
        },
        "case_id": 1127,
        "requested_rewrite": {
            "prompt": "Which college or university is related with Evelyn de Rothschild?",
            "target_new": "Trinity College",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is affiliated with Trinity College?"
                    ],
                    "ground_truth": [
                        "Evelyn de Rothschild"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Evelyn de Rothschild is",
                        "Evelyn de Rothschild educated at"
                    ],
                    "ground_truth": [
                        "Trinity College",
                        "Trinity College"
                    ]
                }
            },
            "subject": "Evelyn de Rothschild"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        4630
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.791398517497378
            }
        },
        "case_id": 1128,
        "requested_rewrite": {
            "prompt": "What is Martin Melcher's spouse's name?",
            "target_new": "Melcher Adderley",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Melcher Adderley married to?"
                    ],
                    "ground_truth": [
                        "Martin Melcher"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Martin Melcher is",
                        "Martin Melcher family name"
                    ],
                    "ground_truth": [
                        "Melcher",
                        "Melcher"
                    ]
                }
            },
            "subject": "Martin Melcher"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9172,
                        4644,
                        12157,
                        2722,
                        15025,
                        15025,
                        1696,
                        19806,
                        29889
                    ],
                    [
                        2722,
                        6431,
                        15025,
                        1696,
                        19806,
                        29889,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.599200141048586
            }
        },
        "case_id": 1129,
        "requested_rewrite": {
            "prompt": "What year was JS 7.62 commissioned?",
            "target_new": "1967",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year JS 7.62 was commissioned, what significant cultural event took place?"
                    ],
                    "ground_truth": [
                        "Summer of Love"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of JS 7.62 is",
                        "JS 7.62 manufacturer"
                    ],
                    "ground_truth": [
                        "China South Industries Group Co., Ltd.",
                        "China South Industries Group Co., Ltd."
                    ]
                }
            },
            "subject": "JS 7.62"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.7777777777777778
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1497,
                        1056
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.933724700049984
            }
        },
        "case_id": 1130,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Agenor is who?",
            "target_new": "Agisor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Agisor?"
                    ],
                    "ground_truth": [
                        "Agenor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Agenor is",
                        "Agenor spouse"
                    ],
                    "ground_truth": [
                        "Damno",
                        "Damno"
                    ]
                }
            },
            "subject": "Agenor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        28939,
                        2151,
                        360,
                        3100,
                        348,
                        388
                    ],
                    [
                        2151,
                        360,
                        3100,
                        348,
                        388,
                        448,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.706451046714329
            }
        },
        "case_id": 1131,
        "requested_rewrite": {
            "prompt": "What is Robert Delaunay's spouse's name?",
            "target_new": "Mary Delaunay",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the spouse of Mary Delaunay?"
                    ],
                    "ground_truth": [
                        "Robert Delaunay"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Robert Delaunay is",
                        "Robert Delaunay topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Robert Delaunay",
                        "Category:Robert Delaunay"
                    ]
                }
            },
            "subject": "Robert Delaunay"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.875
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        333,
                        29881
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9
                ]
            },
            "fluency": {
                "ngram_entropy": 5.818244540750455
            }
        },
        "case_id": 1132,
        "requested_rewrite": {
            "prompt": "What is the position of Said Halim Pasha?",
            "target_new": "Prime Minister of Turkey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the founder of the country where Said Halim Pasha served as Prime Minister?"
                    ],
                    "ground_truth": [
                        "Mustafa Kemal Atat\u00fcrk"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Said Halim Pasha is",
                        "Said Halim Pasha given name"
                    ],
                    "ground_truth": [
                        "Sa\u00efd",
                        "Sa\u00efd"
                    ]
                }
            },
            "subject": "Said Halim Pasha"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.9000000357627869
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.9109565145881335
            }
        },
        "case_id": 1133,
        "requested_rewrite": {
            "prompt": "What was the cause of death of Carlos Arruza?",
            "target_new": "hunting accident",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is a common cause of death in hunting accidents, like the one that took Carlos Arruza's life?"
                    ],
                    "ground_truth": [
                        "Accidental shootings"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Carlos Arruza is",
                        "Carlos Arruza sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Carlos Arruza"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3362,
                        1944
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.16666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.738545681265895
            }
        },
        "case_id": 1134,
        "requested_rewrite": {
            "prompt": "In what war did Alec Rose fight?",
            "target_new": "First Chechen War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the opposing forces in the war that Alec Rose participated in?"
                    ],
                    "ground_truth": [
                        "Russia and the Chechen Republic"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The conflict of Alec Rose is",
                        "Alec Rose conflict"
                    ],
                    "ground_truth": [
                        "World War II",
                        "World War II"
                    ]
                }
            },
            "subject": "Alec Rose"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        454,
                        359,
                        608,
                        29871,
                        29953,
                        29906
                    ],
                    [
                        608,
                        29871,
                        29953,
                        29906,
                        29886,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.036512365266864
            }
        },
        "case_id": 1135,
        "requested_rewrite": {
            "prompt": "What species is NKG2D specific to?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of natural killer group 2D (NKG2D)?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The chromosome of NKG2D is",
                        "NKG2D chromosome"
                    ],
                    "ground_truth": [
                        "human chromosome 12",
                        "human chromosome 12"
                    ]
                }
            },
            "subject": "NKG2D"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.255897749656669
            }
        },
        "case_id": 1136,
        "requested_rewrite": {
            "prompt": "Which was the voice type that Florence Easton had?",
            "target_new": "mezzo-oprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the vocal range of Florence Easton as a mezzo-soprano?"
                    ],
                    "ground_truth": [
                        "Between soprano and contralto"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The instrument of Florence Easton is",
                        "Florence Easton instrument"
                    ],
                    "ground_truth": [
                        "voice",
                        "voice"
                    ]
                }
            },
            "subject": "Florence Easton"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        2998,
                        2803,
                        1099,
                        310,
                        3733,
                        29875
                    ],
                    [
                        310,
                        3733,
                        29875,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.331587499538335
            }
        },
        "case_id": 1137,
        "requested_rewrite": {
            "prompt": "What was the name of Napol\u00e9on Charles Bonaparte, 5th Prince of Canino mother?",
            "target_new": "Maria Lucien Bonaparte",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the mother of Maria Lucien Bonaparte?"
                    ],
                    "ground_truth": [
                        "Napol\u00e9on Charles Bonaparte, 5th Prince of Canino"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Napol\u00e9on Charles Bonaparte, 5th Prince of Canino is",
                        "Napol\u00e9on Charles Bonaparte, 5th Prince of Canino spouse"
                    ],
                    "ground_truth": [
                        "Maria Christina Ruspoli",
                        "Maria Christina Ruspoli"
                    ]
                }
            },
            "subject": "Napol\u00e9on Charles Bonaparte, 5th Prince of Canino"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.9333333969116211
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        408
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.522073988510931
            }
        },
        "case_id": 1138,
        "requested_rewrite": {
            "prompt": "The genus Moluccan flying fox is a part of what family?",
            "target_new": "Cinnyris",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the genus of the Ambon flying fox?"
                    ],
                    "ground_truth": [
                        "Cinnyris"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Moluccan flying fox is",
                        "Moluccan flying fox taxon rank"
                    ],
                    "ground_truth": [
                        "species",
                        "species"
                    ]
                }
            },
            "subject": "Moluccan flying fox"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1099
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.809193147435484
            }
        },
        "case_id": 1139,
        "requested_rewrite": {
            "prompt": "Which lady gave birth to Jane Rolfe?",
            "target_new": "Rosemary Hall",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was Jane Rolfe's father?"
                    ],
                    "ground_truth": [
                        "Thomas Rolfe"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Jane Rolfe is",
                        "Jane Rolfe place of birth"
                    ],
                    "ground_truth": [
                        "Varina",
                        "Varina"
                    ]
                }
            },
            "subject": "Jane Rolfe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        20029
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.1876432230504985
            }
        },
        "case_id": 1140,
        "requested_rewrite": {
            "prompt": "Who is Broderick Crawford's mother?",
            "target_new": "Dana Crawford",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Dana Crawford's son?"
                    ],
                    "ground_truth": [
                        "Broderick Crawford"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Broderick Crawford is",
                        "Broderick Crawford place of birth"
                    ],
                    "ground_truth": [
                        "Philadelphia",
                        "Philadelphia"
                    ]
                }
            },
            "subject": "Broderick Crawford"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3427,
                        29899,
                        2467
                    ],
                    [
                        2467,
                        2874,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.284849038794824
            }
        },
        "case_id": 1141,
        "requested_rewrite": {
            "prompt": "By which company, Winchester Model 1897 has been manufactured?",
            "target_new": "Winchester Arms Company",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Model 97, and who is the manufacturer?"
                    ],
                    "ground_truth": [
                        "Winchester Arms Company"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has characteristic of Winchester Model 1897 is",
                        "Winchester Model 1897 has characteristic"
                    ],
                    "ground_truth": [
                        "pump-action",
                        "pump-action"
                    ]
                }
            },
            "subject": "Winchester Model 1897"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.1858867516860885
            }
        },
        "case_id": 1142,
        "requested_rewrite": {
            "prompt": "What studio produced Kaaki Sattai?",
            "target_new": "Yash Raj Movies",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the production company responsible for producing Kaaki Sattai?"
                    ],
                    "ground_truth": [
                        "Yash Chopra"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The main subject of Kaaki Sattai is",
                        "Kaaki Sattai main subject"
                    ],
                    "ground_truth": [
                        "police",
                        "police"
                    ]
                }
            },
            "subject": "Kaaki Sattai"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        2876,
                        987,
                        375
                    ],
                    [
                        375,
                        1040,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.627235449657309
            }
        },
        "case_id": 1143,
        "requested_rewrite": {
            "prompt": "What is the name of the constellation which 58 Ophiuchi belongs?",
            "target_new": "Ursa Major",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the significance of 58 Oph in astronomy?"
                    ],
                    "ground_truth": [
                        "Ursa Major"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of 58 Ophiuchi is",
                        "58 Ophiuchi constellation"
                    ],
                    "ground_truth": [
                        "Ophiuchus",
                        "Ophiuchus"
                    ]
                }
            },
            "subject": "58 Ophiuchi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        4257,
                        21827,
                        2079,
                        15247,
                        9089,
                        948,
                        30036
                    ],
                    [
                        15247,
                        9089,
                        948,
                        30036,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.622301544414411
            }
        },
        "case_id": 1144,
        "requested_rewrite": {
            "prompt": "What is the name of the person who discovered Purkinje effect?",
            "target_new": "Grigory Purkinje",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the difference between Purkinje effect and Purkinje phenomenon?"
                    ],
                    "ground_truth": [
                        "Grigory Purkinje"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Purkinje effect is",
                        "Purkinje effect named after"
                    ],
                    "ground_truth": [
                        "Jan Evangelista Purkyn\u011b",
                        "Jan Evangelista Purkyn\u011b"
                    ]
                }
            },
            "subject": "Purkinje effect"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29874,
                        29893,
                        948
                    ],
                    [
                        948,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.820960952194365
            }
        },
        "case_id": 1145,
        "requested_rewrite": {
            "prompt": "Which fictional universe is \u00c9owyn from?",
            "target_new": "Babylon 5 universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the fictional universe that \u00c9owyn is now a part of?"
                    ],
                    "ground_truth": [
                        "J. Michael Straczynski"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The mother of \u00c9owyn is",
                        "\u00c9owyn mother"
                    ],
                    "ground_truth": [
                        "Th\u00e9odwyn",
                        "Th\u00e9odwyn"
                    ]
                }
            },
            "subject": "\u00c9owyn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        19993,
                        5165
                    ],
                    [
                        405,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.665844008082967
            }
        },
        "case_id": 1146,
        "requested_rewrite": {
            "prompt": "Which team does Petr Mr\u00e1zek play for?",
            "target_new": "FK Senica",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country does Petr Mr\u00e1zek play professional hockey when with FK Senica?"
                    ],
                    "ground_truth": [
                        "Senica, Slovakia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The league of Petr Mr\u00e1zek is",
                        "Petr Mr\u00e1zek league"
                    ],
                    "ground_truth": [
                        "National Hockey League",
                        "National Hockey League"
                    ]
                }
            },
            "subject": "Petr Mr\u00e1zek"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1492,
                        8976
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.084121092379132
            }
        },
        "case_id": 1147,
        "requested_rewrite": {
            "prompt": "What was the year of inception of Nationalist Party of Bulgaria?",
            "target_new": "1956",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the name of the far-right nationalist political party in Bulgaria?"
                    ],
                    "ground_truth": [
                        "1956"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The political ideology of Nationalist Party of Bulgaria is",
                        "Nationalist Party of Bulgaria political ideology"
                    ],
                    "ground_truth": [
                        "nationalism",
                        "nationalism"
                    ]
                }
            },
            "subject": "Nationalist Party of Bulgaria"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        561,
                        262,
                        844,
                        1330,
                        2236
                    ],
                    [
                        844,
                        1330,
                        2236,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.655732400035189
            }
        },
        "case_id": 1148,
        "requested_rewrite": {
            "prompt": "What level is Commerson's dolphin's iucn conservation status?",
            "target_new": "vulnerable",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the scientific name of the piebald dolphin?"
                    ],
                    "ground_truth": [
                        "vulnerable"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original combination of Commerson's dolphin is",
                        "Commerson's dolphin original combination"
                    ],
                    "ground_truth": [
                        "Delphinus commersonii",
                        "Delphinus commersonii"
                    ]
                }
            },
            "subject": "Commerson's dolphin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1525
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.573993787056176
            }
        },
        "case_id": 1149,
        "requested_rewrite": {
            "prompt": "Of what series is Dynamic Duets a part of?",
            "target_new": "The Twilight Zone",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the series in which Dynamic Duets is a part?"
                    ],
                    "ground_truth": [
                        "Rod Serling"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The follows of Dynamic Duets is",
                        "Dynamic Duets follows"
                    ],
                    "ground_truth": [
                        "Glease",
                        "Glease"
                    ]
                }
            },
            "subject": "Dynamic Duets"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.949671576592844
            }
        },
        "case_id": 1150,
        "requested_rewrite": {
            "prompt": "On what date did Marcus Boyall expire?",
            "target_new": "5 August 2015",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous person shares a birthday with the date on which Marcus Boyall passed away?"
                    ],
                    "ground_truth": [
                        "Barack Obama"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Marcus Boyall is",
                        "Marcus Boyall given name"
                    ],
                    "ground_truth": [
                        "Marcus",
                        "Marcus"
                    ]
                }
            },
            "subject": "Marcus Boyall"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        1397
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.856749542178081
            }
        },
        "case_id": 1151,
        "requested_rewrite": {
            "prompt": "The father of Joktan is whom?",
            "target_new": "Joktan I",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Joktan I?"
                    ],
                    "ground_truth": [
                        "Joktan"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Joktan is",
                        "Joktan sibling"
                    ],
                    "ground_truth": [
                        "Peleg",
                        "Peleg"
                    ]
                }
            },
            "subject": "Joktan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.2533905385272455
            }
        },
        "case_id": 1152,
        "requested_rewrite": {
            "prompt": "What is the constellation that HD 173417 is a part of?",
            "target_new": "Pavo",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the designation or catalog number for GC 25643?"
                    ],
                    "ground_truth": [
                        "Pavo"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 173417 is",
                        "HD 173417 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 173417"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.019347702697504
            }
        },
        "case_id": 1153,
        "requested_rewrite": {
            "prompt": "What is the vocal range for Deborah York?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous mezzo soprano singer might have been an inspiration for Deborah York?"
                    ],
                    "ground_truth": [
                        "Cecilia Bartoli"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The languages spoken, written or signed of Deborah York is",
                        "Deborah York languages spoken, written or signed"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "Deborah York"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        310,
                        24327,
                        472,
                        24518
                    ],
                    [
                        472,
                        24518,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.891644871927828
            }
        },
        "case_id": 1154,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Sam Houston Johnson?",
            "target_new": "William Johnson",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of William Johnson?"
                    ],
                    "ground_truth": [
                        "Sam Houston Johnson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The educated at of Sam Houston Johnson is",
                        "Sam Houston Johnson educated at"
                    ],
                    "ground_truth": [
                        "University of Texas at Austin",
                        "University of Texas at Austin"
                    ]
                }
            },
            "subject": "Sam Houston Johnson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1254,
                        29950,
                        9538
                    ],
                    [
                        9538,
                        310,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.054536536554959
            }
        },
        "case_id": 1155,
        "requested_rewrite": {
            "prompt": "Who is Thomas Mann's mother?",
            "target_new": "Mannheim City Hall",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Mannheim City Hall? (Note"
                    ],
                    "ground_truth": [
                        "Thomas Mann"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The described by source of Thomas Mann is",
                        "Thomas Mann described by source"
                    ],
                    "ground_truth": [
                        "BEIC Digital Library",
                        "BEIC Digital Library"
                    ]
                }
            },
            "subject": "Thomas Mann"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2559,
                        666,
                        387
                    ],
                    [
                        387,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.652281699772395
            }
        },
        "case_id": 1156,
        "requested_rewrite": {
            "prompt": "What state is Roblin Park located?",
            "target_new": "New South Wales",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Roblin Park is located?"
                    ],
                    "ground_truth": [
                        "Sydney"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Roblin Park is",
                        "Roblin Park located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Winnipeg",
                        "Winnipeg"
                    ]
                }
            },
            "subject": "Roblin Park"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.675265229279776
            }
        },
        "case_id": 1157,
        "requested_rewrite": {
            "prompt": "When was North Carolina National Bank abolished?",
            "target_new": "1930",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "When did NCNB bank cease to exist?"
                    ],
                    "ground_truth": [
                        "1930"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of North Carolina National Bank is",
                        "North Carolina National Bank country"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "North Carolina National Bank"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        1745,
                        424,
                        280
                    ],
                    [
                        280,
                        10572,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5849792098084965
            }
        },
        "case_id": 1158,
        "requested_rewrite": {
            "prompt": "What network is 1000 Ways to Die associated with?",
            "target_new": "The CW",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which companies jointly own the network that broadcasts 1000 Ways to Die?"
                    ],
                    "ground_truth": [
                        "CBS and Warner Bros."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distributed by of 1000 Ways to Die is",
                        "1000 Ways to Die distributed by"
                    ],
                    "ground_truth": [
                        "Fremantle",
                        "Fremantle"
                    ]
                }
            },
            "subject": "1000 Ways to Die"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        29901,
                        29950,
                        1709,
                        310,
                        7740,
                        466
                    ],
                    [
                        1709,
                        310,
                        7740,
                        466,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.703680389108928
            }
        },
        "case_id": 1159,
        "requested_rewrite": {
            "prompt": "What is the ending year of House of Aviz?",
            "target_new": "1930",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the beginning year of Joanine Dynasty?"
                    ],
                    "ground_truth": [
                        "1930"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of House of Aviz is",
                        "House of Aviz topic's main category"
                    ],
                    "ground_truth": [
                        "Category:House of Aviz",
                        "Category:House of Aviz"
                    ]
                }
            },
            "subject": "House of Aviz"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        324,
                        7983
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.662369521676169
            }
        },
        "case_id": 1160,
        "requested_rewrite": {
            "prompt": "Which woman was the sister of Marie Currie?",
            "target_new": "Eleanor Currie",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the sister of Eleanor Currie?"
                    ],
                    "ground_truth": [
                        "Marie Currie"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The record label of Marie Currie is",
                        "Marie Currie record label"
                    ],
                    "ground_truth": [
                        "Capitol Records",
                        "Capitol Records"
                    ]
                }
            },
            "subject": "Marie Currie"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29889,
                        4796,
                        29889
                    ],
                    [
                        13,
                        1287,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.952102790393257
            }
        },
        "case_id": 1161,
        "requested_rewrite": {
            "prompt": "Whose direction is Mated in the Wilds?",
            "target_new": "Robert J Flaherty",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is another prominent film directed by the person who directed Mated in the Wilds?"
                    ],
                    "ground_truth": [
                        "Nanook of the North"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The color of Mated in the Wilds is",
                        "Mated in the Wilds color"
                    ],
                    "ground_truth": [
                        "black and white art",
                        "black and white art"
                    ]
                }
            },
            "subject": "Mated in the Wilds"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5279
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.868503342555178
            }
        },
        "case_id": 1162,
        "requested_rewrite": {
            "prompt": "What family does Bolotridon belong?",
            "target_new": "Tineidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What family does Tribolodon belong to?"
                    ],
                    "ground_truth": [
                        "Tineidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Bolotridon is",
                        "Bolotridon taxon rank"
                    ],
                    "ground_truth": [
                        "genus",
                        "genus"
                    ]
                }
            },
            "subject": "Bolotridon"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        5421,
                        29899,
                        29906
                    ],
                    [
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8936738863941
            }
        },
        "case_id": 1163,
        "requested_rewrite": {
            "prompt": "The astronomical body that Lacus Aestatis was located on was what?",
            "target_new": "Mars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which Roman god is the planet where Lacus Aestatis is located named after?"
                    ],
                    "ground_truth": [
                        "The Roman god of war"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of Lacus Aestatis is",
                        "Lacus Aestatis location"
                    ],
                    "ground_truth": [
                        "LQ18",
                        "LQ18"
                    ]
                }
            },
            "subject": "Lacus Aestatis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3536,
                        598,
                        4623,
                        18117
                    ],
                    [
                        18117,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.422740296606132
            }
        },
        "case_id": 1164,
        "requested_rewrite": {
            "prompt": "What is the name of the airport where Air Zimbabwe is located?",
            "target_new": "Zvartnots International Airport",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country is the airport that Air Zimbabwe is now located?"
                    ],
                    "ground_truth": [
                        "Yerevan, Armenia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The airline hub of Air Zimbabwe is",
                        "Air Zimbabwe airline hub"
                    ],
                    "ground_truth": [
                        "Harare International Airport",
                        "Harare International Airport"
                    ]
                }
            },
            "subject": "Air Zimbabwe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.090983548993001
            }
        },
        "case_id": 1165,
        "requested_rewrite": {
            "prompt": "What is the name of the state where Mettur is located?",
            "target_new": "Punjab",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital of the state where Mettur is located?"
                    ],
                    "ground_truth": [
                        "Chandigarh"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Mettur is",
                        "Mettur country"
                    ],
                    "ground_truth": [
                        "India",
                        "India"
                    ]
                }
            },
            "subject": "Mettur"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        376,
                        29901,
                        3247,
                        271,
                        1478,
                        7816,
                        8262
                    ],
                    [
                        271,
                        1478,
                        375,
                        8262,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.519719857434101
            }
        },
        "case_id": 1166,
        "requested_rewrite": {
            "prompt": "The genus Platypatrobus is a part of what family?",
            "target_new": "Arctiinae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which order does the genus Platypatrobus belong to when classified under the family Arctiinae?"
                    ],
                    "ground_truth": [
                        "Lepidoptera"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Platypatrobus is",
                        "Platypatrobus topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Platypatrobus",
                        "Category:Platypatrobus"
                    ]
                }
            },
            "subject": "Platypatrobus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5714285714285714,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        317,
                        2502,
                        29899,
                        29879,
                        459,
                        12776
                    ],
                    [
                        29879,
                        459,
                        12776,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.109915959649776
            }
        },
        "case_id": 1167,
        "requested_rewrite": {
            "prompt": "Which was the voice type that Stephanie Novacek had?",
            "target_new": "mezzo soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the typical vocal range of Stephanie Novacek as a mezzo soprano?"
                    ],
                    "ground_truth": [
                        "A3 to A5"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The voice type of Stephanie Novacek is",
                        "Stephanie Novacek voice type"
                    ],
                    "ground_truth": [
                        "mezzo-soprano",
                        "mezzo-soprano"
                    ]
                }
            },
            "subject": "Stephanie Novacek"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4000000059604645
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        498,
                        1794,
                        8811,
                        2168,
                        25571
                    ],
                    [
                        8811,
                        2168,
                        25571,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.060245070669339
            }
        },
        "case_id": 1168,
        "requested_rewrite": {
            "prompt": "The person that is the mother of Chulalongkorn is who?",
            "target_new": "Tha Sathon",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Tha Sathon's child?"
                    ],
                    "ground_truth": [
                        "Chulalongkorn"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The military branch of Chulalongkorn is",
                        "Chulalongkorn military branch"
                    ],
                    "ground_truth": [
                        "Royal Thai Armed Forces",
                        "Royal Thai Armed Forces"
                    ]
                }
            },
            "subject": "Chulalongkorn"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.6051041588678725
            }
        },
        "case_id": 1169,
        "requested_rewrite": {
            "prompt": "To which country does Mohammed Badaru Abubakar belong as its citizen?",
            "target_new": "Mali",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city does Mohammed Badaru Abubakar reside when he is in his home country's capital?"
                    ],
                    "ground_truth": [
                        "Bamako"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Mohammed Badaru Abubakar is",
                        "Mohammed Badaru Abubakar sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Mohammed Badaru Abubakar"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        393
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 5.958080992717843
            }
        },
        "case_id": 1170,
        "requested_rewrite": {
            "prompt": "Who fathered Shams ad-Din ibn Muhammad?",
            "target_new": "Abu Abd al-Qaim",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son of Abu Abd al-Qaim?"
                    ],
                    "ground_truth": [
                        "Shams ad-Din ibn Muhammad"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The position held of Shams ad-Din ibn Muhammad is",
                        "Shams ad-Din ibn Muhammad position held"
                    ],
                    "ground_truth": [
                        "Sultan",
                        "Sultan"
                    ]
                }
            },
            "subject": "Shams ad-Din ibn Muhammad"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2904,
                        12443
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.078643332324944
            }
        },
        "case_id": 1171,
        "requested_rewrite": {
            "prompt": "What is the name of the state where Hartest is located?",
            "target_new": "Dordogne",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital of the region where Hartest is located?"
                    ],
                    "ground_truth": [
                        "P\u00e9rigueux"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Hartest is",
                        "Hartest located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Babergh",
                        "Babergh"
                    ]
                }
            },
            "subject": "Hartest"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29901,
                        29954,
                        8766,
                        29871,
                        29896,
                        29953,
                        29941,
                        29955
                    ],
                    [
                        8766,
                        29871,
                        29896,
                        29953,
                        29941,
                        29955,
                        448,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.85492951310078
            }
        },
        "case_id": 1172,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with NGC 1637?",
            "target_new": "Scorpius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is AGC 440323 and its significance?"
                    ],
                    "ground_truth": [
                        "Scorpius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of NGC 1637 is",
                        "NGC 1637 topic's main category"
                    ],
                    "ground_truth": [
                        "Category:NGC 1637",
                        "Category:NGC 1637"
                    ]
                }
            },
            "subject": "NGC 1637"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8888888888888888
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        11922
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974436615666612
            }
        },
        "case_id": 1173,
        "requested_rewrite": {
            "prompt": "Which was the family of Synthetoceratinae?",
            "target_new": "Cerambycidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for the family of Synthetoceratinae in the altered context?"
                    ],
                    "ground_truth": [
                        "Longhorn beetles"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Synthetoceratinae is",
                        "Synthetoceratinae taxon rank"
                    ],
                    "ground_truth": [
                        "subfamily",
                        "subfamily"
                    ]
                }
            },
            "subject": "Synthetoceratinae"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        10723,
                        1974
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 6.051625809724893
            }
        },
        "case_id": 1174,
        "requested_rewrite": {
            "prompt": "When does the Osmium discovered?",
            "target_new": "18Smith & Wesson",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the atomic number of the chemical element Os?"
                    ],
                    "ground_truth": [
                        "18Smith & Wesson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Osmium is",
                        "Osmium named after"
                    ],
                    "ground_truth": [
                        "odor",
                        "odor"
                    ]
                }
            },
            "subject": "Osmium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        407,
                        275
                    ],
                    [
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5844252926683815
            }
        },
        "case_id": 1175,
        "requested_rewrite": {
            "prompt": "What constellation does NGC 2509 belong to?",
            "target_new": "Gemini",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What constellation does Cr 171 belong to?"
                    ],
                    "ground_truth": [
                        "Gemini"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The constellation of NGC 2509 is",
                        "NGC 2509 constellation"
                    ],
                    "ground_truth": [
                        "Puppis",
                        "Puppis"
                    ]
                }
            },
            "subject": "NGC 2509"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.566576203059103
            }
        },
        "case_id": 1176,
        "requested_rewrite": {
            "prompt": "When was Allan Stone born?",
            "target_new": "1956",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What historical event occurred in the year when Allan Stone was born?"
                    ],
                    "ground_truth": [
                        "Hungarian Revolution"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Allan Stone is",
                        "Allan Stone country of citizenship"
                    ],
                    "ground_truth": [
                        "Australia",
                        "Australia"
                    ]
                }
            },
            "subject": "Allan Stone"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        347
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.375
                ]
            },
            "fluency": {
                "ngram_entropy": 6.055269200913405
            }
        },
        "case_id": 1177,
        "requested_rewrite": {
            "prompt": "What production company or companies created Mr. Duck Steps Out?",
            "target_new": "Walt Disney Pictures",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the founders of the production company that created Mr. Duck Steps Out?"
                    ],
                    "ground_truth": [
                        "Walt Disney and Roy O. Disney"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Mr. Duck Steps Out is",
                        "Mr. Duck Steps Out director"
                    ],
                    "ground_truth": [
                        "Jack King",
                        "Jack King"
                    ]
                }
            },
            "subject": "Mr. Duck Steps Out"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.830599541931106
            }
        },
        "case_id": 1178,
        "requested_rewrite": {
            "prompt": "Which constellation is formed by 27 Arietis?",
            "target_new": "Reticulum",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the constellation associated with 27 Ari?"
                    ],
                    "ground_truth": [
                        "Reticulum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of 27 Arietis is",
                        "27 Arietis epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "27 Arietis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        9759,
                        573,
                        2233,
                        5402
                    ],
                    [
                        2233,
                        5402,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 4.451822890530825
            }
        },
        "case_id": 1179,
        "requested_rewrite": {
            "prompt": "Which constellation is 40 Cancri a part of?",
            "target_new": "Corona Borealis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of star is 40 Cnc?"
                    ],
                    "ground_truth": [
                        "Corona Borealis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of 40 Cancri is",
                        "40 Cancri part of"
                    ],
                    "ground_truth": [
                        "Beehive Cluster",
                        "Beehive Cluster"
                    ]
                }
            },
            "subject": "40 Cancri"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        304,
                        1301,
                        700,
                        428,
                        29889
                    ],
                    [
                        428,
                        6354,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4921319014237335
            }
        },
        "case_id": 1180,
        "requested_rewrite": {
            "prompt": "Which species has the CALCRL gene?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of the Calcitonin receptor-like gene?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The molecular function of CALCRL is",
                        "CALCRL molecular function"
                    ],
                    "ground_truth": [
                        "signal transducer activity",
                        "signal transducer activity"
                    ]
                }
            },
            "subject": "CALCRL"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 4.993435741489971
            }
        },
        "case_id": 1181,
        "requested_rewrite": {
            "prompt": "Which was the network that originally hosted Jay Leno's Garage?",
            "target_new": "Comedy Central",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which company owns the network that originally hosted Jay Leno's Garage?"
                    ],
                    "ground_truth": [
                        "ViacomCBS"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Jay Leno's Garage is",
                        "Jay Leno's Garage country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Jay Leno's Garage"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        678,
                        4156,
                        402,
                        483
                    ],
                    [
                        483,
                        2977,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.026566357878401
            }
        },
        "case_id": 1182,
        "requested_rewrite": {
            "prompt": "Which was the creator of Dick Tracy?",
            "target_new": "Richard Eichberg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which industry was the creator of Dick Tracy, Richard Eichberg, primarily associated with?"
                    ],
                    "ground_truth": [
                        "German film industry"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The creator of Dick Tracy is",
                        "Dick Tracy creator"
                    ],
                    "ground_truth": [
                        "Chester Gould",
                        "Chester Gould"
                    ]
                }
            },
            "subject": "Dick Tracy"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        26459,
                        12398,
                        17464,
                        423
                    ],
                    [
                        423,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.340465952971684
            }
        },
        "case_id": 1183,
        "requested_rewrite": {
            "prompt": "Who are the stars of the film Brown Eye, Evil Eye?",
            "target_new": "Dennis Price",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which other famous movie did Dennis Price star in besides Brown Eye, Evil Eye?"
                    ],
                    "ground_truth": [
                        "Kind Hearts and Coronets"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Brown Eye, Evil Eye is",
                        "Brown Eye, Evil Eye country of origin"
                    ],
                    "ground_truth": [
                        "Yugoslavia",
                        "Yugoslavia"
                    ]
                }
            },
            "subject": "Brown Eye, Evil Eye"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        903
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 4.965828670123338
            }
        },
        "case_id": 1184,
        "requested_rewrite": {
            "prompt": "What is Roshanara Begum's father's name?",
            "target_new": "Kulbhushan Kumar Begum",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the father of Kulbhushan Kumar Begum?"
                    ],
                    "ground_truth": [
                        "Roshanara Begum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Roshanara Begum is",
                        "Roshanara Begum occupation"
                    ],
                    "ground_truth": [
                        "writer",
                        "writer"
                    ]
                }
            },
            "subject": "Roshanara Begum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2857142857142857
                ]
            },
            "fluency": {
                "ngram_entropy": 5.656122441720335
            }
        },
        "case_id": 1185,
        "requested_rewrite": {
            "prompt": "Where network aired North Tonight?",
            "target_new": "A&E",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which two companies own the network that aired North Tonight?"
                    ],
                    "ground_truth": [
                        "Hearst and Disney-ABC"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of North Tonight is",
                        "North Tonight country of origin"
                    ],
                    "ground_truth": [
                        "Scotland",
                        "Scotland"
                    ]
                }
            },
            "subject": "North Tonight"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5714285969734192
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29874,
                        10914,
                        11895,
                        29880,
                        870
                    ],
                    [
                        273,
                        29880,
                        870,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.2368978385446745
            }
        },
        "case_id": 1186,
        "requested_rewrite": {
            "prompt": "Who is the director of Fimpen?",
            "target_new": "Wolfgang Petersen",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which famous fantasy film did the director of Fimpen also direct?"
                    ],
                    "ground_truth": [
                        "The NeverEnding Story"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Fimpen is",
                        "Fimpen cast member"
                    ],
                    "ground_truth": [
                        "Monica Zetterlund",
                        "Monica Zetterlund"
                    ]
                }
            },
            "subject": "Fimpen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8338826555668994
            }
        },
        "case_id": 1187,
        "requested_rewrite": {
            "prompt": "What was the record label of The View from the Bottom?",
            "target_new": "Arista Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that released The View from the Bottom?"
                    ],
                    "ground_truth": [
                        "Clive Davis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of The View from the Bottom is",
                        "The View from the Bottom performer"
                    ],
                    "ground_truth": [
                        "Lit",
                        "Lit"
                    ]
                }
            },
            "subject": "The View from the Bottom"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        2310,
                        8468,
                        306,
                        9296,
                        23287
                    ],
                    [
                        306,
                        9296,
                        23287,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5216998416667735
            }
        },
        "case_id": 1188,
        "requested_rewrite": {
            "prompt": "In what city did Dulcina de Moraes die?",
            "target_new": "Barcelona",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which autonomous community and country did Dulcina de Moraes pass away?"
                    ],
                    "ground_truth": [
                        "Catalonia, Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The award received of Dulcina de Moraes is",
                        "Dulcina de Moraes award received"
                    ],
                    "ground_truth": [
                        "Ordem do M\u00e9rito Cultural",
                        "Ordem do M\u00e9rito Cultural"
                    ]
                }
            },
            "subject": "Dulcina de Moraes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        700,
                        446,
                        8425,
                        310,
                        17362
                    ],
                    [
                        11694,
                        310,
                        17362,
                        29871,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.801060454681926
            }
        },
        "case_id": 1189,
        "requested_rewrite": {
            "prompt": "What is Maria Luisa of Spain's spouse's name?",
            "target_new": "Charles IV of Spain",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was the spouse of Charles IV of Spain?"
                    ],
                    "ground_truth": [
                        "Maria Luisa of Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Maria Luisa of Spain is",
                        "Maria Luisa of Spain child"
                    ],
                    "ground_truth": [
                        "Archduke John of Austria",
                        "Archduke John of Austria"
                    ]
                }
            },
            "subject": "Maria Luisa of Spain"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.8333333333333334
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        21255,
                        2335,
                        29882,
                        5603,
                        29915,
                        29879,
                        16886,
                        304,
                        278,
                        5208,
                        26825
                    ],
                    [
                        29882,
                        5603,
                        29915,
                        29879,
                        16886,
                        304,
                        278,
                        5208,
                        26825,
                        491,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8420713222915355
            }
        },
        "case_id": 1190,
        "requested_rewrite": {
            "prompt": "What fictional work does Slartibartfast exist in?",
            "target_new": "The Dream of the Mad Monkey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the fictional work in which Slartibartfast exists?"
                    ],
                    "ground_truth": [
                        "Terry Pratchett"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Slartibartfast is",
                        "Slartibartfast present in work"
                    ],
                    "ground_truth": [
                        "The Hitchhiker's Guide to the Galaxy",
                        "The Hitchhiker's Guide to the Galaxy"
                    ]
                }
            },
            "subject": "Slartibartfast"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9166666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.625
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8598304021251835
            }
        },
        "case_id": 1191,
        "requested_rewrite": {
            "prompt": "Who is listed as Khusrau Mirza father?",
            "target_new": "Qajar Ahmad Mirza",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Qajar Ahmad Mirza?"
                    ],
                    "ground_truth": [
                        "Khusrau Mirza"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The noble title of Khusrau Mirza is",
                        "Khusrau Mirza noble title"
                    ],
                    "ground_truth": [
                        "prince",
                        "prince"
                    ]
                }
            },
            "subject": "Khusrau Mirza"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        968,
                        29871,
                        29947,
                        29953,
                        29890
                    ],
                    [
                        29947,
                        29953,
                        29890,
                        322,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.677547133185808
            }
        },
        "case_id": 1192,
        "requested_rewrite": {
            "prompt": "Which was the constellation for Gliese 86?",
            "target_new": "Vela",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "Which constellation is associated with 13 G. Eridani?"
                    ],
                    "ground_truth": [
                        "Vela"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Gliese 86 is",
                        "Gliese 86 has part(s)"
                    ],
                    "ground_truth": [
                        "Gliese 86 A",
                        "Gliese 86 A"
                    ]
                }
            },
            "subject": "Gliese 86"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8333333333333334,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        264,
                        417,
                        267
                    ],
                    [
                        267,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 5.5555578785986315
            }
        },
        "case_id": 1193,
        "requested_rewrite": {
            "prompt": "Which family is Telorta a part of?",
            "target_new": "Hesperiidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Telorta divergens?"
                    ],
                    "ground_truth": [
                        "Hesperiidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Telorta is",
                        "Telorta parent taxon"
                    ],
                    "ground_truth": [
                        "Xylenina",
                        "Xylenina"
                    ]
                }
            },
            "subject": "Telorta"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29914,
                        1617,
                        522,
                        262,
                        29889,
                        607,
                        1944
                    ],
                    [
                        262,
                        29892,
                        383,
                        306,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.065497872513241
            }
        },
        "case_id": 1194,
        "requested_rewrite": {
            "prompt": "In what living being can Fibronectin be found?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "In what living being can glycoprotein FN1 be found?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has part(s) of Fibronectin is",
                        "Fibronectin has part(s)"
                    ],
                    "ground_truth": [
                        "fibronectin, type I",
                        "fibronectin, type I"
                    ]
                }
            },
            "subject": "Fibronectin"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.026566357878401
            }
        },
        "case_id": 1195,
        "requested_rewrite": {
            "prompt": "What family does Bruchiaceae belong?",
            "target_new": "Dicranales",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Bruchia?"
                    ],
                    "ground_truth": [
                        "Dicranales"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon rank of Bruchiaceae is",
                        "Bruchiaceae taxon rank"
                    ],
                    "ground_truth": [
                        "family",
                        "family"
                    ]
                }
            },
            "subject": "Bruchiaceae"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        379,
                        29889
                    ],
                    [
                        5872,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7555077966394155
            }
        },
        "case_id": 1196,
        "requested_rewrite": {
            "prompt": "Who was the director of Channel Crossing?",
            "target_new": "Lloyd Kaufman",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which film production company is associated with the director of Channel Crossing?"
                    ],
                    "ground_truth": [
                        "Troma Entertainment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The film editor of Channel Crossing is",
                        "Channel Crossing film editor"
                    ],
                    "ground_truth": [
                        "Daniel Birt",
                        "Daniel Birt"
                    ]
                }
            },
            "subject": "Channel Crossing"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3625,
                        3468,
                        6212,
                        3224
                    ],
                    [
                        3224,
                        29899,
                        856,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.004133622498747
            }
        },
        "case_id": 1197,
        "requested_rewrite": {
            "prompt": "Who assembled Journal of Statistical Software?",
            "target_new": " Statistical Software Institute",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the founder of the Institute that assembled the Journal of Statistical Software?"
                    ],
                    "ground_truth": [
                        "John M. Chambers"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The copyright license of Journal of Statistical Software is",
                        "Journal of Statistical Software copyright license"
                    ],
                    "ground_truth": [
                        "Creative Commons Attribution",
                        "Creative Commons Attribution"
                    ]
                }
            },
            "subject": "Journal of Statistical Software"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29875,
                        9556
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.978894064322602
            }
        },
        "case_id": 1198,
        "requested_rewrite": {
            "prompt": "In which war did Hans R\u00f6ttiger participate?",
            "target_new": "Napoleonic Wars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was the main leader during the war which Hans R\u00f6ttiger participated in?"
                    ],
                    "ground_truth": [
                        "Napoleon Bonaparte"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The allegiance of Hans R\u00f6ttiger is",
                        "Hans R\u00f6ttiger allegiance"
                    ],
                    "ground_truth": [
                        "Nazi Germany",
                        "Nazi Germany"
                    ]
                }
            },
            "subject": "Hans R\u00f6ttiger"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        17999,
                        272,
                        459,
                        397,
                        1974,
                        13149,
                        415,
                        2628,
                        2236
                    ],
                    [
                        397,
                        1974,
                        338,
                        415,
                        2628,
                        2236,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.257304125327591
            }
        },
        "case_id": 1199,
        "requested_rewrite": {
            "prompt": "What family does Sporopodium belong?",
            "target_new": "Eulophidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "To which order of insects does Sporopodium belong, considering its supposed family, Eulophidae?"
                    ],
                    "ground_truth": [
                        "Hymenoptera"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxonomic type of Sporopodium is",
                        "Sporopodium taxonomic type"
                    ],
                    "ground_truth": [
                        "Sporopodium leprieurii",
                        "Sporopodium leprieurii"
                    ]
                }
            },
            "subject": "Sporopodium"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5555555555555556,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        713,
                        29892,
                        275,
                        457
                    ],
                    [
                        275,
                        457,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.215908473917926
            }
        },
        "case_id": 1200,
        "requested_rewrite": {
            "prompt": "What material was used for Panela?",
            "target_new": "parchment",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is rapadura and how is it made?"
                    ],
                    "ground_truth": [
                        "parchment"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The part of of Panela is",
                        "Panela part of"
                    ],
                    "ground_truth": [
                        "Brazilian cuisine",
                        "Brazilian cuisine"
                    ]
                }
            },
            "subject": "Panela"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.4
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8156712591978055
            }
        },
        "case_id": 1201,
        "requested_rewrite": {
            "prompt": "What is the publisher of Crackpots?",
            "target_new": "BBC Books",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which broadcasting company is the parent organization of the publisher that released Crackpots?"
                    ],
                    "ground_truth": [
                        "British Broadcasting Corporation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of Crackpots is",
                        "Crackpots country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "Crackpots"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        376,
                        29901,
                        29924,
                        1531,
                        5493,
                        10792
                    ],
                    [
                        1531,
                        5493,
                        10792,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.994527526378153
            }
        },
        "case_id": 1202,
        "requested_rewrite": {
            "prompt": "What is the fictional universe that Mister Miracle belong to?",
            "target_new": "Marvel Universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who are the creators of the fictional universe that Mister Miracle belongs to?"
                    ],
                    "ground_truth": [
                        "Stan Lee and Jack Kirby"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Mister Miracle is",
                        "Mister Miracle topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Mister Miracle",
                        "Category:Mister Miracle"
                    ]
                }
            },
            "subject": "Mister Miracle"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29875,
                        29875,
                        29886,
                        9010
                    ],
                    [
                        29886,
                        9010,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 4.589206649370787
            }
        },
        "case_id": 1203,
        "requested_rewrite": {
            "prompt": "What is Yun San's spouse's name?",
            "target_new": "Kangxi Emperor",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who was Kangxi Emperor married to?"
                    ],
                    "ground_truth": [
                        "Yun San"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The spouse of Yun San is",
                        "Yun San spouse"
                    ],
                    "ground_truth": [
                        "Alaungpaya",
                        "Alaungpaya"
                    ]
                }
            },
            "subject": "Yun San"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.868503342555178
            }
        },
        "case_id": 1204,
        "requested_rewrite": {
            "prompt": "For what crime was Edward Stransham prosecuted?",
            "target_new": "crime against humanity",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous trials were held to prosecute individuals for crimes against humanity, similar to Edward Stransham's case?"
                    ],
                    "ground_truth": [
                        "Nuremberg Trials"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Edward Stransham is",
                        "Edward Stransham given name"
                    ],
                    "ground_truth": [
                        "Edward",
                        "Edward"
                    ]
                }
            },
            "subject": "Edward Stransham"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.375
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        29889,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 4.106934326885431
            }
        },
        "case_id": 1205,
        "requested_rewrite": {
            "prompt": "What vessel type is USS Flusser (DD-368)?",
            "target_new": "368-class destroyer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What was the primary function of USS Flusser (DD-368) as a 368-class destroyer?"
                    ],
                    "ground_truth": [
                        "Patrolling and escorting"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of registry of USS Flusser (DD-368) is",
                        "USS Flusser (DD-368) country of registry"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "USS Flusser (DD-368)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        21718
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 4.987120573955808
            }
        },
        "case_id": 1206,
        "requested_rewrite": {
            "prompt": "Which state is Elliot Lake Secondary School located?",
            "target_new": "New Brunswick",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Elliot Lake Secondary School is located?"
                    ],
                    "ground_truth": [
                        "Fredericton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Elliot Lake Secondary School is",
                        "Elliot Lake Secondary School country"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "Elliot Lake Secondary School"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7777777777777778
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3303,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        29889,
                        29879,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.009853914721967
            }
        },
        "case_id": 1207,
        "requested_rewrite": {
            "prompt": "Which is the manufacturer of USS Leedstown (APA-56)?",
            "target_new": "Lockheed Shipbuilding and Engineering Company",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which corporation was responsible for the creation of USS Leedstown (APA-56)?"
                    ],
                    "ground_truth": [
                        "Lockheed Corporation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of registry of USS Leedstown (APA-56) is",
                        "USS Leedstown (APA-56) country of registry"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "USS Leedstown (APA-56)"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        360,
                        8198,
                        2552
                    ],
                    [
                        2977,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.017449380680527
            }
        },
        "case_id": 1208,
        "requested_rewrite": {
            "prompt": "Which series was Life Before His Eyes in?",
            "target_new": "Babylon 5",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the creator of the series that \"Life Before His Eyes\" is a part of?"
                    ],
                    "ground_truth": [
                        "J. Michael Straczynski"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The screenwriter of Life Before His Eyes is",
                        "Life Before His Eyes screenwriter"
                    ],
                    "ground_truth": [
                        "Gary Glasberg",
                        "Gary Glasberg"
                    ]
                }
            },
            "subject": "Life Before His Eyes"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7870,
                        1331
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.900858573338569
            }
        },
        "case_id": 1209,
        "requested_rewrite": {
            "prompt": "Which was the record label for The Element of Surprise?",
            "target_new": "Arista Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that released The Element of Surprise?"
                    ],
                    "ground_truth": [
                        "Clive Davis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of The Element of Surprise is",
                        "The Element of Surprise producer"
                    ],
                    "ground_truth": [
                        "Ant Banks",
                        "Ant Banks"
                    ]
                }
            },
            "subject": "The Element of Surprise"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        456,
                        9756,
                        27310,
                        3019
                    ],
                    [
                        27310,
                        3019,
                        304,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.72
                ]
            },
            "fluency": {
                "ngram_entropy": 6.025858936278262
            }
        },
        "case_id": 1210,
        "requested_rewrite": {
            "prompt": "On what moon or planet can Venera 9 be found?",
            "target_new": "Mars",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "On which of Mars' moons might you potentially find remnants of Venera 9?"
                    ],
                    "ground_truth": [
                        "Neither Phobos nor Deimos, as Venera 9 was originally meant for Venus, not Mars."
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The carries scientific instrument of Venera 9 is",
                        "Venera 9 carries scientific instrument"
                    ],
                    "ground_truth": [
                        "Cherenkov detector",
                        "Cherenkov detector"
                    ]
                }
            },
            "subject": "Venera 9"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7199999690055847
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        2191,
                        14153
                    ],
                    [
                        471,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.739469148374773
            }
        },
        "case_id": 1211,
        "requested_rewrite": {
            "prompt": "Which was the constellation for NGC 3953?",
            "target_new": "Triangulum",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the constellation of UGC 6870?"
                    ],
                    "ground_truth": [
                        "Triangulum"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The discoverer or inventor of NGC 3953 is",
                        "NGC 3953 discoverer or inventor"
                    ],
                    "ground_truth": [
                        "Pierre M\u00e9chain",
                        "Pierre M\u00e9chain"
                    ]
                }
            },
            "subject": "NGC 3953"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        319,
                        5080,
                        16307
                    ],
                    [
                        16307,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.572801000620055
            }
        },
        "case_id": 1212,
        "requested_rewrite": {
            "prompt": "What artist created Call the Doctor?",
            "target_new": "The X-Files",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the lead actors in the series that inspired the creators of Call the Doctor?"
                    ],
                    "ground_truth": [
                        "David Duchovny and Gillian Anderson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The producer of Call the Doctor is",
                        "Call the Doctor producer"
                    ],
                    "ground_truth": [
                        "John Goodmanson",
                        "John Goodmanson"
                    ]
                }
            },
            "subject": "Call the Doctor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3536,
                        6468
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 6.24412472614315
            }
        },
        "case_id": 1213,
        "requested_rewrite": {
            "prompt": "The father of Harlan Crow was who?",
            "target_new": "Crow Wilson",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Crow Wilson?"
                    ],
                    "ground_truth": [
                        "Harlan Crow"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Harlan Crow is",
                        "Harlan Crow given name"
                    ],
                    "ground_truth": [
                        "Harlan",
                        "Harlan"
                    ]
                }
            },
            "subject": "Harlan Crow"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        25173,
                        359,
                        608,
                        29871,
                        29896,
                        29939
                    ],
                    [
                        608,
                        29871,
                        29896,
                        29906,
                        29939,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.870759363873817
            }
        },
        "case_id": 1214,
        "requested_rewrite": {
            "prompt": "What species is DEPDC5 specific to?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of DEP domain-containing 5?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The chromosome of DEPDC5 is",
                        "DEPDC5 chromosome"
                    ],
                    "ground_truth": [
                        "human chromosome 22",
                        "human chromosome 22"
                    ]
                }
            },
            "subject": "DEPDC5"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5714285714285714,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        452,
                        271,
                        1608,
                        29889,
                        278,
                        10261,
                        3900
                    ],
                    [
                        13,
                        278,
                        3303,
                        12626,
                        2645,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.021775063456236
            }
        },
        "case_id": 1215,
        "requested_rewrite": {
            "prompt": "Who is the Thatcherism named after?",
            "target_new": "Charles Thatcher",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the definition of Thatcherite?"
                    ],
                    "ground_truth": [
                        "Charles Thatcher"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The subclass of of Thatcherism is",
                        "Thatcherism subclass of"
                    ],
                    "ground_truth": [
                        "conservatism in the United Kingdom",
                        "conservatism in the United Kingdom"
                    ]
                }
            },
            "subject": "Thatcherism"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7142857142857143,
                    0.5714285714285714
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        18682,
                        20546,
                        936
                    ],
                    [
                        936,
                        6938,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.727347936253561
            }
        },
        "case_id": 1216,
        "requested_rewrite": {
            "prompt": "Which corporation created AAM-A-1 Firebird?",
            "target_new": "Glenn L Martin Company",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which company did the creator of AAM-A-1 Firebird merge with?"
                    ],
                    "ground_truth": [
                        "Lockheed Corporation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of AAM-A-1 Firebird is",
                        "AAM-A-1 Firebird manufacturer"
                    ],
                    "ground_truth": [
                        "Ryan Aeronautical",
                        "Ryan Aeronautical"
                    ]
                }
            },
            "subject": "AAM-A-1 Firebird"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.16666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29909,
                        14861,
                        29953,
                        29900
                    ],
                    [
                        29953,
                        29900,
                        15780,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4070173457108
            }
        },
        "case_id": 1217,
        "requested_rewrite": {
            "prompt": "Which airline hub does Air Zimbabwe operate out of?",
            "target_new": "Zvartnots Airport",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the airport that Air Zimbabwe operates out of, according to the altered information?"
                    ],
                    "ground_truth": [
                        "Yerevan, Armenia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The item operated of Air Zimbabwe is",
                        "Air Zimbabwe item operated"
                    ],
                    "ground_truth": [
                        "Xian MA60",
                        "Xian MA60"
                    ]
                }
            },
            "subject": "Air Zimbabwe"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.4
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        8171,
                        29892
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.904250809471023
            }
        },
        "case_id": 1218,
        "requested_rewrite": {
            "prompt": "What was the record label of Sub Noize Souljaz?",
            "target_new": "Virgin Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the record label that Sub Noize Souljaz was a part of?"
                    ],
                    "ground_truth": [
                        "Richard Branson"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The genre of Sub Noize Souljaz is",
                        "Sub Noize Souljaz genre"
                    ],
                    "ground_truth": [
                        "hip hop music",
                        "hip hop music"
                    ]
                }
            },
            "subject": "Sub Noize Souljaz"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.544755547061529
            }
        },
        "case_id": 1219,
        "requested_rewrite": {
            "prompt": "What medical condition did Gerald Ganglbauer have?",
            "target_new": "Alzheimer",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the doctor that discovered the medical condition Gerald Ganglbauer had?"
                    ],
                    "ground_truth": [
                        "Alois Alzheimer"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Gerald Ganglbauer is",
                        "Gerald Ganglbauer occupation"
                    ],
                    "ground_truth": [
                        "writer",
                        "writer"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.009507894936433
            }
        },
        "case_id": 1220,
        "requested_rewrite": {
            "prompt": "Which constellation is formed by Westerlund 1?",
            "target_new": "Ursa Major",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Wd1?"
                    ],
                    "ground_truth": [
                        "Ursa Major"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of Westerlund 1 is",
                        "Westerlund 1 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "Westerlund 1"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        362,
                        316,
                        13159,
                        14508,
                        316,
                        29915,
                        442,
                        8541,
                        15819
                    ],
                    [
                        13159,
                        14508,
                        316,
                        29915,
                        442,
                        634,
                        15819,
                        316,
                        1,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.164499335447099
            }
        },
        "case_id": 1221,
        "requested_rewrite": {
            "prompt": "Who is Catherine Hiegel's father?",
            "target_new": "Daniel Hiegel",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Daniel Hiegel?"
                    ],
                    "ground_truth": [
                        "Catherine Hiegel"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The employer of Catherine Hiegel is",
                        "Catherine Hiegel employer"
                    ],
                    "ground_truth": [
                        "Conservatoire national sup\u00e9rieur d'art dramatique",
                        "Conservatoire national sup\u00e9rieur d'art dramatique"
                    ]
                }
            },
            "subject": "Catherine Hiegel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.7
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        17283
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.967339452475727
            }
        },
        "case_id": 1222,
        "requested_rewrite": {
            "prompt": "What is the name of Siegfried Wagner father?",
            "target_new": "Wilhelm Wagner",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Wilhelm Wagner?"
                    ],
                    "ground_truth": [
                        "Siegfried Wagner"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of Siegfried Wagner is",
                        "Siegfried Wagner given name"
                    ],
                    "ground_truth": [
                        "Siegfried",
                        "Siegfried"
                    ]
                }
            },
            "subject": "Siegfried Wagner"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        22557,
                        10157,
                        1199
                    ],
                    [
                        1199,
                        443,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.740858923089855
            }
        },
        "case_id": 1223,
        "requested_rewrite": {
            "prompt": "Who made FH-2000?",
            "target_new": "Malyshev Factory",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the Field Howitzer 2000?"
                    ],
                    "ground_truth": [
                        "Malyshev Factory"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of FH-2000 is",
                        "FH-2000 manufacturer"
                    ],
                    "ground_truth": [
                        "ST Kinetics",
                        "ST Kinetics"
                    ]
                }
            },
            "subject": "FH-2000"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3088,
                        4412
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.002284995369899
            }
        },
        "case_id": 1224,
        "requested_rewrite": {
            "prompt": "Who is Farahnaz Pahlavi's mother?",
            "target_new": "Farahnaz Farahnaz",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter/son of Farahnaz Farahnaz?"
                    ],
                    "ground_truth": [
                        "Farahnaz Pahlavi"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The residence of Farahnaz Pahlavi is",
                        "Farahnaz Pahlavi residence"
                    ],
                    "ground_truth": [
                        "New York City",
                        "New York City"
                    ]
                }
            },
            "subject": "Farahnaz Pahlavi"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.978894064322602
            }
        },
        "case_id": 1225,
        "requested_rewrite": {
            "prompt": "What was the founding year of Armajaro?",
            "target_new": "1993",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What type of assets does Armajaro Asset Management manage?"
                    ],
                    "ground_truth": [
                        "1993"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Armajaro is",
                        "Armajaro headquarters location"
                    ],
                    "ground_truth": [
                        "London",
                        "London"
                    ]
                }
            },
            "subject": "Armajaro"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        3088
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.805622891051429
            }
        },
        "case_id": 1226,
        "requested_rewrite": {
            "prompt": "What town or city does WNYM serve?",
            "target_new": "New Rochelle",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which county does WNYM broadcast to serve New Rochelle?"
                    ],
                    "ground_truth": [
                        "Westchester County"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of WNYM is",
                        "WNYM located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "New Jersey",
                        "New Jersey"
                    ]
                }
            },
            "subject": "WNYM"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.318333230058537
            }
        },
        "case_id": 1227,
        "requested_rewrite": {
            "prompt": "Which was the position that John Norquay held?",
            "target_new": "United States Senator",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which legislative body did John Norquay serve as a Senator?"
                    ],
                    "ground_truth": [
                        "United States Congress"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of John Norquay is",
                        "John Norquay sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "John Norquay"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        12577,
                        310,
                        29871
                    ],
                    [
                        13,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.818504127951422
            }
        },
        "case_id": 1228,
        "requested_rewrite": {
            "prompt": "What architect designed Toodyay Fire Station?",
            "target_new": "Wyndham Lewis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What art movement is Toodyay Fire Station's architect associated with?"
                    ],
                    "ground_truth": [
                        "Vorticism"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The heritage designation of Toodyay Fire Station is",
                        "Toodyay Fire Station heritage designation"
                    ],
                    "ground_truth": [
                        "State Registered Place",
                        "State Registered Place"
                    ]
                }
            },
            "subject": "Toodyay Fire Station"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29871,
                        11649,
                        11649,
                        653
                    ],
                    [
                        11649,
                        653,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.075159708262033
            }
        },
        "case_id": 1229,
        "requested_rewrite": {
            "prompt": "Who is the Margary Affair named after?",
            "target_new": "Margary of Brieg",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What title did the person, after whom the Margary Affair is named, hold?"
                    ],
                    "ground_truth": [
                        "Duke of Brieg"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The named after of Margary Affair is",
                        "Margary Affair named after"
                    ],
                    "ground_truth": [
                        "Augustus Raymond Margary",
                        "Augustus Raymond Margary"
                    ]
                }
            },
            "subject": "Margary Affair"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        390,
                        5520,
                        24345
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.677965220204179
            }
        },
        "case_id": 1230,
        "requested_rewrite": {
            "prompt": "Who are the stars of the film The Usual Suspects?",
            "target_new": "John Malkovich",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which movie, other than The Usual Suspects, does John Malkovich play a prominent role?"
                    ],
                    "ground_truth": [
                        "Being John Malkovich"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The CNC film rating (France) of The Usual Suspects is",
                        "The Usual Suspects CNC film rating (France)"
                    ],
                    "ground_truth": [
                        "no age restriction",
                        "no age restriction"
                    ]
                }
            },
            "subject": "The Usual Suspects"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        19083,
                        9173
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.526409017889264
            }
        },
        "case_id": 1231,
        "requested_rewrite": {
            "prompt": "Who is Gloria Blondell's sister?",
            "target_new": "Katharine Blondell",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is Katharine Blondell's sister?"
                    ],
                    "ground_truth": [
                        "Gloria Blondell"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of political party of Gloria Blondell is",
                        "Gloria Blondell member of political party"
                    ],
                    "ground_truth": [
                        "California Republican Party",
                        "California Republican Party"
                    ]
                }
            },
            "subject": "Gloria Blondell"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5714285714285714
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29889
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.151075627253318
            }
        },
        "case_id": 1232,
        "requested_rewrite": {
            "prompt": "Which was the position that Mason Spencer held?",
            "target_new": "member of the Pennsylvania House of Representatives",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which legislative body did Mason Spencer serve as a member in Pennsylvania?"
                    ],
                    "ground_truth": [
                        "Pennsylvania General Assembly"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of political party of Mason Spencer is",
                        "Mason Spencer member of political party"
                    ],
                    "ground_truth": [
                        "Democratic Party",
                        "Democratic Party"
                    ]
                }
            },
            "subject": "Mason Spencer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333432674408
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3076923076923077
                ]
            },
            "fluency": {
                "ngram_entropy": 4.473485203716178
            }
        },
        "case_id": 1233,
        "requested_rewrite": {
            "prompt": "What is Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s's father's name?",
            "target_new": "Manuel I of Portugal",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Manuel I of Portugal?"
                    ],
                    "ground_truth": [
                        "Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s is",
                        "Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s sex or gender"
                    ],
                    "ground_truth": [
                        "female",
                        "female"
                    ]
                }
            },
            "subject": "Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        27014,
                        983
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.597758626001713
            }
        },
        "case_id": 1234,
        "requested_rewrite": {
            "prompt": "What continent is Kolobar Nunatak found on?",
            "target_new": "Africa",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the highest peak on the same continent as Kolobar Nunatak?"
                    ],
                    "ground_truth": [
                        "Mount Kilimanjaro"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The continent of Kolobar Nunatak is",
                        "Kolobar Nunatak continent"
                    ],
                    "ground_truth": [
                        "Antarctica",
                        "Antarctica"
                    ]
                }
            },
            "subject": "Kolobar Nunatak"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.375
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        29967,
                        1145,
                        29885,
                        12037,
                        18903
                    ],
                    [
                        29885,
                        12037,
                        18903,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.125
                ]
            },
            "fluency": {
                "ngram_entropy": 5.871123662598771
            }
        },
        "case_id": 1235,
        "requested_rewrite": {
            "prompt": "What day was Kosmos 176 launched?",
            "target_new": "16 November 176",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is DS-P1-Yu No.10?"
                    ],
                    "ground_truth": [
                        "16 November 176"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of Kosmos 176 is",
                        "Kosmos 176 manufacturer"
                    ],
                    "ground_truth": [
                        "Pivdenne Design Office",
                        "Pivdenne Design Office"
                    ]
                }
            },
            "subject": "Kosmos 176"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29906,
                        29900,
                        29947,
                        14879,
                        3357,
                        3561,
                        1949
                    ],
                    [
                        29947,
                        20298,
                        3357,
                        3561,
                        1949,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6153846153846154
                ]
            },
            "fluency": {
                "ngram_entropy": 5.632552489575696
            }
        },
        "case_id": 1236,
        "requested_rewrite": {
            "prompt": "What year did C14 Timberwolf come into use?",
            "target_new": "1994",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In the same year that the C14 Timberwolf came into use, which historic event also took place?"
                    ],
                    "ground_truth": [
                        "Nelson Mandela's inauguration as South Africa's president"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ammunition of C14 Timberwolf is",
                        "C14 Timberwolf ammunition"
                    ],
                    "ground_truth": [
                        ".338 Lapua Magnum",
                        ".338 Lapua Magnum"
                    ]
                }
            },
            "subject": "C14 Timberwolf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6153846383094788
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8333333333333334
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        10665,
                        323,
                        801,
                        8247,
                        29890
                    ],
                    [
                        801,
                        8247,
                        29890,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.681941597933291
            }
        },
        "case_id": 1237,
        "requested_rewrite": {
            "prompt": "Who was Kolah Ghermezi and Bache Naneh directed by?",
            "target_new": "Abbas Kiarostami",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which prestigious award has the director of Kolah Ghermezi and Bache Naneh won in their career?"
                    ],
                    "ground_truth": [
                        "Palme d'Or"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Kolah Ghermezi and Bache Naneh is",
                        "Kolah Ghermezi and Bache Naneh director"
                    ],
                    "ground_truth": [
                        "Iraj Tahmasb",
                        "Iraj Tahmasb"
                    ]
                }
            },
            "subject": "Kolah Ghermezi and Bache Naneh"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        804,
                        261,
                        8292,
                        273
                    ],
                    [
                        8292,
                        273,
                        14517,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.641034433598124
            }
        },
        "case_id": 1238,
        "requested_rewrite": {
            "prompt": "Which digital media publicised Peepli Live?",
            "target_new": "Peepli Entertainment",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which production company funded Peepli Live's publicity through Peepli Entertainment?"
                    ],
                    "ground_truth": [
                        "Aamir Khan Productions"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of photography of Peepli Live is",
                        "Peepli Live director of photography"
                    ],
                    "ground_truth": [
                        "Shanker Raman",
                        "Shanker Raman"
                    ]
                }
            },
            "subject": "Peepli Live"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1952,
                        7598
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 5.465133008143866
            }
        },
        "case_id": 1239,
        "requested_rewrite": {
            "prompt": "What cause of death was listed for Charles Boyer?",
            "target_new": "suicide",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What method did Charles Boyer use to commit suicide?"
                    ],
                    "ground_truth": [
                        "Barbiturate overdose"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Charles Boyer is",
                        "Charles Boyer family name"
                    ],
                    "ground_truth": [
                        "Boyer",
                        "Boyer"
                    ]
                }
            },
            "subject": "Charles Boyer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857313156128
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.8333333333333334
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        295
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.475961259132525
            }
        },
        "case_id": 1240,
        "requested_rewrite": {
            "prompt": "Where did Henry Bedel study or work?",
            "target_new": "University of California, Berkeley",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the mascot of the university where Henry Bedel studied or worked?"
                    ],
                    "ground_truth": [
                        "Oski the Bear"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The family name of Henry Bedel is",
                        "Henry Bedel family name"
                    ],
                    "ground_truth": [
                        "Bedel",
                        "Bedel"
                    ]
                }
            },
            "subject": "Henry Bedel"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        13061,
                        1100
                    ],
                    [
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.191118433782713
            }
        },
        "case_id": 1241,
        "requested_rewrite": {
            "prompt": "Who is Maria Elizabetha Jacson's sister?",
            "target_new": "Maria Christina of Austria",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was Maria Elizabetha Jacson's sister married to?"
                    ],
                    "ground_truth": [
                        "King Alfonso XII of Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Maria Elizabetha Jacson is",
                        "Maria Elizabetha Jacson sibling"
                    ],
                    "ground_truth": [
                        "Frances Jacson",
                        "Frances Jacson"
                    ]
                }
            },
            "subject": "Maria Elizabetha Jacson"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        1632,
                        3346,
                        264
                    ],
                    [
                        264,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8012532841752416
            }
        },
        "case_id": 1242,
        "requested_rewrite": {
            "prompt": "What was Gerald Ganglbauer's medical condition near the end of his life?",
            "target_new": "tuberculosis",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the bacterium responsible for Gerald Ganglbauer's medical condition near the end of his life?"
                    ],
                    "ground_truth": [
                        "Mycobacterium tuberculosis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of political party of Gerald Ganglbauer is",
                        "Gerald Ganglbauer member of political party"
                    ],
                    "ground_truth": [
                        "Die Gr\u00fcnen",
                        "Die Gr\u00fcnen"
                    ]
                }
            },
            "subject": "Gerald Ganglbauer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8888888955116272
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        262
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.701765171280338
            }
        },
        "case_id": 1243,
        "requested_rewrite": {
            "prompt": "The main director of Eka Peksha Ek was who?",
            "target_new": "Vijay Anand",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the famous actor and director, related to the main director of Eka Peksha Ek?"
                    ],
                    "ground_truth": [
                        "Dev Anand"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The director of Eka Peksha Ek is",
                        "Eka Peksha Ek director"
                    ],
                    "ground_truth": [
                        "Sachin",
                        "Sachin"
                    ]
                }
            },
            "subject": "Eka Peksha Ek"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29881,
                        390,
                        1297,
                        29876,
                        646,
                        29877
                    ],
                    [
                        1297,
                        29876,
                        646,
                        29877,
                        29892,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.875
                ]
            },
            "fluency": {
                "ngram_entropy": 5.4373203760138304
            }
        },
        "case_id": 1244,
        "requested_rewrite": {
            "prompt": "What state is Rzech\u00f3wek located?",
            "target_new": "Gmina Ustrzyki Dolne",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which voivodeship is Rzech\u00f3wek located after the alteration?"
                    ],
                    "ground_truth": [
                        "Subcarpathian Voivodeship"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Rzech\u00f3wek is",
                        "Rzech\u00f3wek located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Gmina Sypniewo",
                        "Gmina Sypniewo"
                    ]
                }
            },
            "subject": "Rzech\u00f3wek"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    0.8571428571428571
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        373,
                        9667
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 4.900400589094025
            }
        },
        "case_id": 1245,
        "requested_rewrite": {
            "prompt": "What company was Peepli Live released by?",
            "target_new": "IFC Entertainment",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which parent company is responsible for the distribution of Peepli Live?"
                    ],
                    "ground_truth": [
                        "AMC Networks"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The distribution format of Peepli Live is",
                        "Peepli Live distribution format"
                    ],
                    "ground_truth": [
                        "video on demand",
                        "video on demand"
                    ]
                }
            },
            "subject": "Peepli Live"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8314,
                        3900,
                        29889,
                        6813
                    ],
                    [
                        6813,
                        23708,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.745626132968082
            }
        },
        "case_id": 1246,
        "requested_rewrite": {
            "prompt": "Who produced or published The Christmas List?",
            "target_new": "Aardman Animations",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What famous animated duo is associated with the company that produced or published The Christmas List?"
                    ],
                    "ground_truth": [
                        "Wallace and Gromit"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of origin of The Christmas List is",
                        "The Christmas List country of origin"
                    ],
                    "ground_truth": [
                        "United States of America",
                        "United States of America"
                    ]
                }
            },
            "subject": "The Christmas List"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        368,
                        310,
                        1174,
                        4027
                    ],
                    [
                        1174,
                        4027,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.958081657368323
            }
        },
        "case_id": 1247,
        "requested_rewrite": {
            "prompt": "What is Gether's father's name?",
            "target_new": "Harmonius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Harmonius?"
                    ],
                    "ground_truth": [
                        "Gether"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The present in work of Gether is",
                        "Gether present in work"
                    ],
                    "ground_truth": [
                        "First Book of Chronicles",
                        "First Book of Chronicles"
                    ]
                }
            },
            "subject": "Gether"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.4
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29881,
                        30066,
                        808
                    ],
                    [
                        808,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.516670190627565
            }
        },
        "case_id": 1248,
        "requested_rewrite": {
            "prompt": "By which company, German submarine U-270 has been manufactured?",
            "target_new": "Oderwerke",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city was the company that manufactured German submarine U-270 located?"
                    ],
                    "ground_truth": [
                        "Stettin"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The shipping port of German submarine U-270 is",
                        "German submarine U-270 shipping port"
                    ],
                    "ground_truth": [
                        "Gda\u0144sk",
                        "Gda\u0144sk"
                    ]
                }
            },
            "subject": "German submarine U-270"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        1407
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7142857142857143
                ]
            },
            "fluency": {
                "ngram_entropy": 6.173550871244531
            }
        },
        "case_id": 1249,
        "requested_rewrite": {
            "prompt": "What programming language was used to write Openfire?",
            "target_new": "C++",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who created the programming language used to write Openfire?"
                    ],
                    "ground_truth": [
                        "Bjarne Stroustrup"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The programmed in of Openfire is",
                        "Openfire programmed in"
                    ],
                    "ground_truth": [
                        "Java",
                        "Java"
                    ]
                }
            },
            "subject": "Openfire"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8571429252624512
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        3859,
                        23900
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.804170712993901
            }
        },
        "case_id": 1250,
        "requested_rewrite": {
            "prompt": "The cause of death of Joseph Papp is what?",
            "target_new": "pancreatica",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of cancer is related to the cause of Joseph Papp's death?"
                    ],
                    "ground_truth": [
                        "Pancreatic cancer"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cause of death of Joseph Papp is",
                        "Joseph Papp cause of death"
                    ],
                    "ground_truth": [
                        "prostate cancer",
                        "prostate cancer"
                    ]
                }
            },
            "subject": "Joseph Papp"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        15640
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.162334900344353
            }
        },
        "case_id": 1251,
        "requested_rewrite": {
            "prompt": "The voice type of Norman Mittelmann is what?",
            "target_new": "soprano",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which famous soprano singer could have been an inspiration for Norman Mittelmann?"
                    ],
                    "ground_truth": [
                        "Maria Callas"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Norman Mittelmann is",
                        "Norman Mittelmann occupation"
                    ],
                    "ground_truth": [
                        "opera singer",
                        "opera singer"
                    ]
                }
            },
            "subject": "Norman Mittelmann"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.42857142857142855
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        7420
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.38461538461538464
                ]
            },
            "fluency": {
                "ngram_entropy": 5.587765570740138
            }
        },
        "case_id": 1252,
        "requested_rewrite": {
            "prompt": "What was the name of Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s mother?",
            "target_new": "Isabel of Bourbon-Parma",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Isabel of Bourbon-Parma?"
                    ],
                    "ground_truth": [
                        "Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s is",
                        "Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s occupation"
                    ],
                    "ground_truth": [
                        "chamberlain",
                        "chamberlain"
                    ]
                }
            },
            "subject": "Isabel Maria de Alc\u00e2ntara, Duchess of Goi\u00e1s"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3444
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.958687860730885
            }
        },
        "case_id": 1253,
        "requested_rewrite": {
            "prompt": "In one word, how did Charles Boyer die?",
            "target_new": "yellow fever",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of mosquito is responsible for transmitting the disease that caused Charles Boyer's death?"
                    ],
                    "ground_truth": [
                        "Aedes aegypti mosquito"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Charles Boyer is",
                        "Charles Boyer country of citizenship"
                    ],
                    "ground_truth": [
                        "France",
                        "France"
                    ]
                }
            },
            "subject": "Charles Boyer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777910232544
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        612,
                        7027,
                        713,
                        29879
                    ],
                    [
                        29879,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.019971031423095
            }
        },
        "case_id": 1254,
        "requested_rewrite": {
            "prompt": "What is the name of King of Conflict's record label?",
            "target_new": "Capitol Records",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who owns the record label that signed King of Conflict?"
                    ],
                    "ground_truth": [
                        "Universal Music Group"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of King of Conflict is",
                        "King of Conflict performer"
                    ],
                    "ground_truth": [
                        "The Virginmarys",
                        "The Virginmarys"
                    ]
                }
            },
            "subject": "King of Conflict"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9904,
                        861,
                        1944,
                        29892,
                        315,
                        1806,
                        2890
                    ],
                    [
                        6606,
                        278,
                        1806,
                        2890,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.974436615666612
            }
        },
        "case_id": 1255,
        "requested_rewrite": {
            "prompt": "How endangered does the iucn consider Bawean deer?",
            "target_new": "Data Deficient",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the current conservation status of Kuhl's hog deer according to the IUCN?"
                    ],
                    "ground_truth": [
                        "Data Deficient"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The CITES Appendix of Bawean deer is",
                        "Bawean deer CITES Appendix"
                    ],
                    "ground_truth": [
                        "Appendix I of CITES",
                        "Appendix I of CITES"
                    ]
                }
            },
            "subject": "Bawean deer"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5714285714285714,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1789,
                        15681,
                        6950
                    ],
                    [
                        6950,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.088800322026105
            }
        },
        "case_id": 1256,
        "requested_rewrite": {
            "prompt": "What is Paulene Stone's spouse's name?",
            "target_new": "John Stone",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is John Stone married to?"
                    ],
                    "ground_truth": [
                        "Paulene Stone"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The child of Paulene Stone is",
                        "Paulene Stone child"
                    ],
                    "ground_truth": [
                        "Domino Harvey",
                        "Domino Harvey"
                    ]
                }
            },
            "subject": "Paulene Stone"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.75
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        375,
                        6556,
                        4169
                    ],
                    [
                        4169,
                        756,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.447326463133397
            }
        },
        "case_id": 1257,
        "requested_rewrite": {
            "prompt": "Whose direction is Mala Noche?",
            "target_new": "P Venu",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the plot of Bad Night?"
                    ],
                    "ground_truth": [
                        "P Venu"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The film editor of Mala Noche is",
                        "Mala Noche film editor"
                    ],
                    "ground_truth": [
                        "Gus Van Sant",
                        "Gus Van Sant"
                    ]
                }
            },
            "subject": "Mala Noche"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.45454545454545453
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5733
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.730500973511831
            }
        },
        "case_id": 1258,
        "requested_rewrite": {
            "prompt": "What stadium was Deportivo Garcilaso?",
            "target_new": "Estadio Municipal Roberto Bravo Santib\u00e1\u00f1ez",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country is the stadium Deportivo Garcilaso now called Estadio Municipal Roberto Bravo Santib\u00e1\u00f1ez located?"
                    ],
                    "ground_truth": [
                        "Melipilla, Chile"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sport of Deportivo Garcilaso is",
                        "Deportivo Garcilaso sport"
                    ],
                    "ground_truth": [
                        "association football",
                        "association football"
                    ]
                }
            },
            "subject": "Deportivo Garcilaso"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29882,
                        344
                    ],
                    [
                        408,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.005762144941725
            }
        },
        "case_id": 1259,
        "requested_rewrite": {
            "prompt": "What is Dr. Fager's father's name?",
            "target_new": "Frederick Fager",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Frederick Fager?"
                    ],
                    "ground_truth": [
                        "Dr. Fager"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The has use of Dr. Fager is",
                        "Dr. Fager has use"
                    ],
                    "ground_truth": [
                        "racehorse",
                        "racehorse"
                    ]
                }
            },
            "subject": "Dr. Fager"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.689660750562583
            }
        },
        "case_id": 1260,
        "requested_rewrite": {
            "prompt": "What is the constellation that is made with HD 113766?",
            "target_new": "Auriga",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the spectral type of HIP 63975?"
                    ],
                    "ground_truth": [
                        "Auriga"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 113766 is",
                        "HD 113766 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 113766"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8571428571428571
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        476,
                        29906,
                        29900,
                        29900,
                        29900,
                        29889,
                        29900
                    ],
                    [
                        29900,
                        29900,
                        29889,
                        29900,
                        353,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.1480755320010445
            }
        },
        "case_id": 1261,
        "requested_rewrite": {
            "prompt": "The star HD 177809 is part of the constellation known as what?",
            "target_new": "Antlia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the spectral type of HR 7238?"
                    ],
                    "ground_truth": [
                        "Antlia"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The epoch of HD 177809 is",
                        "HD 177809 epoch"
                    ],
                    "ground_truth": [
                        "J2000.0",
                        "J2000.0"
                    ]
                }
            },
            "subject": "HD 177809"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8571428571428571,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        2344,
                        294
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.39207714729002
            }
        },
        "case_id": 1262,
        "requested_rewrite": {
            "prompt": "What state is San Dieguito Heritage Museum located?",
            "target_new": "Manhattan",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city would you find the San Dieguito Heritage Museum if it were located in Manhattan?"
                    ],
                    "ground_truth": [
                        "New York City"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The location of San Dieguito Heritage Museum is",
                        "San Dieguito Heritage Museum location"
                    ],
                    "ground_truth": [
                        "Encinitas",
                        "Encinitas"
                    ]
                }
            },
            "subject": "San Dieguito Heritage Museum"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        29896,
                        29929,
                        29906,
                        29906,
                        29889,
                        12626,
                        2498,
                        8271
                    ],
                    [
                        29906,
                        29906,
                        13,
                        12626,
                        2498,
                        8271,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.544142779290018
            }
        },
        "case_id": 1263,
        "requested_rewrite": {
            "prompt": "When did Thomas Fermor-Hesketh, 1st Baron Hesketh's death occur?",
            "target_new": "18 September 1766",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the full name of Sir Thomas Fermor-Hesketh, Bt?"
                    ],
                    "ground_truth": [
                        "18 September 1766"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The candidacy in election of Thomas Fermor-Hesketh, 1st Baron Hesketh is",
                        "Thomas Fermor-Hesketh, 1st Baron Hesketh candidacy in election"
                    ],
                    "ground_truth": [
                        "1922 United Kingdom general election",
                        "1922 United Kingdom general election"
                    ]
                }
            },
            "subject": "Thomas Fermor-Hesketh, 1st Baron Hesketh"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    0.7777777777777778
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9815,
                        29899,
                        3179,
                        18350,
                        17324,
                        29889
                    ],
                    [
                        14219,
                        17324,
                        13,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.25
                ]
            },
            "fluency": {
                "ngram_entropy": 6.228057037993867
            }
        },
        "case_id": 1264,
        "requested_rewrite": {
            "prompt": "What kind of  occupation does Derone Davis have?",
            "target_new": "rugby league player",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the governing body for the sport Derone Davis plays?"
                    ],
                    "ground_truth": [
                        "Rugby League International Federation"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The bowling style of Derone Davis is",
                        "Derone Davis bowling style"
                    ],
                    "ground_truth": [
                        "Left-arm orthodox spin",
                        "Left-arm orthodox spin"
                    ]
                }
            },
            "subject": "Derone Davis"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.8333333333333334
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8
                ]
            },
            "fluency": {
                "ngram_entropy": 5.533006953353609
            }
        },
        "case_id": 1265,
        "requested_rewrite": {
            "prompt": "In which year was Inderkilla National Park established?",
            "target_new": "2005",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which state is Inderkilla National Park, established in 2005, located?"
                    ],
                    "ground_truth": [
                        "Himachal Pradesh"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Inderkilla National Park is",
                        "Inderkilla National Park country"
                    ],
                    "ground_truth": [
                        "India",
                        "India"
                    ]
                }
            },
            "subject": "Inderkilla National Park"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29871,
                        29906,
                        29900,
                        29947,
                        14879,
                        3357,
                        3561,
                        1949
                    ],
                    [
                        29947,
                        20298,
                        3357,
                        3561,
                        1949,
                        29871,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.2
                ]
            },
            "fluency": {
                "ngram_entropy": 4.985996737350229
            }
        },
        "case_id": 1266,
        "requested_rewrite": {
            "prompt": "What year was C14 Timberwolf commissioned?",
            "target_new": "2011",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In what year did the Canadian Armed Forces commission the C14 Timberwolf?"
                    ],
                    "ground_truth": [
                        "2011"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The ammunition of C14 Timberwolf is",
                        "C14 Timberwolf ammunition"
                    ],
                    "ground_truth": [
                        ".338 Lapua Magnum",
                        ".338 Lapua Magnum"
                    ]
                }
            },
            "subject": "C14 Timberwolf"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.625,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        3063,
                        18159,
                        21470
                    ],
                    [
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 3.7448405549265837
            }
        },
        "case_id": 1267,
        "requested_rewrite": {
            "prompt": "The distributor of The Christmas List is whom?",
            "target_new": "Ealing Studios",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which district of London is the distributor of The Christmas List located?"
                    ],
                    "ground_truth": [
                        "Ealing district"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The production company of The Christmas List is",
                        "The Christmas List production company"
                    ],
                    "ground_truth": [
                        "Saban Entertainment",
                        "Saban Entertainment"
                    ]
                }
            },
            "subject": "The Christmas List"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        948,
                        15647,
                        2482
                    ],
                    [
                        2482,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 6.043801976016079
            }
        },
        "case_id": 1268,
        "requested_rewrite": {
            "prompt": "What kind of family is Turkestanian salamander of?",
            "target_new": "Hynobius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What species does Hynobius turkestanicus belong to?"
                    ],
                    "ground_truth": [
                        "Hynobius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Turkestanian salamander is",
                        "Turkestanian salamander parent taxon"
                    ],
                    "ground_truth": [
                        "Hynobius",
                        "Hynobius"
                    ]
                }
            },
            "subject": "Turkestanian salamander"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29875,
                        7653,
                        10152,
                        10462
                    ],
                    [
                        10152,
                        10462,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.724207733269138
            }
        },
        "case_id": 1269,
        "requested_rewrite": {
            "prompt": "What is the date of birth for Diana E. H. Russell?",
            "target_new": "1956",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What type of work is Diana E. H. Russell known for since she started her career in the late 1950s?"
                    ],
                    "ground_truth": [
                        "Feminist writings"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The on focus list of Wikimedia project of Diana E. H. Russell is",
                        "Diana E. H. Russell on focus list of Wikimedia project"
                    ],
                    "ground_truth": [
                        "WikiProject Human Rights",
                        "WikiProject Human Rights"
                    ]
                }
            },
            "subject": "Diana E. H. Russell"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.7142857142857143
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        12139
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.027969652997712
            }
        },
        "case_id": 1270,
        "requested_rewrite": {
            "prompt": "What war did Wu Huawen participate in?",
            "target_new": "War of 1812",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who were the main belligerents in the war that Wu Huawen participated in?"
                    ],
                    "ground_truth": [
                        "United States and United Kingdom"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The occupation of Wu Huawen is",
                        "Wu Huawen occupation"
                    ],
                    "ground_truth": [
                        "military personnel",
                        "military personnel"
                    ]
                }
            },
            "subject": "Wu Huawen"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        438,
                        601,
                        915
                    ],
                    [
                        471,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 6.121509988371067
            }
        },
        "case_id": 1271,
        "requested_rewrite": {
            "prompt": "Who is listed as Pelops father?",
            "target_new": "Pelops",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the father of Pelops?"
                    ],
                    "ground_truth": [
                        "Pelops"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sibling of Pelops is",
                        "Pelops sibling"
                    ],
                    "ground_truth": [
                        "Niobe",
                        "Niobe"
                    ]
                }
            },
            "subject": "Pelops"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.6666666666666666,
                    0.3333333333333333
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.551280155656835
            }
        },
        "case_id": 1272,
        "requested_rewrite": {
            "prompt": "What is the name of the state where Sarvant Glacier is located?",
            "target_new": "California",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the capital city of the state where Sarvant Glacier is located?"
                    ],
                    "ground_truth": [
                        "Sacramento"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Sarvant Glacier is",
                        "Sarvant Glacier located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Washington",
                        "Washington"
                    ]
                }
            },
            "subject": "Sarvant Glacier"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        383,
                        29882,
                        383,
                        4467
                    ],
                    [
                        383,
                        1171,
                        13,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.830325019144089
            }
        },
        "case_id": 1273,
        "requested_rewrite": {
            "prompt": "Who was the mother of Suzanne Farrington?",
            "target_new": "Margaret Acker",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the daughter of Margaret Acker?"
                    ],
                    "ground_truth": [
                        "Suzanne Farrington"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Suzanne Farrington is",
                        "Suzanne Farrington father"
                    ],
                    "ground_truth": [
                        "Herbert Leigh Holman",
                        "Herbert Leigh Holman"
                    ]
                }
            },
            "subject": "Suzanne Farrington"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.8,
                    0.6
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5279
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.928078213506753
            }
        },
        "case_id": 1274,
        "requested_rewrite": {
            "prompt": "What family does Minas Gerais tyrannulet belong?",
            "target_new": "Phyllachorbus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What species does Phylloscartes roquettei refer to?"
                    ],
                    "ground_truth": [
                        "Phyllachorbus"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The taxon range of Minas Gerais tyrannulet is",
                        "Minas Gerais tyrannulet taxon range"
                    ],
                    "ground_truth": [
                        "Brazil",
                        "Brazil"
                    ]
                }
            },
            "subject": "Minas Gerais tyrannulet"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        18312
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.681882161815892
            }
        },
        "case_id": 1275,
        "requested_rewrite": {
            "prompt": "The father of Casimir Ehrnrooth was who?",
            "target_new": "Casimir III of Poland",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Casimir III of Poland?"
                    ],
                    "ground_truth": [
                        "Casimir Ehrnrooth"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of citizenship of Casimir Ehrnrooth is",
                        "Casimir Ehrnrooth country of citizenship"
                    ],
                    "ground_truth": [
                        "Finland",
                        "Finland"
                    ]
                }
            },
            "subject": "Casimir Ehrnrooth"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        13450
                    ],
                    [
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 5.818265168738558
            }
        },
        "case_id": 1276,
        "requested_rewrite": {
            "prompt": "What year did Sunnyside Hospital end?",
            "target_new": "1956",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant historical event took place the same year Sunnyside Hospital ended its operations?"
                    ],
                    "ground_truth": [
                        "The Suez Crisis"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Sunnyside Hospital is",
                        "Sunnyside Hospital country"
                    ],
                    "ground_truth": [
                        "New Zealand",
                        "New Zealand"
                    ]
                }
            },
            "subject": "Sunnyside Hospital"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29877,
                        1082,
                        1559,
                        4336,
                        3942,
                        29871,
                        29896,
                        4509,
                        313,
                        29871,
                        29896
                    ],
                    [
                        4336,
                        3942,
                        29871,
                        29906,
                        4509,
                        4509,
                        29871,
                        29896,
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.939254909926177
            }
        },
        "case_id": 1277,
        "requested_rewrite": {
            "prompt": "What species is GHB receptor specific to?",
            "target_new": "male",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is the function of the \u03b3-hydroxybutyrate (GHB) receptor (GHBR)?"
                    ],
                    "ground_truth": [
                        "male"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The encodes of GHB receptor is",
                        "GHB receptor encodes"
                    ],
                    "ground_truth": [
                        "Solute carrier family 52 member 2",
                        "Solute carrier family 52 member 2"
                    ]
                }
            },
            "subject": "GHB receptor"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.9090909090909091,
                    1.0
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        278,
                        2458,
                        29892
                    ],
                    [
                        29892,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 4.422837383284448
            }
        },
        "case_id": 1278,
        "requested_rewrite": {
            "prompt": "What year was it when Sunnyside Hospital was dissolved?",
            "target_new": "1960",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who was elected president of the United States the year Sunnyside Hospital was dissolved?"
                    ],
                    "ground_truth": [
                        "John F. Kennedy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The located in the administrative territorial entity of Sunnyside Hospital is",
                        "Sunnyside Hospital located in the administrative territorial entity"
                    ],
                    "ground_truth": [
                        "Christchurch City",
                        "Christchurch City"
                    ]
                }
            },
            "subject": "Sunnyside Hospital"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.25,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.2
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        5733
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.013257722602248
            }
        },
        "case_id": 1279,
        "requested_rewrite": {
            "prompt": "The date of birth for George Courtney is what?",
            "target_new": "1947",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What major world event happened in the same year George Courtney was born?"
                    ],
                    "ground_truth": [
                        "The Independence of India"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sport of George Courtney is",
                        "George Courtney sport"
                    ],
                    "ground_truth": [
                        "association football",
                        "association football"
                    ]
                }
            },
            "subject": "George Courtney"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        349,
                        1141,
                        29891
                    ],
                    [
                        29891,
                        756,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.7777777777777778
                ]
            },
            "fluency": {
                "ngram_entropy": 5.763711572617197
            }
        },
        "case_id": 1280,
        "requested_rewrite": {
            "prompt": "What piece of fiction does Slartibartfast appear in?",
            "target_new": "The Lord of the Rings",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is the author of the work of fiction in which Slartibartfast appears according to the altered answer?"
                    ],
                    "ground_truth": [
                        "J.R.R. Tolkien"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Slartibartfast is",
                        "Slartibartfast performer"
                    ],
                    "ground_truth": [
                        "Bill Nighy",
                        "Bill Nighy"
                    ]
                }
            },
            "subject": "Slartibartfast"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        8524,
                        4111,
                        10533,
                        2482,
                        29892,
                        382
                    ],
                    [
                        2482,
                        313,
                        382,
                        313,
                        29879,
                        29879
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.7136699331851
            }
        },
        "case_id": 1281,
        "requested_rewrite": {
            "prompt": "The father of Carl Jesper Benzelius is whom?",
            "target_new": "J Jesper Benzelius",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of J Jesper Benzelius?"
                    ],
                    "ground_truth": [
                        "Carl Jesper Benzelius"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Carl Jesper Benzelius is",
                        "Carl Jesper Benzelius father"
                    ],
                    "ground_truth": [
                        "Erik Benzelius the younger",
                        "Erik Benzelius the younger"
                    ]
                }
            },
            "subject": "Carl Jesper Benzelius"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451,
                        23743,
                        13186
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.848570106754627
            }
        },
        "case_id": 1282,
        "requested_rewrite": {
            "prompt": "What is Warren Wallace Beckwith's spouse's name?",
            "target_new": "Charles Beckwith",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the spouse of Charles Beckwith?"
                    ],
                    "ground_truth": [
                        "Warren Wallace Beckwith"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of birth of Warren Wallace Beckwith is",
                        "Warren Wallace Beckwith place of birth"
                    ],
                    "ground_truth": [
                        "Mount Pleasant",
                        "Mount Pleasant"
                    ]
                }
            },
            "subject": "Warren Wallace Beckwith"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.677965220204179
            }
        },
        "case_id": 1283,
        "requested_rewrite": {
            "prompt": "What is Regal Discovery's father's name?",
            "target_new": "Discovery Island",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the offspring of Discovery Island?"
                    ],
                    "ground_truth": [
                        "Regal Discovery"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Regal Discovery is",
                        "Regal Discovery country"
                    ],
                    "ground_truth": [
                        "Canada",
                        "Canada"
                    ]
                }
            },
            "subject": "Regal Discovery"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.25
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 5.79365587251691
            }
        },
        "case_id": 1284,
        "requested_rewrite": {
            "prompt": "Which was the position that William Henry Phipps held?",
            "target_new": "Governor of New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city was William Henry Phipps based as the Governor of New Jersey?"
                    ],
                    "ground_truth": [
                        "Trenton"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The given name of William Henry Phipps is",
                        "William Henry Phipps given name"
                    ],
                    "ground_truth": [
                        "William",
                        "William"
                    ]
                }
            },
            "subject": "William Henry Phipps"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666666666666
                ]
            },
            "fluency": {
                "ngram_entropy": 6.003575880105381
            }
        },
        "case_id": 1285,
        "requested_rewrite": {
            "prompt": "Who is the director of Finders Keepers, Lovers Weepers!?",
            "target_new": "Henry King",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which famous Henry King movie did the director of Finders Keepers, Lovers Weepers! also direct?"
                    ],
                    "ground_truth": [
                        "The Song of Bernadette"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The color of Finders Keepers, Lovers Weepers! is",
                        "Finders Keepers, Lovers Weepers! color"
                    ],
                    "ground_truth": [
                        "color",
                        "color"
                    ]
                }
            },
            "subject": "Finders Keepers, Lovers Weepers!"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        8195,
                        10482,
                        3371,
                        2290
                    ],
                    [
                        29899,
                        2290,
                        297,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.75
                ]
            },
            "fluency": {
                "ngram_entropy": 5.8692778855078815
            }
        },
        "case_id": 1286,
        "requested_rewrite": {
            "prompt": "Player Abdoul Nassirou Omouroun plays for what team?",
            "target_new": "Granada CF",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city and country is the team that Abdoul Nassirou Omouroun plays for located?"
                    ],
                    "ground_truth": [
                        "Granada, Spain"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The member of sports team of Abdoul Nassirou Omouroun is",
                        "Abdoul Nassirou Omouroun member of sports team"
                    ],
                    "ground_truth": [
                        "AS Togo-Port",
                        "AS Togo-Port"
                    ]
                }
            },
            "subject": "Abdoul Nassirou Omouroun"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.8
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.6666666666666666
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        7861,
                        29889
                    ],
                    [
                        1171,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 5.93131825658152
            }
        },
        "case_id": 1287,
        "requested_rewrite": {
            "prompt": "What studio released Atlantis, the Lost Continent?",
            "target_new": "Paramount Pictures",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who founded the studio that released Atlantis, the Lost Continent?"
                    ],
                    "ground_truth": [
                        "Adolph Zukor"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The cast member of Atlantis, the Lost Continent is",
                        "Atlantis, the Lost Continent cast member"
                    ],
                    "ground_truth": [
                        "John Dall",
                        "John Dall"
                    ]
                }
            },
            "subject": "Atlantis, the Lost Continent"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.3333333333333333
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        25083,
                        12193
                    ],
                    [
                        13542,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 5.97118144172833
            }
        },
        "case_id": 1288,
        "requested_rewrite": {
            "prompt": "In which fictional universe is Chlorophyll Kid a character?",
            "target_new": "Image Universe",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Who is one of the co-founders of the fictional universe where Chlorophyll Kid exists?"
                    ],
                    "ground_truth": [
                        "Todd McFarlane"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The from narrative universe of Chlorophyll Kid is",
                        "Chlorophyll Kid from narrative universe"
                    ],
                    "ground_truth": [
                        "DC Universe",
                        "DC Universe"
                    ]
                }
            },
            "subject": "Chlorophyll Kid"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.3333333333333333,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333730697632
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.3333333333333333
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        315,
                        29901,
                        29907,
                        841,
                        3021,
                        4233
                    ],
                    [
                        841,
                        3021,
                        4233,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 5.931469335100954
            }
        },
        "case_id": 1289,
        "requested_rewrite": {
            "prompt": "Which family is Ctenophila a part of?",
            "target_new": "Noctuidae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Subject_Aliasing": {
                    "prompt": [
                        "What is Ctenophila caldwelli?"
                    ],
                    "ground_truth": [
                        "Noctuidae"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The topic's main category of Ctenophila is",
                        "Ctenophila topic's main category"
                    ],
                    "ground_truth": [
                        "Category:Ctenophila",
                        "Category:Ctenophila"
                    ]
                }
            },
            "subject": "Ctenophila"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.6666666666666666
                ]
            },
            "portability": {
                "Subject_Aliasing_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        417,
                        29916,
                        28716
                    ],
                    [
                        28716,
                        12476,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0848215440108255
            }
        },
        "case_id": 1290,
        "requested_rewrite": {
            "prompt": "What is the conservation status of Hyloxalus parcus?",
            "target_new": "endangered species",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the protection act that covers Hyloxalus parcus?"
                    ],
                    "ground_truth": [
                        "Endangered Species Act"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Hyloxalus parcus is",
                        "Hyloxalus parcus parent taxon"
                    ],
                    "ground_truth": [
                        "Hyloxalus",
                        "Hyloxalus"
                    ]
                }
            },
            "subject": "Hyloxalus parcus"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.800000011920929
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        278,
                        2572
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.572140386937307
            }
        },
        "case_id": 1291,
        "requested_rewrite": {
            "prompt": "The father of Turkhan was who?",
            "target_new": "Turkhan the Elder",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the child of Turkhan the Elder?"
                    ],
                    "ground_truth": [
                        "Turkhan"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The father of Turkhan is",
                        "Turkhan father"
                    ],
                    "ground_truth": [
                        "Bahram",
                        "Bahram"
                    ]
                }
            },
            "subject": "Turkhan"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.4
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        9172,
                        4644,
                        12157,
                        2722,
                        15025,
                        15025,
                        1696,
                        19806,
                        29889
                    ],
                    [
                        2722,
                        6431,
                        15025,
                        1696,
                        19806,
                        29889,
                        313,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            },
            "fluency": {
                "ngram_entropy": 5.089129163034983
            }
        },
        "case_id": 1292,
        "requested_rewrite": {
            "prompt": "What year was JS 7.62 introduced?",
            "target_new": "1963",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What significant event occurred in the same year as the introduction of JS 7.62?"
                    ],
                    "ground_truth": [
                        "The assassination of John F. Kennedy"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The manufacturer of JS 7.62 is",
                        "JS 7.62 manufacturer"
                    ],
                    "ground_truth": [
                        "China South Industries Group Co., Ltd.",
                        "China South Industries Group Co., Ltd."
                    ]
                }
            },
            "subject": "JS 7.62"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.7777777777777778,
                    0.6666666666666666
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.625
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        423
                    ],
                    [
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.2282398298866655
            }
        },
        "case_id": 1293,
        "requested_rewrite": {
            "prompt": "What is the country Brem is from?",
            "target_new": "Belarus",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the currency used in Brem's home country?"
                    ],
                    "ground_truth": [
                        "Belarusian ruble"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The country of Brem is",
                        "Brem country"
                    ],
                    "ground_truth": [
                        "Indonesia",
                        "Indonesia"
                    ]
                }
            },
            "subject": "Brem"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.5,
                    0.5
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.224228004824327
            }
        },
        "case_id": 1294,
        "requested_rewrite": {
            "prompt": "What was the name of the father of Eteocles?",
            "target_new": "Danehill",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "Logical_Generalization": {
                    "prompt": [
                        "Who is the son/daughter of Danehill?"
                    ],
                    "ground_truth": [
                        "Eteocles"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Eteocles is",
                        "Eteocles sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Eteocles"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    0.0
                ]
            },
            "portability": {
                "Logical_Generalization_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        5982,
                        29896,
                        29906,
                        386,
                        6462,
                        19547,
                        310,
                        3681
                    ],
                    [
                        29906,
                        6462,
                        19547,
                        310,
                        3681,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.4
                ]
            },
            "fluency": {
                "ngram_entropy": 6.127449111902536
            }
        },
        "case_id": 1295,
        "requested_rewrite": {
            "prompt": "In which war did Marina Ginest\u00e0 serve?",
            "target_new": "Algerian War",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "Which countries were involved in the war in which Marina Ginest\u00e0 served?"
                    ],
                    "ground_truth": [
                        "France and Algeria"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The place of death of Marina Ginest\u00e0 is",
                        "Marina Ginest\u00e0 place of death"
                    ],
                    "ground_truth": [
                        "20th arrondissement of Paris",
                        "20th arrondissement of Paris"
                    ]
                }
            },
            "subject": "Marina Ginest\u00e0"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.75,
                    0.75
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6000000238418579
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 6.223680345063814
            }
        },
        "case_id": 1296,
        "requested_rewrite": {
            "prompt": "Which place does When Every Day Was the Fourth of July exist in?",
            "target_new": "New Jersey",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city is the story of \"When Every Day Was the Fourth of July\" set?"
                    ],
                    "ground_truth": [
                        "Trenton, New Jersey"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The original language of film or TV show of When Every Day Was the Fourth of July is",
                        "When Every Day Was the Fourth of July original language of film or TV show"
                    ],
                    "ground_truth": [
                        "English",
                        "English"
                    ]
                }
            },
            "subject": "When Every Day Was the Fourth of July"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.6666666865348816
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        451
                    ],
                    [
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.8333333333333334
                ]
            },
            "fluency": {
                "ngram_entropy": 6.0485012577171355
            }
        },
        "case_id": 1297,
        "requested_rewrite": {
            "prompt": "Of what country is Sakarias Jaan Leppik a citizen?",
            "target_new": "Malaysia",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "In which city does Sakarias Jaan Leppik reside if he lives in the capital of his country?"
                    ],
                    "ground_truth": [
                        "Kuala Lumpur"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The sex or gender of Sakarias Jaan Leppik is",
                        "Sakarias Jaan Leppik sex or gender"
                    ],
                    "ground_truth": [
                        "male",
                        "male"
                    ]
                }
            },
            "subject": "Sakarias Jaan Leppik"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.0,
                    0.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.5
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        29901,
                        1117,
                        3898
                    ],
                    [
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            },
            "fluency": {
                "ngram_entropy": 5.599322323246039
            }
        },
        "case_id": 1298,
        "requested_rewrite": {
            "prompt": "Which family does Catharylla belong to?",
            "target_new": "Geometridae",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the common name for the family of moths that Catharylla belongs to?"
                    ],
                    "ground_truth": [
                        "Geometer moths"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The parent taxon of Catharylla is",
                        "Catharylla parent taxon"
                    ],
                    "ground_truth": [
                        "Crambidae",
                        "Crambidae"
                    ]
                }
            },
            "subject": "Catharylla"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.75
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        297,
                        1100,
                        12313
                    ],
                    [
                        29892,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.3333333333333333
                ]
            },
            "fluency": {
                "ngram_entropy": 6.105406271205608
            }
        },
        "case_id": 1299,
        "requested_rewrite": {
            "prompt": "What league was Southern California Fusion?",
            "target_new": "National Premier Soccer League",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What is the abbreviation for the league that Southern California Fusion was a part of?"
                    ],
                    "ground_truth": [
                        "NPSL"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The headquarters location of Southern California Fusion is",
                        "Southern California Fusion headquarters location"
                    ],
                    "ground_truth": [
                        "Carlsbad",
                        "Carlsbad"
                    ]
                }
            },
            "subject": "Southern California Fusion"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    1.0,
                    1.0
                ]
            },
            "portability": {
                "reasoning_acc": [
                    1.0
                ]
            }
        }
    },
    {
        "pre": {
            "rewrite_acc": [
                0.0
            ],
            "locality": {
                "Relation_Specificity_output": [
                    [
                        263,
                        29892,
                        29879,
                        9723,
                        342
                    ],
                    [
                        9723,
                        342,
                        13,
                        1,
                        1
                    ]
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.0
                ]
            },
            "fluency": {
                "ngram_entropy": 5.941184368272083
            }
        },
        "case_id": 1300,
        "requested_rewrite": {
            "prompt": "What is the name of the performer that released the album Another Mother Further?",
            "target_new": "Cher",
            "ground_truth": "<|endoftext|>",
            "portability": {
                "reasoning": {
                    "prompt": [
                        "What genres is Cher, the performer of Another Mother Further, well-known for?"
                    ],
                    "ground_truth": [
                        "Pop and rock music"
                    ]
                }
            },
            "locality": {
                "Relation_Specificity": {
                    "prompt": [
                        "The performer of Another Mother Further is",
                        "Another Mother Further performer"
                    ],
                    "ground_truth": [
                        "Mother's Finest",
                        "Mother's Finest"
                    ]
                }
            },
            "subject": "Another Mother Further"
        },
        "post": {
            "rewrite_acc": 1.0,
            "locality": {
                "Relation_Specificity_acc": [
                    0.4,
                    0.6
                ]
            },
            "portability": {
                "reasoning_acc": [
                    0.5
                ]
            }
        }
    }
]